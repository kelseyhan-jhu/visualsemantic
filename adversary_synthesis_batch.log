/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.579553 Content Loss: 0.003374

run [100]:
Style Loss : 0.822290 Content Loss: 0.006636

run [150]:
Style Loss : 0.637154 Content Loss: 0.008263

run [200]:
Style Loss : 0.539513 Content Loss: 0.009360

run [250]:
Style Loss : 0.476377 Content Loss: 0.010246

run [300]:
Style Loss : 0.429454 Content Loss: 0.011012

run [350]:
Style Loss : 0.395862 Content Loss: 0.011723

run [400]:
Style Loss : 0.369523 Content Loss: 0.012382

run [450]:
Style Loss : 0.350448 Content Loss: 0.012947

run [500]:
Style Loss : 0.335174 Content Loss: 0.013455

run [550]:
Style Loss : 0.322974 Content Loss: 0.013922

run [600]:
Style Loss : 0.313494 Content Loss: 0.014301

run [650]:
Style Loss : 0.305176 Content Loss: 0.014630

run [700]:
Style Loss : 0.298630 Content Loss: 0.014893

run [750]:
Style Loss : 0.293108 Content Loss: 0.015161

run [800]:
Style Loss : 0.288156 Content Loss: 0.015367

run [850]:
Style Loss : 0.283889 Content Loss: 0.015559

run [900]:
Style Loss : 0.279983 Content Loss: 0.015723

run [950]:
Style Loss : 0.276514 Content Loss: 0.015896

run [1000]:
Style Loss : 0.273417 Content Loss: 0.016036

run [1050]:
Style Loss : 0.270672 Content Loss: 0.016189

run [1100]:
Style Loss : 0.268195 Content Loss: 0.016331

run [1150]:
Style Loss : 0.265995 Content Loss: 0.016462

run [1200]:
Style Loss : 0.263997 Content Loss: 0.016575

run [1250]:
Style Loss : 0.262119 Content Loss: 0.016683

run [1300]:
Style Loss : 0.260399 Content Loss: 0.016781

run [1350]:
Style Loss : 0.258777 Content Loss: 0.016873

run [1400]:
Style Loss : 0.257335 Content Loss: 0.016957

run [1450]:
Style Loss : 0.255957 Content Loss: 0.017049

run [1500]:
Style Loss : 0.254692 Content Loss: 0.017129

run [1550]:
Style Loss : 0.253534 Content Loss: 0.017204

run [1600]:
Style Loss : 0.252425 Content Loss: 0.017278

run [1650]:
Style Loss : 0.251349 Content Loss: 0.017343

run [1700]:
Style Loss : 0.250373 Content Loss: 0.017407

run [1750]:
Style Loss : 0.249412 Content Loss: 0.017474

run [1800]:
Style Loss : 0.248479 Content Loss: 0.017538

run [1850]:
Style Loss : 0.247649 Content Loss: 0.017594

run [1900]:
Style Loss : 0.246854 Content Loss: 0.017660

run [1950]:
Style Loss : 0.246113 Content Loss: 0.017709

run [2000]:
Style Loss : 0.245447 Content Loss: 0.017761

run [2050]:
Style Loss : 0.244754 Content Loss: 0.017807

run [2100]:
Style Loss : 0.244113 Content Loss: 0.017854

run [2150]:
Style Loss : 0.243432 Content Loss: 0.017901

run [2200]:
Style Loss : 0.242859 Content Loss: 0.017948

run [2250]:
Style Loss : 0.242369 Content Loss: 0.017988

run [2300]:
Style Loss : 0.241894 Content Loss: 0.018027

run [2350]:
Style Loss : 0.241468 Content Loss: 0.018059

run [2400]:
Style Loss : 0.241070 Content Loss: 0.018092

run [2450]:
Style Loss : 0.240695 Content Loss: 0.018121

run [2500]:
Style Loss : 0.240336 Content Loss: 0.018150

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.926858 Content Loss: 0.004120

run [100]:
Style Loss : 0.954874 Content Loss: 0.007763

run [150]:
Style Loss : 0.691999 Content Loss: 0.009586

run [200]:
Style Loss : 0.561980 Content Loss: 0.010713

run [250]:
Style Loss : 0.489804 Content Loss: 0.011628

run [300]:
Style Loss : 0.440140 Content Loss: 0.012567

run [350]:
Style Loss : 0.402103 Content Loss: 0.013439

run [400]:
Style Loss : 0.371093 Content Loss: 0.014210

run [450]:
Style Loss : 0.346386 Content Loss: 0.014966

run [500]:
Style Loss : 0.325533 Content Loss: 0.015596

run [550]:
Style Loss : 0.308275 Content Loss: 0.016163

run [600]:
Style Loss : 0.294236 Content Loss: 0.016570

run [650]:
Style Loss : 0.282428 Content Loss: 0.016944

run [700]:
Style Loss : 0.272264 Content Loss: 0.017248

run [750]:
Style Loss : 0.263830 Content Loss: 0.017512

run [800]:
Style Loss : 0.256340 Content Loss: 0.017808

run [850]:
Style Loss : 0.249507 Content Loss: 0.018051

run [900]:
Style Loss : 0.243521 Content Loss: 0.018240

run [950]:
Style Loss : 0.237716 Content Loss: 0.018448

run [1000]:
Style Loss : 0.231805 Content Loss: 0.018649

run [1050]:
Style Loss : 0.226078 Content Loss: 0.018825

run [1100]:
Style Loss : 0.220617 Content Loss: 0.019018

run [1150]:
Style Loss : 0.216147 Content Loss: 0.019193

run [1200]:
Style Loss : 0.212052 Content Loss: 0.019382

run [1250]:
Style Loss : 0.208102 Content Loss: 0.019562

run [1300]:
Style Loss : 0.204528 Content Loss: 0.019744

run [1350]:
Style Loss : 0.201326 Content Loss: 0.019902

run [1400]:
Style Loss : 0.198282 Content Loss: 0.020082

run [1450]:
Style Loss : 0.195417 Content Loss: 0.020265

run [1500]:
Style Loss : 0.192573 Content Loss: 0.020462

run [1550]:
Style Loss : 0.189758 Content Loss: 0.020644

run [1600]:
Style Loss : 0.187007 Content Loss: 0.020841

run [1650]:
Style Loss : 0.184331 Content Loss: 0.021025

run [1700]:
Style Loss : 0.181857 Content Loss: 0.021197

run [1750]:
Style Loss : 0.179502 Content Loss: 0.021396

run [1800]:
Style Loss : 0.177258 Content Loss: 0.021564

run [1850]:
Style Loss : 0.174694 Content Loss: 0.021774

run [1900]:
Style Loss : 0.172259 Content Loss: 0.021995

run [1950]:
Style Loss : 0.169535 Content Loss: 0.022227

run [2000]:
Style Loss : 0.166893 Content Loss: 0.022453

run [2050]:
Style Loss : 0.164538 Content Loss: 0.022669

run [2100]:
Style Loss : 0.162245 Content Loss: 0.022881

run [2150]:
Style Loss : 0.160010 Content Loss: 0.023091

run [2200]:
Style Loss : 0.157991 Content Loss: 0.023309

run [2250]:
Style Loss : 0.156078 Content Loss: 0.023482

run [2300]:
Style Loss : 0.154283 Content Loss: 0.023687

run [2350]:
Style Loss : 0.152464 Content Loss: 0.023836

run [2400]:
Style Loss : 0.150809 Content Loss: 0.024007

run [2450]:
Style Loss : 0.149171 Content Loss: 0.024198

run [2500]:
Style Loss : 0.147470 Content Loss: 0.024370

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.852930 Content Loss: 0.004863

run [100]:
Style Loss : 1.437365 Content Loss: 0.008540

run [150]:
Style Loss : 1.003592 Content Loss: 0.010164

run [200]:
Style Loss : 0.812348 Content Loss: 0.011438

run [250]:
Style Loss : 0.696770 Content Loss: 0.012079

run [300]:
Style Loss : 0.626669 Content Loss: 0.012695

run [350]:
Style Loss : 0.576454 Content Loss: 0.013144

run [400]:
Style Loss : 0.541050 Content Loss: 0.013612

run [450]:
Style Loss : 0.510835 Content Loss: 0.014040

run [500]:
Style Loss : 0.486752 Content Loss: 0.014405

run [550]:
Style Loss : 0.467222 Content Loss: 0.014705

run [600]:
Style Loss : 0.451457 Content Loss: 0.015001

run [650]:
Style Loss : 0.437290 Content Loss: 0.015269

run [700]:
Style Loss : 0.424775 Content Loss: 0.015519

run [750]:
Style Loss : 0.413646 Content Loss: 0.015783

run [800]:
Style Loss : 0.403232 Content Loss: 0.016036

run [850]:
Style Loss : 0.394511 Content Loss: 0.016237

run [900]:
Style Loss : 0.386811 Content Loss: 0.016429

run [950]:
Style Loss : 0.380345 Content Loss: 0.016603

run [1000]:
Style Loss : 0.374535 Content Loss: 0.016762

run [1050]:
Style Loss : 0.369068 Content Loss: 0.016923

run [1100]:
Style Loss : 0.364125 Content Loss: 0.017099

run [1150]:
Style Loss : 0.359246 Content Loss: 0.017240

run [1200]:
Style Loss : 0.355009 Content Loss: 0.017379

run [1250]:
Style Loss : 0.351141 Content Loss: 0.017504

run [1300]:
Style Loss : 0.347305 Content Loss: 0.017631

run [1350]:
Style Loss : 0.343521 Content Loss: 0.017763

run [1400]:
Style Loss : 0.339865 Content Loss: 0.017892

run [1450]:
Style Loss : 0.336512 Content Loss: 0.018004

run [1500]:
Style Loss : 0.333435 Content Loss: 0.018105

run [1550]:
Style Loss : 0.330532 Content Loss: 0.018196

run [1600]:
Style Loss : 0.327659 Content Loss: 0.018289

run [1650]:
Style Loss : 0.324334 Content Loss: 0.018402

run [1700]:
Style Loss : 0.321167 Content Loss: 0.018516

run [1750]:
Style Loss : 0.317938 Content Loss: 0.018629

run [1800]:
Style Loss : 0.314773 Content Loss: 0.018731

run [1850]:
Style Loss : 0.311730 Content Loss: 0.018834

run [1900]:
Style Loss : 0.308817 Content Loss: 0.018945

run [1950]:
Style Loss : 0.306064 Content Loss: 0.019062

run [2000]:
Style Loss : 0.303394 Content Loss: 0.019176

run [2050]:
Style Loss : 0.300843 Content Loss: 0.019300

run [2100]:
Style Loss : 0.298374 Content Loss: 0.019417

run [2150]:
Style Loss : 0.295999 Content Loss: 0.019541

run [2200]:
Style Loss : 0.293588 Content Loss: 0.019681

run [2250]:
Style Loss : 0.291222 Content Loss: 0.019824

run [2300]:
Style Loss : 0.288827 Content Loss: 0.019975

run [2350]:
Style Loss : 0.286449 Content Loss: 0.020131

run [2400]:
Style Loss : 0.284059 Content Loss: 0.020314

run [2450]:
Style Loss : 0.281609 Content Loss: 0.020491

run [2500]:
Style Loss : 0.279235 Content Loss: 0.020674

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.656493 Content Loss: 0.008297

run [100]:
Style Loss : 0.401061 Content Loss: 0.011291

run [150]:
Style Loss : 0.324328 Content Loss: 0.012802

run [200]:
Style Loss : 0.284201 Content Loss: 0.013774

run [250]:
Style Loss : 0.259200 Content Loss: 0.014614

run [300]:
Style Loss : 0.242547 Content Loss: 0.015266

run [350]:
Style Loss : 0.230494 Content Loss: 0.015886

run [400]:
Style Loss : 0.221759 Content Loss: 0.016344

run [450]:
Style Loss : 0.214505 Content Loss: 0.016787

run [500]:
Style Loss : 0.208485 Content Loss: 0.017152

run [550]:
Style Loss : 0.202854 Content Loss: 0.017498

run [600]:
Style Loss : 0.198388 Content Loss: 0.017767

run [650]:
Style Loss : 0.194746 Content Loss: 0.018012

run [700]:
Style Loss : 0.191517 Content Loss: 0.018221

run [750]:
Style Loss : 0.188878 Content Loss: 0.018403

run [800]:
Style Loss : 0.186721 Content Loss: 0.018561

run [850]:
Style Loss : 0.184789 Content Loss: 0.018691

run [900]:
Style Loss : 0.183244 Content Loss: 0.018811

run [950]:
Style Loss : 0.181921 Content Loss: 0.018901

run [1000]:
Style Loss : 0.180762 Content Loss: 0.018977

run [1050]:
Style Loss : 0.179836 Content Loss: 0.019028

run [1100]:
Style Loss : 0.179015 Content Loss: 0.019086

run [1150]:
Style Loss : 0.178241 Content Loss: 0.019130

run [1200]:
Style Loss : 0.177477 Content Loss: 0.019172

run [1250]:
Style Loss : 0.176811 Content Loss: 0.019200

run [1300]:
Style Loss : 0.176220 Content Loss: 0.019236

run [1350]:
Style Loss : 0.175652 Content Loss: 0.019265

run [1400]:
Style Loss : 0.175078 Content Loss: 0.019285

run [1450]:
Style Loss : 0.174601 Content Loss: 0.019304

run [1500]:
Style Loss : 0.174175 Content Loss: 0.019315

run [1550]:
Style Loss : 0.173781 Content Loss: 0.019322

run [1600]:
Style Loss : 0.173411 Content Loss: 0.019333

run [1650]:
Style Loss : 0.173078 Content Loss: 0.019342

run [1700]:
Style Loss : 0.172772 Content Loss: 0.019344

run [1750]:
Style Loss : 0.172500 Content Loss: 0.019343

run [1800]:
Style Loss : 0.172247 Content Loss: 0.019343

run [1850]:
Style Loss : 0.171968 Content Loss: 0.019344

run [1900]:
Style Loss : 0.171719 Content Loss: 0.019348

run [1950]:
Style Loss : 0.171474 Content Loss: 0.019348

run [2000]:
Style Loss : 0.171246 Content Loss: 0.019348

run [2050]:
Style Loss : 0.171022 Content Loss: 0.019352

run [2100]:
Style Loss : 0.170808 Content Loss: 0.019356

run [2150]:
Style Loss : 0.170613 Content Loss: 0.019359

run [2200]:
Style Loss : 0.170410 Content Loss: 0.019365

run [2250]:
Style Loss : 0.170191 Content Loss: 0.019369

run [2300]:
Style Loss : 0.169980 Content Loss: 0.019375

run [2350]:
Style Loss : 0.169782 Content Loss: 0.019381

run [2400]:
Style Loss : 0.169598 Content Loss: 0.019388

run [2450]:
Style Loss : 0.169425 Content Loss: 0.019394

run [2500]:
Style Loss : 0.169262 Content Loss: 0.019400

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.703532 Content Loss: 0.010178

run [100]:
Style Loss : 0.399981 Content Loss: 0.014677

run [150]:
Style Loss : 0.319026 Content Loss: 0.018232

run [200]:
Style Loss : 0.272146 Content Loss: 0.020425

run [250]:
Style Loss : 0.240948 Content Loss: 0.021986

run [300]:
Style Loss : 0.223387 Content Loss: 0.023204

run [350]:
Style Loss : 0.211667 Content Loss: 0.024045

run [400]:
Style Loss : 0.202053 Content Loss: 0.024797

run [450]:
Style Loss : 0.194165 Content Loss: 0.025317

run [500]:
Style Loss : 0.186335 Content Loss: 0.025585

run [550]:
Style Loss : 0.179778 Content Loss: 0.025799

run [600]:
Style Loss : 0.173807 Content Loss: 0.026035

run [650]:
Style Loss : 0.168202 Content Loss: 0.026234

run [700]:
Style Loss : 0.163713 Content Loss: 0.026382

run [750]:
Style Loss : 0.160026 Content Loss: 0.026510

run [800]:
Style Loss : 0.156881 Content Loss: 0.026590

run [850]:
Style Loss : 0.154350 Content Loss: 0.026668

run [900]:
Style Loss : 0.152051 Content Loss: 0.026737

run [950]:
Style Loss : 0.150015 Content Loss: 0.026805

run [1000]:
Style Loss : 0.148348 Content Loss: 0.026840

run [1050]:
Style Loss : 0.146593 Content Loss: 0.026856

run [1100]:
Style Loss : 0.144910 Content Loss: 0.026880

run [1150]:
Style Loss : 0.143449 Content Loss: 0.026924

run [1200]:
Style Loss : 0.142297 Content Loss: 0.026973

run [1250]:
Style Loss : 0.141198 Content Loss: 0.027014

run [1300]:
Style Loss : 0.140221 Content Loss: 0.027056

run [1350]:
Style Loss : 0.139380 Content Loss: 0.027107

run [1400]:
Style Loss : 0.138581 Content Loss: 0.027152

run [1450]:
Style Loss : 0.137310 Content Loss: 0.027211

run [1500]:
Style Loss : 0.136284 Content Loss: 0.027271

run [1550]:
Style Loss : 0.132744 Content Loss: 0.027342

run [1600]:
Style Loss : 0.130989 Content Loss: 0.027368

run [1650]:
Style Loss : 0.129858 Content Loss: 0.027392

run [1700]:
Style Loss : 0.128642 Content Loss: 0.027445

run [1750]:
Style Loss : 0.127573 Content Loss: 0.027493

run [1800]:
Style Loss : 0.126718 Content Loss: 0.027533

run [1850]:
Style Loss : 0.125886 Content Loss: 0.027562

run [1900]:
Style Loss : 0.125166 Content Loss: 0.027602

run [1950]:
Style Loss : 0.124461 Content Loss: 0.027635

run [2000]:
Style Loss : 0.123763 Content Loss: 0.027676

run [2050]:
Style Loss : 0.123141 Content Loss: 0.027692

run [2100]:
Style Loss : 0.122486 Content Loss: 0.027719

run [2150]:
Style Loss : 0.121813 Content Loss: 0.027747

run [2200]:
Style Loss : 0.121102 Content Loss: 0.027781

run [2250]:
Style Loss : 0.120421 Content Loss: 0.027821

run [2300]:
Style Loss : 0.119793 Content Loss: 0.027854

run [2350]:
Style Loss : 0.119251 Content Loss: 0.027880

run [2400]:
Style Loss : 0.118741 Content Loss: 0.027906

run [2450]:
Style Loss : 0.118252 Content Loss: 0.027926

run [2500]:
Style Loss : 0.117805 Content Loss: 0.027947

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.129565 Content Loss: 0.008820

run [100]:
Style Loss : 1.136317 Content Loss: 0.014298

run [150]:
Style Loss : 0.835534 Content Loss: 0.017680

run [200]:
Style Loss : 0.699252 Content Loss: 0.020096

run [250]:
Style Loss : 0.621801 Content Loss: 0.021901

run [300]:
Style Loss : 0.567738 Content Loss: 0.023417

run [350]:
Style Loss : 0.528236 Content Loss: 0.024582

run [400]:
Style Loss : 0.496924 Content Loss: 0.025563

run [450]:
Style Loss : 0.473535 Content Loss: 0.026396

run [500]:
Style Loss : 0.455822 Content Loss: 0.027041

run [550]:
Style Loss : 0.441128 Content Loss: 0.027522

run [600]:
Style Loss : 0.429729 Content Loss: 0.027938

run [650]:
Style Loss : 0.420612 Content Loss: 0.028300

run [700]:
Style Loss : 0.412934 Content Loss: 0.028647

run [750]:
Style Loss : 0.406309 Content Loss: 0.028960

run [800]:
Style Loss : 0.400861 Content Loss: 0.029172

run [850]:
Style Loss : 0.396322 Content Loss: 0.029392

run [900]:
Style Loss : 0.392570 Content Loss: 0.029567

run [950]:
Style Loss : 0.389225 Content Loss: 0.029755

run [1000]:
Style Loss : 0.385294 Content Loss: 0.029874

run [1050]:
Style Loss : 0.381637 Content Loss: 0.030021

run [1100]:
Style Loss : 0.378716 Content Loss: 0.030138

run [1150]:
Style Loss : 0.376194 Content Loss: 0.030263

run [1200]:
Style Loss : 0.373921 Content Loss: 0.030362

run [1250]:
Style Loss : 0.371833 Content Loss: 0.030475

run [1300]:
Style Loss : 0.369913 Content Loss: 0.030582

run [1350]:
Style Loss : 0.368258 Content Loss: 0.030659

run [1400]:
Style Loss : 0.366174 Content Loss: 0.030736

run [1450]:
Style Loss : 0.364428 Content Loss: 0.030815

run [1500]:
Style Loss : 0.362988 Content Loss: 0.030875

run [1550]:
Style Loss : 0.361563 Content Loss: 0.030929

run [1600]:
Style Loss : 0.360274 Content Loss: 0.030992

run [1650]:
Style Loss : 0.359127 Content Loss: 0.031025

run [1700]:
Style Loss : 0.358153 Content Loss: 0.031061

run [1750]:
Style Loss : 0.357255 Content Loss: 0.031088

run [1800]:
Style Loss : 0.356377 Content Loss: 0.031122

run [1850]:
Style Loss : 0.355559 Content Loss: 0.031150

run [1900]:
Style Loss : 0.354852 Content Loss: 0.031180

run [1950]:
Style Loss : 0.354121 Content Loss: 0.031200

run [2000]:
Style Loss : 0.353458 Content Loss: 0.031207

run [2050]:
Style Loss : 0.352802 Content Loss: 0.031231

run [2100]:
Style Loss : 0.352221 Content Loss: 0.031241

run [2150]:
Style Loss : 0.351661 Content Loss: 0.031253

run [2200]:
Style Loss : 0.351112 Content Loss: 0.031265

run [2250]:
Style Loss : 0.350608 Content Loss: 0.031278

run [2300]:
Style Loss : 0.350156 Content Loss: 0.031289

run [2350]:
Style Loss : 0.349725 Content Loss: 0.031301

run [2400]:
Style Loss : 0.349281 Content Loss: 0.031319

run [2450]:
Style Loss : 0.348827 Content Loss: 0.031334

run [2500]:
Style Loss : 0.348397 Content Loss: 0.031336

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.746709 Content Loss: 0.004670

run [100]:
Style Loss : 0.873579 Content Loss: 0.008444

run [150]:
Style Loss : 0.642372 Content Loss: 0.010123

run [200]:
Style Loss : 0.523091 Content Loss: 0.011387

run [250]:
Style Loss : 0.445858 Content Loss: 0.012546

run [300]:
Style Loss : 0.393436 Content Loss: 0.013713

run [350]:
Style Loss : 0.355627 Content Loss: 0.014833

run [400]:
Style Loss : 0.326218 Content Loss: 0.015926

run [450]:
Style Loss : 0.303544 Content Loss: 0.016801

run [500]:
Style Loss : 0.287404 Content Loss: 0.017443

run [550]:
Style Loss : 0.274919 Content Loss: 0.017908

run [600]:
Style Loss : 0.265635 Content Loss: 0.018269

run [650]:
Style Loss : 0.258006 Content Loss: 0.018572

run [700]:
Style Loss : 0.250633 Content Loss: 0.018812

run [750]:
Style Loss : 0.244185 Content Loss: 0.019009

run [800]:
Style Loss : 0.239116 Content Loss: 0.019204

run [850]:
Style Loss : 0.234665 Content Loss: 0.019404

run [900]:
Style Loss : 0.230641 Content Loss: 0.019610

run [950]:
Style Loss : 0.227089 Content Loss: 0.019809

run [1000]:
Style Loss : 0.223823 Content Loss: 0.020020

run [1050]:
Style Loss : 0.221052 Content Loss: 0.020188

run [1100]:
Style Loss : 0.218443 Content Loss: 0.020356

run [1150]:
Style Loss : 0.216129 Content Loss: 0.020519

run [1200]:
Style Loss : 0.213801 Content Loss: 0.020688

run [1250]:
Style Loss : 0.211537 Content Loss: 0.020848

run [1300]:
Style Loss : 0.209565 Content Loss: 0.020982

run [1350]:
Style Loss : 0.207610 Content Loss: 0.021145

run [1400]:
Style Loss : 0.205952 Content Loss: 0.021306

run [1450]:
Style Loss : 0.204301 Content Loss: 0.021445

run [1500]:
Style Loss : 0.202655 Content Loss: 0.021575

run [1550]:
Style Loss : 0.201137 Content Loss: 0.021703

run [1600]:
Style Loss : 0.199697 Content Loss: 0.021820

run [1650]:
Style Loss : 0.198413 Content Loss: 0.021928

run [1700]:
Style Loss : 0.197159 Content Loss: 0.022035

run [1750]:
Style Loss : 0.196043 Content Loss: 0.022132

run [1800]:
Style Loss : 0.195012 Content Loss: 0.022210

run [1850]:
Style Loss : 0.194113 Content Loss: 0.022290

run [1900]:
Style Loss : 0.193258 Content Loss: 0.022377

run [1950]:
Style Loss : 0.192348 Content Loss: 0.022459

run [2000]:
Style Loss : 0.191224 Content Loss: 0.022546

run [2050]:
Style Loss : 0.190141 Content Loss: 0.022636

run [2100]:
Style Loss : 0.189119 Content Loss: 0.022718

run [2150]:
Style Loss : 0.188214 Content Loss: 0.022791

run [2200]:
Style Loss : 0.187294 Content Loss: 0.022868

run [2250]:
Style Loss : 0.186426 Content Loss: 0.022952

run [2300]:
Style Loss : 0.185622 Content Loss: 0.023021

run [2350]:
Style Loss : 0.184886 Content Loss: 0.023076

run [2400]:
Style Loss : 0.184115 Content Loss: 0.023146

run [2450]:
Style Loss : 0.183415 Content Loss: 0.023206

run [2500]:
Style Loss : 0.182712 Content Loss: 0.023270

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.337616 Content Loss: 0.006111

run [100]:
Style Loss : 0.735899 Content Loss: 0.009017

run [150]:
Style Loss : 0.545206 Content Loss: 0.010943

run [200]:
Style Loss : 0.437873 Content Loss: 0.012818

run [250]:
Style Loss : 0.360516 Content Loss: 0.014653

run [300]:
Style Loss : 0.313837 Content Loss: 0.016156

run [350]:
Style Loss : 0.281448 Content Loss: 0.017395

run [400]:
Style Loss : 0.260287 Content Loss: 0.018258

run [450]:
Style Loss : 0.244723 Content Loss: 0.018784

run [500]:
Style Loss : 0.231822 Content Loss: 0.019200

run [550]:
Style Loss : 0.220347 Content Loss: 0.019543

run [600]:
Style Loss : 0.209255 Content Loss: 0.019841

run [650]:
Style Loss : 0.198761 Content Loss: 0.020136

run [700]:
Style Loss : 0.188362 Content Loss: 0.020461

run [750]:
Style Loss : 0.178983 Content Loss: 0.020827

run [800]:
Style Loss : 0.170454 Content Loss: 0.021198

run [850]:
Style Loss : 0.162839 Content Loss: 0.021612

run [900]:
Style Loss : 0.155466 Content Loss: 0.022070

run [950]:
Style Loss : 0.148560 Content Loss: 0.022547

run [1000]:
Style Loss : 0.142257 Content Loss: 0.023044

run [1050]:
Style Loss : 0.135982 Content Loss: 0.023643

run [1100]:
Style Loss : 0.129896 Content Loss: 0.024277

run [1150]:
Style Loss : 0.124232 Content Loss: 0.024853

run [1200]:
Style Loss : 0.118880 Content Loss: 0.025451

run [1250]:
Style Loss : 0.114160 Content Loss: 0.025972

run [1300]:
Style Loss : 0.109932 Content Loss: 0.026368

run [1350]:
Style Loss : 0.106323 Content Loss: 0.026730

run [1400]:
Style Loss : 0.103361 Content Loss: 0.026957

run [1450]:
Style Loss : 0.100719 Content Loss: 0.027141

run [1500]:
Style Loss : 0.098561 Content Loss: 0.027269

run [1550]:
Style Loss : 0.096659 Content Loss: 0.027346

run [1600]:
Style Loss : 0.094949 Content Loss: 0.027417

run [1650]:
Style Loss : 0.093525 Content Loss: 0.027451

run [1700]:
Style Loss : 0.092307 Content Loss: 0.027486

run [1750]:
Style Loss : 0.091079 Content Loss: 0.027470

run [1800]:
Style Loss : 0.089876 Content Loss: 0.027447

run [1850]:
Style Loss : 0.088878 Content Loss: 0.027417

run [1900]:
Style Loss : 0.087955 Content Loss: 0.027374

run [1950]:
Style Loss : 0.087207 Content Loss: 0.027329

run [2000]:
Style Loss : 0.086565 Content Loss: 0.027287

run [2050]:
Style Loss : 0.085931 Content Loss: 0.027240

run [2100]:
Style Loss : 0.085298 Content Loss: 0.027195

run [2150]:
Style Loss : 0.084714 Content Loss: 0.027148

run [2200]:
Style Loss : 0.084210 Content Loss: 0.027090

run [2250]:
Style Loss : 0.083664 Content Loss: 0.027027

run [2300]:
Style Loss : 0.083249 Content Loss: 0.026969

run [2350]:
Style Loss : 0.082898 Content Loss: 0.026906

run [2400]:
Style Loss : 0.082506 Content Loss: 0.026854

run [2450]:
Style Loss : 0.082186 Content Loss: 0.026799

run [2500]:
Style Loss : 0.081909 Content Loss: 0.026734

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.522629 Content Loss: 0.005900

run [100]:
Style Loss : 0.674661 Content Loss: 0.009067

run [150]:
Style Loss : 0.454074 Content Loss: 0.010956

run [200]:
Style Loss : 0.353182 Content Loss: 0.012038

run [250]:
Style Loss : 0.290815 Content Loss: 0.012962

run [300]:
Style Loss : 0.248793 Content Loss: 0.013862

run [350]:
Style Loss : 0.215986 Content Loss: 0.014583

run [400]:
Style Loss : 0.192603 Content Loss: 0.015286

run [450]:
Style Loss : 0.173712 Content Loss: 0.016003

run [500]:
Style Loss : 0.156804 Content Loss: 0.016587

run [550]:
Style Loss : 0.144015 Content Loss: 0.017035

run [600]:
Style Loss : 0.134412 Content Loss: 0.017371

run [650]:
Style Loss : 0.127126 Content Loss: 0.017633

run [700]:
Style Loss : 0.121307 Content Loss: 0.017790

run [750]:
Style Loss : 0.117045 Content Loss: 0.017912

run [800]:
Style Loss : 0.113552 Content Loss: 0.018028

run [850]:
Style Loss : 0.110389 Content Loss: 0.018142

run [900]:
Style Loss : 0.107777 Content Loss: 0.018226

run [950]:
Style Loss : 0.105260 Content Loss: 0.018298

run [1000]:
Style Loss : 0.102953 Content Loss: 0.018400

run [1050]:
Style Loss : 0.100994 Content Loss: 0.018483

run [1100]:
Style Loss : 0.099149 Content Loss: 0.018561

run [1150]:
Style Loss : 0.097470 Content Loss: 0.018648

run [1200]:
Style Loss : 0.096069 Content Loss: 0.018728

run [1250]:
Style Loss : 0.094784 Content Loss: 0.018808

run [1300]:
Style Loss : 0.093670 Content Loss: 0.018879

run [1350]:
Style Loss : 0.092668 Content Loss: 0.018956

run [1400]:
Style Loss : 0.091768 Content Loss: 0.019030

run [1450]:
Style Loss : 0.090805 Content Loss: 0.019118

run [1500]:
Style Loss : 0.089955 Content Loss: 0.019190

run [1550]:
Style Loss : 0.089031 Content Loss: 0.019274

run [1600]:
Style Loss : 0.088181 Content Loss: 0.019333

run [1650]:
Style Loss : 0.087436 Content Loss: 0.019385

run [1700]:
Style Loss : 0.086789 Content Loss: 0.019433

run [1750]:
Style Loss : 0.086161 Content Loss: 0.019482

run [1800]:
Style Loss : 0.085559 Content Loss: 0.019534

run [1850]:
Style Loss : 0.084894 Content Loss: 0.019594

run [1900]:
Style Loss : 0.084299 Content Loss: 0.019647

run [1950]:
Style Loss : 0.083741 Content Loss: 0.019692

run [2000]:
Style Loss : 0.083228 Content Loss: 0.019732

run [2050]:
Style Loss : 0.082801 Content Loss: 0.019770

run [2100]:
Style Loss : 0.082420 Content Loss: 0.019795

run [2150]:
Style Loss : 0.082026 Content Loss: 0.019830

run [2200]:
Style Loss : 0.081648 Content Loss: 0.019868

run [2250]:
Style Loss : 0.081231 Content Loss: 0.019910

run [2300]:
Style Loss : 0.080525 Content Loss: 0.019939

run [2350]:
Style Loss : 0.080022 Content Loss: 0.019969

run [2400]:
Style Loss : 0.079578 Content Loss: 0.020009

run [2450]:
Style Loss : 0.079132 Content Loss: 0.020045

run [2500]:
Style Loss : 0.078713 Content Loss: 0.020072

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.575695 Content Loss: 0.006174

run [100]:
Style Loss : 1.007871 Content Loss: 0.010842

run [150]:
Style Loss : 0.722789 Content Loss: 0.015939

run [200]:
Style Loss : 0.545348 Content Loss: 0.022040

run [250]:
Style Loss : 0.453649 Content Loss: 0.026912

run [300]:
Style Loss : 0.407096 Content Loss: 0.029157

run [350]:
Style Loss : 0.375157 Content Loss: 0.030310

run [400]:
Style Loss : 0.353071 Content Loss: 0.031004

run [450]:
Style Loss : 0.335173 Content Loss: 0.031818

run [500]:
Style Loss : 0.320962 Content Loss: 0.032513

run [550]:
Style Loss : 0.309399 Content Loss: 0.033344

run [600]:
Style Loss : 0.299014 Content Loss: 0.033925

run [650]:
Style Loss : 0.288654 Content Loss: 0.034664

run [700]:
Style Loss : 0.280031 Content Loss: 0.035311

run [750]:
Style Loss : 0.271630 Content Loss: 0.035983

run [800]:
Style Loss : 0.264093 Content Loss: 0.036597

run [850]:
Style Loss : 0.257714 Content Loss: 0.037065

run [900]:
Style Loss : 0.251728 Content Loss: 0.037601

run [950]:
Style Loss : 0.246523 Content Loss: 0.038048

run [1000]:
Style Loss : 0.242290 Content Loss: 0.038482

run [1050]:
Style Loss : 0.238228 Content Loss: 0.038832

run [1100]:
Style Loss : 0.235068 Content Loss: 0.039196

run [1150]:
Style Loss : 0.232555 Content Loss: 0.039558

run [1200]:
Style Loss : 0.230475 Content Loss: 0.039883

run [1250]:
Style Loss : 0.228654 Content Loss: 0.040196

run [1300]:
Style Loss : 0.227066 Content Loss: 0.040503

run [1350]:
Style Loss : 0.225623 Content Loss: 0.040788

run [1400]:
Style Loss : 0.224469 Content Loss: 0.041035

run [1450]:
Style Loss : 0.223237 Content Loss: 0.041219

run [1500]:
Style Loss : 0.222481 Content Loss: 0.041453

run [1550]:
Style Loss : 0.221463 Content Loss: 0.041562

run [1600]:
Style Loss : 0.220700 Content Loss: 0.041689

run [1650]:
Style Loss : 0.220023 Content Loss: 0.041818

run [1700]:
Style Loss : 0.219531 Content Loss: 0.041921

run [1750]:
Style Loss : 0.218530 Content Loss: 0.042005

run [1800]:
Style Loss : 0.218154 Content Loss: 0.042074

run [1850]:
Style Loss : 0.217461 Content Loss: 0.042098

run [1900]:
Style Loss : 0.217120 Content Loss: 0.042136

run [1950]:
Style Loss : 0.216717 Content Loss: 0.042131

run [2000]:
Style Loss : 0.215496 Content Loss: 0.042079

run [2050]:
Style Loss : 0.216282 Content Loss: 0.042071

run [2100]:
Style Loss : 0.214421 Content Loss: 0.041990

run [2150]:
Style Loss : 0.215196 Content Loss: 0.041899

run [2200]:
Style Loss : 0.213110 Content Loss: 0.041839

run [2250]:
Style Loss : 0.212851 Content Loss: 0.041738

run [2300]:
Style Loss : 0.212336 Content Loss: 0.041648

run [2350]:
Style Loss : 0.211771 Content Loss: 0.041562

run [2400]:
Style Loss : 0.211617 Content Loss: 0.041422

run [2450]:
Style Loss : 0.210893 Content Loss: 0.041299

run [2500]:
Style Loss : 0.215084 Content Loss: 0.041262

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.936393 Content Loss: 0.009550

run [100]:
Style Loss : 0.502583 Content Loss: 0.017141

run [150]:
Style Loss : 0.344089 Content Loss: 0.021128

run [200]:
Style Loss : 0.275994 Content Loss: 0.023078

run [250]:
Style Loss : 0.239242 Content Loss: 0.024128

run [300]:
Style Loss : 0.216708 Content Loss: 0.024682

run [350]:
Style Loss : 0.201686 Content Loss: 0.025082

run [400]:
Style Loss : 0.190622 Content Loss: 0.025401

run [450]:
Style Loss : 0.181467 Content Loss: 0.025914

run [500]:
Style Loss : 0.173631 Content Loss: 0.026351

run [550]:
Style Loss : 0.166409 Content Loss: 0.026778

run [600]:
Style Loss : 0.160209 Content Loss: 0.027125

run [650]:
Style Loss : 0.154922 Content Loss: 0.027515

run [700]:
Style Loss : 0.150397 Content Loss: 0.027871

run [750]:
Style Loss : 0.146397 Content Loss: 0.028140

run [800]:
Style Loss : 0.142993 Content Loss: 0.028371

run [850]:
Style Loss : 0.139816 Content Loss: 0.028628

run [900]:
Style Loss : 0.137095 Content Loss: 0.028857

run [950]:
Style Loss : 0.134645 Content Loss: 0.029057

run [1000]:
Style Loss : 0.132475 Content Loss: 0.029233

run [1050]:
Style Loss : 0.130517 Content Loss: 0.029382

run [1100]:
Style Loss : 0.128751 Content Loss: 0.029510

run [1150]:
Style Loss : 0.127117 Content Loss: 0.029597

run [1200]:
Style Loss : 0.125579 Content Loss: 0.029698

run [1250]:
Style Loss : 0.124138 Content Loss: 0.029783

run [1300]:
Style Loss : 0.122891 Content Loss: 0.029861

run [1350]:
Style Loss : 0.121724 Content Loss: 0.029920

run [1400]:
Style Loss : 0.120732 Content Loss: 0.029954

run [1450]:
Style Loss : 0.119897 Content Loss: 0.029982

run [1500]:
Style Loss : 0.119163 Content Loss: 0.029999

run [1550]:
Style Loss : 0.118527 Content Loss: 0.030006

run [1600]:
Style Loss : 0.117952 Content Loss: 0.029997

run [1650]:
Style Loss : 0.117429 Content Loss: 0.029997

run [1700]:
Style Loss : 0.116924 Content Loss: 0.029985

run [1750]:
Style Loss : 0.116472 Content Loss: 0.029952

run [1800]:
Style Loss : 0.116022 Content Loss: 0.029920

run [1850]:
Style Loss : 0.115602 Content Loss: 0.029892

run [1900]:
Style Loss : 0.115222 Content Loss: 0.029856

run [1950]:
Style Loss : 0.114905 Content Loss: 0.029825

run [2000]:
Style Loss : 0.114539 Content Loss: 0.029789

run [2050]:
Style Loss : 0.114202 Content Loss: 0.029760

run [2100]:
Style Loss : 0.113860 Content Loss: 0.029736

run [2150]:
Style Loss : 0.113492 Content Loss: 0.029716

run [2200]:
Style Loss : 0.113119 Content Loss: 0.029693

run [2250]:
Style Loss : 0.112763 Content Loss: 0.029669

run [2300]:
Style Loss : 0.112409 Content Loss: 0.029638

run [2350]:
Style Loss : 0.112082 Content Loss: 0.029619

run [2400]:
Style Loss : 0.111809 Content Loss: 0.029599

run [2450]:
Style Loss : 0.111557 Content Loss: 0.029574

run [2500]:
Style Loss : 0.111204 Content Loss: 0.029558

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.841550 Content Loss: 0.003327

run [100]:
Style Loss : 1.663993 Content Loss: 0.006618

run [150]:
Style Loss : 1.222183 Content Loss: 0.008585

run [200]:
Style Loss : 1.004480 Content Loss: 0.010242

run [250]:
Style Loss : 0.874281 Content Loss: 0.011488

run [300]:
Style Loss : 0.779862 Content Loss: 0.012843

run [350]:
Style Loss : 0.705409 Content Loss: 0.013848

run [400]:
Style Loss : 0.647791 Content Loss: 0.014989

run [450]:
Style Loss : 0.603795 Content Loss: 0.015956

run [500]:
Style Loss : 0.570585 Content Loss: 0.016830

run [550]:
Style Loss : 0.546309 Content Loss: 0.017664

run [600]:
Style Loss : 0.526947 Content Loss: 0.018355

run [650]:
Style Loss : 0.511855 Content Loss: 0.018917

run [700]:
Style Loss : 0.499366 Content Loss: 0.019442

run [750]:
Style Loss : 0.487895 Content Loss: 0.019939

run [800]:
Style Loss : 0.478244 Content Loss: 0.020293

run [850]:
Style Loss : 0.468743 Content Loss: 0.020621

run [900]:
Style Loss : 0.459961 Content Loss: 0.020914

run [950]:
Style Loss : 0.452677 Content Loss: 0.021147

run [1000]:
Style Loss : 0.445984 Content Loss: 0.021381

run [1050]:
Style Loss : 0.439880 Content Loss: 0.021610

run [1100]:
Style Loss : 0.433873 Content Loss: 0.021826

run [1150]:
Style Loss : 0.428660 Content Loss: 0.022011

run [1200]:
Style Loss : 0.423615 Content Loss: 0.022196

run [1250]:
Style Loss : 0.419284 Content Loss: 0.022379

run [1300]:
Style Loss : 0.414915 Content Loss: 0.022534

run [1350]:
Style Loss : 0.411052 Content Loss: 0.022675

run [1400]:
Style Loss : 0.407457 Content Loss: 0.022797

run [1450]:
Style Loss : 0.404549 Content Loss: 0.022907

run [1500]:
Style Loss : 0.401667 Content Loss: 0.023026

run [1550]:
Style Loss : 0.398898 Content Loss: 0.023144

run [1600]:
Style Loss : 0.396302 Content Loss: 0.023257

run [1650]:
Style Loss : 0.393601 Content Loss: 0.023381

run [1700]:
Style Loss : 0.390658 Content Loss: 0.023491

run [1750]:
Style Loss : 0.387504 Content Loss: 0.023602

run [1800]:
Style Loss : 0.384643 Content Loss: 0.023710

run [1850]:
Style Loss : 0.382009 Content Loss: 0.023814

run [1900]:
Style Loss : 0.379627 Content Loss: 0.023906

run [1950]:
Style Loss : 0.377428 Content Loss: 0.023998

run [2000]:
Style Loss : 0.375364 Content Loss: 0.024093

run [2050]:
Style Loss : 0.373303 Content Loss: 0.024183

run [2100]:
Style Loss : 0.371234 Content Loss: 0.024270

run [2150]:
Style Loss : 0.369167 Content Loss: 0.024358

run [2200]:
Style Loss : 0.367212 Content Loss: 0.024424

run [2250]:
Style Loss : 0.365411 Content Loss: 0.024496

run [2300]:
Style Loss : 0.363688 Content Loss: 0.024564

run [2350]:
Style Loss : 0.362044 Content Loss: 0.024630

run [2400]:
Style Loss : 0.360531 Content Loss: 0.024684

run [2450]:
Style Loss : 0.359133 Content Loss: 0.024740

run [2500]:
Style Loss : 0.357971 Content Loss: 0.024784

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.185566 Content Loss: 0.003398

run [100]:
Style Loss : 1.577863 Content Loss: 0.006077

run [150]:
Style Loss : 1.111554 Content Loss: 0.008194

run [200]:
Style Loss : 0.901503 Content Loss: 0.009701

run [250]:
Style Loss : 0.772601 Content Loss: 0.010862

run [300]:
Style Loss : 0.691314 Content Loss: 0.011780

run [350]:
Style Loss : 0.631734 Content Loss: 0.012581

run [400]:
Style Loss : 0.587332 Content Loss: 0.013403

run [450]:
Style Loss : 0.551872 Content Loss: 0.014154

run [500]:
Style Loss : 0.523260 Content Loss: 0.014889

run [550]:
Style Loss : 0.500209 Content Loss: 0.015597

run [600]:
Style Loss : 0.480911 Content Loss: 0.016224

run [650]:
Style Loss : 0.464039 Content Loss: 0.016908

run [700]:
Style Loss : 0.450271 Content Loss: 0.017519

run [750]:
Style Loss : 0.439497 Content Loss: 0.017988

run [800]:
Style Loss : 0.430200 Content Loss: 0.018372

run [850]:
Style Loss : 0.422671 Content Loss: 0.018717

run [900]:
Style Loss : 0.416046 Content Loss: 0.019067

run [950]:
Style Loss : 0.409694 Content Loss: 0.019383

run [1000]:
Style Loss : 0.403927 Content Loss: 0.019643

run [1050]:
Style Loss : 0.398714 Content Loss: 0.019849

run [1100]:
Style Loss : 0.393554 Content Loss: 0.020029

run [1150]:
Style Loss : 0.388570 Content Loss: 0.020240

run [1200]:
Style Loss : 0.383691 Content Loss: 0.020429

run [1250]:
Style Loss : 0.379057 Content Loss: 0.020578

run [1300]:
Style Loss : 0.374897 Content Loss: 0.020776

run [1350]:
Style Loss : 0.370618 Content Loss: 0.020946

run [1400]:
Style Loss : 0.366081 Content Loss: 0.021129

run [1450]:
Style Loss : 0.361502 Content Loss: 0.021297

run [1500]:
Style Loss : 0.356928 Content Loss: 0.021484

run [1550]:
Style Loss : 0.352452 Content Loss: 0.021664

run [1600]:
Style Loss : 0.347903 Content Loss: 0.021851

run [1650]:
Style Loss : 0.343243 Content Loss: 0.022060

run [1700]:
Style Loss : 0.338717 Content Loss: 0.022263

run [1750]:
Style Loss : 0.333901 Content Loss: 0.022492

run [1800]:
Style Loss : 0.329074 Content Loss: 0.022728

run [1850]:
Style Loss : 0.324441 Content Loss: 0.022978

run [1900]:
Style Loss : 0.319866 Content Loss: 0.023228

run [1950]:
Style Loss : 0.315183 Content Loss: 0.023540

run [2000]:
Style Loss : 0.310593 Content Loss: 0.023822

run [2050]:
Style Loss : 0.306203 Content Loss: 0.024144

run [2100]:
Style Loss : 0.301309 Content Loss: 0.024470

run [2150]:
Style Loss : 0.295996 Content Loss: 0.024869

run [2200]:
Style Loss : 0.290943 Content Loss: 0.025221

run [2250]:
Style Loss : 0.286322 Content Loss: 0.025582

run [2300]:
Style Loss : 0.281674 Content Loss: 0.025976

run [2350]:
Style Loss : 0.277338 Content Loss: 0.026376

run [2400]:
Style Loss : 0.272975 Content Loss: 0.026785

run [2450]:
Style Loss : 0.268828 Content Loss: 0.027155

run [2500]:
Style Loss : 0.264882 Content Loss: 0.027497

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.172189 Content Loss: 0.004855

run [100]:
Style Loss : 1.101079 Content Loss: 0.007905

run [150]:
Style Loss : 0.820105 Content Loss: 0.009988

run [200]:
Style Loss : 0.677198 Content Loss: 0.011620

run [250]:
Style Loss : 0.599302 Content Loss: 0.012890

run [300]:
Style Loss : 0.545294 Content Loss: 0.014197

run [350]:
Style Loss : 0.505605 Content Loss: 0.015281

run [400]:
Style Loss : 0.474205 Content Loss: 0.016163

run [450]:
Style Loss : 0.452626 Content Loss: 0.016935

run [500]:
Style Loss : 0.436419 Content Loss: 0.017677

run [550]:
Style Loss : 0.423494 Content Loss: 0.018218

run [600]:
Style Loss : 0.412857 Content Loss: 0.018693

run [650]:
Style Loss : 0.402656 Content Loss: 0.019149

run [700]:
Style Loss : 0.393641 Content Loss: 0.019568

run [750]:
Style Loss : 0.385760 Content Loss: 0.019930

run [800]:
Style Loss : 0.377975 Content Loss: 0.020308

run [850]:
Style Loss : 0.371071 Content Loss: 0.020656

run [900]:
Style Loss : 0.365270 Content Loss: 0.020934

run [950]:
Style Loss : 0.359974 Content Loss: 0.021213

run [1000]:
Style Loss : 0.355059 Content Loss: 0.021436

run [1050]:
Style Loss : 0.350235 Content Loss: 0.021653

run [1100]:
Style Loss : 0.345803 Content Loss: 0.021886

run [1150]:
Style Loss : 0.342235 Content Loss: 0.022064

run [1200]:
Style Loss : 0.338908 Content Loss: 0.022229

run [1250]:
Style Loss : 0.335863 Content Loss: 0.022414

run [1300]:
Style Loss : 0.332956 Content Loss: 0.022576

run [1350]:
Style Loss : 0.330155 Content Loss: 0.022745

run [1400]:
Style Loss : 0.327412 Content Loss: 0.022897

run [1450]:
Style Loss : 0.324092 Content Loss: 0.023073

run [1500]:
Style Loss : 0.320604 Content Loss: 0.023246

run [1550]:
Style Loss : 0.317464 Content Loss: 0.023407

run [1600]:
Style Loss : 0.314854 Content Loss: 0.023530

run [1650]:
Style Loss : 0.312478 Content Loss: 0.023681

run [1700]:
Style Loss : 0.310212 Content Loss: 0.023785

run [1750]:
Style Loss : 0.307981 Content Loss: 0.023922

run [1800]:
Style Loss : 0.305725 Content Loss: 0.024046

run [1850]:
Style Loss : 0.303560 Content Loss: 0.024180

run [1900]:
Style Loss : 0.301551 Content Loss: 0.024306

run [1950]:
Style Loss : 0.299546 Content Loss: 0.024430

run [2000]:
Style Loss : 0.297696 Content Loss: 0.024562

run [2050]:
Style Loss : 0.295375 Content Loss: 0.024704

run [2100]:
Style Loss : 0.293486 Content Loss: 0.024830

run [2150]:
Style Loss : 0.291734 Content Loss: 0.024936

run [2200]:
Style Loss : 0.290077 Content Loss: 0.025032

run [2250]:
Style Loss : 0.288566 Content Loss: 0.025139

run [2300]:
Style Loss : 0.287129 Content Loss: 0.025243

run [2350]:
Style Loss : 0.285697 Content Loss: 0.025345

run [2400]:
Style Loss : 0.284228 Content Loss: 0.025445

run [2450]:
Style Loss : 0.282643 Content Loss: 0.025563

run [2500]:
Style Loss : 0.281123 Content Loss: 0.025656

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.426612 Content Loss: 0.002910

run [100]:
Style Loss : 2.281312 Content Loss: 0.006016

run [150]:
Style Loss : 1.574184 Content Loss: 0.008356

run [200]:
Style Loss : 1.233245 Content Loss: 0.010034

run [250]:
Style Loss : 1.041570 Content Loss: 0.011082

run [300]:
Style Loss : 0.928391 Content Loss: 0.012069

run [350]:
Style Loss : 0.848376 Content Loss: 0.012757

run [400]:
Style Loss : 0.790003 Content Loss: 0.013455

run [450]:
Style Loss : 0.744723 Content Loss: 0.013989

run [500]:
Style Loss : 0.709318 Content Loss: 0.014379

run [550]:
Style Loss : 0.679209 Content Loss: 0.014813

run [600]:
Style Loss : 0.656078 Content Loss: 0.015187

run [650]:
Style Loss : 0.635741 Content Loss: 0.015560

run [700]:
Style Loss : 0.618149 Content Loss: 0.015869

run [750]:
Style Loss : 0.600280 Content Loss: 0.016169

run [800]:
Style Loss : 0.583832 Content Loss: 0.016459

run [850]:
Style Loss : 0.569097 Content Loss: 0.016734

run [900]:
Style Loss : 0.556087 Content Loss: 0.016953

run [950]:
Style Loss : 0.543833 Content Loss: 0.017186

run [1000]:
Style Loss : 0.533592 Content Loss: 0.017385

run [1050]:
Style Loss : 0.524038 Content Loss: 0.017599

run [1100]:
Style Loss : 0.515530 Content Loss: 0.017785

run [1150]:
Style Loss : 0.507132 Content Loss: 0.017954

run [1200]:
Style Loss : 0.499056 Content Loss: 0.018110

run [1250]:
Style Loss : 0.492223 Content Loss: 0.018226

run [1300]:
Style Loss : 0.485551 Content Loss: 0.018373

run [1350]:
Style Loss : 0.479467 Content Loss: 0.018509

run [1400]:
Style Loss : 0.473987 Content Loss: 0.018630

run [1450]:
Style Loss : 0.469306 Content Loss: 0.018738

run [1500]:
Style Loss : 0.465068 Content Loss: 0.018829

run [1550]:
Style Loss : 0.461097 Content Loss: 0.018919

run [1600]:
Style Loss : 0.457354 Content Loss: 0.018995

run [1650]:
Style Loss : 0.454132 Content Loss: 0.019061

run [1700]:
Style Loss : 0.451181 Content Loss: 0.019120

run [1750]:
Style Loss : 0.448511 Content Loss: 0.019189

run [1800]:
Style Loss : 0.445984 Content Loss: 0.019250

run [1850]:
Style Loss : 0.443698 Content Loss: 0.019296

run [1900]:
Style Loss : 0.441718 Content Loss: 0.019342

run [1950]:
Style Loss : 0.439831 Content Loss: 0.019389

run [2000]:
Style Loss : 0.438059 Content Loss: 0.019433

run [2050]:
Style Loss : 0.436404 Content Loss: 0.019475

run [2100]:
Style Loss : 0.434780 Content Loss: 0.019515

run [2150]:
Style Loss : 0.433224 Content Loss: 0.019557

run [2200]:
Style Loss : 0.431803 Content Loss: 0.019585

run [2250]:
Style Loss : 0.430491 Content Loss: 0.019610

run [2300]:
Style Loss : 0.429321 Content Loss: 0.019638

run [2350]:
Style Loss : 0.428142 Content Loss: 0.019675

run [2400]:
Style Loss : 0.427077 Content Loss: 0.019708

run [2450]:
Style Loss : 0.426053 Content Loss: 0.019742

run [2500]:
Style Loss : 0.425049 Content Loss: 0.019782

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 5.043741 Content Loss: 0.004662

run [100]:
Style Loss : 2.430850 Content Loss: 0.006801

run [150]:
Style Loss : 1.664315 Content Loss: 0.008839

run [200]:
Style Loss : 1.302076 Content Loss: 0.010463

run [250]:
Style Loss : 1.083985 Content Loss: 0.011769

run [300]:
Style Loss : 0.930999 Content Loss: 0.012705

run [350]:
Style Loss : 0.819964 Content Loss: 0.013421

run [400]:
Style Loss : 0.746545 Content Loss: 0.014083

run [450]:
Style Loss : 0.693621 Content Loss: 0.014647

run [500]:
Style Loss : 0.651655 Content Loss: 0.015166

run [550]:
Style Loss : 0.619034 Content Loss: 0.015630

run [600]:
Style Loss : 0.589922 Content Loss: 0.016036

run [650]:
Style Loss : 0.568072 Content Loss: 0.016390

run [700]:
Style Loss : 0.547892 Content Loss: 0.016780

run [750]:
Style Loss : 0.529517 Content Loss: 0.017126

run [800]:
Style Loss : 0.513536 Content Loss: 0.017405

run [850]:
Style Loss : 0.499217 Content Loss: 0.017666

run [900]:
Style Loss : 0.486746 Content Loss: 0.017933

run [950]:
Style Loss : 0.475836 Content Loss: 0.018173

run [1000]:
Style Loss : 0.465706 Content Loss: 0.018397

run [1050]:
Style Loss : 0.456586 Content Loss: 0.018636

run [1100]:
Style Loss : 0.448569 Content Loss: 0.018850

run [1150]:
Style Loss : 0.441393 Content Loss: 0.019040

run [1200]:
Style Loss : 0.435331 Content Loss: 0.019229

run [1250]:
Style Loss : 0.430216 Content Loss: 0.019401

run [1300]:
Style Loss : 0.425771 Content Loss: 0.019555

run [1350]:
Style Loss : 0.421378 Content Loss: 0.019716

run [1400]:
Style Loss : 0.416963 Content Loss: 0.019871

run [1450]:
Style Loss : 0.412629 Content Loss: 0.020021

run [1500]:
Style Loss : 0.408526 Content Loss: 0.020152

run [1550]:
Style Loss : 0.404761 Content Loss: 0.020279

run [1600]:
Style Loss : 0.400974 Content Loss: 0.020394

run [1650]:
Style Loss : 0.397231 Content Loss: 0.020532

run [1700]:
Style Loss : 0.393292 Content Loss: 0.020659

run [1750]:
Style Loss : 0.389682 Content Loss: 0.020775

run [1800]:
Style Loss : 0.386298 Content Loss: 0.020897

run [1850]:
Style Loss : 0.382975 Content Loss: 0.021021

run [1900]:
Style Loss : 0.379852 Content Loss: 0.021121

run [1950]:
Style Loss : 0.376919 Content Loss: 0.021223

run [2000]:
Style Loss : 0.374399 Content Loss: 0.021321

run [2050]:
Style Loss : 0.371880 Content Loss: 0.021424

run [2100]:
Style Loss : 0.369510 Content Loss: 0.021512

run [2150]:
Style Loss : 0.367285 Content Loss: 0.021596

run [2200]:
Style Loss : 0.365202 Content Loss: 0.021671

run [2250]:
Style Loss : 0.363209 Content Loss: 0.021741

run [2300]:
Style Loss : 0.361420 Content Loss: 0.021806

run [2350]:
Style Loss : 0.359584 Content Loss: 0.021875

run [2400]:
Style Loss : 0.357808 Content Loss: 0.021945

run [2450]:
Style Loss : 0.356253 Content Loss: 0.022001

run [2500]:
Style Loss : 0.354737 Content Loss: 0.022063

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.445318 Content Loss: 0.004057

run [100]:
Style Loss : 2.588083 Content Loss: 0.005790

run [150]:
Style Loss : 1.991979 Content Loss: 0.007923

run [200]:
Style Loss : 1.668799 Content Loss: 0.009625

run [250]:
Style Loss : 1.476329 Content Loss: 0.011157

run [300]:
Style Loss : 1.353496 Content Loss: 0.012327

run [350]:
Style Loss : 1.263810 Content Loss: 0.013380

run [400]:
Style Loss : 1.197729 Content Loss: 0.014463

run [450]:
Style Loss : 1.144683 Content Loss: 0.015220

run [500]:
Style Loss : 1.096580 Content Loss: 0.015847

run [550]:
Style Loss : 1.059905 Content Loss: 0.016422

run [600]:
Style Loss : 1.030297 Content Loss: 0.016858

run [650]:
Style Loss : 1.002838 Content Loss: 0.017379

run [700]:
Style Loss : 0.978384 Content Loss: 0.017735

run [750]:
Style Loss : 0.958240 Content Loss: 0.018129

run [800]:
Style Loss : 0.940419 Content Loss: 0.018497

run [850]:
Style Loss : 0.923974 Content Loss: 0.018887

run [900]:
Style Loss : 0.909756 Content Loss: 0.019232

run [950]:
Style Loss : 0.897571 Content Loss: 0.019527

run [1000]:
Style Loss : 0.886238 Content Loss: 0.019771

run [1050]:
Style Loss : 0.875521 Content Loss: 0.020057

run [1100]:
Style Loss : 0.865883 Content Loss: 0.020284

run [1150]:
Style Loss : 0.857358 Content Loss: 0.020481

run [1200]:
Style Loss : 0.849581 Content Loss: 0.020665

run [1250]:
Style Loss : 0.842169 Content Loss: 0.020872

run [1300]:
Style Loss : 0.834977 Content Loss: 0.021083

run [1350]:
Style Loss : 0.827687 Content Loss: 0.021242

run [1400]:
Style Loss : 0.821026 Content Loss: 0.021384

run [1450]:
Style Loss : 0.814197 Content Loss: 0.021546

run [1500]:
Style Loss : 0.807667 Content Loss: 0.021714

run [1550]:
Style Loss : 0.801574 Content Loss: 0.021879

run [1600]:
Style Loss : 0.795950 Content Loss: 0.022016

run [1650]:
Style Loss : 0.790868 Content Loss: 0.022147

run [1700]:
Style Loss : 0.785868 Content Loss: 0.022268

run [1750]:
Style Loss : 0.781201 Content Loss: 0.022384

run [1800]:
Style Loss : 0.776712 Content Loss: 0.022496

run [1850]:
Style Loss : 0.772685 Content Loss: 0.022599

run [1900]:
Style Loss : 0.768712 Content Loss: 0.022698

run [1950]:
Style Loss : 0.765143 Content Loss: 0.022793

run [2000]:
Style Loss : 0.761821 Content Loss: 0.022890

run [2050]:
Style Loss : 0.758722 Content Loss: 0.022978

run [2100]:
Style Loss : 0.756005 Content Loss: 0.023046

run [2150]:
Style Loss : 0.753045 Content Loss: 0.023134

run [2200]:
Style Loss : 0.750391 Content Loss: 0.023202

run [2250]:
Style Loss : 0.747899 Content Loss: 0.023291

run [2300]:
Style Loss : 0.745544 Content Loss: 0.023364

run [2350]:
Style Loss : 0.743240 Content Loss: 0.023439

run [2400]:
Style Loss : 0.740815 Content Loss: 0.023515

run [2450]:
Style Loss : 0.738755 Content Loss: 0.023571

run [2500]:
Style Loss : 0.736876 Content Loss: 0.023626

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.997734 Content Loss: 0.003636

run [100]:
Style Loss : 1.347646 Content Loss: 0.005372

run [150]:
Style Loss : 0.863894 Content Loss: 0.007394

run [200]:
Style Loss : 0.651836 Content Loss: 0.009371

run [250]:
Style Loss : 0.530583 Content Loss: 0.010691

run [300]:
Style Loss : 0.453499 Content Loss: 0.011946

run [350]:
Style Loss : 0.399210 Content Loss: 0.012921

run [400]:
Style Loss : 0.357231 Content Loss: 0.013737

run [450]:
Style Loss : 0.324480 Content Loss: 0.014503

run [500]:
Style Loss : 0.303455 Content Loss: 0.015022

run [550]:
Style Loss : 0.287302 Content Loss: 0.015440

run [600]:
Style Loss : 0.274558 Content Loss: 0.015790

run [650]:
Style Loss : 0.264032 Content Loss: 0.016183

run [700]:
Style Loss : 0.253379 Content Loss: 0.016472

run [750]:
Style Loss : 0.250860 Content Loss: 0.016759

run [800]:
Style Loss : 0.237022 Content Loss: 0.016943

run [850]:
Style Loss : 0.230504 Content Loss: 0.017111

run [900]:
Style Loss : 0.225080 Content Loss: 0.017249

run [950]:
Style Loss : 0.220261 Content Loss: 0.017368

run [1000]:
Style Loss : 0.215536 Content Loss: 0.017445

run [1050]:
Style Loss : 0.211744 Content Loss: 0.017524

run [1100]:
Style Loss : 0.208042 Content Loss: 0.017596

run [1150]:
Style Loss : 0.204741 Content Loss: 0.017680

run [1200]:
Style Loss : 0.202036 Content Loss: 0.017744

run [1250]:
Style Loss : 0.199565 Content Loss: 0.017807

run [1300]:
Style Loss : 0.197079 Content Loss: 0.017860

run [1350]:
Style Loss : 0.194658 Content Loss: 0.017921

run [1400]:
Style Loss : 0.192298 Content Loss: 0.017993

run [1450]:
Style Loss : 0.190235 Content Loss: 0.018042

run [1500]:
Style Loss : 0.188181 Content Loss: 0.018090

run [1550]:
Style Loss : 0.186384 Content Loss: 0.018133

run [1600]:
Style Loss : 0.184722 Content Loss: 0.018185

run [1650]:
Style Loss : 0.183064 Content Loss: 0.018241

run [1700]:
Style Loss : 0.181730 Content Loss: 0.018283

run [1750]:
Style Loss : 0.180440 Content Loss: 0.018322

run [1800]:
Style Loss : 0.179235 Content Loss: 0.018367

run [1850]:
Style Loss : 0.178097 Content Loss: 0.018408

run [1900]:
Style Loss : 0.176887 Content Loss: 0.018457

run [1950]:
Style Loss : 0.175738 Content Loss: 0.018499

run [2000]:
Style Loss : 0.174704 Content Loss: 0.018549

run [2050]:
Style Loss : 0.173614 Content Loss: 0.018607

run [2100]:
Style Loss : 0.172622 Content Loss: 0.018655

run [2150]:
Style Loss : 0.171562 Content Loss: 0.018713

run [2200]:
Style Loss : 0.170393 Content Loss: 0.018780

run [2250]:
Style Loss : 0.169178 Content Loss: 0.018854

run [2300]:
Style Loss : 0.168075 Content Loss: 0.018907

run [2350]:
Style Loss : 0.167065 Content Loss: 0.018963

run [2400]:
Style Loss : 0.166050 Content Loss: 0.019022

run [2450]:
Style Loss : 0.165070 Content Loss: 0.019069

run [2500]:
Style Loss : 0.164121 Content Loss: 0.019115

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.446011 Content Loss: 0.005552

run [100]:
Style Loss : 1.239169 Content Loss: 0.009027

run [150]:
Style Loss : 0.918974 Content Loss: 0.011184

run [200]:
Style Loss : 0.763767 Content Loss: 0.012675

run [250]:
Style Loss : 0.677999 Content Loss: 0.013835

run [300]:
Style Loss : 0.619866 Content Loss: 0.014862

run [350]:
Style Loss : 0.574309 Content Loss: 0.015609

run [400]:
Style Loss : 0.542545 Content Loss: 0.016290

run [450]:
Style Loss : 0.519431 Content Loss: 0.016881

run [500]:
Style Loss : 0.501512 Content Loss: 0.017379

run [550]:
Style Loss : 0.487395 Content Loss: 0.017818

run [600]:
Style Loss : 0.475681 Content Loss: 0.018246

run [650]:
Style Loss : 0.466056 Content Loss: 0.018626

run [700]:
Style Loss : 0.457478 Content Loss: 0.018961

run [750]:
Style Loss : 0.449694 Content Loss: 0.019305

run [800]:
Style Loss : 0.442196 Content Loss: 0.019626

run [850]:
Style Loss : 0.435826 Content Loss: 0.019923

run [900]:
Style Loss : 0.430349 Content Loss: 0.020189

run [950]:
Style Loss : 0.424785 Content Loss: 0.020478

run [1000]:
Style Loss : 0.419556 Content Loss: 0.020762

run [1050]:
Style Loss : 0.414975 Content Loss: 0.021029

run [1100]:
Style Loss : 0.410618 Content Loss: 0.021280

run [1150]:
Style Loss : 0.406463 Content Loss: 0.021510

run [1200]:
Style Loss : 0.402621 Content Loss: 0.021761

run [1250]:
Style Loss : 0.398813 Content Loss: 0.022011

run [1300]:
Style Loss : 0.395087 Content Loss: 0.022262

run [1350]:
Style Loss : 0.391597 Content Loss: 0.022494

run [1400]:
Style Loss : 0.388190 Content Loss: 0.022758

run [1450]:
Style Loss : 0.384702 Content Loss: 0.023011

run [1500]:
Style Loss : 0.381265 Content Loss: 0.023248

run [1550]:
Style Loss : 0.377648 Content Loss: 0.023515

run [1600]:
Style Loss : 0.374220 Content Loss: 0.023785

run [1650]:
Style Loss : 0.370915 Content Loss: 0.024024

run [1700]:
Style Loss : 0.367854 Content Loss: 0.024260

run [1750]:
Style Loss : 0.364838 Content Loss: 0.024504

run [1800]:
Style Loss : 0.361924 Content Loss: 0.024763

run [1850]:
Style Loss : 0.358995 Content Loss: 0.025018

run [1900]:
Style Loss : 0.355682 Content Loss: 0.025277

run [1950]:
Style Loss : 0.352641 Content Loss: 0.025519

run [2000]:
Style Loss : 0.348948 Content Loss: 0.025777

run [2050]:
Style Loss : 0.345825 Content Loss: 0.026021

run [2100]:
Style Loss : 0.342984 Content Loss: 0.026241

run [2150]:
Style Loss : 0.340343 Content Loss: 0.026491

run [2200]:
Style Loss : 0.337709 Content Loss: 0.026721

run [2250]:
Style Loss : 0.335335 Content Loss: 0.026940

run [2300]:
Style Loss : 0.332904 Content Loss: 0.027192

run [2350]:
Style Loss : 0.330602 Content Loss: 0.027391

run [2400]:
Style Loss : 0.328458 Content Loss: 0.027610

run [2450]:
Style Loss : 0.326371 Content Loss: 0.027831

run [2500]:
Style Loss : 0.324396 Content Loss: 0.027987

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.768497 Content Loss: 0.005218

run [100]:
Style Loss : 0.886537 Content Loss: 0.008657

run [150]:
Style Loss : 0.619841 Content Loss: 0.010310

run [200]:
Style Loss : 0.515383 Content Loss: 0.011255

run [250]:
Style Loss : 0.457552 Content Loss: 0.012048

run [300]:
Style Loss : 0.423605 Content Loss: 0.012583

run [350]:
Style Loss : 0.397229 Content Loss: 0.013071

run [400]:
Style Loss : 0.376563 Content Loss: 0.013502

run [450]:
Style Loss : 0.360548 Content Loss: 0.013846

run [500]:
Style Loss : 0.347142 Content Loss: 0.014159

run [550]:
Style Loss : 0.337175 Content Loss: 0.014455

run [600]:
Style Loss : 0.328615 Content Loss: 0.014772

run [650]:
Style Loss : 0.321891 Content Loss: 0.015027

run [700]:
Style Loss : 0.314899 Content Loss: 0.015292

run [750]:
Style Loss : 0.308704 Content Loss: 0.015543

run [800]:
Style Loss : 0.303198 Content Loss: 0.015812

run [850]:
Style Loss : 0.298174 Content Loss: 0.016046

run [900]:
Style Loss : 0.293092 Content Loss: 0.016291

run [950]:
Style Loss : 0.288677 Content Loss: 0.016490

run [1000]:
Style Loss : 0.284792 Content Loss: 0.016716

run [1050]:
Style Loss : 0.281262 Content Loss: 0.016941

run [1100]:
Style Loss : 0.277680 Content Loss: 0.017172

run [1150]:
Style Loss : 0.274459 Content Loss: 0.017383

run [1200]:
Style Loss : 0.271484 Content Loss: 0.017583

run [1250]:
Style Loss : 0.268537 Content Loss: 0.017823

run [1300]:
Style Loss : 0.265455 Content Loss: 0.018034

run [1350]:
Style Loss : 0.262733 Content Loss: 0.018251

run [1400]:
Style Loss : 0.260020 Content Loss: 0.018484

run [1450]:
Style Loss : 0.257408 Content Loss: 0.018731

run [1500]:
Style Loss : 0.254715 Content Loss: 0.018995

run [1550]:
Style Loss : 0.251983 Content Loss: 0.019271

run [1600]:
Style Loss : 0.249247 Content Loss: 0.019553

run [1650]:
Style Loss : 0.246278 Content Loss: 0.019858

run [1700]:
Style Loss : 0.243447 Content Loss: 0.020108

run [1750]:
Style Loss : 0.241011 Content Loss: 0.020340

run [1800]:
Style Loss : 0.238674 Content Loss: 0.020610

run [1850]:
Style Loss : 0.236622 Content Loss: 0.020875

run [1900]:
Style Loss : 0.234130 Content Loss: 0.021085

run [1950]:
Style Loss : 0.231521 Content Loss: 0.021323

run [2000]:
Style Loss : 0.229285 Content Loss: 0.021577

run [2050]:
Style Loss : 0.227255 Content Loss: 0.021877

run [2100]:
Style Loss : 0.224859 Content Loss: 0.022058

run [2150]:
Style Loss : 0.222778 Content Loss: 0.022305

run [2200]:
Style Loss : 0.220465 Content Loss: 0.022458

run [2250]:
Style Loss : 0.218769 Content Loss: 0.022697

run [2300]:
Style Loss : 0.217141 Content Loss: 0.022867

run [2350]:
Style Loss : 0.217045 Content Loss: 0.023062

run [2400]:
Style Loss : 0.214331 Content Loss: 0.023188

run [2450]:
Style Loss : 0.214898 Content Loss: 0.023470

run [2500]:
Style Loss : 0.211282 Content Loss: 0.023526

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.785927 Content Loss: 0.006717

run [100]:
Style Loss : 0.422190 Content Loss: 0.009040

run [150]:
Style Loss : 0.316839 Content Loss: 0.010679

run [200]:
Style Loss : 0.263853 Content Loss: 0.011807

run [250]:
Style Loss : 0.230558 Content Loss: 0.013056

run [300]:
Style Loss : 0.206487 Content Loss: 0.014052

run [350]:
Style Loss : 0.189584 Content Loss: 0.014895

run [400]:
Style Loss : 0.177485 Content Loss: 0.015607

run [450]:
Style Loss : 0.168397 Content Loss: 0.016162

run [500]:
Style Loss : 0.161822 Content Loss: 0.016626

run [550]:
Style Loss : 0.156632 Content Loss: 0.017022

run [600]:
Style Loss : 0.152430 Content Loss: 0.017388

run [650]:
Style Loss : 0.148905 Content Loss: 0.017725

run [700]:
Style Loss : 0.145841 Content Loss: 0.018015

run [750]:
Style Loss : 0.143189 Content Loss: 0.018270

run [800]:
Style Loss : 0.140970 Content Loss: 0.018500

run [850]:
Style Loss : 0.138972 Content Loss: 0.018714

run [900]:
Style Loss : 0.137009 Content Loss: 0.018912

run [950]:
Style Loss : 0.135171 Content Loss: 0.019089

run [1000]:
Style Loss : 0.133599 Content Loss: 0.019229

run [1050]:
Style Loss : 0.132149 Content Loss: 0.019377

run [1100]:
Style Loss : 0.130864 Content Loss: 0.019508

run [1150]:
Style Loss : 0.129697 Content Loss: 0.019627

run [1200]:
Style Loss : 0.128697 Content Loss: 0.019736

run [1250]:
Style Loss : 0.127758 Content Loss: 0.019849

run [1300]:
Style Loss : 0.126895 Content Loss: 0.019953

run [1350]:
Style Loss : 0.125869 Content Loss: 0.020062

run [1400]:
Style Loss : 0.124937 Content Loss: 0.020137

run [1450]:
Style Loss : 0.124138 Content Loss: 0.020213

run [1500]:
Style Loss : 0.123335 Content Loss: 0.020291

run [1550]:
Style Loss : 0.122539 Content Loss: 0.020381

run [1600]:
Style Loss : 0.121780 Content Loss: 0.020467

run [1650]:
Style Loss : 0.121051 Content Loss: 0.020552

run [1700]:
Style Loss : 0.120281 Content Loss: 0.020639

run [1750]:
Style Loss : 0.119570 Content Loss: 0.020726

run [1800]:
Style Loss : 0.118909 Content Loss: 0.020792

run [1850]:
Style Loss : 0.118254 Content Loss: 0.020865

run [1900]:
Style Loss : 0.117704 Content Loss: 0.020943

run [1950]:
Style Loss : 0.117157 Content Loss: 0.021025

run [2000]:
Style Loss : 0.116568 Content Loss: 0.021090

run [2050]:
Style Loss : 0.116075 Content Loss: 0.021170

run [2100]:
Style Loss : 0.115501 Content Loss: 0.021250

run [2150]:
Style Loss : 0.115118 Content Loss: 0.021325

run [2200]:
Style Loss : 0.114797 Content Loss: 0.021399

run [2250]:
Style Loss : 0.113904 Content Loss: 0.021447

run [2300]:
Style Loss : 0.113550 Content Loss: 0.021557

run [2350]:
Style Loss : 0.114925 Content Loss: 0.021720

run [2400]:
Style Loss : 0.114881 Content Loss: 0.021805

run [2450]:
Style Loss : 0.112299 Content Loss: 0.021823

run [2500]:
Style Loss : 0.111943 Content Loss: 0.021933

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.133536 Content Loss: 0.005818

run [100]:
Style Loss : 0.591858 Content Loss: 0.008803

run [150]:
Style Loss : 0.456471 Content Loss: 0.010229

run [200]:
Style Loss : 0.395177 Content Loss: 0.011075

run [250]:
Style Loss : 0.354349 Content Loss: 0.011697

run [300]:
Style Loss : 0.325732 Content Loss: 0.012255

run [350]:
Style Loss : 0.304672 Content Loss: 0.012807

run [400]:
Style Loss : 0.288387 Content Loss: 0.013221

run [450]:
Style Loss : 0.276140 Content Loss: 0.013664

run [500]:
Style Loss : 0.266109 Content Loss: 0.014037

run [550]:
Style Loss : 0.256703 Content Loss: 0.014445

run [600]:
Style Loss : 0.248566 Content Loss: 0.014790

run [650]:
Style Loss : 0.240971 Content Loss: 0.015133

run [700]:
Style Loss : 0.234211 Content Loss: 0.015396

run [750]:
Style Loss : 0.227790 Content Loss: 0.015711

run [800]:
Style Loss : 0.222325 Content Loss: 0.015971

run [850]:
Style Loss : 0.217221 Content Loss: 0.016228

run [900]:
Style Loss : 0.212273 Content Loss: 0.016491

run [950]:
Style Loss : 0.207805 Content Loss: 0.016717

run [1000]:
Style Loss : 0.204061 Content Loss: 0.016901

run [1050]:
Style Loss : 0.200850 Content Loss: 0.017069

run [1100]:
Style Loss : 0.198302 Content Loss: 0.017216

run [1150]:
Style Loss : 0.195767 Content Loss: 0.017376

run [1200]:
Style Loss : 0.193235 Content Loss: 0.017549

run [1250]:
Style Loss : 0.190867 Content Loss: 0.017710

run [1300]:
Style Loss : 0.188402 Content Loss: 0.017890

run [1350]:
Style Loss : 0.185931 Content Loss: 0.018051

run [1400]:
Style Loss : 0.183384 Content Loss: 0.018223

run [1450]:
Style Loss : 0.180915 Content Loss: 0.018394

run [1500]:
Style Loss : 0.178669 Content Loss: 0.018553

run [1550]:
Style Loss : 0.176608 Content Loss: 0.018702

run [1600]:
Style Loss : 0.174638 Content Loss: 0.018852

run [1650]:
Style Loss : 0.172804 Content Loss: 0.019018

run [1700]:
Style Loss : 0.171062 Content Loss: 0.019170

run [1750]:
Style Loss : 0.169432 Content Loss: 0.019315

run [1800]:
Style Loss : 0.167806 Content Loss: 0.019476

run [1850]:
Style Loss : 0.166151 Content Loss: 0.019632

run [1900]:
Style Loss : 0.164557 Content Loss: 0.019776

run [1950]:
Style Loss : 0.163062 Content Loss: 0.019919

run [2000]:
Style Loss : 0.161561 Content Loss: 0.020071

run [2050]:
Style Loss : 0.160133 Content Loss: 0.020229

run [2100]:
Style Loss : 0.158695 Content Loss: 0.020389

run [2150]:
Style Loss : 0.157299 Content Loss: 0.020555

run [2200]:
Style Loss : 0.155999 Content Loss: 0.020708

run [2250]:
Style Loss : 0.154758 Content Loss: 0.020861

run [2300]:
Style Loss : 0.153565 Content Loss: 0.020987

run [2350]:
Style Loss : 0.152397 Content Loss: 0.021128

run [2400]:
Style Loss : 0.151273 Content Loss: 0.021253

run [2450]:
Style Loss : 0.150215 Content Loss: 0.021377

run [2500]:
Style Loss : 0.149089 Content Loss: 0.021469

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.797198 Content Loss: 0.002770

run [100]:
Style Loss : 2.002460 Content Loss: 0.005376

run [150]:
Style Loss : 1.388947 Content Loss: 0.007752

run [200]:
Style Loss : 1.092385 Content Loss: 0.009149

run [250]:
Style Loss : 0.911652 Content Loss: 0.010222

run [300]:
Style Loss : 0.793247 Content Loss: 0.010982

run [350]:
Style Loss : 0.712386 Content Loss: 0.011707

run [400]:
Style Loss : 0.645473 Content Loss: 0.012319

run [450]:
Style Loss : 0.594257 Content Loss: 0.012747

run [500]:
Style Loss : 0.555989 Content Loss: 0.013044

run [550]:
Style Loss : 0.525178 Content Loss: 0.013391

run [600]:
Style Loss : 0.502104 Content Loss: 0.013722

run [650]:
Style Loss : 0.483078 Content Loss: 0.014001

run [700]:
Style Loss : 0.466695 Content Loss: 0.014285

run [750]:
Style Loss : 0.453852 Content Loss: 0.014521

run [800]:
Style Loss : 0.442893 Content Loss: 0.014756

run [850]:
Style Loss : 0.433579 Content Loss: 0.014951

run [900]:
Style Loss : 0.425567 Content Loss: 0.015154

run [950]:
Style Loss : 0.418653 Content Loss: 0.015300

run [1000]:
Style Loss : 0.412734 Content Loss: 0.015463

run [1050]:
Style Loss : 0.407443 Content Loss: 0.015604

run [1100]:
Style Loss : 0.402813 Content Loss: 0.015750

run [1150]:
Style Loss : 0.398408 Content Loss: 0.015879

run [1200]:
Style Loss : 0.394486 Content Loss: 0.016008

run [1250]:
Style Loss : 0.390940 Content Loss: 0.016115

run [1300]:
Style Loss : 0.387825 Content Loss: 0.016206

run [1350]:
Style Loss : 0.385044 Content Loss: 0.016316

run [1400]:
Style Loss : 0.382283 Content Loss: 0.016411

run [1450]:
Style Loss : 0.379603 Content Loss: 0.016517

run [1500]:
Style Loss : 0.377075 Content Loss: 0.016611

run [1550]:
Style Loss : 0.374821 Content Loss: 0.016705

run [1600]:
Style Loss : 0.372900 Content Loss: 0.016768

run [1650]:
Style Loss : 0.371165 Content Loss: 0.016838

run [1700]:
Style Loss : 0.369464 Content Loss: 0.016907

run [1750]:
Style Loss : 0.367817 Content Loss: 0.016972

run [1800]:
Style Loss : 0.366245 Content Loss: 0.017028

run [1850]:
Style Loss : 0.364668 Content Loss: 0.017099

run [1900]:
Style Loss : 0.363125 Content Loss: 0.017162

run [1950]:
Style Loss : 0.361729 Content Loss: 0.017219

run [2000]:
Style Loss : 0.360444 Content Loss: 0.017275

run [2050]:
Style Loss : 0.359197 Content Loss: 0.017315

run [2100]:
Style Loss : 0.358082 Content Loss: 0.017353

run [2150]:
Style Loss : 0.357217 Content Loss: 0.017399

run [2200]:
Style Loss : 0.356160 Content Loss: 0.017424

run [2250]:
Style Loss : 0.355247 Content Loss: 0.017457

run [2300]:
Style Loss : 0.354222 Content Loss: 0.017491

run [2350]:
Style Loss : 0.353107 Content Loss: 0.017534

run [2400]:
Style Loss : 0.352127 Content Loss: 0.017574

run [2450]:
Style Loss : 0.351291 Content Loss: 0.017598

run [2500]:
Style Loss : 0.350558 Content Loss: 0.017622

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.760135 Content Loss: 0.006131

run [100]:
Style Loss : 0.402120 Content Loss: 0.009474

run [150]:
Style Loss : 0.275135 Content Loss: 0.011245

run [200]:
Style Loss : 0.218180 Content Loss: 0.012321

run [250]:
Style Loss : 0.182531 Content Loss: 0.013267

run [300]:
Style Loss : 0.161260 Content Loss: 0.014106

run [350]:
Style Loss : 0.146281 Content Loss: 0.014699

run [400]:
Style Loss : 0.135032 Content Loss: 0.015238

run [450]:
Style Loss : 0.126268 Content Loss: 0.015689

run [500]:
Style Loss : 0.119344 Content Loss: 0.016100

run [550]:
Style Loss : 0.113596 Content Loss: 0.016470

run [600]:
Style Loss : 0.109014 Content Loss: 0.016777

run [650]:
Style Loss : 0.105276 Content Loss: 0.017071

run [700]:
Style Loss : 0.102154 Content Loss: 0.017308

run [750]:
Style Loss : 0.099207 Content Loss: 0.017576

run [800]:
Style Loss : 0.096406 Content Loss: 0.017842

run [850]:
Style Loss : 0.093689 Content Loss: 0.018066

run [900]:
Style Loss : 0.091371 Content Loss: 0.018286

run [950]:
Style Loss : 0.089426 Content Loss: 0.018449

run [1000]:
Style Loss : 0.087616 Content Loss: 0.018618

run [1050]:
Style Loss : 0.085850 Content Loss: 0.018776

run [1100]:
Style Loss : 0.084229 Content Loss: 0.018936

run [1150]:
Style Loss : 0.082786 Content Loss: 0.019087

run [1200]:
Style Loss : 0.081280 Content Loss: 0.019222

run [1250]:
Style Loss : 0.079947 Content Loss: 0.019343

run [1300]:
Style Loss : 0.078735 Content Loss: 0.019466

run [1350]:
Style Loss : 0.077506 Content Loss: 0.019559

run [1400]:
Style Loss : 0.076456 Content Loss: 0.019626

run [1450]:
Style Loss : 0.075497 Content Loss: 0.019686

run [1500]:
Style Loss : 0.074580 Content Loss: 0.019735

run [1550]:
Style Loss : 0.073726 Content Loss: 0.019787

run [1600]:
Style Loss : 0.073011 Content Loss: 0.019825

run [1650]:
Style Loss : 0.072402 Content Loss: 0.019856

run [1700]:
Style Loss : 0.071831 Content Loss: 0.019881

run [1750]:
Style Loss : 0.071311 Content Loss: 0.019901

run [1800]:
Style Loss : 0.070838 Content Loss: 0.019903

run [1850]:
Style Loss : 0.070407 Content Loss: 0.019903

run [1900]:
Style Loss : 0.069988 Content Loss: 0.019906

run [1950]:
Style Loss : 0.069611 Content Loss: 0.019909

run [2000]:
Style Loss : 0.069260 Content Loss: 0.019917

run [2050]:
Style Loss : 0.068932 Content Loss: 0.019928

run [2100]:
Style Loss : 0.068624 Content Loss: 0.019938

run [2150]:
Style Loss : 0.068324 Content Loss: 0.019938

run [2200]:
Style Loss : 0.068044 Content Loss: 0.019944

run [2250]:
Style Loss : 0.067772 Content Loss: 0.019945

run [2300]:
Style Loss : 0.067498 Content Loss: 0.019955

run [2350]:
Style Loss : 0.067194 Content Loss: 0.019965

run [2400]:
Style Loss : 0.066913 Content Loss: 0.019974

run [2450]:
Style Loss : 0.066635 Content Loss: 0.019986

run [2500]:
Style Loss : 0.066329 Content Loss: 0.019999

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.999865 Content Loss: 0.005265

run [100]:
Style Loss : 1.128758 Content Loss: 0.008628

run [150]:
Style Loss : 0.838232 Content Loss: 0.010551

run [200]:
Style Loss : 0.691028 Content Loss: 0.011980

run [250]:
Style Loss : 0.599157 Content Loss: 0.013081

run [300]:
Style Loss : 0.535073 Content Loss: 0.014119

run [350]:
Style Loss : 0.486241 Content Loss: 0.014965

run [400]:
Style Loss : 0.451470 Content Loss: 0.015771

run [450]:
Style Loss : 0.426340 Content Loss: 0.016481

run [500]:
Style Loss : 0.405664 Content Loss: 0.017103

run [550]:
Style Loss : 0.384730 Content Loss: 0.017744

run [600]:
Style Loss : 0.367362 Content Loss: 0.018241

run [650]:
Style Loss : 0.352534 Content Loss: 0.018614

run [700]:
Style Loss : 0.337761 Content Loss: 0.018977

run [750]:
Style Loss : 0.325212 Content Loss: 0.019293

run [800]:
Style Loss : 0.312961 Content Loss: 0.019579

run [850]:
Style Loss : 0.303715 Content Loss: 0.019786

run [900]:
Style Loss : 0.295880 Content Loss: 0.020033

run [950]:
Style Loss : 0.288251 Content Loss: 0.020271

run [1000]:
Style Loss : 0.282417 Content Loss: 0.020470

run [1050]:
Style Loss : 0.277343 Content Loss: 0.020668

run [1100]:
Style Loss : 0.272539 Content Loss: 0.020839

run [1150]:
Style Loss : 0.268631 Content Loss: 0.020997

run [1200]:
Style Loss : 0.265235 Content Loss: 0.021147

run [1250]:
Style Loss : 0.262380 Content Loss: 0.021277

run [1300]:
Style Loss : 0.259765 Content Loss: 0.021407

run [1350]:
Style Loss : 0.257388 Content Loss: 0.021528

run [1400]:
Style Loss : 0.255303 Content Loss: 0.021640

run [1450]:
Style Loss : 0.253115 Content Loss: 0.021774

run [1500]:
Style Loss : 0.251034 Content Loss: 0.021887

run [1550]:
Style Loss : 0.249077 Content Loss: 0.022007

run [1600]:
Style Loss : 0.247231 Content Loss: 0.022117

run [1650]:
Style Loss : 0.245509 Content Loss: 0.022211

run [1700]:
Style Loss : 0.243956 Content Loss: 0.022309

run [1750]:
Style Loss : 0.242348 Content Loss: 0.022403

run [1800]:
Style Loss : 0.240946 Content Loss: 0.022480

run [1850]:
Style Loss : 0.239639 Content Loss: 0.022561

run [1900]:
Style Loss : 0.238404 Content Loss: 0.022622

run [1950]:
Style Loss : 0.237286 Content Loss: 0.022679

run [2000]:
Style Loss : 0.236247 Content Loss: 0.022739

run [2050]:
Style Loss : 0.235295 Content Loss: 0.022800

run [2100]:
Style Loss : 0.234344 Content Loss: 0.022859

run [2150]:
Style Loss : 0.233489 Content Loss: 0.022910

run [2200]:
Style Loss : 0.232671 Content Loss: 0.022962

run [2250]:
Style Loss : 0.231905 Content Loss: 0.023008

run [2300]:
Style Loss : 0.231187 Content Loss: 0.023047

run [2350]:
Style Loss : 0.230524 Content Loss: 0.023085

run [2400]:
Style Loss : 0.229866 Content Loss: 0.023121

run [2450]:
Style Loss : 0.229283 Content Loss: 0.023154

run [2500]:
Style Loss : 0.228739 Content Loss: 0.023184

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.199347 Content Loss: 0.002858

run [100]:
Style Loss : 0.768765 Content Loss: 0.004699

run [150]:
Style Loss : 0.599589 Content Loss: 0.006471

run [200]:
Style Loss : 0.503679 Content Loss: 0.007751

run [250]:
Style Loss : 0.445736 Content Loss: 0.008756

run [300]:
Style Loss : 0.407719 Content Loss: 0.009447

run [350]:
Style Loss : 0.381063 Content Loss: 0.009950

run [400]:
Style Loss : 0.361584 Content Loss: 0.010379

run [450]:
Style Loss : 0.346459 Content Loss: 0.010654

run [500]:
Style Loss : 0.334320 Content Loss: 0.010892

run [550]:
Style Loss : 0.324644 Content Loss: 0.011075

run [600]:
Style Loss : 0.316775 Content Loss: 0.011237

run [650]:
Style Loss : 0.309986 Content Loss: 0.011397

run [700]:
Style Loss : 0.304178 Content Loss: 0.011554

run [750]:
Style Loss : 0.299450 Content Loss: 0.011713

run [800]:
Style Loss : 0.295405 Content Loss: 0.011859

run [850]:
Style Loss : 0.291654 Content Loss: 0.012004

run [900]:
Style Loss : 0.288207 Content Loss: 0.012126

run [950]:
Style Loss : 0.284948 Content Loss: 0.012231

run [1000]:
Style Loss : 0.281976 Content Loss: 0.012334

run [1050]:
Style Loss : 0.279197 Content Loss: 0.012434

run [1100]:
Style Loss : 0.276751 Content Loss: 0.012508

run [1150]:
Style Loss : 0.274652 Content Loss: 0.012578

run [1200]:
Style Loss : 0.272862 Content Loss: 0.012648

run [1250]:
Style Loss : 0.271358 Content Loss: 0.012713

run [1300]:
Style Loss : 0.270058 Content Loss: 0.012772

run [1350]:
Style Loss : 0.268789 Content Loss: 0.012838

run [1400]:
Style Loss : 0.267567 Content Loss: 0.012886

run [1450]:
Style Loss : 0.266447 Content Loss: 0.012933

run [1500]:
Style Loss : 0.265449 Content Loss: 0.012976

run [1550]:
Style Loss : 0.264458 Content Loss: 0.013021

run [1600]:
Style Loss : 0.263482 Content Loss: 0.013070

run [1650]:
Style Loss : 0.262549 Content Loss: 0.013113

run [1700]:
Style Loss : 0.261697 Content Loss: 0.013157

run [1750]:
Style Loss : 0.260941 Content Loss: 0.013192

run [1800]:
Style Loss : 0.260213 Content Loss: 0.013226

run [1850]:
Style Loss : 0.259490 Content Loss: 0.013262

run [1900]:
Style Loss : 0.258786 Content Loss: 0.013301

run [1950]:
Style Loss : 0.258102 Content Loss: 0.013337

run [2000]:
Style Loss : 0.257460 Content Loss: 0.013367

run [2050]:
Style Loss : 0.256833 Content Loss: 0.013401

run [2100]:
Style Loss : 0.256231 Content Loss: 0.013441

run [2150]:
Style Loss : 0.255671 Content Loss: 0.013470

run [2200]:
Style Loss : 0.255138 Content Loss: 0.013506

run [2250]:
Style Loss : 0.254625 Content Loss: 0.013538

run [2300]:
Style Loss : 0.254076 Content Loss: 0.013577

run [2350]:
Style Loss : 0.253592 Content Loss: 0.013606

run [2400]:
Style Loss : 0.253101 Content Loss: 0.013637

run [2450]:
Style Loss : 0.252632 Content Loss: 0.013665

run [2500]:
Style Loss : 0.252113 Content Loss: 0.013692

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.430148 Content Loss: 0.001900

run [100]:
Style Loss : 0.768919 Content Loss: 0.003496

run [150]:
Style Loss : 0.541590 Content Loss: 0.004937

run [200]:
Style Loss : 0.429011 Content Loss: 0.006136

run [250]:
Style Loss : 0.359196 Content Loss: 0.007042

run [300]:
Style Loss : 0.314721 Content Loss: 0.007874

run [350]:
Style Loss : 0.285727 Content Loss: 0.008574

run [400]:
Style Loss : 0.265116 Content Loss: 0.009113

run [450]:
Style Loss : 0.249526 Content Loss: 0.009487

run [500]:
Style Loss : 0.236978 Content Loss: 0.009836

run [550]:
Style Loss : 0.226475 Content Loss: 0.010062

run [600]:
Style Loss : 0.217605 Content Loss: 0.010255

run [650]:
Style Loss : 0.210464 Content Loss: 0.010447

run [700]:
Style Loss : 0.204387 Content Loss: 0.010590

run [750]:
Style Loss : 0.198553 Content Loss: 0.010739

run [800]:
Style Loss : 0.193522 Content Loss: 0.010829

run [850]:
Style Loss : 0.188872 Content Loss: 0.010934

run [900]:
Style Loss : 0.184865 Content Loss: 0.011016

run [950]:
Style Loss : 0.181262 Content Loss: 0.011104

run [1000]:
Style Loss : 0.177603 Content Loss: 0.011199

run [1050]:
Style Loss : 0.174142 Content Loss: 0.011287

run [1100]:
Style Loss : 0.171013 Content Loss: 0.011368

run [1150]:
Style Loss : 0.168109 Content Loss: 0.011430

run [1200]:
Style Loss : 0.165384 Content Loss: 0.011504

run [1250]:
Style Loss : 0.162848 Content Loss: 0.011565

run [1300]:
Style Loss : 0.160275 Content Loss: 0.011648

run [1350]:
Style Loss : 0.157845 Content Loss: 0.011729

run [1400]:
Style Loss : 0.155651 Content Loss: 0.011797

run [1450]:
Style Loss : 0.153794 Content Loss: 0.011852

run [1500]:
Style Loss : 0.152076 Content Loss: 0.011913

run [1550]:
Style Loss : 0.150394 Content Loss: 0.011973

run [1600]:
Style Loss : 0.954249 Content Loss: 0.012038

run [1650]:
Style Loss : 0.165475 Content Loss: 0.012013

run [1700]:
Style Loss : 0.150583 Content Loss: 0.012048

run [1750]:
Style Loss : 0.144387 Content Loss: 0.012126

run [1800]:
Style Loss : 0.140273 Content Loss: 0.012220

run [1850]:
Style Loss : 0.137385 Content Loss: 0.012289

run [1900]:
Style Loss : 0.135037 Content Loss: 0.012349

run [1950]:
Style Loss : 0.133098 Content Loss: 0.012405

run [2000]:
Style Loss : 0.131310 Content Loss: 0.012451

run [2050]:
Style Loss : 0.129821 Content Loss: 0.012485

run [2100]:
Style Loss : 0.128463 Content Loss: 0.012522

run [2150]:
Style Loss : 0.127218 Content Loss: 0.012553

run [2200]:
Style Loss : 0.126176 Content Loss: 0.012581

run [2250]:
Style Loss : 0.125171 Content Loss: 0.012616

run [2300]:
Style Loss : 0.124275 Content Loss: 0.012641

run [2350]:
Style Loss : 0.123428 Content Loss: 0.012668

run [2400]:
Style Loss : 0.122603 Content Loss: 0.012690

run [2450]:
Style Loss : 0.121795 Content Loss: 0.012724

run [2500]:
Style Loss : 0.121065 Content Loss: 0.012750

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.607285 Content Loss: 0.002470

run [100]:
Style Loss : 1.353516 Content Loss: 0.004096

run [150]:
Style Loss : 0.851898 Content Loss: 0.004880

run [200]:
Style Loss : 0.669419 Content Loss: 0.005598

run [250]:
Style Loss : 0.570429 Content Loss: 0.006229

run [300]:
Style Loss : 0.511613 Content Loss: 0.006707

run [350]:
Style Loss : 0.471160 Content Loss: 0.007129

run [400]:
Style Loss : 0.436341 Content Loss: 0.007517

run [450]:
Style Loss : 0.411738 Content Loss: 0.007815

run [500]:
Style Loss : 0.394732 Content Loss: 0.008037

run [550]:
Style Loss : 0.381328 Content Loss: 0.008265

run [600]:
Style Loss : 0.369489 Content Loss: 0.008446

run [650]:
Style Loss : 0.359595 Content Loss: 0.008592

run [700]:
Style Loss : 0.352283 Content Loss: 0.008697

run [750]:
Style Loss : 0.345739 Content Loss: 0.008802

run [800]:
Style Loss : 0.340289 Content Loss: 0.008872

run [850]:
Style Loss : 0.335383 Content Loss: 0.008953

run [900]:
Style Loss : 0.331150 Content Loss: 0.009018

run [950]:
Style Loss : 0.327106 Content Loss: 0.009079

run [1000]:
Style Loss : 0.322981 Content Loss: 0.009156

run [1050]:
Style Loss : 0.318952 Content Loss: 0.009213

run [1100]:
Style Loss : 0.315259 Content Loss: 0.009278

run [1150]:
Style Loss : 0.312163 Content Loss: 0.009335

run [1200]:
Style Loss : 0.309453 Content Loss: 0.009398

run [1250]:
Style Loss : 0.306771 Content Loss: 0.009460

run [1300]:
Style Loss : 0.304361 Content Loss: 0.009517

run [1350]:
Style Loss : 0.302002 Content Loss: 0.009577

run [1400]:
Style Loss : 0.299662 Content Loss: 0.009645

run [1450]:
Style Loss : 0.297392 Content Loss: 0.009713

run [1500]:
Style Loss : 0.295228 Content Loss: 0.009774

run [1550]:
Style Loss : 0.293155 Content Loss: 0.009830

run [1600]:
Style Loss : 0.291367 Content Loss: 0.009890

run [1650]:
Style Loss : 0.289519 Content Loss: 0.009964

run [1700]:
Style Loss : 0.287778 Content Loss: 0.010029

run [1750]:
Style Loss : 0.286057 Content Loss: 0.010100

run [1800]:
Style Loss : 0.284211 Content Loss: 0.010176

run [1850]:
Style Loss : 0.282426 Content Loss: 0.010253

run [1900]:
Style Loss : 0.280625 Content Loss: 0.010327

run [1950]:
Style Loss : 0.278728 Content Loss: 0.010408

run [2000]:
Style Loss : 0.276896 Content Loss: 0.010492

run [2050]:
Style Loss : 0.274944 Content Loss: 0.010572

run [2100]:
Style Loss : 0.273098 Content Loss: 0.010647

run [2150]:
Style Loss : 0.271299 Content Loss: 0.010731

run [2200]:
Style Loss : 0.269488 Content Loss: 0.010813

run [2250]:
Style Loss : 0.267819 Content Loss: 0.010900

run [2300]:
Style Loss : 0.265844 Content Loss: 0.011000

run [2350]:
Style Loss : 0.264054 Content Loss: 0.011090

run [2400]:
Style Loss : 0.262321 Content Loss: 0.011167

run [2450]:
Style Loss : 0.260670 Content Loss: 0.011249

run [2500]:
Style Loss : 0.259040 Content Loss: 0.011332

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.656686 Content Loss: 0.004053

run [100]:
Style Loss : 0.360779 Content Loss: 0.006266

run [150]:
Style Loss : 0.273900 Content Loss: 0.007233

run [200]:
Style Loss : 0.234003 Content Loss: 0.008034

run [250]:
Style Loss : 0.218280 Content Loss: 0.008524

run [300]:
Style Loss : 0.192137 Content Loss: 0.008907

run [350]:
Style Loss : 0.179661 Content Loss: 0.009193

run [400]:
Style Loss : 0.170538 Content Loss: 0.009423

run [450]:
Style Loss : 0.162793 Content Loss: 0.009701

run [500]:
Style Loss : 0.157010 Content Loss: 0.009898

run [550]:
Style Loss : 0.152430 Content Loss: 0.010068

run [600]:
Style Loss : 0.149075 Content Loss: 0.010233

run [650]:
Style Loss : 0.146351 Content Loss: 0.010372

run [700]:
Style Loss : 0.144097 Content Loss: 0.010485

run [750]:
Style Loss : 0.141829 Content Loss: 0.010575

run [800]:
Style Loss : 0.139875 Content Loss: 0.010670

run [850]:
Style Loss : 0.138310 Content Loss: 0.010749

run [900]:
Style Loss : 0.136881 Content Loss: 0.010830

run [950]:
Style Loss : 0.135662 Content Loss: 0.010891

run [1000]:
Style Loss : 0.134592 Content Loss: 0.010927

run [1050]:
Style Loss : 0.133641 Content Loss: 0.010960

run [1100]:
Style Loss : 0.132765 Content Loss: 0.010995

run [1150]:
Style Loss : 0.132029 Content Loss: 0.011020

run [1200]:
Style Loss : 0.131342 Content Loss: 0.011057

run [1250]:
Style Loss : 0.130636 Content Loss: 0.011095

run [1300]:
Style Loss : 0.129915 Content Loss: 0.011135

run [1350]:
Style Loss : 0.129271 Content Loss: 0.011171

run [1400]:
Style Loss : 0.128662 Content Loss: 0.011219

run [1450]:
Style Loss : 0.128053 Content Loss: 0.011248

run [1500]:
Style Loss : 0.127559 Content Loss: 0.011279

run [1550]:
Style Loss : 0.127107 Content Loss: 0.011307

run [1600]:
Style Loss : 0.126708 Content Loss: 0.011321

run [1650]:
Style Loss : 0.126271 Content Loss: 0.011351

run [1700]:
Style Loss : 0.125868 Content Loss: 0.011376

run [1750]:
Style Loss : 0.125647 Content Loss: 0.011420

run [1800]:
Style Loss : 0.125173 Content Loss: 0.011431

run [1850]:
Style Loss : 0.124851 Content Loss: 0.011458

run [1900]:
Style Loss : 0.124490 Content Loss: 0.011483

run [1950]:
Style Loss : 0.124180 Content Loss: 0.011506

run [2000]:
Style Loss : 0.123362 Content Loss: 0.011542

run [2050]:
Style Loss : 0.122967 Content Loss: 0.011590

run [2100]:
Style Loss : 0.122555 Content Loss: 0.011594

run [2150]:
Style Loss : 0.122249 Content Loss: 0.011612

run [2200]:
Style Loss : 0.122004 Content Loss: 0.011643

run [2250]:
Style Loss : 0.121726 Content Loss: 0.011651

run [2300]:
Style Loss : 0.121480 Content Loss: 0.011675

run [2350]:
Style Loss : 0.121259 Content Loss: 0.011684

run [2400]:
Style Loss : 0.121072 Content Loss: 0.011710

run [2450]:
Style Loss : 0.120891 Content Loss: 0.011722

run [2500]:
Style Loss : 0.120684 Content Loss: 0.011728

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.703262 Content Loss: 0.004515

run [100]:
Style Loss : 0.425639 Content Loss: 0.006731

run [150]:
Style Loss : 0.315853 Content Loss: 0.008779

run [200]:
Style Loss : 0.259656 Content Loss: 0.011209

run [250]:
Style Loss : 0.227257 Content Loss: 0.013175

run [300]:
Style Loss : 0.205882 Content Loss: 0.014897

run [350]:
Style Loss : 0.189773 Content Loss: 0.015998

run [400]:
Style Loss : 0.179634 Content Loss: 0.016833

run [450]:
Style Loss : 0.172755 Content Loss: 0.017314

run [500]:
Style Loss : 0.167326 Content Loss: 0.017717

run [550]:
Style Loss : 0.162453 Content Loss: 0.017857

run [600]:
Style Loss : 0.158710 Content Loss: 0.017994

run [650]:
Style Loss : 0.155493 Content Loss: 0.018102

run [700]:
Style Loss : 0.152789 Content Loss: 0.018199

run [750]:
Style Loss : 0.150538 Content Loss: 0.018292

run [800]:
Style Loss : 0.148503 Content Loss: 0.018413

run [850]:
Style Loss : 0.146822 Content Loss: 0.018520

run [900]:
Style Loss : 0.145102 Content Loss: 0.018642

run [950]:
Style Loss : 0.143639 Content Loss: 0.018727

run [1000]:
Style Loss : 0.142280 Content Loss: 0.018853

run [1050]:
Style Loss : 0.140747 Content Loss: 0.018964

run [1100]:
Style Loss : 0.139236 Content Loss: 0.019070

run [1150]:
Style Loss : 0.137794 Content Loss: 0.019151

run [1200]:
Style Loss : 0.136657 Content Loss: 0.019211

run [1250]:
Style Loss : 0.135608 Content Loss: 0.019298

run [1300]:
Style Loss : 0.134735 Content Loss: 0.019354

run [1350]:
Style Loss : 0.133802 Content Loss: 0.019437

run [1400]:
Style Loss : 0.132999 Content Loss: 0.019516

run [1450]:
Style Loss : 0.132146 Content Loss: 0.019580

run [1500]:
Style Loss : 0.131446 Content Loss: 0.019647

run [1550]:
Style Loss : 0.131113 Content Loss: 0.019695

run [1600]:
Style Loss : 0.130254 Content Loss: 0.019781

run [1650]:
Style Loss : 0.129698 Content Loss: 0.019841

run [1700]:
Style Loss : 0.129297 Content Loss: 0.019895

run [1750]:
Style Loss : 0.128740 Content Loss: 0.019942

run [1800]:
Style Loss : 0.127838 Content Loss: 0.020001

run [1850]:
Style Loss : 0.127369 Content Loss: 0.020025

run [1900]:
Style Loss : 0.127020 Content Loss: 0.020081

run [1950]:
Style Loss : 0.126526 Content Loss: 0.020094

run [2000]:
Style Loss : 0.126164 Content Loss: 0.020122

run [2050]:
Style Loss : 0.125819 Content Loss: 0.020144

run [2100]:
Style Loss : 0.125499 Content Loss: 0.020173

run [2150]:
Style Loss : 0.125045 Content Loss: 0.020206

run [2200]:
Style Loss : 0.124713 Content Loss: 0.020246

run [2250]:
Style Loss : 0.124337 Content Loss: 0.020258

run [2300]:
Style Loss : 0.123928 Content Loss: 0.020264

run [2350]:
Style Loss : 0.125492 Content Loss: 0.020383

run [2400]:
Style Loss : 0.123422 Content Loss: 0.020314

run [2450]:
Style Loss : 0.122959 Content Loss: 0.020318

run [2500]:
Style Loss : 0.122648 Content Loss: 0.020331

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.028337 Content Loss: 0.012991

run [100]:
Style Loss : 1.105692 Content Loss: 0.016161

run [150]:
Style Loss : 0.820375 Content Loss: 0.018310

run [200]:
Style Loss : 0.690313 Content Loss: 0.019720

run [250]:
Style Loss : 0.623191 Content Loss: 0.020872

run [300]:
Style Loss : 0.581683 Content Loss: 0.021760

run [350]:
Style Loss : 0.552306 Content Loss: 0.022540

run [400]:
Style Loss : 0.527781 Content Loss: 0.023132

run [450]:
Style Loss : 0.507809 Content Loss: 0.023599

run [500]:
Style Loss : 0.492286 Content Loss: 0.023990

run [550]:
Style Loss : 0.479340 Content Loss: 0.024367

run [600]:
Style Loss : 0.468261 Content Loss: 0.024693

run [650]:
Style Loss : 0.458549 Content Loss: 0.024941

run [700]:
Style Loss : 0.449787 Content Loss: 0.025138

run [750]:
Style Loss : 0.441203 Content Loss: 0.025297

run [800]:
Style Loss : 0.432524 Content Loss: 0.025470

run [850]:
Style Loss : 0.423385 Content Loss: 0.025683

run [900]:
Style Loss : 0.414807 Content Loss: 0.025817

run [950]:
Style Loss : 0.407838 Content Loss: 0.025950

run [1000]:
Style Loss : 0.402226 Content Loss: 0.026047

run [1050]:
Style Loss : 0.397526 Content Loss: 0.026156

run [1100]:
Style Loss : 0.393372 Content Loss: 0.026287

run [1150]:
Style Loss : 0.389393 Content Loss: 0.026419

run [1200]:
Style Loss : 0.385811 Content Loss: 0.026507

run [1250]:
Style Loss : 0.382151 Content Loss: 0.026622

run [1300]:
Style Loss : 0.378862 Content Loss: 0.026734

run [1350]:
Style Loss : 0.376051 Content Loss: 0.026812

run [1400]:
Style Loss : 0.373598 Content Loss: 0.026887

run [1450]:
Style Loss : 0.371118 Content Loss: 0.026966

run [1500]:
Style Loss : 0.367976 Content Loss: 0.027060

run [1550]:
Style Loss : 0.364861 Content Loss: 0.027115

run [1600]:
Style Loss : 0.361818 Content Loss: 0.027172

run [1650]:
Style Loss : 0.359505 Content Loss: 0.027231

run [1700]:
Style Loss : 0.357265 Content Loss: 0.027274

run [1750]:
Style Loss : 0.355204 Content Loss: 0.027322

run [1800]:
Style Loss : 0.353269 Content Loss: 0.027367

run [1850]:
Style Loss : 0.351215 Content Loss: 0.027394

run [1900]:
Style Loss : 0.349235 Content Loss: 0.027452

run [1950]:
Style Loss : 0.347200 Content Loss: 0.027492

run [2000]:
Style Loss : 0.345313 Content Loss: 0.027541

run [2050]:
Style Loss : 0.343759 Content Loss: 0.027555

run [2100]:
Style Loss : 0.342365 Content Loss: 0.027603

run [2150]:
Style Loss : 0.341116 Content Loss: 0.027642

run [2200]:
Style Loss : 0.339863 Content Loss: 0.027661

run [2250]:
Style Loss : 0.338713 Content Loss: 0.027680

run [2300]:
Style Loss : 0.337614 Content Loss: 0.027717

run [2350]:
Style Loss : 0.336613 Content Loss: 0.027738

run [2400]:
Style Loss : 0.335733 Content Loss: 0.027764

run [2450]:
Style Loss : 0.334980 Content Loss: 0.027805

run [2500]:
Style Loss : 0.334023 Content Loss: 0.027808

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.249608 Content Loss: 0.002447

run [100]:
Style Loss : 0.745278 Content Loss: 0.004457

run [150]:
Style Loss : 0.560988 Content Loss: 0.006060

run [200]:
Style Loss : 0.466182 Content Loss: 0.007502

run [250]:
Style Loss : 0.411807 Content Loss: 0.008584

run [300]:
Style Loss : 0.373704 Content Loss: 0.009463

run [350]:
Style Loss : 0.344510 Content Loss: 0.010205

run [400]:
Style Loss : 0.319784 Content Loss: 0.010760

run [450]:
Style Loss : 0.300540 Content Loss: 0.011131

run [500]:
Style Loss : 0.285931 Content Loss: 0.011436

run [550]:
Style Loss : 0.274240 Content Loss: 0.011701

run [600]:
Style Loss : 0.264568 Content Loss: 0.011919

run [650]:
Style Loss : 0.256060 Content Loss: 0.012097

run [700]:
Style Loss : 0.249228 Content Loss: 0.012281

run [750]:
Style Loss : 0.242958 Content Loss: 0.012438

run [800]:
Style Loss : 0.237613 Content Loss: 0.012547

run [850]:
Style Loss : 0.233211 Content Loss: 0.012658

run [900]:
Style Loss : 0.229203 Content Loss: 0.012763

run [950]:
Style Loss : 0.225387 Content Loss: 0.012871

run [1000]:
Style Loss : 0.221798 Content Loss: 0.012947

run [1050]:
Style Loss : 0.218751 Content Loss: 0.013015

run [1100]:
Style Loss : 0.216154 Content Loss: 0.013088

run [1150]:
Style Loss : 0.213772 Content Loss: 0.013157

run [1200]:
Style Loss : 0.211437 Content Loss: 0.013233

run [1250]:
Style Loss : 0.209355 Content Loss: 0.013301

run [1300]:
Style Loss : 0.207475 Content Loss: 0.013356

run [1350]:
Style Loss : 0.205639 Content Loss: 0.013412

run [1400]:
Style Loss : 0.204098 Content Loss: 0.013457

run [1450]:
Style Loss : 0.202701 Content Loss: 0.013509

run [1500]:
Style Loss : 0.201181 Content Loss: 0.013557

run [1550]:
Style Loss : 0.199261 Content Loss: 0.013625

run [1600]:
Style Loss : 0.197618 Content Loss: 0.013668

run [1650]:
Style Loss : 0.196127 Content Loss: 0.013704

run [1700]:
Style Loss : 0.194856 Content Loss: 0.013745

run [1750]:
Style Loss : 0.193665 Content Loss: 0.013783

run [1800]:
Style Loss : 0.192434 Content Loss: 0.013816

run [1850]:
Style Loss : 0.191355 Content Loss: 0.013852

run [1900]:
Style Loss : 0.190298 Content Loss: 0.013881

run [1950]:
Style Loss : 0.189275 Content Loss: 0.013908

run [2000]:
Style Loss : 0.188272 Content Loss: 0.013932

run [2050]:
Style Loss : 0.187336 Content Loss: 0.013968

run [2100]:
Style Loss : 0.186480 Content Loss: 0.013999

run [2150]:
Style Loss : 0.185623 Content Loss: 0.014025

run [2200]:
Style Loss : 0.184729 Content Loss: 0.014060

run [2250]:
Style Loss : 0.183748 Content Loss: 0.014096

run [2300]:
Style Loss : 0.182837 Content Loss: 0.014129

run [2350]:
Style Loss : 0.181909 Content Loss: 0.014156

run [2400]:
Style Loss : 0.181028 Content Loss: 0.014180

run [2450]:
Style Loss : 0.180241 Content Loss: 0.014203

run [2500]:
Style Loss : 0.179530 Content Loss: 0.014221

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.895358 Content Loss: 0.002917

run [100]:
Style Loss : 0.524046 Content Loss: 0.005974

run [150]:
Style Loss : 0.383115 Content Loss: 0.008917

run [200]:
Style Loss : 0.319867 Content Loss: 0.011108

run [250]:
Style Loss : 0.281364 Content Loss: 0.012307

run [300]:
Style Loss : 0.256773 Content Loss: 0.012877

run [350]:
Style Loss : 0.241017 Content Loss: 0.013219

run [400]:
Style Loss : 0.229048 Content Loss: 0.013450

run [450]:
Style Loss : 0.220124 Content Loss: 0.013657

run [500]:
Style Loss : 0.213021 Content Loss: 0.013786

run [550]:
Style Loss : 0.207359 Content Loss: 0.013869

run [600]:
Style Loss : 0.201945 Content Loss: 0.013979

run [650]:
Style Loss : 0.196870 Content Loss: 0.014096

run [700]:
Style Loss : 0.192511 Content Loss: 0.014226

run [750]:
Style Loss : 0.188657 Content Loss: 0.014309

run [800]:
Style Loss : 0.185385 Content Loss: 0.014381

run [850]:
Style Loss : 0.182598 Content Loss: 0.014459

run [900]:
Style Loss : 0.180040 Content Loss: 0.014541

run [950]:
Style Loss : 0.177670 Content Loss: 0.014626

run [1000]:
Style Loss : 0.175486 Content Loss: 0.014724

run [1050]:
Style Loss : 0.173359 Content Loss: 0.014823

run [1100]:
Style Loss : 0.171351 Content Loss: 0.014919

run [1150]:
Style Loss : 0.169509 Content Loss: 0.015019

run [1200]:
Style Loss : 0.167842 Content Loss: 0.015102

run [1250]:
Style Loss : 0.166241 Content Loss: 0.015180

run [1300]:
Style Loss : 0.164748 Content Loss: 0.015255

run [1350]:
Style Loss : 0.163310 Content Loss: 0.015328

run [1400]:
Style Loss : 0.161917 Content Loss: 0.015403

run [1450]:
Style Loss : 0.160588 Content Loss: 0.015472

run [1500]:
Style Loss : 0.159175 Content Loss: 0.015538

run [1550]:
Style Loss : 0.157993 Content Loss: 0.015586

run [1600]:
Style Loss : 0.156927 Content Loss: 0.015635

run [1650]:
Style Loss : 0.155964 Content Loss: 0.015672

run [1700]:
Style Loss : 0.155137 Content Loss: 0.015712

run [1750]:
Style Loss : 0.154414 Content Loss: 0.015741

run [1800]:
Style Loss : 0.153760 Content Loss: 0.015768

run [1850]:
Style Loss : 0.153144 Content Loss: 0.015796

run [1900]:
Style Loss : 0.152531 Content Loss: 0.015824

run [1950]:
Style Loss : 0.151936 Content Loss: 0.015846

run [2000]:
Style Loss : 0.151393 Content Loss: 0.015865

run [2050]:
Style Loss : 0.150910 Content Loss: 0.015876

run [2100]:
Style Loss : 0.150468 Content Loss: 0.015892

run [2150]:
Style Loss : 0.150055 Content Loss: 0.015904

run [2200]:
Style Loss : 0.149685 Content Loss: 0.015912

run [2250]:
Style Loss : 0.149327 Content Loss: 0.015918

run [2300]:
Style Loss : 0.148874 Content Loss: 0.015925

run [2350]:
Style Loss : 0.148571 Content Loss: 0.015932

run [2400]:
Style Loss : 0.148293 Content Loss: 0.015943

run [2450]:
Style Loss : 0.148035 Content Loss: 0.015952

run [2500]:
Style Loss : 0.147804 Content Loss: 0.015959

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.963291 Content Loss: 0.002070

run [100]:
Style Loss : 0.451951 Content Loss: 0.003899

run [150]:
Style Loss : 0.306782 Content Loss: 0.005145

run [200]:
Style Loss : 0.239747 Content Loss: 0.006198

run [250]:
Style Loss : 0.200226 Content Loss: 0.006963

run [300]:
Style Loss : 0.172036 Content Loss: 0.007527

run [350]:
Style Loss : 0.154571 Content Loss: 0.007950

run [400]:
Style Loss : 0.141024 Content Loss: 0.008312

run [450]:
Style Loss : 0.129855 Content Loss: 0.008546

run [500]:
Style Loss : 0.122044 Content Loss: 0.008801

run [550]:
Style Loss : 0.116485 Content Loss: 0.008940

run [600]:
Style Loss : 0.112163 Content Loss: 0.009101

run [650]:
Style Loss : 0.108746 Content Loss: 0.009220

run [700]:
Style Loss : 0.106108 Content Loss: 0.009312

run [750]:
Style Loss : 0.103784 Content Loss: 0.009390

run [800]:
Style Loss : 0.101897 Content Loss: 0.009437

run [850]:
Style Loss : 0.100292 Content Loss: 0.009480

run [900]:
Style Loss : 0.098982 Content Loss: 0.009518

run [950]:
Style Loss : 0.097817 Content Loss: 0.009556

run [1000]:
Style Loss : 0.096779 Content Loss: 0.009599

run [1050]:
Style Loss : 0.095777 Content Loss: 0.009644

run [1100]:
Style Loss : 0.094822 Content Loss: 0.009678

run [1150]:
Style Loss : 0.093915 Content Loss: 0.009715

run [1200]:
Style Loss : 0.093027 Content Loss: 0.009750

run [1250]:
Style Loss : 0.092238 Content Loss: 0.009785

run [1300]:
Style Loss : 0.091470 Content Loss: 0.009820

run [1350]:
Style Loss : 0.090727 Content Loss: 0.009853

run [1400]:
Style Loss : 0.090104 Content Loss: 0.009881

run [1450]:
Style Loss : 0.089474 Content Loss: 0.009909

run [1500]:
Style Loss : 0.088857 Content Loss: 0.009942

run [1550]:
Style Loss : 0.088312 Content Loss: 0.009973

run [1600]:
Style Loss : 0.087772 Content Loss: 0.009997

run [1650]:
Style Loss : 0.087313 Content Loss: 0.010021

run [1700]:
Style Loss : 0.086863 Content Loss: 0.010047

run [1750]:
Style Loss : 0.086467 Content Loss: 0.010071

run [1800]:
Style Loss : 0.086086 Content Loss: 0.010095

run [1850]:
Style Loss : 0.085721 Content Loss: 0.010112

run [1900]:
Style Loss : 0.085397 Content Loss: 0.010133

run [1950]:
Style Loss : 0.085083 Content Loss: 0.010150

run [2000]:
Style Loss : 0.084784 Content Loss: 0.010171

run [2050]:
Style Loss : 0.084454 Content Loss: 0.010191

run [2100]:
Style Loss : 0.084097 Content Loss: 0.010215

run [2150]:
Style Loss : 0.083709 Content Loss: 0.010232

run [2200]:
Style Loss : 0.083357 Content Loss: 0.010253

run [2250]:
Style Loss : 0.083027 Content Loss: 0.010275

run [2300]:
Style Loss : 0.082702 Content Loss: 0.010293

run [2350]:
Style Loss : 0.082390 Content Loss: 0.010305

run [2400]:
Style Loss : 0.082097 Content Loss: 0.010317

run [2450]:
Style Loss : 0.081828 Content Loss: 0.010333

run [2500]:
Style Loss : 0.081541 Content Loss: 0.010349

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.374107 Content Loss: 0.005814

run [100]:
Style Loss : 0.841879 Content Loss: 0.009890

run [150]:
Style Loss : 0.615497 Content Loss: 0.013625

run [200]:
Style Loss : 0.477576 Content Loss: 0.017236

run [250]:
Style Loss : 0.403030 Content Loss: 0.019621

run [300]:
Style Loss : 0.363691 Content Loss: 0.020800

run [350]:
Style Loss : 0.340270 Content Loss: 0.021428

run [400]:
Style Loss : 0.324949 Content Loss: 0.021829

run [450]:
Style Loss : 0.313313 Content Loss: 0.022117

run [500]:
Style Loss : 0.303436 Content Loss: 0.022549

run [550]:
Style Loss : 0.295041 Content Loss: 0.022847

run [600]:
Style Loss : 0.287026 Content Loss: 0.023088

run [650]:
Style Loss : 0.279889 Content Loss: 0.023297

run [700]:
Style Loss : 0.273775 Content Loss: 0.023562

run [750]:
Style Loss : 0.268683 Content Loss: 0.023812

run [800]:
Style Loss : 0.264052 Content Loss: 0.024018

run [850]:
Style Loss : 0.260015 Content Loss: 0.024168

run [900]:
Style Loss : 0.256262 Content Loss: 0.024317

run [950]:
Style Loss : 0.253043 Content Loss: 0.024414

run [1000]:
Style Loss : 0.250266 Content Loss: 0.024489

run [1050]:
Style Loss : 0.247642 Content Loss: 0.024569

run [1100]:
Style Loss : 0.245130 Content Loss: 0.024652

run [1150]:
Style Loss : 0.242812 Content Loss: 0.024700

run [1200]:
Style Loss : 0.240839 Content Loss: 0.024771

run [1250]:
Style Loss : 0.239154 Content Loss: 0.024839

run [1300]:
Style Loss : 0.237244 Content Loss: 0.024924

run [1350]:
Style Loss : 0.235356 Content Loss: 0.025053

run [1400]:
Style Loss : 0.233126 Content Loss: 0.025172

run [1450]:
Style Loss : 0.231117 Content Loss: 0.025266

run [1500]:
Style Loss : 0.229142 Content Loss: 0.025361

run [1550]:
Style Loss : 0.227012 Content Loss: 0.025432

run [1600]:
Style Loss : 0.224867 Content Loss: 0.025506

run [1650]:
Style Loss : 0.222445 Content Loss: 0.025571

run [1700]:
Style Loss : 0.220703 Content Loss: 0.025635

run [1750]:
Style Loss : 0.219115 Content Loss: 0.025672

run [1800]:
Style Loss : 0.218451 Content Loss: 0.025737

run [1850]:
Style Loss : 0.217027 Content Loss: 0.025772

run [1900]:
Style Loss : 0.216092 Content Loss: 0.025832

run [1950]:
Style Loss : 0.215248 Content Loss: 0.025900

run [2000]:
Style Loss : 0.214438 Content Loss: 0.025982

run [2050]:
Style Loss : 0.213007 Content Loss: 0.026067

run [2100]:
Style Loss : 0.211776 Content Loss: 0.026144

run [2150]:
Style Loss : 0.210815 Content Loss: 0.026208

run [2200]:
Style Loss : 0.209815 Content Loss: 0.026266

run [2250]:
Style Loss : 0.208834 Content Loss: 0.026308

run [2300]:
Style Loss : 0.207790 Content Loss: 0.026380

run [2350]:
Style Loss : 0.206806 Content Loss: 0.026423

run [2400]:
Style Loss : 0.206172 Content Loss: 0.026497

run [2450]:
Style Loss : 0.205449 Content Loss: 0.026561

run [2500]:
Style Loss : 0.204633 Content Loss: 0.026584

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.989197 Content Loss: 0.006827

run [100]:
Style Loss : 0.479245 Content Loss: 0.010730

run [150]:
Style Loss : 0.315307 Content Loss: 0.013176

run [200]:
Style Loss : 0.240882 Content Loss: 0.014734

run [250]:
Style Loss : 0.201888 Content Loss: 0.015638

run [300]:
Style Loss : 0.178934 Content Loss: 0.016266

run [350]:
Style Loss : 0.163342 Content Loss: 0.016804

run [400]:
Style Loss : 0.151810 Content Loss: 0.017147

run [450]:
Style Loss : 0.143086 Content Loss: 0.017417

run [500]:
Style Loss : 0.136349 Content Loss: 0.017681

run [550]:
Style Loss : 0.130405 Content Loss: 0.017884

run [600]:
Style Loss : 0.124999 Content Loss: 0.018050

run [650]:
Style Loss : 0.120501 Content Loss: 0.018182

run [700]:
Style Loss : 0.109997 Content Loss: 0.018274

run [750]:
Style Loss : 0.103548 Content Loss: 0.018358

run [800]:
Style Loss : 0.099518 Content Loss: 0.018413

run [850]:
Style Loss : 0.096064 Content Loss: 0.018466

run [900]:
Style Loss : 0.092985 Content Loss: 0.018512

run [950]:
Style Loss : 0.090224 Content Loss: 0.018545

run [1000]:
Style Loss : 0.087650 Content Loss: 0.018590

run [1050]:
Style Loss : 0.085288 Content Loss: 0.018608

run [1100]:
Style Loss : 0.083073 Content Loss: 0.018648

run [1150]:
Style Loss : 0.081169 Content Loss: 0.018658

run [1200]:
Style Loss : 0.079565 Content Loss: 0.018636

run [1250]:
Style Loss : 0.077935 Content Loss: 0.018613

run [1300]:
Style Loss : 0.076620 Content Loss: 0.018584

run [1350]:
Style Loss : 0.075213 Content Loss: 0.018572

run [1400]:
Style Loss : 0.073969 Content Loss: 0.018566

run [1450]:
Style Loss : 0.072901 Content Loss: 0.018562

run [1500]:
Style Loss : 0.072070 Content Loss: 0.018544

run [1550]:
Style Loss : 0.071344 Content Loss: 0.018522

run [1600]:
Style Loss : 0.070689 Content Loss: 0.018508

run [1650]:
Style Loss : 0.070113 Content Loss: 0.018490

run [1700]:
Style Loss : 0.069538 Content Loss: 0.018479

run [1750]:
Style Loss : 0.068973 Content Loss: 0.018466

run [1800]:
Style Loss : 0.068409 Content Loss: 0.018460

run [1850]:
Style Loss : 0.067887 Content Loss: 0.018441

run [1900]:
Style Loss : 0.067451 Content Loss: 0.018417

run [1950]:
Style Loss : 0.067064 Content Loss: 0.018399

run [2000]:
Style Loss : 0.066704 Content Loss: 0.018381

run [2050]:
Style Loss : 0.066351 Content Loss: 0.018360

run [2100]:
Style Loss : 0.065987 Content Loss: 0.018338

run [2150]:
Style Loss : 0.065624 Content Loss: 0.018321

run [2200]:
Style Loss : 0.065297 Content Loss: 0.018303

run [2250]:
Style Loss : 0.064976 Content Loss: 0.018293

run [2300]:
Style Loss : 0.064682 Content Loss: 0.018282

run [2350]:
Style Loss : 0.064419 Content Loss: 0.018264

run [2400]:
Style Loss : 0.064174 Content Loss: 0.018250

run [2450]:
Style Loss : 0.063940 Content Loss: 0.018237

run [2500]:
Style Loss : 0.063710 Content Loss: 0.018224

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.917495 Content Loss: 0.002844

run [100]:
Style Loss : 1.106449 Content Loss: 0.004214

run [150]:
Style Loss : 0.841762 Content Loss: 0.005555

run [200]:
Style Loss : 0.708850 Content Loss: 0.006813

run [250]:
Style Loss : 0.627431 Content Loss: 0.007846

run [300]:
Style Loss : 0.571485 Content Loss: 0.008656

run [350]:
Style Loss : 0.532765 Content Loss: 0.009382

run [400]:
Style Loss : 0.503090 Content Loss: 0.010062

run [450]:
Style Loss : 0.478312 Content Loss: 0.010646

run [500]:
Style Loss : 0.459931 Content Loss: 0.011115

run [550]:
Style Loss : 0.445854 Content Loss: 0.011497

run [600]:
Style Loss : 0.434888 Content Loss: 0.011814

run [650]:
Style Loss : 0.426470 Content Loss: 0.012077

run [700]:
Style Loss : 0.419266 Content Loss: 0.012301

run [750]:
Style Loss : 0.413092 Content Loss: 0.012499

run [800]:
Style Loss : 0.407557 Content Loss: 0.012660

run [850]:
Style Loss : 0.402024 Content Loss: 0.012790

run [900]:
Style Loss : 0.397685 Content Loss: 0.012870

run [950]:
Style Loss : 0.394193 Content Loss: 0.012968

run [1000]:
Style Loss : 0.391047 Content Loss: 0.013044

run [1050]:
Style Loss : 0.388245 Content Loss: 0.013108

run [1100]:
Style Loss : 0.385583 Content Loss: 0.013174

run [1150]:
Style Loss : 0.382870 Content Loss: 0.013231

run [1200]:
Style Loss : 0.380537 Content Loss: 0.013286

run [1250]:
Style Loss : 0.378384 Content Loss: 0.013340

run [1300]:
Style Loss : 0.376540 Content Loss: 0.013381

run [1350]:
Style Loss : 0.374874 Content Loss: 0.013424

run [1400]:
Style Loss : 0.373327 Content Loss: 0.013463

run [1450]:
Style Loss : 0.372008 Content Loss: 0.013498

run [1500]:
Style Loss : 0.370744 Content Loss: 0.013540

run [1550]:
Style Loss : 0.369428 Content Loss: 0.013581

run [1600]:
Style Loss : 0.368359 Content Loss: 0.013614

run [1650]:
Style Loss : 0.367332 Content Loss: 0.013650

run [1700]:
Style Loss : 0.366380 Content Loss: 0.013682

run [1750]:
Style Loss : 0.365067 Content Loss: 0.013726

run [1800]:
Style Loss : 0.363697 Content Loss: 0.013762

run [1850]:
Style Loss : 0.362725 Content Loss: 0.013794

run [1900]:
Style Loss : 0.361795 Content Loss: 0.013826

run [1950]:
Style Loss : 0.361005 Content Loss: 0.013852

run [2000]:
Style Loss : 0.360283 Content Loss: 0.013879

run [2050]:
Style Loss : 0.359561 Content Loss: 0.013908

run [2100]:
Style Loss : 0.358875 Content Loss: 0.013943

run [2150]:
Style Loss : 0.358220 Content Loss: 0.013971

run [2200]:
Style Loss : 0.357546 Content Loss: 0.014001

run [2250]:
Style Loss : 0.356910 Content Loss: 0.014023

run [2300]:
Style Loss : 0.356363 Content Loss: 0.014046

run [2350]:
Style Loss : 0.355872 Content Loss: 0.014064

run [2400]:
Style Loss : 0.355381 Content Loss: 0.014085

run [2450]:
Style Loss : 0.354909 Content Loss: 0.014103

run [2500]:
Style Loss : 0.354408 Content Loss: 0.014126

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.915891 Content Loss: 0.002686

run [100]:
Style Loss : 1.013899 Content Loss: 0.003385

run [150]:
Style Loss : 0.744613 Content Loss: 0.004267

run [200]:
Style Loss : 0.612606 Content Loss: 0.005045

run [250]:
Style Loss : 0.539062 Content Loss: 0.005691

run [300]:
Style Loss : 0.488619 Content Loss: 0.006267

run [350]:
Style Loss : 0.452165 Content Loss: 0.006799

run [400]:
Style Loss : 0.425667 Content Loss: 0.007265

run [450]:
Style Loss : 0.405420 Content Loss: 0.007699

run [500]:
Style Loss : 0.388895 Content Loss: 0.008058

run [550]:
Style Loss : 0.374878 Content Loss: 0.008405

run [600]:
Style Loss : 0.362909 Content Loss: 0.008692

run [650]:
Style Loss : 0.352616 Content Loss: 0.008943

run [700]:
Style Loss : 0.343891 Content Loss: 0.009164

run [750]:
Style Loss : 0.336387 Content Loss: 0.009337

run [800]:
Style Loss : 0.330260 Content Loss: 0.009531

run [850]:
Style Loss : 0.324473 Content Loss: 0.009699

run [900]:
Style Loss : 0.319575 Content Loss: 0.009836

run [950]:
Style Loss : 0.314954 Content Loss: 0.009995

run [1000]:
Style Loss : 0.310807 Content Loss: 0.010094

run [1050]:
Style Loss : 0.306734 Content Loss: 0.010214

run [1100]:
Style Loss : 0.303048 Content Loss: 0.010305

run [1150]:
Style Loss : 0.299572 Content Loss: 0.010404

run [1200]:
Style Loss : 0.296123 Content Loss: 0.010492

run [1250]:
Style Loss : 0.292681 Content Loss: 0.010577

run [1300]:
Style Loss : 0.289726 Content Loss: 0.010643

run [1350]:
Style Loss : 0.286885 Content Loss: 0.010713

run [1400]:
Style Loss : 0.283993 Content Loss: 0.010799

run [1450]:
Style Loss : 0.281014 Content Loss: 0.010862

run [1500]:
Style Loss : 0.278004 Content Loss: 0.010924

run [1550]:
Style Loss : 0.275448 Content Loss: 0.010983

run [1600]:
Style Loss : 0.272683 Content Loss: 0.011034

run [1650]:
Style Loss : 0.270429 Content Loss: 0.011105

run [1700]:
Style Loss : 0.267914 Content Loss: 0.011176

run [1750]:
Style Loss : 0.265463 Content Loss: 0.011225

run [1800]:
Style Loss : 0.262972 Content Loss: 0.011299

run [1850]:
Style Loss : 0.260620 Content Loss: 0.011362

run [1900]:
Style Loss : 0.258841 Content Loss: 0.011432

run [1950]:
Style Loss : 0.256405 Content Loss: 0.011517

run [2000]:
Style Loss : 0.254135 Content Loss: 0.011574

run [2050]:
Style Loss : 0.252039 Content Loss: 0.011643

run [2100]:
Style Loss : 0.250157 Content Loss: 0.011725

run [2150]:
Style Loss : 0.248202 Content Loss: 0.011801

run [2200]:
Style Loss : 0.246465 Content Loss: 0.011925

run [2250]:
Style Loss : 0.244516 Content Loss: 0.012016

run [2300]:
Style Loss : 0.242693 Content Loss: 0.012113

run [2350]:
Style Loss : 0.240953 Content Loss: 0.012179

run [2400]:
Style Loss : 0.239201 Content Loss: 0.012305

run [2450]:
Style Loss : 0.238612 Content Loss: 0.012502

run [2500]:
Style Loss : 0.235821 Content Loss: 0.012530

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.936620 Content Loss: 0.003845

run [100]:
Style Loss : 1.043393 Content Loss: 0.005827

run [150]:
Style Loss : 0.755808 Content Loss: 0.007921

run [200]:
Style Loss : 0.623656 Content Loss: 0.009995

run [250]:
Style Loss : 0.535680 Content Loss: 0.011401

run [300]:
Style Loss : 0.472424 Content Loss: 0.012385

run [350]:
Style Loss : 0.430847 Content Loss: 0.013143

run [400]:
Style Loss : 0.403838 Content Loss: 0.013582

run [450]:
Style Loss : 0.383182 Content Loss: 0.013977

run [500]:
Style Loss : 0.365905 Content Loss: 0.014385

run [550]:
Style Loss : 0.349687 Content Loss: 0.014657

run [600]:
Style Loss : 0.336058 Content Loss: 0.014878

run [650]:
Style Loss : 0.323772 Content Loss: 0.015112

run [700]:
Style Loss : 0.314000 Content Loss: 0.015306

run [750]:
Style Loss : 0.305947 Content Loss: 0.015499

run [800]:
Style Loss : 0.299584 Content Loss: 0.015682

run [850]:
Style Loss : 0.293852 Content Loss: 0.015836

run [900]:
Style Loss : 0.289306 Content Loss: 0.016006

run [950]:
Style Loss : 0.284994 Content Loss: 0.016166

run [1000]:
Style Loss : 0.281371 Content Loss: 0.016299

run [1050]:
Style Loss : 0.278164 Content Loss: 0.016418

run [1100]:
Style Loss : 0.275277 Content Loss: 0.016524

run [1150]:
Style Loss : 0.272226 Content Loss: 0.016630

run [1200]:
Style Loss : 0.269785 Content Loss: 0.016715

run [1250]:
Style Loss : 0.267553 Content Loss: 0.016803

run [1300]:
Style Loss : 0.265602 Content Loss: 0.016873

run [1350]:
Style Loss : 0.263627 Content Loss: 0.016960

run [1400]:
Style Loss : 0.261632 Content Loss: 0.017039

run [1450]:
Style Loss : 0.259953 Content Loss: 0.017104

run [1500]:
Style Loss : 0.258244 Content Loss: 0.017180

run [1550]:
Style Loss : 0.256672 Content Loss: 0.017255

run [1600]:
Style Loss : 0.255179 Content Loss: 0.017325

run [1650]:
Style Loss : 0.253749 Content Loss: 0.017377

run [1700]:
Style Loss : 0.252376 Content Loss: 0.017446

run [1750]:
Style Loss : 0.251095 Content Loss: 0.017516

run [1800]:
Style Loss : 0.249932 Content Loss: 0.017570

run [1850]:
Style Loss : 0.248749 Content Loss: 0.017635

run [1900]:
Style Loss : 0.247633 Content Loss: 0.017689

run [1950]:
Style Loss : 0.246494 Content Loss: 0.017743

run [2000]:
Style Loss : 0.245445 Content Loss: 0.017778

run [2050]:
Style Loss : 0.244452 Content Loss: 0.017820

run [2100]:
Style Loss : 0.243508 Content Loss: 0.017849

run [2150]:
Style Loss : 0.242597 Content Loss: 0.017891

run [2200]:
Style Loss : 0.241705 Content Loss: 0.017928

run [2250]:
Style Loss : 0.240855 Content Loss: 0.017966

run [2300]:
Style Loss : 0.239884 Content Loss: 0.018019

run [2350]:
Style Loss : 0.239001 Content Loss: 0.018067

run [2400]:
Style Loss : 0.238148 Content Loss: 0.018116

run [2450]:
Style Loss : 0.237358 Content Loss: 0.018162

run [2500]:
Style Loss : 0.236577 Content Loss: 0.018219

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.177910 Content Loss: 0.002416

run [100]:
Style Loss : 1.338006 Content Loss: 0.003087

run [150]:
Style Loss : 0.976464 Content Loss: 0.003989

run [200]:
Style Loss : 0.792374 Content Loss: 0.004630

run [250]:
Style Loss : 0.670522 Content Loss: 0.005108

run [300]:
Style Loss : 0.593455 Content Loss: 0.005508

run [350]:
Style Loss : 0.534003 Content Loss: 0.005816

run [400]:
Style Loss : 0.494308 Content Loss: 0.006029

run [450]:
Style Loss : 0.465343 Content Loss: 0.006268

run [500]:
Style Loss : 0.442899 Content Loss: 0.006452

run [550]:
Style Loss : 0.424728 Content Loss: 0.006613

run [600]:
Style Loss : 0.409459 Content Loss: 0.006760

run [650]:
Style Loss : 0.397651 Content Loss: 0.006881

run [700]:
Style Loss : 0.387617 Content Loss: 0.006977

run [750]:
Style Loss : 0.379568 Content Loss: 0.007070

run [800]:
Style Loss : 0.372512 Content Loss: 0.007156

run [850]:
Style Loss : 0.366320 Content Loss: 0.007241

run [900]:
Style Loss : 0.360684 Content Loss: 0.007309

run [950]:
Style Loss : 0.355022 Content Loss: 0.007385

run [1000]:
Style Loss : 0.350333 Content Loss: 0.007449

run [1050]:
Style Loss : 0.346089 Content Loss: 0.007517

run [1100]:
Style Loss : 0.341851 Content Loss: 0.007589

run [1150]:
Style Loss : 0.337969 Content Loss: 0.007656

run [1200]:
Style Loss : 0.334182 Content Loss: 0.007712

run [1250]:
Style Loss : 0.330371 Content Loss: 0.007769

run [1300]:
Style Loss : 0.326781 Content Loss: 0.007820

run [1350]:
Style Loss : 0.323466 Content Loss: 0.007872

run [1400]:
Style Loss : 0.320605 Content Loss: 0.007916

run [1450]:
Style Loss : 0.317899 Content Loss: 0.007964

run [1500]:
Style Loss : 0.315586 Content Loss: 0.008003

run [1550]:
Style Loss : 0.313368 Content Loss: 0.008052

run [1600]:
Style Loss : 0.310513 Content Loss: 0.008095

run [1650]:
Style Loss : 0.307872 Content Loss: 0.008135

run [1700]:
Style Loss : 0.305709 Content Loss: 0.008168

run [1750]:
Style Loss : 0.303810 Content Loss: 0.008196

run [1800]:
Style Loss : 0.302201 Content Loss: 0.008219

run [1850]:
Style Loss : 0.300603 Content Loss: 0.008248

run [1900]:
Style Loss : 0.299064 Content Loss: 0.008277

run [1950]:
Style Loss : 0.297756 Content Loss: 0.008298

run [2000]:
Style Loss : 0.296503 Content Loss: 0.008322

run [2050]:
Style Loss : 0.295307 Content Loss: 0.008347

run [2100]:
Style Loss : 0.294108 Content Loss: 0.008371

run [2150]:
Style Loss : 0.293002 Content Loss: 0.008395

run [2200]:
Style Loss : 0.291970 Content Loss: 0.008418

run [2250]:
Style Loss : 0.290998 Content Loss: 0.008442

run [2300]:
Style Loss : 0.290102 Content Loss: 0.008465

run [2350]:
Style Loss : 0.289255 Content Loss: 0.008484

run [2400]:
Style Loss : 0.288408 Content Loss: 0.008508

run [2450]:
Style Loss : 0.287528 Content Loss: 0.008531

run [2500]:
Style Loss : 0.286663 Content Loss: 0.008554

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.845376 Content Loss: 0.003439

run [100]:
Style Loss : 1.550807 Content Loss: 0.004453

run [150]:
Style Loss : 1.173916 Content Loss: 0.005388

run [200]:
Style Loss : 0.991264 Content Loss: 0.006203

run [250]:
Style Loss : 0.872419 Content Loss: 0.006868

run [300]:
Style Loss : 0.789050 Content Loss: 0.007325

run [350]:
Style Loss : 0.727560 Content Loss: 0.007702

run [400]:
Style Loss : 0.683560 Content Loss: 0.008072

run [450]:
Style Loss : 0.649379 Content Loss: 0.008410

run [500]:
Style Loss : 0.622461 Content Loss: 0.008687

run [550]:
Style Loss : 0.599358 Content Loss: 0.008976

run [600]:
Style Loss : 0.580034 Content Loss: 0.009233

run [650]:
Style Loss : 0.561489 Content Loss: 0.009473

run [700]:
Style Loss : 0.544771 Content Loss: 0.009672

run [750]:
Style Loss : 0.529074 Content Loss: 0.009861

run [800]:
Style Loss : 0.515985 Content Loss: 0.010016

run [850]:
Style Loss : 0.505224 Content Loss: 0.010171

run [900]:
Style Loss : 0.495979 Content Loss: 0.010290

run [950]:
Style Loss : 0.488239 Content Loss: 0.010405

run [1000]:
Style Loss : 0.481765 Content Loss: 0.010506

run [1050]:
Style Loss : 0.476086 Content Loss: 0.010608

run [1100]:
Style Loss : 0.470989 Content Loss: 0.010696

run [1150]:
Style Loss : 0.466760 Content Loss: 0.010780

run [1200]:
Style Loss : 0.462882 Content Loss: 0.010850

run [1250]:
Style Loss : 0.459236 Content Loss: 0.010922

run [1300]:
Style Loss : 0.455931 Content Loss: 0.010982

run [1350]:
Style Loss : 0.452265 Content Loss: 0.011051

run [1400]:
Style Loss : 0.449177 Content Loss: 0.011116

run [1450]:
Style Loss : 0.446186 Content Loss: 0.011176

run [1500]:
Style Loss : 0.443360 Content Loss: 0.011231

run [1550]:
Style Loss : 0.440646 Content Loss: 0.011279

run [1600]:
Style Loss : 0.437829 Content Loss: 0.011336

run [1650]:
Style Loss : 0.435064 Content Loss: 0.011375

run [1700]:
Style Loss : 0.432595 Content Loss: 0.011412

run [1750]:
Style Loss : 0.430343 Content Loss: 0.011442

run [1800]:
Style Loss : 0.428303 Content Loss: 0.011477

run [1850]:
Style Loss : 0.426178 Content Loss: 0.011516

run [1900]:
Style Loss : 0.424386 Content Loss: 0.011546

run [1950]:
Style Loss : 0.422919 Content Loss: 0.011572

run [2000]:
Style Loss : 0.421483 Content Loss: 0.011599

run [2050]:
Style Loss : 0.420163 Content Loss: 0.011629

run [2100]:
Style Loss : 0.418835 Content Loss: 0.011653

run [2150]:
Style Loss : 0.417656 Content Loss: 0.011681

run [2200]:
Style Loss : 0.416557 Content Loss: 0.011700

run [2250]:
Style Loss : 0.415516 Content Loss: 0.011720

run [2300]:
Style Loss : 0.414419 Content Loss: 0.011745

run [2350]:
Style Loss : 0.413358 Content Loss: 0.011762

run [2400]:
Style Loss : 0.412345 Content Loss: 0.011783

run [2450]:
Style Loss : 0.411415 Content Loss: 0.011804

run [2500]:
Style Loss : 0.410481 Content Loss: 0.011819

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.450118 Content Loss: 0.005111

run [100]:
Style Loss : 2.154226 Content Loss: 0.006155

run [150]:
Style Loss : 1.642043 Content Loss: 0.007177

run [200]:
Style Loss : 1.382152 Content Loss: 0.008119

run [250]:
Style Loss : 1.223768 Content Loss: 0.008966

run [300]:
Style Loss : 1.114901 Content Loss: 0.009601

run [350]:
Style Loss : 1.036076 Content Loss: 0.010235

run [400]:
Style Loss : 0.970078 Content Loss: 0.010687

run [450]:
Style Loss : 0.916451 Content Loss: 0.011145

run [500]:
Style Loss : 0.873512 Content Loss: 0.011597

run [550]:
Style Loss : 0.838526 Content Loss: 0.011954

run [600]:
Style Loss : 0.811712 Content Loss: 0.012262

run [650]:
Style Loss : 0.790732 Content Loss: 0.012523

run [700]:
Style Loss : 0.771743 Content Loss: 0.012764

run [750]:
Style Loss : 0.754035 Content Loss: 0.012974

run [800]:
Style Loss : 0.738641 Content Loss: 0.013146

run [850]:
Style Loss : 0.724808 Content Loss: 0.013309

run [900]:
Style Loss : 0.710867 Content Loss: 0.013446

run [950]:
Style Loss : 0.697174 Content Loss: 0.013575

run [1000]:
Style Loss : 0.685067 Content Loss: 0.013716

run [1050]:
Style Loss : 0.673758 Content Loss: 0.013803

run [1100]:
Style Loss : 0.664073 Content Loss: 0.013916

run [1150]:
Style Loss : 0.655161 Content Loss: 0.014010

run [1200]:
Style Loss : 0.647663 Content Loss: 0.014080

run [1250]:
Style Loss : 0.640491 Content Loss: 0.014175

run [1300]:
Style Loss : 0.633997 Content Loss: 0.014266

run [1350]:
Style Loss : 0.628870 Content Loss: 0.014343

run [1400]:
Style Loss : 0.623821 Content Loss: 0.014416

run [1450]:
Style Loss : 0.619548 Content Loss: 0.014489

run [1500]:
Style Loss : 0.615777 Content Loss: 0.014522

run [1550]:
Style Loss : 0.612203 Content Loss: 0.014577

run [1600]:
Style Loss : 0.609043 Content Loss: 0.014612

run [1650]:
Style Loss : 0.606011 Content Loss: 0.014642

run [1700]:
Style Loss : 0.603231 Content Loss: 0.014668

run [1750]:
Style Loss : 0.600681 Content Loss: 0.014707

run [1800]:
Style Loss : 0.598202 Content Loss: 0.014754

run [1850]:
Style Loss : 0.595921 Content Loss: 0.014781

run [1900]:
Style Loss : 0.593603 Content Loss: 0.014817

run [1950]:
Style Loss : 0.591608 Content Loss: 0.014852

run [2000]:
Style Loss : 0.589799 Content Loss: 0.014877

run [2050]:
Style Loss : 0.588063 Content Loss: 0.014897

run [2100]:
Style Loss : 0.586507 Content Loss: 0.014926

run [2150]:
Style Loss : 0.584941 Content Loss: 0.014959

run [2200]:
Style Loss : 0.583329 Content Loss: 0.014993

run [2250]:
Style Loss : 0.581883 Content Loss: 0.015016

run [2300]:
Style Loss : 0.580557 Content Loss: 0.015032

run [2350]:
Style Loss : 0.579302 Content Loss: 0.015060

run [2400]:
Style Loss : 0.578110 Content Loss: 0.015087

run [2450]:
Style Loss : 0.577070 Content Loss: 0.015110

run [2500]:
Style Loss : 0.575980 Content Loss: 0.015130

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.297859 Content Loss: 0.003422

run [100]:
Style Loss : 1.236547 Content Loss: 0.004267

run [150]:
Style Loss : 0.858351 Content Loss: 0.005182

run [200]:
Style Loss : 0.680071 Content Loss: 0.005803

run [250]:
Style Loss : 0.575406 Content Loss: 0.006405

run [300]:
Style Loss : 0.498104 Content Loss: 0.006897

run [350]:
Style Loss : 0.450371 Content Loss: 0.007378

run [400]:
Style Loss : 0.405657 Content Loss: 0.007631

run [450]:
Style Loss : 0.374028 Content Loss: 0.007994

run [500]:
Style Loss : 0.351076 Content Loss: 0.008289

run [550]:
Style Loss : 0.332184 Content Loss: 0.008524

run [600]:
Style Loss : 0.316025 Content Loss: 0.008811

run [650]:
Style Loss : 0.303376 Content Loss: 0.009023

run [700]:
Style Loss : 0.292233 Content Loss: 0.009204

run [750]:
Style Loss : 0.283187 Content Loss: 0.009389

run [800]:
Style Loss : 0.275421 Content Loss: 0.009546

run [850]:
Style Loss : 0.268781 Content Loss: 0.009663

run [900]:
Style Loss : 0.263107 Content Loss: 0.009773

run [950]:
Style Loss : 0.257078 Content Loss: 0.009851

run [1000]:
Style Loss : 0.252783 Content Loss: 0.009911

run [1050]:
Style Loss : 0.248971 Content Loss: 0.009986

run [1100]:
Style Loss : 0.245606 Content Loss: 0.010031

run [1150]:
Style Loss : 0.242692 Content Loss: 0.010088

run [1200]:
Style Loss : 0.240122 Content Loss: 0.010115

run [1250]:
Style Loss : 0.237587 Content Loss: 0.010164

run [1300]:
Style Loss : 0.235602 Content Loss: 0.010190

run [1350]:
Style Loss : 0.233748 Content Loss: 0.010226

run [1400]:
Style Loss : 0.232114 Content Loss: 0.010263

run [1450]:
Style Loss : 0.230573 Content Loss: 0.010297

run [1500]:
Style Loss : 0.229178 Content Loss: 0.010309

run [1550]:
Style Loss : 0.227905 Content Loss: 0.010329

run [1600]:
Style Loss : 0.226751 Content Loss: 0.010340

run [1650]:
Style Loss : 0.225576 Content Loss: 0.010352

run [1700]:
Style Loss : 0.224646 Content Loss: 0.010358

run [1750]:
Style Loss : 0.223857 Content Loss: 0.010368

run [1800]:
Style Loss : 0.222940 Content Loss: 0.010378

run [1850]:
Style Loss : 0.224578 Content Loss: 0.010323

run [1900]:
Style Loss : 0.221443 Content Loss: 0.010393

run [1950]:
Style Loss : 0.220022 Content Loss: 0.010400

run [2000]:
Style Loss : 0.218779 Content Loss: 0.010413

run [2050]:
Style Loss : 0.217692 Content Loss: 0.010431

run [2100]:
Style Loss : 0.216658 Content Loss: 0.010447

run [2150]:
Style Loss : 0.215590 Content Loss: 0.010462

run [2200]:
Style Loss : 0.214724 Content Loss: 0.010469

run [2250]:
Style Loss : 0.213824 Content Loss: 0.010474

run [2300]:
Style Loss : 0.212928 Content Loss: 0.010486

run [2350]:
Style Loss : 0.212130 Content Loss: 0.010493

run [2400]:
Style Loss : 0.211327 Content Loss: 0.010501

run [2450]:
Style Loss : 0.210588 Content Loss: 0.010513

run [2500]:
Style Loss : 0.209861 Content Loss: 0.010527

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.419179 Content Loss: 0.003202

run [100]:
Style Loss : 0.886675 Content Loss: 0.005186

run [150]:
Style Loss : 0.710621 Content Loss: 0.006462

run [200]:
Style Loss : 0.622294 Content Loss: 0.007420

run [250]:
Style Loss : 0.571900 Content Loss: 0.008115

run [300]:
Style Loss : 0.531384 Content Loss: 0.008764

run [350]:
Style Loss : 0.501783 Content Loss: 0.009247

run [400]:
Style Loss : 0.480324 Content Loss: 0.009621

run [450]:
Style Loss : 0.463859 Content Loss: 0.009972

run [500]:
Style Loss : 0.451004 Content Loss: 0.010235

run [550]:
Style Loss : 0.439911 Content Loss: 0.010484

run [600]:
Style Loss : 0.429023 Content Loss: 0.010714

run [650]:
Style Loss : 0.420211 Content Loss: 0.010895

run [700]:
Style Loss : 0.412414 Content Loss: 0.011064

run [750]:
Style Loss : 0.406122 Content Loss: 0.011218

run [800]:
Style Loss : 0.400967 Content Loss: 0.011353

run [850]:
Style Loss : 0.396324 Content Loss: 0.011489

run [900]:
Style Loss : 0.392083 Content Loss: 0.011611

run [950]:
Style Loss : 0.388258 Content Loss: 0.011712

run [1000]:
Style Loss : 0.384664 Content Loss: 0.011815

run [1050]:
Style Loss : 0.381583 Content Loss: 0.011915

run [1100]:
Style Loss : 0.378055 Content Loss: 0.012024

run [1150]:
Style Loss : 0.375443 Content Loss: 0.012109

run [1200]:
Style Loss : 0.372915 Content Loss: 0.012199

run [1250]:
Style Loss : 0.370518 Content Loss: 0.012286

run [1300]:
Style Loss : 0.367796 Content Loss: 0.012391

run [1350]:
Style Loss : 0.365225 Content Loss: 0.012473

run [1400]:
Style Loss : 0.362554 Content Loss: 0.012546

run [1450]:
Style Loss : 0.360059 Content Loss: 0.012636

run [1500]:
Style Loss : 0.357941 Content Loss: 0.012713

run [1550]:
Style Loss : 0.355982 Content Loss: 0.012781

run [1600]:
Style Loss : 0.354074 Content Loss: 0.012853

run [1650]:
Style Loss : 0.352321 Content Loss: 0.012928

run [1700]:
Style Loss : 0.350628 Content Loss: 0.012993

run [1750]:
Style Loss : 0.349048 Content Loss: 0.013056

run [1800]:
Style Loss : 0.347603 Content Loss: 0.013112

run [1850]:
Style Loss : 0.346177 Content Loss: 0.013171

run [1900]:
Style Loss : 0.344730 Content Loss: 0.013237

run [1950]:
Style Loss : 0.343444 Content Loss: 0.013291

run [2000]:
Style Loss : 0.342172 Content Loss: 0.013353

run [2050]:
Style Loss : 0.340957 Content Loss: 0.013413

run [2100]:
Style Loss : 0.339721 Content Loss: 0.013475

run [2150]:
Style Loss : 0.338551 Content Loss: 0.013526

run [2200]:
Style Loss : 0.337387 Content Loss: 0.013582

run [2250]:
Style Loss : 0.336265 Content Loss: 0.013638

run [2300]:
Style Loss : 0.335215 Content Loss: 0.013698

run [2350]:
Style Loss : 0.334177 Content Loss: 0.013752

run [2400]:
Style Loss : 0.333191 Content Loss: 0.013813

run [2450]:
Style Loss : 0.332203 Content Loss: 0.013875

run [2500]:
Style Loss : 0.331160 Content Loss: 0.013934

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.153948 Content Loss: 0.002422

run [100]:
Style Loss : 0.686570 Content Loss: 0.003594

run [150]:
Style Loss : 0.490048 Content Loss: 0.004573

run [200]:
Style Loss : 0.408380 Content Loss: 0.005180

run [250]:
Style Loss : 0.367274 Content Loss: 0.005736

run [300]:
Style Loss : 0.337818 Content Loss: 0.006217

run [350]:
Style Loss : 0.317164 Content Loss: 0.006572

run [400]:
Style Loss : 0.301655 Content Loss: 0.006920

run [450]:
Style Loss : 0.289396 Content Loss: 0.007198

run [500]:
Style Loss : 0.280233 Content Loss: 0.007462

run [550]:
Style Loss : 0.271742 Content Loss: 0.007729

run [600]:
Style Loss : 0.264928 Content Loss: 0.007947

run [650]:
Style Loss : 0.259181 Content Loss: 0.008156

run [700]:
Style Loss : 0.254371 Content Loss: 0.008331

run [750]:
Style Loss : 0.250259 Content Loss: 0.008491

run [800]:
Style Loss : 0.246550 Content Loss: 0.008619

run [850]:
Style Loss : 0.243248 Content Loss: 0.008749

run [900]:
Style Loss : 0.240297 Content Loss: 0.008879

run [950]:
Style Loss : 0.237609 Content Loss: 0.008997

run [1000]:
Style Loss : 0.234916 Content Loss: 0.009124

run [1050]:
Style Loss : 0.232320 Content Loss: 0.009243

run [1100]:
Style Loss : 0.229746 Content Loss: 0.009360

run [1150]:
Style Loss : 0.227079 Content Loss: 0.009470

run [1200]:
Style Loss : 0.224321 Content Loss: 0.009589

run [1250]:
Style Loss : 0.221797 Content Loss: 0.009704

run [1300]:
Style Loss : 0.219110 Content Loss: 0.009825

run [1350]:
Style Loss : 0.216826 Content Loss: 0.009921

run [1400]:
Style Loss : 0.214861 Content Loss: 0.010028

run [1450]:
Style Loss : 0.213096 Content Loss: 0.010108

run [1500]:
Style Loss : 0.211382 Content Loss: 0.010201

run [1550]:
Style Loss : 0.209686 Content Loss: 0.010285

run [1600]:
Style Loss : 0.208181 Content Loss: 0.010374

run [1650]:
Style Loss : 0.206657 Content Loss: 0.010464

run [1700]:
Style Loss : 0.205194 Content Loss: 0.010557

run [1750]:
Style Loss : 0.203816 Content Loss: 0.010648

run [1800]:
Style Loss : 0.202479 Content Loss: 0.010744

run [1850]:
Style Loss : 0.201247 Content Loss: 0.010827

run [1900]:
Style Loss : 0.200070 Content Loss: 0.010909

run [1950]:
Style Loss : 0.198904 Content Loss: 0.010994

run [2000]:
Style Loss : 0.197854 Content Loss: 0.011084

run [2050]:
Style Loss : 0.196872 Content Loss: 0.011157

run [2100]:
Style Loss : 0.195940 Content Loss: 0.011236

run [2150]:
Style Loss : 0.195013 Content Loss: 0.011315

run [2200]:
Style Loss : 0.194185 Content Loss: 0.011389

run [2250]:
Style Loss : 0.193404 Content Loss: 0.011452

run [2300]:
Style Loss : 0.192646 Content Loss: 0.011524

run [2350]:
Style Loss : 0.191926 Content Loss: 0.011588

run [2400]:
Style Loss : 0.191263 Content Loss: 0.011645

run [2450]:
Style Loss : 0.190627 Content Loss: 0.011705

run [2500]:
Style Loss : 0.189971 Content Loss: 0.011766

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.897664 Content Loss: 0.003147

run [100]:
Style Loss : 0.511243 Content Loss: 0.005156

run [150]:
Style Loss : 0.395084 Content Loss: 0.006558

run [200]:
Style Loss : 0.337016 Content Loss: 0.007600

run [250]:
Style Loss : 0.298683 Content Loss: 0.008241

run [300]:
Style Loss : 0.272557 Content Loss: 0.008761

run [350]:
Style Loss : 0.253212 Content Loss: 0.009252

run [400]:
Style Loss : 0.238503 Content Loss: 0.009613

run [450]:
Style Loss : 0.228569 Content Loss: 0.009967

run [500]:
Style Loss : 0.219970 Content Loss: 0.010298

run [550]:
Style Loss : 0.213165 Content Loss: 0.010558

run [600]:
Style Loss : 0.207401 Content Loss: 0.010788

run [650]:
Style Loss : 0.202735 Content Loss: 0.010999

run [700]:
Style Loss : 0.198562 Content Loss: 0.011200

run [750]:
Style Loss : 0.195151 Content Loss: 0.011370

run [800]:
Style Loss : 0.192041 Content Loss: 0.011509

run [850]:
Style Loss : 0.189061 Content Loss: 0.011655

run [900]:
Style Loss : 0.186597 Content Loss: 0.011769

run [950]:
Style Loss : 0.184371 Content Loss: 0.011900

run [1000]:
Style Loss : 0.182413 Content Loss: 0.012008

run [1050]:
Style Loss : 0.180561 Content Loss: 0.012139

run [1100]:
Style Loss : 0.178810 Content Loss: 0.012237

run [1150]:
Style Loss : 0.176505 Content Loss: 0.012350

run [1200]:
Style Loss : 0.174583 Content Loss: 0.012475

run [1250]:
Style Loss : 0.172598 Content Loss: 0.012605

run [1300]:
Style Loss : 0.170689 Content Loss: 0.012749

run [1350]:
Style Loss : 0.168972 Content Loss: 0.012871

run [1400]:
Style Loss : 0.167457 Content Loss: 0.013019

run [1450]:
Style Loss : 0.165379 Content Loss: 0.013140

run [1500]:
Style Loss : 0.163909 Content Loss: 0.013284

run [1550]:
Style Loss : 0.162448 Content Loss: 0.013448

run [1600]:
Style Loss : 0.161064 Content Loss: 0.013606

run [1650]:
Style Loss : 0.159730 Content Loss: 0.013753

run [1700]:
Style Loss : 0.158668 Content Loss: 0.013972

run [1750]:
Style Loss : 0.158047 Content Loss: 0.014097

run [1800]:
Style Loss : 0.155636 Content Loss: 0.014322

run [1850]:
Style Loss : 0.154028 Content Loss: 0.014480

run [1900]:
Style Loss : 0.155948 Content Loss: 0.014951

run [1950]:
Style Loss : 0.150827 Content Loss: 0.014783

run [2000]:
Style Loss : 0.182403 Content Loss: 0.015350

run [2050]:
Style Loss : 0.148382 Content Loss: 0.015134

run [2100]:
Style Loss : 0.147365 Content Loss: 0.015289

run [2150]:
Style Loss : 0.146191 Content Loss: 0.015441

run [2200]:
Style Loss : 0.733155 Content Loss: 0.016611

run [2250]:
Style Loss : 575.633606 Content Loss: 0.390317

run [2300]:
Style Loss : 630.524841 Content Loss: 0.395323

run [2350]:
Style Loss : 1.125689 Content Loss: 0.020995

run [2400]:
Style Loss : 0.559314 Content Loss: 0.020172

run [2450]:
Style Loss : 0.419603 Content Loss: 0.020513

run [2500]:
Style Loss : 0.346647 Content Loss: 0.020950

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.086338 Content Loss: 0.001980

run [100]:
Style Loss : 0.591353 Content Loss: 0.003672

run [150]:
Style Loss : 0.431269 Content Loss: 0.004590

run [200]:
Style Loss : 0.358370 Content Loss: 0.005368

run [250]:
Style Loss : 0.310813 Content Loss: 0.006006

run [300]:
Style Loss : 0.273789 Content Loss: 0.006468

run [350]:
Style Loss : 0.251428 Content Loss: 0.006907

run [400]:
Style Loss : 0.235303 Content Loss: 0.007307

run [450]:
Style Loss : 0.223967 Content Loss: 0.007590

run [500]:
Style Loss : 0.215499 Content Loss: 0.007844

run [550]:
Style Loss : 0.208501 Content Loss: 0.008050

run [600]:
Style Loss : 0.202461 Content Loss: 0.008230

run [650]:
Style Loss : 0.197092 Content Loss: 0.008407

run [700]:
Style Loss : 0.192357 Content Loss: 0.008563

run [750]:
Style Loss : 0.188254 Content Loss: 0.008697

run [800]:
Style Loss : 0.184806 Content Loss: 0.008829

run [850]:
Style Loss : 0.181696 Content Loss: 0.008955

run [900]:
Style Loss : 0.178420 Content Loss: 0.009069

run [950]:
Style Loss : 0.175384 Content Loss: 0.009164

run [1000]:
Style Loss : 0.172801 Content Loss: 0.009269

run [1050]:
Style Loss : 0.170485 Content Loss: 0.009357

run [1100]:
Style Loss : 0.168342 Content Loss: 0.009443

run [1150]:
Style Loss : 0.166638 Content Loss: 0.009511

run [1200]:
Style Loss : 0.165050 Content Loss: 0.009580

run [1250]:
Style Loss : 0.163616 Content Loss: 0.009653

run [1300]:
Style Loss : 0.162246 Content Loss: 0.009712

run [1350]:
Style Loss : 0.160909 Content Loss: 0.009787

run [1400]:
Style Loss : 0.159687 Content Loss: 0.009849

run [1450]:
Style Loss : 0.158481 Content Loss: 0.009908

run [1500]:
Style Loss : 0.157363 Content Loss: 0.009974

run [1550]:
Style Loss : 0.156258 Content Loss: 0.010031

run [1600]:
Style Loss : 0.155270 Content Loss: 0.010067

run [1650]:
Style Loss : 0.154304 Content Loss: 0.010116

run [1700]:
Style Loss : 0.153371 Content Loss: 0.010153

run [1750]:
Style Loss : 0.152206 Content Loss: 0.010203

run [1800]:
Style Loss : 0.151262 Content Loss: 0.010249

run [1850]:
Style Loss : 0.150408 Content Loss: 0.010284

run [1900]:
Style Loss : 0.149640 Content Loss: 0.010321

run [1950]:
Style Loss : 0.148826 Content Loss: 0.010376

run [2000]:
Style Loss : 0.147999 Content Loss: 0.010416

run [2050]:
Style Loss : 0.147231 Content Loss: 0.010473

run [2100]:
Style Loss : 0.146307 Content Loss: 0.010517

run [2150]:
Style Loss : 0.145489 Content Loss: 0.010568

run [2200]:
Style Loss : 0.144735 Content Loss: 0.010612

run [2250]:
Style Loss : 0.143971 Content Loss: 0.010652

run [2300]:
Style Loss : 0.143315 Content Loss: 0.010680

run [2350]:
Style Loss : 0.142664 Content Loss: 0.010712

run [2400]:
Style Loss : 0.142061 Content Loss: 0.010741

run [2450]:
Style Loss : 0.141472 Content Loss: 0.010776

run [2500]:
Style Loss : 0.140884 Content Loss: 0.010811

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.789651 Content Loss: 0.002092

run [100]:
Style Loss : 1.538754 Content Loss: 0.002619

run [150]:
Style Loss : 1.051625 Content Loss: 0.003476

run [200]:
Style Loss : 0.832552 Content Loss: 0.004166

run [250]:
Style Loss : 0.715050 Content Loss: 0.004792

run [300]:
Style Loss : 0.640589 Content Loss: 0.005328

run [350]:
Style Loss : 0.582716 Content Loss: 0.005711

run [400]:
Style Loss : 0.535290 Content Loss: 0.005983

run [450]:
Style Loss : 0.501098 Content Loss: 0.006220

run [500]:
Style Loss : 0.475024 Content Loss: 0.006491

run [550]:
Style Loss : 0.454441 Content Loss: 0.006692

run [600]:
Style Loss : 0.438011 Content Loss: 0.006834

run [650]:
Style Loss : 0.424783 Content Loss: 0.006974

run [700]:
Style Loss : 0.414180 Content Loss: 0.007134

run [750]:
Style Loss : 0.403638 Content Loss: 0.007257

run [800]:
Style Loss : 0.394812 Content Loss: 0.007345

run [850]:
Style Loss : 0.387769 Content Loss: 0.007425

run [900]:
Style Loss : 0.381377 Content Loss: 0.007520

run [950]:
Style Loss : 0.374823 Content Loss: 0.007617

run [1000]:
Style Loss : 0.369014 Content Loss: 0.007689

run [1050]:
Style Loss : 0.363464 Content Loss: 0.007794

run [1100]:
Style Loss : 0.358698 Content Loss: 0.007841

run [1150]:
Style Loss : 0.355126 Content Loss: 0.007920

run [1200]:
Style Loss : 0.351535 Content Loss: 0.007981

run [1250]:
Style Loss : 0.347358 Content Loss: 0.008035

run [1300]:
Style Loss : 0.345002 Content Loss: 0.008124

run [1350]:
Style Loss : 0.350159 Content Loss: 0.008235

run [1400]:
Style Loss : 0.337773 Content Loss: 0.008254

run [1450]:
Style Loss : 0.334895 Content Loss: 0.008298

run [1500]:
Style Loss : 0.331884 Content Loss: 0.008317

run [1550]:
Style Loss : 0.329706 Content Loss: 0.008394

run [1600]:
Style Loss : 0.326561 Content Loss: 0.008414

run [1650]:
Style Loss : 0.324409 Content Loss: 0.008452

run [1700]:
Style Loss : 0.322165 Content Loss: 0.008514

run [1750]:
Style Loss : 0.319986 Content Loss: 0.008555

run [1800]:
Style Loss : 0.317891 Content Loss: 0.008594

run [1850]:
Style Loss : 0.316006 Content Loss: 0.008638

run [1900]:
Style Loss : 0.314097 Content Loss: 0.008668

run [1950]:
Style Loss : 0.312274 Content Loss: 0.008710

run [2000]:
Style Loss : 0.310571 Content Loss: 0.008745

run [2050]:
Style Loss : 0.309043 Content Loss: 0.008805

run [2100]:
Style Loss : 0.307910 Content Loss: 0.008869

run [2150]:
Style Loss : 0.305957 Content Loss: 0.008883

run [2200]:
Style Loss : 0.304484 Content Loss: 0.008907

run [2250]:
Style Loss : 0.302834 Content Loss: 0.008965

run [2300]:
Style Loss : 0.303190 Content Loss: 0.009122

run [2350]:
Style Loss : 0.299585 Content Loss: 0.009057

run [2400]:
Style Loss : 0.298549 Content Loss: 0.009086

run [2450]:
Style Loss : 3.072245 Content Loss: 0.011093

run [2500]:
Style Loss : 0.352002 Content Loss: 0.009632

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.651934 Content Loss: 0.002950

run [100]:
Style Loss : 0.330762 Content Loss: 0.005397

run [150]:
Style Loss : 0.240981 Content Loss: 0.006714

run [200]:
Style Loss : 0.196939 Content Loss: 0.007534

run [250]:
Style Loss : 0.171062 Content Loss: 0.008042

run [300]:
Style Loss : 0.154299 Content Loss: 0.008349

run [350]:
Style Loss : 0.142406 Content Loss: 0.008665

run [400]:
Style Loss : 0.133375 Content Loss: 0.008912

run [450]:
Style Loss : 0.126212 Content Loss: 0.009121

run [500]:
Style Loss : 0.120370 Content Loss: 0.009302

run [550]:
Style Loss : 0.115777 Content Loss: 0.009436

run [600]:
Style Loss : 0.111942 Content Loss: 0.009558

run [650]:
Style Loss : 0.108714 Content Loss: 0.009649

run [700]:
Style Loss : 0.105848 Content Loss: 0.009743

run [750]:
Style Loss : 0.103189 Content Loss: 0.009822

run [800]:
Style Loss : 0.100959 Content Loss: 0.009876

run [850]:
Style Loss : 0.099082 Content Loss: 0.009943

run [900]:
Style Loss : 0.097392 Content Loss: 0.010002

run [950]:
Style Loss : 0.095946 Content Loss: 0.010057

run [1000]:
Style Loss : 0.094445 Content Loss: 0.010108

run [1050]:
Style Loss : 0.093141 Content Loss: 0.010154

run [1100]:
Style Loss : 0.092028 Content Loss: 0.010194

run [1150]:
Style Loss : 0.090949 Content Loss: 0.010232

run [1200]:
Style Loss : 0.089960 Content Loss: 0.010275

run [1250]:
Style Loss : 0.088969 Content Loss: 0.010310

run [1300]:
Style Loss : 0.087920 Content Loss: 0.010347

run [1350]:
Style Loss : 0.086942 Content Loss: 0.010386

run [1400]:
Style Loss : 0.085932 Content Loss: 0.010419

run [1450]:
Style Loss : 0.085068 Content Loss: 0.010453

run [1500]:
Style Loss : 0.084313 Content Loss: 0.010489

run [1550]:
Style Loss : 0.083657 Content Loss: 0.010531

run [1600]:
Style Loss : 0.083024 Content Loss: 0.010568

run [1650]:
Style Loss : 0.082414 Content Loss: 0.010609

run [1700]:
Style Loss : 0.081836 Content Loss: 0.010639

run [1750]:
Style Loss : 0.080785 Content Loss: 0.010685

run [1800]:
Style Loss : 0.079822 Content Loss: 0.010706

run [1850]:
Style Loss : 0.078928 Content Loss: 0.010731

run [1900]:
Style Loss : 0.078051 Content Loss: 0.010755

run [1950]:
Style Loss : 0.077192 Content Loss: 0.010790

run [2000]:
Style Loss : 0.076373 Content Loss: 0.010807

run [2050]:
Style Loss : 0.075676 Content Loss: 0.010831

run [2100]:
Style Loss : 0.074986 Content Loss: 0.010860

run [2150]:
Style Loss : 0.074356 Content Loss: 0.010863

run [2200]:
Style Loss : 0.073796 Content Loss: 0.010876

run [2250]:
Style Loss : 0.073244 Content Loss: 0.010876

run [2300]:
Style Loss : 0.072744 Content Loss: 0.010888

run [2350]:
Style Loss : 0.072325 Content Loss: 0.010901

run [2400]:
Style Loss : 0.071904 Content Loss: 0.010918

run [2450]:
Style Loss : 0.071394 Content Loss: 0.010936

run [2500]:
Style Loss : 0.070953 Content Loss: 0.010951

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.640525 Content Loss: 0.002462

run [100]:
Style Loss : 0.978589 Content Loss: 0.004062

run [150]:
Style Loss : 0.703538 Content Loss: 0.005429

run [200]:
Style Loss : 0.566402 Content Loss: 0.006493

run [250]:
Style Loss : 0.492228 Content Loss: 0.007186

run [300]:
Style Loss : 0.446298 Content Loss: 0.007862

run [350]:
Style Loss : 0.413204 Content Loss: 0.008457

run [400]:
Style Loss : 0.388902 Content Loss: 0.008923

run [450]:
Style Loss : 0.370445 Content Loss: 0.009333

run [500]:
Style Loss : 0.355099 Content Loss: 0.009703

run [550]:
Style Loss : 0.342870 Content Loss: 0.009993

run [600]:
Style Loss : 0.333673 Content Loss: 0.010232

run [650]:
Style Loss : 0.326827 Content Loss: 0.010420

run [700]:
Style Loss : 0.321183 Content Loss: 0.010595

run [750]:
Style Loss : 0.316409 Content Loss: 0.010741

run [800]:
Style Loss : 0.311712 Content Loss: 0.010875

run [850]:
Style Loss : 0.307928 Content Loss: 0.010983

run [900]:
Style Loss : 0.304604 Content Loss: 0.011089

run [950]:
Style Loss : 0.301478 Content Loss: 0.011185

run [1000]:
Style Loss : 0.298784 Content Loss: 0.011267

run [1050]:
Style Loss : 0.296529 Content Loss: 0.011333

run [1100]:
Style Loss : 0.294433 Content Loss: 0.011401

run [1150]:
Style Loss : 0.292599 Content Loss: 0.011467

run [1200]:
Style Loss : 0.290888 Content Loss: 0.011521

run [1250]:
Style Loss : 0.289261 Content Loss: 0.011573

run [1300]:
Style Loss : 0.287767 Content Loss: 0.011616

run [1350]:
Style Loss : 0.286282 Content Loss: 0.011662

run [1400]:
Style Loss : 0.284936 Content Loss: 0.011696

run [1450]:
Style Loss : 0.283576 Content Loss: 0.011735

run [1500]:
Style Loss : 0.282450 Content Loss: 0.011769

run [1550]:
Style Loss : 0.281388 Content Loss: 0.011803

run [1600]:
Style Loss : 0.280429 Content Loss: 0.011832

run [1650]:
Style Loss : 0.279514 Content Loss: 0.011863

run [1700]:
Style Loss : 0.278667 Content Loss: 0.011890

run [1750]:
Style Loss : 0.277866 Content Loss: 0.011915

run [1800]:
Style Loss : 0.276977 Content Loss: 0.011943

run [1850]:
Style Loss : 0.275978 Content Loss: 0.011974

run [1900]:
Style Loss : 0.275132 Content Loss: 0.012000

run [1950]:
Style Loss : 0.274389 Content Loss: 0.012020

run [2000]:
Style Loss : 0.273667 Content Loss: 0.012042

run [2050]:
Style Loss : 0.273041 Content Loss: 0.012062

run [2100]:
Style Loss : 0.272436 Content Loss: 0.012081

run [2150]:
Style Loss : 0.271914 Content Loss: 0.012100

run [2200]:
Style Loss : 0.271302 Content Loss: 0.012125

run [2250]:
Style Loss : 0.270611 Content Loss: 0.012149

run [2300]:
Style Loss : 0.269969 Content Loss: 0.012173

run [2350]:
Style Loss : 0.269381 Content Loss: 0.012194

run [2400]:
Style Loss : 0.268832 Content Loss: 0.012217

run [2450]:
Style Loss : 0.268216 Content Loss: 0.012239

run [2500]:
Style Loss : 0.267594 Content Loss: 0.012264

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.598505 Content Loss: 0.002683

run [100]:
Style Loss : 1.094447 Content Loss: 0.003009

run [150]:
Style Loss : 0.882753 Content Loss: 0.003594

run [200]:
Style Loss : 0.766140 Content Loss: 0.004387

run [250]:
Style Loss : 0.684582 Content Loss: 0.005385

run [300]:
Style Loss : 0.625250 Content Loss: 0.006455

run [350]:
Style Loss : 0.573478 Content Loss: 0.007731

run [400]:
Style Loss : 0.524593 Content Loss: 0.009031

run [450]:
Style Loss : 0.479497 Content Loss: 0.010675

run [500]:
Style Loss : 0.440212 Content Loss: 0.012444

run [550]:
Style Loss : 0.407612 Content Loss: 0.014182

run [600]:
Style Loss : 0.380389 Content Loss: 0.015877

run [650]:
Style Loss : 0.360721 Content Loss: 0.017250

run [700]:
Style Loss : 0.346474 Content Loss: 0.018226

run [750]:
Style Loss : 0.335478 Content Loss: 0.018896

run [800]:
Style Loss : 0.326699 Content Loss: 0.019306

run [850]:
Style Loss : 0.319004 Content Loss: 0.019580

run [900]:
Style Loss : 0.311881 Content Loss: 0.019824

run [950]:
Style Loss : 0.305375 Content Loss: 0.020003

run [1000]:
Style Loss : 0.299282 Content Loss: 0.020179

run [1050]:
Style Loss : 0.293886 Content Loss: 0.020294

run [1100]:
Style Loss : 0.289092 Content Loss: 0.020407

run [1150]:
Style Loss : 0.284611 Content Loss: 0.020549

run [1200]:
Style Loss : 0.280293 Content Loss: 0.020661

run [1250]:
Style Loss : 0.276184 Content Loss: 0.020794

run [1300]:
Style Loss : 0.272205 Content Loss: 0.020932

run [1350]:
Style Loss : 0.268301 Content Loss: 0.021075

run [1400]:
Style Loss : 0.264529 Content Loss: 0.021228

run [1450]:
Style Loss : 0.260862 Content Loss: 0.021404

run [1500]:
Style Loss : 0.257215 Content Loss: 0.021586

run [1550]:
Style Loss : 0.253356 Content Loss: 0.021787

run [1600]:
Style Loss : 0.249810 Content Loss: 0.021986

run [1650]:
Style Loss : 0.246208 Content Loss: 0.022209

run [1700]:
Style Loss : 0.242665 Content Loss: 0.022444

run [1750]:
Style Loss : 0.239440 Content Loss: 0.022673

run [1800]:
Style Loss : 0.235978 Content Loss: 0.022888

run [1850]:
Style Loss : 0.232879 Content Loss: 0.023094

run [1900]:
Style Loss : 0.229873 Content Loss: 0.023319

run [1950]:
Style Loss : 0.227019 Content Loss: 0.023546

run [2000]:
Style Loss : 0.224368 Content Loss: 0.023746

run [2050]:
Style Loss : 0.221833 Content Loss: 0.023952

run [2100]:
Style Loss : 0.219400 Content Loss: 0.024135

run [2150]:
Style Loss : 0.217243 Content Loss: 0.024324

run [2200]:
Style Loss : 0.215272 Content Loss: 0.024494

run [2250]:
Style Loss : 0.213455 Content Loss: 0.024649

run [2300]:
Style Loss : 0.211876 Content Loss: 0.024800

run [2350]:
Style Loss : 0.210394 Content Loss: 0.024929

run [2400]:
Style Loss : 0.209099 Content Loss: 0.025057

run [2450]:
Style Loss : 0.207872 Content Loss: 0.025170

run [2500]:
Style Loss : 0.206772 Content Loss: 0.025285

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.272878 Content Loss: 0.001421

run [100]:
Style Loss : 0.873233 Content Loss: 0.001647

run [150]:
Style Loss : 0.736970 Content Loss: 0.001964

run [200]:
Style Loss : 0.654940 Content Loss: 0.002527

run [250]:
Style Loss : 0.594344 Content Loss: 0.003261

run [300]:
Style Loss : 0.537729 Content Loss: 0.004303

run [350]:
Style Loss : 0.484451 Content Loss: 0.005441

run [400]:
Style Loss : 0.434539 Content Loss: 0.006919

run [450]:
Style Loss : 0.386930 Content Loss: 0.008605

run [500]:
Style Loss : 0.341053 Content Loss: 0.010650

run [550]:
Style Loss : 0.301085 Content Loss: 0.012701

run [600]:
Style Loss : 0.269759 Content Loss: 0.014719

run [650]:
Style Loss : 0.246619 Content Loss: 0.016358

run [700]:
Style Loss : 0.231243 Content Loss: 0.017396

run [750]:
Style Loss : 0.221196 Content Loss: 0.017990

run [800]:
Style Loss : 0.213700 Content Loss: 0.018436

run [850]:
Style Loss : 0.206910 Content Loss: 0.018600

run [900]:
Style Loss : 0.201310 Content Loss: 0.018628

run [950]:
Style Loss : 0.196687 Content Loss: 0.018700

run [1000]:
Style Loss : 0.192632 Content Loss: 0.018786

run [1050]:
Style Loss : 0.188792 Content Loss: 0.018882

run [1100]:
Style Loss : 0.185390 Content Loss: 0.018905

run [1150]:
Style Loss : 0.182482 Content Loss: 0.018990

run [1200]:
Style Loss : 0.179573 Content Loss: 0.019051

run [1250]:
Style Loss : 0.177025 Content Loss: 0.019111

run [1300]:
Style Loss : 0.174691 Content Loss: 0.019156

run [1350]:
Style Loss : 0.172772 Content Loss: 0.019201

run [1400]:
Style Loss : 0.170969 Content Loss: 0.019253

run [1450]:
Style Loss : 0.169376 Content Loss: 0.019308

run [1500]:
Style Loss : 0.167779 Content Loss: 0.019375

run [1550]:
Style Loss : 0.166358 Content Loss: 0.019437

run [1600]:
Style Loss : 0.165015 Content Loss: 0.019496

run [1650]:
Style Loss : 0.163689 Content Loss: 0.019564

run [1700]:
Style Loss : 0.162481 Content Loss: 0.019627

run [1750]:
Style Loss : 0.161287 Content Loss: 0.019684

run [1800]:
Style Loss : 0.160162 Content Loss: 0.019745

run [1850]:
Style Loss : 0.159130 Content Loss: 0.019794

run [1900]:
Style Loss : 0.158107 Content Loss: 0.019846

run [1950]:
Style Loss : 0.157172 Content Loss: 0.019891

run [2000]:
Style Loss : 0.156297 Content Loss: 0.019945

run [2050]:
Style Loss : 0.155479 Content Loss: 0.019983

run [2100]:
Style Loss : 0.154670 Content Loss: 0.020027

run [2150]:
Style Loss : 0.153847 Content Loss: 0.020068

run [2200]:
Style Loss : 0.153105 Content Loss: 0.020117

run [2250]:
Style Loss : 0.152408 Content Loss: 0.020157

run [2300]:
Style Loss : 0.151701 Content Loss: 0.020198

run [2350]:
Style Loss : 0.151010 Content Loss: 0.020234

run [2400]:
Style Loss : 0.150361 Content Loss: 0.020275

run [2450]:
Style Loss : 0.149704 Content Loss: 0.020309

run [2500]:
Style Loss : 0.149083 Content Loss: 0.020347

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.229131 Content Loss: 0.001794

run [100]:
Style Loss : 1.174460 Content Loss: 0.001877

run [150]:
Style Loss : 0.918374 Content Loss: 0.002036

run [200]:
Style Loss : 0.789531 Content Loss: 0.002440

run [250]:
Style Loss : 0.696841 Content Loss: 0.002819

run [300]:
Style Loss : 0.631421 Content Loss: 0.003273

run [350]:
Style Loss : 0.579335 Content Loss: 0.003742

run [400]:
Style Loss : 0.540313 Content Loss: 0.004244

run [450]:
Style Loss : 0.508502 Content Loss: 0.004818

run [500]:
Style Loss : 0.479960 Content Loss: 0.005458

run [550]:
Style Loss : 0.453109 Content Loss: 0.006225

run [600]:
Style Loss : 0.427400 Content Loss: 0.007142

run [650]:
Style Loss : 0.400869 Content Loss: 0.008243

run [700]:
Style Loss : 0.376433 Content Loss: 0.009302

run [750]:
Style Loss : 0.355209 Content Loss: 0.010183

run [800]:
Style Loss : 0.337682 Content Loss: 0.010899

run [850]:
Style Loss : 0.324747 Content Loss: 0.011550

run [900]:
Style Loss : 0.313565 Content Loss: 0.012065

run [950]:
Style Loss : 0.304206 Content Loss: 0.012408

run [1000]:
Style Loss : 0.296630 Content Loss: 0.012672

run [1050]:
Style Loss : 0.290972 Content Loss: 0.012813

run [1100]:
Style Loss : 0.286687 Content Loss: 0.012946

run [1150]:
Style Loss : 0.283267 Content Loss: 0.013067

run [1200]:
Style Loss : 0.280133 Content Loss: 0.013179

run [1250]:
Style Loss : 0.277274 Content Loss: 0.013263

run [1300]:
Style Loss : 0.274732 Content Loss: 0.013342

run [1350]:
Style Loss : 0.272260 Content Loss: 0.013386

run [1400]:
Style Loss : 0.270067 Content Loss: 0.013425

run [1450]:
Style Loss : 0.268153 Content Loss: 0.013452

run [1500]:
Style Loss : 0.266352 Content Loss: 0.013474

run [1550]:
Style Loss : 0.264796 Content Loss: 0.013496

run [1600]:
Style Loss : 0.263473 Content Loss: 0.013506

run [1650]:
Style Loss : 0.262261 Content Loss: 0.013516

run [1700]:
Style Loss : 0.261131 Content Loss: 0.013520

run [1750]:
Style Loss : 0.260029 Content Loss: 0.013519

run [1800]:
Style Loss : 0.258973 Content Loss: 0.013519

run [1850]:
Style Loss : 0.257935 Content Loss: 0.013515

run [1900]:
Style Loss : 0.256913 Content Loss: 0.013512

run [1950]:
Style Loss : 0.255894 Content Loss: 0.013509

run [2000]:
Style Loss : 0.254903 Content Loss: 0.013508

run [2050]:
Style Loss : 0.253867 Content Loss: 0.013507

run [2100]:
Style Loss : 0.252866 Content Loss: 0.013505

run [2150]:
Style Loss : 0.251899 Content Loss: 0.013500

run [2200]:
Style Loss : 0.251057 Content Loss: 0.013495

run [2250]:
Style Loss : 0.250246 Content Loss: 0.013494

run [2300]:
Style Loss : 0.249518 Content Loss: 0.013492

run [2350]:
Style Loss : 0.248867 Content Loss: 0.013494

run [2400]:
Style Loss : 0.248263 Content Loss: 0.013494

run [2450]:
Style Loss : 0.247706 Content Loss: 0.013494

run [2500]:
Style Loss : 0.247158 Content Loss: 0.013496

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.116397 Content Loss: 0.003434

run [100]:
Style Loss : 0.672604 Content Loss: 0.004887

run [150]:
Style Loss : 0.489982 Content Loss: 0.006840

run [200]:
Style Loss : 0.369399 Content Loss: 0.009873

run [250]:
Style Loss : 0.293662 Content Loss: 0.013262

run [300]:
Style Loss : 0.253574 Content Loss: 0.015711

run [350]:
Style Loss : 0.232828 Content Loss: 0.016849

run [400]:
Style Loss : 0.219175 Content Loss: 0.017328

run [450]:
Style Loss : 0.204916 Content Loss: 0.017637

run [500]:
Style Loss : 0.194251 Content Loss: 0.017911

run [550]:
Style Loss : 0.185102 Content Loss: 0.018226

run [600]:
Style Loss : 0.176425 Content Loss: 0.018617

run [650]:
Style Loss : 0.167896 Content Loss: 0.019075

run [700]:
Style Loss : 0.160056 Content Loss: 0.019590

run [750]:
Style Loss : 0.152811 Content Loss: 0.020146

run [800]:
Style Loss : 0.146650 Content Loss: 0.020655

run [850]:
Style Loss : 0.141255 Content Loss: 0.021170

run [900]:
Style Loss : 0.136849 Content Loss: 0.021609

run [950]:
Style Loss : 0.132373 Content Loss: 0.021994

run [1000]:
Style Loss : 0.128681 Content Loss: 0.022305

run [1050]:
Style Loss : 0.125918 Content Loss: 0.022608

run [1100]:
Style Loss : 0.123712 Content Loss: 0.022865

run [1150]:
Style Loss : 0.121912 Content Loss: 0.023050

run [1200]:
Style Loss : 0.120381 Content Loss: 0.023225

run [1250]:
Style Loss : 0.119057 Content Loss: 0.023328

run [1300]:
Style Loss : 0.131944 Content Loss: 0.023950

run [1350]:
Style Loss : 0.116398 Content Loss: 0.023864

run [1400]:
Style Loss : 0.113609 Content Loss: 0.023845

run [1450]:
Style Loss : 0.112063 Content Loss: 0.023776

run [1500]:
Style Loss : 0.111146 Content Loss: 0.023709

run [1550]:
Style Loss : 0.110273 Content Loss: 0.023663

run [1600]:
Style Loss : 0.109635 Content Loss: 0.023621

run [1650]:
Style Loss : 0.109102 Content Loss: 0.023579

run [1700]:
Style Loss : 0.108611 Content Loss: 0.023540

run [1750]:
Style Loss : 0.108185 Content Loss: 0.023500

run [1800]:
Style Loss : 0.107821 Content Loss: 0.023455

run [1850]:
Style Loss : 0.107483 Content Loss: 0.023411

run [1900]:
Style Loss : 0.107121 Content Loss: 0.023372

run [1950]:
Style Loss : 0.106767 Content Loss: 0.023326

run [2000]:
Style Loss : 0.106432 Content Loss: 0.023283

run [2050]:
Style Loss : 0.106111 Content Loss: 0.023244

run [2100]:
Style Loss : 0.105823 Content Loss: 0.023212

run [2150]:
Style Loss : 0.105566 Content Loss: 0.023183

run [2200]:
Style Loss : 0.105318 Content Loss: 0.023156

run [2250]:
Style Loss : 0.105083 Content Loss: 0.023128

run [2300]:
Style Loss : 0.104875 Content Loss: 0.023101

run [2350]:
Style Loss : 0.104683 Content Loss: 0.023070

run [2400]:
Style Loss : 0.104482 Content Loss: 0.023043

run [2450]:
Style Loss : 0.104312 Content Loss: 0.023009

run [2500]:
Style Loss : 0.104116 Content Loss: 0.022979

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.007716 Content Loss: 0.003201

run [100]:
Style Loss : 0.606323 Content Loss: 0.004391

run [150]:
Style Loss : 0.456368 Content Loss: 0.006495

run [200]:
Style Loss : 0.364447 Content Loss: 0.009732

run [250]:
Style Loss : 0.294667 Content Loss: 0.013718

run [300]:
Style Loss : 0.246895 Content Loss: 0.017567

run [350]:
Style Loss : 0.219045 Content Loss: 0.020171

run [400]:
Style Loss : 0.200794 Content Loss: 0.021450

run [450]:
Style Loss : 0.187498 Content Loss: 0.022207

run [500]:
Style Loss : 0.175921 Content Loss: 0.022660

run [550]:
Style Loss : 0.165672 Content Loss: 0.023346

run [600]:
Style Loss : 0.157443 Content Loss: 0.023862

run [650]:
Style Loss : 0.149696 Content Loss: 0.024504

run [700]:
Style Loss : 0.142949 Content Loss: 0.025112

run [750]:
Style Loss : 0.136587 Content Loss: 0.025631

run [800]:
Style Loss : 0.130247 Content Loss: 0.026141

run [850]:
Style Loss : 0.123929 Content Loss: 0.026622

run [900]:
Style Loss : 0.117525 Content Loss: 0.026950

run [950]:
Style Loss : 0.111543 Content Loss: 0.027293

run [1000]:
Style Loss : 0.106180 Content Loss: 0.027564

run [1050]:
Style Loss : 0.102071 Content Loss: 0.027823

run [1100]:
Style Loss : 0.098745 Content Loss: 0.028111

run [1150]:
Style Loss : 0.096130 Content Loss: 0.028305

run [1200]:
Style Loss : 0.093819 Content Loss: 0.028405

run [1250]:
Style Loss : 0.091810 Content Loss: 0.028534

run [1300]:
Style Loss : 0.090251 Content Loss: 0.028637

run [1350]:
Style Loss : 0.088912 Content Loss: 0.028738

run [1400]:
Style Loss : 0.087692 Content Loss: 0.028791

run [1450]:
Style Loss : 0.086276 Content Loss: 0.028843

run [1500]:
Style Loss : 0.084642 Content Loss: 0.028892

run [1550]:
Style Loss : 0.083171 Content Loss: 0.028914

run [1600]:
Style Loss : 0.081771 Content Loss: 0.028923

run [1650]:
Style Loss : 0.080588 Content Loss: 0.028940

run [1700]:
Style Loss : 0.079614 Content Loss: 0.028952

run [1750]:
Style Loss : 0.078823 Content Loss: 0.028947

run [1800]:
Style Loss : 0.077988 Content Loss: 0.028944

run [1850]:
Style Loss : 0.077228 Content Loss: 0.028938

run [1900]:
Style Loss : 0.076508 Content Loss: 0.028924

run [1950]:
Style Loss : 0.075792 Content Loss: 0.028919

run [2000]:
Style Loss : 0.075178 Content Loss: 0.028913

run [2050]:
Style Loss : 0.074637 Content Loss: 0.028898

run [2100]:
Style Loss : 0.074064 Content Loss: 0.028891

run [2150]:
Style Loss : 0.073573 Content Loss: 0.028870

run [2200]:
Style Loss : 0.073145 Content Loss: 0.028831

run [2250]:
Style Loss : 0.072740 Content Loss: 0.028800

run [2300]:
Style Loss : 0.072364 Content Loss: 0.028769

run [2350]:
Style Loss : 0.072013 Content Loss: 0.028732

run [2400]:
Style Loss : 0.071687 Content Loss: 0.028700

run [2450]:
Style Loss : 0.071321 Content Loss: 0.028663

run [2500]:
Style Loss : 0.070977 Content Loss: 0.028630

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.964246 Content Loss: 0.018131

run [100]:
Style Loss : 1.878634 Content Loss: 0.022875

run [150]:
Style Loss : 1.308413 Content Loss: 0.029320

run [200]:
Style Loss : 1.017922 Content Loss: 0.035296

run [250]:
Style Loss : 0.885055 Content Loss: 0.038117

run [300]:
Style Loss : 0.808705 Content Loss: 0.039547

run [350]:
Style Loss : 0.753744 Content Loss: 0.040049

run [400]:
Style Loss : 0.709912 Content Loss: 0.040690

run [450]:
Style Loss : 0.672322 Content Loss: 0.041067

run [500]:
Style Loss : 0.640027 Content Loss: 0.041444

run [550]:
Style Loss : 0.612461 Content Loss: 0.041820

run [600]:
Style Loss : 0.586635 Content Loss: 0.042131

run [650]:
Style Loss : 0.561615 Content Loss: 0.042460

run [700]:
Style Loss : 0.540633 Content Loss: 0.042783

run [750]:
Style Loss : 0.522155 Content Loss: 0.043101

run [800]:
Style Loss : 0.503965 Content Loss: 0.043417

run [850]:
Style Loss : 0.486615 Content Loss: 0.043722

run [900]:
Style Loss : 0.470902 Content Loss: 0.044027

run [950]:
Style Loss : 0.456835 Content Loss: 0.044243

run [1000]:
Style Loss : 0.444455 Content Loss: 0.044587

run [1050]:
Style Loss : 0.434053 Content Loss: 0.044831

run [1100]:
Style Loss : 0.425397 Content Loss: 0.045078

run [1150]:
Style Loss : 0.417699 Content Loss: 0.045329

run [1200]:
Style Loss : 0.411219 Content Loss: 0.045575

run [1250]:
Style Loss : 0.405460 Content Loss: 0.045740

run [1300]:
Style Loss : 0.400216 Content Loss: 0.046020

run [1350]:
Style Loss : 0.395452 Content Loss: 0.046210

run [1400]:
Style Loss : 0.390982 Content Loss: 0.046386

run [1450]:
Style Loss : 0.387178 Content Loss: 0.046509

run [1500]:
Style Loss : 0.383928 Content Loss: 0.046678

run [1550]:
Style Loss : 0.380888 Content Loss: 0.046745

run [1600]:
Style Loss : 0.378214 Content Loss: 0.046915

run [1650]:
Style Loss : 0.375592 Content Loss: 0.046955

run [1700]:
Style Loss : 0.373443 Content Loss: 0.047018

run [1750]:
Style Loss : 0.371266 Content Loss: 0.047055

run [1800]:
Style Loss : 0.369026 Content Loss: 0.047111

run [1850]:
Style Loss : 0.366850 Content Loss: 0.047170

run [1900]:
Style Loss : 0.364818 Content Loss: 0.047211

run [1950]:
Style Loss : 0.363127 Content Loss: 0.047235

run [2000]:
Style Loss : 0.361464 Content Loss: 0.047272

run [2050]:
Style Loss : 0.359854 Content Loss: 0.047318

run [2100]:
Style Loss : 0.358113 Content Loss: 0.047324

run [2150]:
Style Loss : 0.356692 Content Loss: 0.047362

run [2200]:
Style Loss : 0.355327 Content Loss: 0.047393

run [2250]:
Style Loss : 0.354105 Content Loss: 0.047385

run [2300]:
Style Loss : 0.352935 Content Loss: 0.047389

run [2350]:
Style Loss : 0.351855 Content Loss: 0.047409

run [2400]:
Style Loss : 0.350846 Content Loss: 0.047405

run [2450]:
Style Loss : 0.349931 Content Loss: 0.047407

run [2500]:
Style Loss : 0.349059 Content Loss: 0.047390

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.688875 Content Loss: 0.001623

run [100]:
Style Loss : 1.142392 Content Loss: 0.002158

run [150]:
Style Loss : 0.893032 Content Loss: 0.002827

run [200]:
Style Loss : 0.757780 Content Loss: 0.003654

run [250]:
Style Loss : 0.662471 Content Loss: 0.005108

run [300]:
Style Loss : 0.578346 Content Loss: 0.007186

run [350]:
Style Loss : 0.496946 Content Loss: 0.010064

run [400]:
Style Loss : 0.422253 Content Loss: 0.013665

run [450]:
Style Loss : 0.362090 Content Loss: 0.016720

run [500]:
Style Loss : 0.319982 Content Loss: 0.019571

run [550]:
Style Loss : 0.293777 Content Loss: 0.020879

run [600]:
Style Loss : 0.277389 Content Loss: 0.021638

run [650]:
Style Loss : 0.265089 Content Loss: 0.021861

run [700]:
Style Loss : 0.255845 Content Loss: 0.022079

run [750]:
Style Loss : 0.248049 Content Loss: 0.022177

run [800]:
Style Loss : 0.241172 Content Loss: 0.022289

run [850]:
Style Loss : 0.234755 Content Loss: 0.022498

run [900]:
Style Loss : 0.229216 Content Loss: 0.022671

run [950]:
Style Loss : 0.224237 Content Loss: 0.022839

run [1000]:
Style Loss : 0.219434 Content Loss: 0.023001

run [1050]:
Style Loss : 0.215006 Content Loss: 0.023170

run [1100]:
Style Loss : 0.210554 Content Loss: 0.023376

run [1150]:
Style Loss : 0.206212 Content Loss: 0.023584

run [1200]:
Style Loss : 0.202081 Content Loss: 0.023789

run [1250]:
Style Loss : 0.198435 Content Loss: 0.024001

run [1300]:
Style Loss : 0.194891 Content Loss: 0.024234

run [1350]:
Style Loss : 0.191011 Content Loss: 0.024495

run [1400]:
Style Loss : 0.187474 Content Loss: 0.024780

run [1450]:
Style Loss : 0.184131 Content Loss: 0.025082

run [1500]:
Style Loss : 0.180623 Content Loss: 0.025360

run [1550]:
Style Loss : 0.177347 Content Loss: 0.025691

run [1600]:
Style Loss : 0.174434 Content Loss: 0.026018

run [1650]:
Style Loss : 0.171666 Content Loss: 0.026325

run [1700]:
Style Loss : 0.168957 Content Loss: 0.026622

run [1750]:
Style Loss : 0.166212 Content Loss: 0.026884

run [1800]:
Style Loss : 0.163652 Content Loss: 0.027174

run [1850]:
Style Loss : 0.161369 Content Loss: 0.027436

run [1900]:
Style Loss : 0.159191 Content Loss: 0.027673

run [1950]:
Style Loss : 0.157478 Content Loss: 0.027900

run [2000]:
Style Loss : 0.155684 Content Loss: 0.028163

run [2050]:
Style Loss : 0.154103 Content Loss: 0.028371

run [2100]:
Style Loss : 0.152709 Content Loss: 0.028568

run [2150]:
Style Loss : 0.151323 Content Loss: 0.028730

run [2200]:
Style Loss : 0.150053 Content Loss: 0.028920

run [2250]:
Style Loss : 0.148898 Content Loss: 0.029102

run [2300]:
Style Loss : 0.148035 Content Loss: 0.029294

run [2350]:
Style Loss : 0.147019 Content Loss: 0.029422

run [2400]:
Style Loss : 0.146323 Content Loss: 0.029595

run [2450]:
Style Loss : 0.145282 Content Loss: 0.029688

run [2500]:
Style Loss : 0.144586 Content Loss: 0.029839

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.215731 Content Loss: 0.002119

run [100]:
Style Loss : 0.865066 Content Loss: 0.003116

run [150]:
Style Loss : 0.701286 Content Loss: 0.005114

run [200]:
Style Loss : 0.588635 Content Loss: 0.008044

run [250]:
Style Loss : 0.490354 Content Loss: 0.011751

run [300]:
Style Loss : 0.403600 Content Loss: 0.015889

run [350]:
Style Loss : 0.337133 Content Loss: 0.019108

run [400]:
Style Loss : 0.297883 Content Loss: 0.020972

run [450]:
Style Loss : 0.277373 Content Loss: 0.021890

run [500]:
Style Loss : 0.265922 Content Loss: 0.022255

run [550]:
Style Loss : 0.257993 Content Loss: 0.022361

run [600]:
Style Loss : 0.251989 Content Loss: 0.022421

run [650]:
Style Loss : 0.246672 Content Loss: 0.022562

run [700]:
Style Loss : 0.241872 Content Loss: 0.022667

run [750]:
Style Loss : 0.237888 Content Loss: 0.022759

run [800]:
Style Loss : 0.234113 Content Loss: 0.022805

run [850]:
Style Loss : 0.230824 Content Loss: 0.022859

run [900]:
Style Loss : 0.228039 Content Loss: 0.022896

run [950]:
Style Loss : 0.225786 Content Loss: 0.022926

run [1000]:
Style Loss : 0.223794 Content Loss: 0.022962

run [1050]:
Style Loss : 0.221993 Content Loss: 0.022998

run [1100]:
Style Loss : 0.220225 Content Loss: 0.023041

run [1150]:
Style Loss : 0.218455 Content Loss: 0.023079

run [1200]:
Style Loss : 0.216605 Content Loss: 0.023126

run [1250]:
Style Loss : 0.214845 Content Loss: 0.023158

run [1300]:
Style Loss : 0.213391 Content Loss: 0.023191

run [1350]:
Style Loss : 0.211959 Content Loss: 0.023231

run [1400]:
Style Loss : 0.210733 Content Loss: 0.023264

run [1450]:
Style Loss : 0.209477 Content Loss: 0.023303

run [1500]:
Style Loss : 0.208493 Content Loss: 0.023334

run [1550]:
Style Loss : 0.207650 Content Loss: 0.023368

run [1600]:
Style Loss : 0.206802 Content Loss: 0.023392

run [1650]:
Style Loss : 0.205763 Content Loss: 0.023429

run [1700]:
Style Loss : 0.204727 Content Loss: 0.023462

run [1750]:
Style Loss : 0.203768 Content Loss: 0.023488

run [1800]:
Style Loss : 0.202703 Content Loss: 0.023521

run [1850]:
Style Loss : 0.201850 Content Loss: 0.023536

run [1900]:
Style Loss : 0.201058 Content Loss: 0.023556

run [1950]:
Style Loss : 0.200285 Content Loss: 0.023577

run [2000]:
Style Loss : 0.199459 Content Loss: 0.023599

run [2050]:
Style Loss : 0.198725 Content Loss: 0.023623

run [2100]:
Style Loss : 0.197955 Content Loss: 0.023638

run [2150]:
Style Loss : 0.197347 Content Loss: 0.023656

run [2200]:
Style Loss : 0.196613 Content Loss: 0.023674

run [2250]:
Style Loss : 0.195957 Content Loss: 0.023694

run [2300]:
Style Loss : 0.195371 Content Loss: 0.023713

run [2350]:
Style Loss : 0.194776 Content Loss: 0.023733

run [2400]:
Style Loss : 0.194228 Content Loss: 0.023748

run [2450]:
Style Loss : 0.193628 Content Loss: 0.023767

run [2500]:
Style Loss : 0.193113 Content Loss: 0.023780

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.011409 Content Loss: 0.001295

run [100]:
Style Loss : 0.687027 Content Loss: 0.001388

run [150]:
Style Loss : 0.560379 Content Loss: 0.001717

run [200]:
Style Loss : 0.492314 Content Loss: 0.002383

run [250]:
Style Loss : 0.437505 Content Loss: 0.003480

run [300]:
Style Loss : 0.384502 Content Loss: 0.005147

run [350]:
Style Loss : 0.331495 Content Loss: 0.007565

run [400]:
Style Loss : 0.278398 Content Loss: 0.010844

run [450]:
Style Loss : 0.232790 Content Loss: 0.013522

run [500]:
Style Loss : 0.206177 Content Loss: 0.015304

run [550]:
Style Loss : 0.189976 Content Loss: 0.016324

run [600]:
Style Loss : 0.179447 Content Loss: 0.016752

run [650]:
Style Loss : 0.172325 Content Loss: 0.016962

run [700]:
Style Loss : 0.166622 Content Loss: 0.017064

run [750]:
Style Loss : 0.161627 Content Loss: 0.017167

run [800]:
Style Loss : 0.157144 Content Loss: 0.017263

run [850]:
Style Loss : 0.153155 Content Loss: 0.017377

run [900]:
Style Loss : 0.149389 Content Loss: 0.017525

run [950]:
Style Loss : 0.145987 Content Loss: 0.017654

run [1000]:
Style Loss : 0.142756 Content Loss: 0.017749

run [1050]:
Style Loss : 0.139548 Content Loss: 0.017868

run [1100]:
Style Loss : 0.136418 Content Loss: 0.018022

run [1150]:
Style Loss : 0.133154 Content Loss: 0.018213

run [1200]:
Style Loss : 0.130030 Content Loss: 0.018413

run [1250]:
Style Loss : 0.126774 Content Loss: 0.018630

run [1300]:
Style Loss : 0.123374 Content Loss: 0.018853

run [1350]:
Style Loss : 0.120145 Content Loss: 0.019095

run [1400]:
Style Loss : 0.116978 Content Loss: 0.019361

run [1450]:
Style Loss : 0.114036 Content Loss: 0.019649

run [1500]:
Style Loss : 0.110911 Content Loss: 0.019975

run [1550]:
Style Loss : 0.108020 Content Loss: 0.020346

run [1600]:
Style Loss : 0.105268 Content Loss: 0.020703

run [1650]:
Style Loss : 0.102850 Content Loss: 0.021028

run [1700]:
Style Loss : 0.100615 Content Loss: 0.021414

run [1750]:
Style Loss : 0.098634 Content Loss: 0.021725

run [1800]:
Style Loss : 0.096984 Content Loss: 0.022071

run [1850]:
Style Loss : 0.095442 Content Loss: 0.022423

run [1900]:
Style Loss : 0.094060 Content Loss: 0.022690

run [1950]:
Style Loss : 0.092908 Content Loss: 0.023001

run [2000]:
Style Loss : 0.091998 Content Loss: 0.023343

run [2050]:
Style Loss : 0.091483 Content Loss: 0.023664

run [2100]:
Style Loss : 0.090338 Content Loss: 0.023847

run [2150]:
Style Loss : 0.089745 Content Loss: 0.024110

run [2200]:
Style Loss : 0.089290 Content Loss: 0.024413

run [2250]:
Style Loss : 0.088212 Content Loss: 0.024662

run [2300]:
Style Loss : 0.087599 Content Loss: 0.024942

run [2350]:
Style Loss : 0.087293 Content Loss: 0.025268

run [2400]:
Style Loss : 0.085392 Content Loss: 0.025488

run [2450]:
Style Loss : 0.083891 Content Loss: 0.025695

run [2500]:
Style Loss : 0.083084 Content Loss: 0.025931

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.080834 Content Loss: 0.005704

run [100]:
Style Loss : 1.456860 Content Loss: 0.008598

run [150]:
Style Loss : 1.062426 Content Loss: 0.014842

run [200]:
Style Loss : 0.685109 Content Loss: 0.026874

run [250]:
Style Loss : 0.465236 Content Loss: 0.035753

run [300]:
Style Loss : 0.376062 Content Loss: 0.041578

run [350]:
Style Loss : 0.336134 Content Loss: 0.042918

run [400]:
Style Loss : 0.311434 Content Loss: 0.043452

run [450]:
Style Loss : 0.292918 Content Loss: 0.043735

run [500]:
Style Loss : 0.279409 Content Loss: 0.043901

run [550]:
Style Loss : 0.269407 Content Loss: 0.044150

run [600]:
Style Loss : 0.260872 Content Loss: 0.044425

run [650]:
Style Loss : 0.254354 Content Loss: 0.044647

run [700]:
Style Loss : 0.248883 Content Loss: 0.044864

run [750]:
Style Loss : 0.244239 Content Loss: 0.045063

run [800]:
Style Loss : 0.240275 Content Loss: 0.045256

run [850]:
Style Loss : 0.236950 Content Loss: 0.045435

run [900]:
Style Loss : 0.233562 Content Loss: 0.045553

run [950]:
Style Loss : 0.230599 Content Loss: 0.045718

run [1000]:
Style Loss : 0.227941 Content Loss: 0.045886

run [1050]:
Style Loss : 0.225384 Content Loss: 0.046012

run [1100]:
Style Loss : 0.223271 Content Loss: 0.046147

run [1150]:
Style Loss : 0.221066 Content Loss: 0.046248

run [1200]:
Style Loss : 0.218958 Content Loss: 0.046330

run [1250]:
Style Loss : 0.217076 Content Loss: 0.046404

run [1300]:
Style Loss : 0.215367 Content Loss: 0.046467

run [1350]:
Style Loss : 0.213633 Content Loss: 0.046534

run [1400]:
Style Loss : 0.212185 Content Loss: 0.046595

run [1450]:
Style Loss : 0.210567 Content Loss: 0.046630

run [1500]:
Style Loss : 0.209146 Content Loss: 0.046670

run [1550]:
Style Loss : 0.207907 Content Loss: 0.046720

run [1600]:
Style Loss : 0.206478 Content Loss: 0.046736

run [1650]:
Style Loss : 0.205100 Content Loss: 0.046782

run [1700]:
Style Loss : 0.203789 Content Loss: 0.046806

run [1750]:
Style Loss : 0.202586 Content Loss: 0.046846

run [1800]:
Style Loss : 0.201538 Content Loss: 0.046873

run [1850]:
Style Loss : 0.200897 Content Loss: 0.046864

run [1900]:
Style Loss : 0.199918 Content Loss: 0.046880

run [1950]:
Style Loss : 0.198968 Content Loss: 0.046897

run [2000]:
Style Loss : 0.199148 Content Loss: 0.046815

run [2050]:
Style Loss : 0.197144 Content Loss: 0.046872

run [2100]:
Style Loss : 0.196529 Content Loss: 0.046879

run [2150]:
Style Loss : 0.195324 Content Loss: 0.046877

run [2200]:
Style Loss : 0.194527 Content Loss: 0.046880

run [2250]:
Style Loss : 0.194558 Content Loss: 0.046843

run [2300]:
Style Loss : 0.192611 Content Loss: 0.046888

run [2350]:
Style Loss : 0.191845 Content Loss: 0.046924

run [2400]:
Style Loss : 0.216752 Content Loss: 0.046961

run [2450]:
Style Loss : 0.193806 Content Loss: 0.046802

run [2500]:
Style Loss : 0.189978 Content Loss: 0.047045

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.609000 Content Loss: 0.007870

run [100]:
Style Loss : 0.982028 Content Loss: 0.010860

run [150]:
Style Loss : 0.659406 Content Loss: 0.016776

run [200]:
Style Loss : 0.428204 Content Loss: 0.024022

run [250]:
Style Loss : 0.305973 Content Loss: 0.030035

run [300]:
Style Loss : 0.257150 Content Loss: 0.032321

run [350]:
Style Loss : 0.229609 Content Loss: 0.032818

run [400]:
Style Loss : 0.211580 Content Loss: 0.032996

run [450]:
Style Loss : 0.196591 Content Loss: 0.033179

run [500]:
Style Loss : 0.181025 Content Loss: 0.033396

run [550]:
Style Loss : 0.167073 Content Loss: 0.033489

run [600]:
Style Loss : 0.157435 Content Loss: 0.033926

run [650]:
Style Loss : 0.150168 Content Loss: 0.034175

run [700]:
Style Loss : 0.144086 Content Loss: 0.034429

run [750]:
Style Loss : 0.139024 Content Loss: 0.034630

run [800]:
Style Loss : 0.134696 Content Loss: 0.034887

run [850]:
Style Loss : 0.130790 Content Loss: 0.035157

run [900]:
Style Loss : 0.127461 Content Loss: 0.035363

run [950]:
Style Loss : 0.124657 Content Loss: 0.035525

run [1000]:
Style Loss : 0.122195 Content Loss: 0.035655

run [1050]:
Style Loss : 0.119978 Content Loss: 0.035752

run [1100]:
Style Loss : 0.117987 Content Loss: 0.035821

run [1150]:
Style Loss : 0.115455 Content Loss: 0.035853

run [1200]:
Style Loss : 0.113365 Content Loss: 0.035874

run [1250]:
Style Loss : 0.111716 Content Loss: 0.035888

run [1300]:
Style Loss : 0.110227 Content Loss: 0.035914

run [1350]:
Style Loss : 0.108933 Content Loss: 0.035960

run [1400]:
Style Loss : 0.107747 Content Loss: 0.036007

run [1450]:
Style Loss : 0.106722 Content Loss: 0.036040

run [1500]:
Style Loss : 0.105678 Content Loss: 0.036054

run [1550]:
Style Loss : 0.104824 Content Loss: 0.036073

run [1600]:
Style Loss : 0.104100 Content Loss: 0.036081

run [1650]:
Style Loss : 0.103336 Content Loss: 0.036078

run [1700]:
Style Loss : 0.102716 Content Loss: 0.036089

run [1750]:
Style Loss : 0.102129 Content Loss: 0.036085

run [1800]:
Style Loss : 0.101575 Content Loss: 0.036077

run [1850]:
Style Loss : 0.101091 Content Loss: 0.036066

run [1900]:
Style Loss : 0.100595 Content Loss: 0.036056

run [1950]:
Style Loss : 0.100127 Content Loss: 0.036053

run [2000]:
Style Loss : 0.099685 Content Loss: 0.036041

run [2050]:
Style Loss : 0.099166 Content Loss: 0.036025

run [2100]:
Style Loss : 0.098722 Content Loss: 0.036011

run [2150]:
Style Loss : 0.098294 Content Loss: 0.035991

run [2200]:
Style Loss : 0.097882 Content Loss: 0.035981

run [2250]:
Style Loss : 0.097514 Content Loss: 0.035970

run [2300]:
Style Loss : 0.097189 Content Loss: 0.035963

run [2350]:
Style Loss : 0.096881 Content Loss: 0.035943

run [2400]:
Style Loss : 0.096579 Content Loss: 0.035916

run [2450]:
Style Loss : 0.096291 Content Loss: 0.035892

run [2500]:
Style Loss : 0.096006 Content Loss: 0.035867

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.741115 Content Loss: 0.003463

run [100]:
Style Loss : 1.997399 Content Loss: 0.003839

run [150]:
Style Loss : 1.663772 Content Loss: 0.004337

run [200]:
Style Loss : 1.433536 Content Loss: 0.004949

run [250]:
Style Loss : 1.263436 Content Loss: 0.005684

run [300]:
Style Loss : 1.135886 Content Loss: 0.006722

run [350]:
Style Loss : 1.033360 Content Loss: 0.007981

run [400]:
Style Loss : 0.931854 Content Loss: 0.009904

run [450]:
Style Loss : 0.837211 Content Loss: 0.012305

run [500]:
Style Loss : 0.750894 Content Loss: 0.015401

run [550]:
Style Loss : 0.678078 Content Loss: 0.018491

run [600]:
Style Loss : 0.626482 Content Loss: 0.021194

run [650]:
Style Loss : 0.586963 Content Loss: 0.023305

run [700]:
Style Loss : 0.559620 Content Loss: 0.024620

run [750]:
Style Loss : 0.539430 Content Loss: 0.025412

run [800]:
Style Loss : 0.522471 Content Loss: 0.025847

run [850]:
Style Loss : 0.507584 Content Loss: 0.026171

run [900]:
Style Loss : 0.495659 Content Loss: 0.026407

run [950]:
Style Loss : 0.485926 Content Loss: 0.026604

run [1000]:
Style Loss : 0.476263 Content Loss: 0.026813

run [1050]:
Style Loss : 0.466643 Content Loss: 0.026986

run [1100]:
Style Loss : 0.458636 Content Loss: 0.027156

run [1150]:
Style Loss : 0.451428 Content Loss: 0.027312

run [1200]:
Style Loss : 0.444026 Content Loss: 0.027473

run [1250]:
Style Loss : 0.437194 Content Loss: 0.027604

run [1300]:
Style Loss : 0.430919 Content Loss: 0.027737

run [1350]:
Style Loss : 0.424158 Content Loss: 0.027892

run [1400]:
Style Loss : 0.417559 Content Loss: 0.028024

run [1450]:
Style Loss : 0.410963 Content Loss: 0.028173

run [1500]:
Style Loss : 0.404301 Content Loss: 0.028324

run [1550]:
Style Loss : 0.398037 Content Loss: 0.028484

run [1600]:
Style Loss : 0.391789 Content Loss: 0.028655

run [1650]:
Style Loss : 0.385483 Content Loss: 0.028835

run [1700]:
Style Loss : 0.379662 Content Loss: 0.029014

run [1750]:
Style Loss : 0.374084 Content Loss: 0.029202

run [1800]:
Style Loss : 0.368791 Content Loss: 0.029399

run [1850]:
Style Loss : 0.363928 Content Loss: 0.029593

run [1900]:
Style Loss : 0.358956 Content Loss: 0.029825

run [1950]:
Style Loss : 0.354749 Content Loss: 0.030017

run [2000]:
Style Loss : 0.350524 Content Loss: 0.030228

run [2050]:
Style Loss : 0.346544 Content Loss: 0.030455

run [2100]:
Style Loss : 0.342830 Content Loss: 0.030644

run [2150]:
Style Loss : 0.339447 Content Loss: 0.030819

run [2200]:
Style Loss : 0.335334 Content Loss: 0.031021

run [2250]:
Style Loss : 0.332076 Content Loss: 0.031178

run [2300]:
Style Loss : 0.329333 Content Loss: 0.031348

run [2350]:
Style Loss : 0.326761 Content Loss: 0.031485

run [2400]:
Style Loss : 0.324441 Content Loss: 0.031634

run [2450]:
Style Loss : 0.322417 Content Loss: 0.031769

run [2500]:
Style Loss : 0.319808 Content Loss: 0.031898

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.144876 Content Loss: 0.002717

run [100]:
Style Loss : 1.191382 Content Loss: 0.002586

run [150]:
Style Loss : 0.956562 Content Loss: 0.002744

run [200]:
Style Loss : 0.833489 Content Loss: 0.003001

run [250]:
Style Loss : 0.747513 Content Loss: 0.003425

run [300]:
Style Loss : 0.678425 Content Loss: 0.003988

run [350]:
Style Loss : 0.613921 Content Loss: 0.004901

run [400]:
Style Loss : 0.550713 Content Loss: 0.006057

run [450]:
Style Loss : 0.492237 Content Loss: 0.007585

run [500]:
Style Loss : 0.427391 Content Loss: 0.009809

run [550]:
Style Loss : 0.367713 Content Loss: 0.012375

run [600]:
Style Loss : 0.319082 Content Loss: 0.015039

run [650]:
Style Loss : 0.283792 Content Loss: 0.017285

run [700]:
Style Loss : 0.259518 Content Loss: 0.019054

run [750]:
Style Loss : 0.245296 Content Loss: 0.020004

run [800]:
Style Loss : 0.234698 Content Loss: 0.020550

run [850]:
Style Loss : 0.226704 Content Loss: 0.020692

run [900]:
Style Loss : 0.220430 Content Loss: 0.020742

run [950]:
Style Loss : 0.215760 Content Loss: 0.020738

run [1000]:
Style Loss : 0.211691 Content Loss: 0.020730

run [1050]:
Style Loss : 0.208261 Content Loss: 0.020777

run [1100]:
Style Loss : 0.205245 Content Loss: 0.020771

run [1150]:
Style Loss : 0.202717 Content Loss: 0.020766

run [1200]:
Style Loss : 0.200520 Content Loss: 0.020759

run [1250]:
Style Loss : 0.198427 Content Loss: 0.020764

run [1300]:
Style Loss : 0.196739 Content Loss: 0.020762

run [1350]:
Style Loss : 0.195094 Content Loss: 0.020769

run [1400]:
Style Loss : 0.193515 Content Loss: 0.020785

run [1450]:
Style Loss : 0.192151 Content Loss: 0.020793

run [1500]:
Style Loss : 0.190875 Content Loss: 0.020798

run [1550]:
Style Loss : 0.189584 Content Loss: 0.020806

run [1600]:
Style Loss : 0.188444 Content Loss: 0.020812

run [1650]:
Style Loss : 0.187382 Content Loss: 0.020811

run [1700]:
Style Loss : 0.186397 Content Loss: 0.020814

run [1750]:
Style Loss : 0.185382 Content Loss: 0.020809

run [1800]:
Style Loss : 0.184460 Content Loss: 0.020809

run [1850]:
Style Loss : 0.183623 Content Loss: 0.020809

run [1900]:
Style Loss : 0.182841 Content Loss: 0.020811

run [1950]:
Style Loss : 0.182164 Content Loss: 0.020807

run [2000]:
Style Loss : 0.181524 Content Loss: 0.020804

run [2050]:
Style Loss : 0.180918 Content Loss: 0.020801

run [2100]:
Style Loss : 0.180360 Content Loss: 0.020802

run [2150]:
Style Loss : 0.179841 Content Loss: 0.020804

run [2200]:
Style Loss : 0.179370 Content Loss: 0.020805

run [2250]:
Style Loss : 0.178940 Content Loss: 0.020808

run [2300]:
Style Loss : 0.178529 Content Loss: 0.020809

run [2350]:
Style Loss : 0.178165 Content Loss: 0.020810

run [2400]:
Style Loss : 0.177810 Content Loss: 0.020812

run [2450]:
Style Loss : 0.177460 Content Loss: 0.020813

run [2500]:
Style Loss : 0.177127 Content Loss: 0.020816

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.126618 Content Loss: 0.004427

run [100]:
Style Loss : 1.265896 Content Loss: 0.004562

run [150]:
Style Loss : 1.013938 Content Loss: 0.005756

run [200]:
Style Loss : 0.853116 Content Loss: 0.007346

run [250]:
Style Loss : 0.721051 Content Loss: 0.009509

run [300]:
Style Loss : 0.617717 Content Loss: 0.011845

run [350]:
Style Loss : 0.533686 Content Loss: 0.014533

run [400]:
Style Loss : 0.467659 Content Loss: 0.017128

run [450]:
Style Loss : 0.417735 Content Loss: 0.019166

run [500]:
Style Loss : 0.383963 Content Loss: 0.020408

run [550]:
Style Loss : 0.363784 Content Loss: 0.021171

run [600]:
Style Loss : 0.350685 Content Loss: 0.021613

run [650]:
Style Loss : 0.340607 Content Loss: 0.021862

run [700]:
Style Loss : 0.332210 Content Loss: 0.022053

run [750]:
Style Loss : 0.324712 Content Loss: 0.022191

run [800]:
Style Loss : 0.318819 Content Loss: 0.022328

run [850]:
Style Loss : 0.313801 Content Loss: 0.022480

run [900]:
Style Loss : 0.309528 Content Loss: 0.022592

run [950]:
Style Loss : 0.305784 Content Loss: 0.022710

run [1000]:
Style Loss : 0.302420 Content Loss: 0.022799

run [1050]:
Style Loss : 0.299528 Content Loss: 0.022917

run [1100]:
Style Loss : 0.296762 Content Loss: 0.023018

run [1150]:
Style Loss : 0.294019 Content Loss: 0.023095

run [1200]:
Style Loss : 0.291647 Content Loss: 0.023178

run [1250]:
Style Loss : 0.289051 Content Loss: 0.023246

run [1300]:
Style Loss : 0.286951 Content Loss: 0.023329

run [1350]:
Style Loss : 0.284997 Content Loss: 0.023392

run [1400]:
Style Loss : 0.283364 Content Loss: 0.023481

run [1450]:
Style Loss : 0.281704 Content Loss: 0.023534

run [1500]:
Style Loss : 0.280253 Content Loss: 0.023587

run [1550]:
Style Loss : 0.278937 Content Loss: 0.023655

run [1600]:
Style Loss : 0.277750 Content Loss: 0.023731

run [1650]:
Style Loss : 0.276395 Content Loss: 0.023762

run [1700]:
Style Loss : 0.275278 Content Loss: 0.023837

run [1750]:
Style Loss : 0.274626 Content Loss: 0.023900

run [1800]:
Style Loss : 0.274228 Content Loss: 0.024006

run [1850]:
Style Loss : 0.275723 Content Loss: 0.024002

run [1900]:
Style Loss : 0.270802 Content Loss: 0.024050

run [1950]:
Style Loss : 0.320568 Content Loss: 0.024634

run [2000]:
Style Loss : 0.269887 Content Loss: 0.024232

run [2050]:
Style Loss : 0.267205 Content Loss: 0.024263

run [2100]:
Style Loss : 0.265747 Content Loss: 0.024307

run [2150]:
Style Loss : 0.264652 Content Loss: 0.024338

run [2200]:
Style Loss : 0.263357 Content Loss: 0.024375

run [2250]:
Style Loss : 0.262061 Content Loss: 0.024405

run [2300]:
Style Loss : 0.260890 Content Loss: 0.024427

run [2350]:
Style Loss : 0.259969 Content Loss: 0.024435

run [2400]:
Style Loss : 0.258823 Content Loss: 0.024471

run [2450]:
Style Loss : 0.257729 Content Loss: 0.024493

run [2500]:
Style Loss : 0.256823 Content Loss: 0.024520

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.796592 Content Loss: 0.002216

run [100]:
Style Loss : 1.763733 Content Loss: 0.002467

run [150]:
Style Loss : 1.384923 Content Loss: 0.002585

run [200]:
Style Loss : 1.174789 Content Loss: 0.002784

run [250]:
Style Loss : 1.038627 Content Loss: 0.002963

run [300]:
Style Loss : 0.933373 Content Loss: 0.003194

run [350]:
Style Loss : 0.859082 Content Loss: 0.003406

run [400]:
Style Loss : 0.801511 Content Loss: 0.003648

run [450]:
Style Loss : 0.751089 Content Loss: 0.003909

run [500]:
Style Loss : 0.707604 Content Loss: 0.004227

run [550]:
Style Loss : 0.669038 Content Loss: 0.004593

run [600]:
Style Loss : 0.635504 Content Loss: 0.005026

run [650]:
Style Loss : 0.605484 Content Loss: 0.005523

run [700]:
Style Loss : 0.579077 Content Loss: 0.006096

run [750]:
Style Loss : 0.554038 Content Loss: 0.006730

run [800]:
Style Loss : 0.530899 Content Loss: 0.007502

run [850]:
Style Loss : 0.510223 Content Loss: 0.008296

run [900]:
Style Loss : 0.491140 Content Loss: 0.009159

run [950]:
Style Loss : 0.474320 Content Loss: 0.010040

run [1000]:
Style Loss : 0.460817 Content Loss: 0.010828

run [1050]:
Style Loss : 0.449425 Content Loss: 0.011554

run [1100]:
Style Loss : 0.440330 Content Loss: 0.012144

run [1150]:
Style Loss : 0.433300 Content Loss: 0.012639

run [1200]:
Style Loss : 0.427770 Content Loss: 0.013016

run [1250]:
Style Loss : 0.423267 Content Loss: 0.013340

run [1300]:
Style Loss : 0.419497 Content Loss: 0.013579

run [1350]:
Style Loss : 0.416491 Content Loss: 0.013719

run [1400]:
Style Loss : 0.413831 Content Loss: 0.013867

run [1450]:
Style Loss : 0.411543 Content Loss: 0.013995

run [1500]:
Style Loss : 0.409541 Content Loss: 0.014089

run [1550]:
Style Loss : 0.407565 Content Loss: 0.014181

run [1600]:
Style Loss : 0.405741 Content Loss: 0.014257

run [1650]:
Style Loss : 0.404051 Content Loss: 0.014323

run [1700]:
Style Loss : 0.402353 Content Loss: 0.014388

run [1750]:
Style Loss : 0.400707 Content Loss: 0.014439

run [1800]:
Style Loss : 0.399168 Content Loss: 0.014486

run [1850]:
Style Loss : 0.397759 Content Loss: 0.014516

run [1900]:
Style Loss : 0.396420 Content Loss: 0.014538

run [1950]:
Style Loss : 0.395114 Content Loss: 0.014555

run [2000]:
Style Loss : 0.393818 Content Loss: 0.014575

run [2050]:
Style Loss : 0.392724 Content Loss: 0.014588

run [2100]:
Style Loss : 0.391660 Content Loss: 0.014601

run [2150]:
Style Loss : 0.390663 Content Loss: 0.014608

run [2200]:
Style Loss : 0.389738 Content Loss: 0.014612

run [2250]:
Style Loss : 0.388842 Content Loss: 0.014613

run [2300]:
Style Loss : 0.387961 Content Loss: 0.014616

run [2350]:
Style Loss : 0.387094 Content Loss: 0.014613

run [2400]:
Style Loss : 0.386255 Content Loss: 0.014612

run [2450]:
Style Loss : 0.385417 Content Loss: 0.014610

run [2500]:
Style Loss : 0.384586 Content Loss: 0.014609

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.282975 Content Loss: 0.005269

run [100]:
Style Loss : 2.100713 Content Loss: 0.004589

run [150]:
Style Loss : 1.499893 Content Loss: 0.004406

run [200]:
Style Loss : 1.210074 Content Loss: 0.004551

run [250]:
Style Loss : 1.043594 Content Loss: 0.004882

run [300]:
Style Loss : 0.936184 Content Loss: 0.005364

run [350]:
Style Loss : 0.852587 Content Loss: 0.005916

run [400]:
Style Loss : 0.785855 Content Loss: 0.006672

run [450]:
Style Loss : 0.726532 Content Loss: 0.007595

run [500]:
Style Loss : 0.675978 Content Loss: 0.008730

run [550]:
Style Loss : 0.631077 Content Loss: 0.010032

run [600]:
Style Loss : 0.592740 Content Loss: 0.011520

run [650]:
Style Loss : 0.562993 Content Loss: 0.012766

run [700]:
Style Loss : 0.541455 Content Loss: 0.013824

run [750]:
Style Loss : 0.526086 Content Loss: 0.014645

run [800]:
Style Loss : 0.514338 Content Loss: 0.015222

run [850]:
Style Loss : 0.505900 Content Loss: 0.015608

run [900]:
Style Loss : 0.499128 Content Loss: 0.015923

run [950]:
Style Loss : 0.493522 Content Loss: 0.016103

run [1000]:
Style Loss : 0.488673 Content Loss: 0.016248

run [1050]:
Style Loss : 0.484418 Content Loss: 0.016343

run [1100]:
Style Loss : 0.480600 Content Loss: 0.016416

run [1150]:
Style Loss : 0.477051 Content Loss: 0.016481

run [1200]:
Style Loss : 0.473574 Content Loss: 0.016557

run [1250]:
Style Loss : 0.470379 Content Loss: 0.016599

run [1300]:
Style Loss : 0.467280 Content Loss: 0.016641

run [1350]:
Style Loss : 0.464289 Content Loss: 0.016684

run [1400]:
Style Loss : 0.461669 Content Loss: 0.016713

run [1450]:
Style Loss : 0.459144 Content Loss: 0.016738

run [1500]:
Style Loss : 0.456814 Content Loss: 0.016752

run [1550]:
Style Loss : 0.454830 Content Loss: 0.016766

run [1600]:
Style Loss : 0.452870 Content Loss: 0.016791

run [1650]:
Style Loss : 0.450948 Content Loss: 0.016820

run [1700]:
Style Loss : 0.449108 Content Loss: 0.016850

run [1750]:
Style Loss : 0.447387 Content Loss: 0.016869

run [1800]:
Style Loss : 0.445818 Content Loss: 0.016891

run [1850]:
Style Loss : 0.444294 Content Loss: 0.016910

run [1900]:
Style Loss : 0.442904 Content Loss: 0.016936

run [1950]:
Style Loss : 0.441515 Content Loss: 0.016960

run [2000]:
Style Loss : 0.440053 Content Loss: 0.016985

run [2050]:
Style Loss : 0.438661 Content Loss: 0.017017

run [2100]:
Style Loss : 0.437294 Content Loss: 0.017051

run [2150]:
Style Loss : 0.435984 Content Loss: 0.017078

run [2200]:
Style Loss : 0.434626 Content Loss: 0.017108

run [2250]:
Style Loss : 0.433303 Content Loss: 0.017136

run [2300]:
Style Loss : 0.432037 Content Loss: 0.017164

run [2350]:
Style Loss : 0.430795 Content Loss: 0.017203

run [2400]:
Style Loss : 0.429658 Content Loss: 0.017234

run [2450]:
Style Loss : 0.428439 Content Loss: 0.017266

run [2500]:
Style Loss : 0.427285 Content Loss: 0.017304

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.735425 Content Loss: 0.007120

run [100]:
Style Loss : 3.132683 Content Loss: 0.007064

run [150]:
Style Loss : 2.545746 Content Loss: 0.007640

run [200]:
Style Loss : 2.203565 Content Loss: 0.008251

run [250]:
Style Loss : 1.958181 Content Loss: 0.009003

run [300]:
Style Loss : 1.775341 Content Loss: 0.009777

run [350]:
Style Loss : 1.621657 Content Loss: 0.010624

run [400]:
Style Loss : 1.497413 Content Loss: 0.011747

run [450]:
Style Loss : 1.395734 Content Loss: 0.012880

run [500]:
Style Loss : 1.298542 Content Loss: 0.014150

run [550]:
Style Loss : 1.213460 Content Loss: 0.015392

run [600]:
Style Loss : 1.142676 Content Loss: 0.016654

run [650]:
Style Loss : 1.080454 Content Loss: 0.017793

run [700]:
Style Loss : 1.031835 Content Loss: 0.018809

run [750]:
Style Loss : 0.992244 Content Loss: 0.019592

run [800]:
Style Loss : 0.959216 Content Loss: 0.020152

run [850]:
Style Loss : 0.933552 Content Loss: 0.020610

run [900]:
Style Loss : 0.911252 Content Loss: 0.020994

run [950]:
Style Loss : 0.891389 Content Loss: 0.021304

run [1000]:
Style Loss : 0.874316 Content Loss: 0.021517

run [1050]:
Style Loss : 0.859731 Content Loss: 0.021712

run [1100]:
Style Loss : 0.846022 Content Loss: 0.021927

run [1150]:
Style Loss : 0.833584 Content Loss: 0.022115

run [1200]:
Style Loss : 0.822928 Content Loss: 0.022206

run [1250]:
Style Loss : 0.813803 Content Loss: 0.022303

run [1300]:
Style Loss : 0.805377 Content Loss: 0.022376

run [1350]:
Style Loss : 0.797762 Content Loss: 0.022454

run [1400]:
Style Loss : 0.790800 Content Loss: 0.022495

run [1450]:
Style Loss : 0.784040 Content Loss: 0.022562

run [1500]:
Style Loss : 0.777527 Content Loss: 0.022605

run [1550]:
Style Loss : 0.771626 Content Loss: 0.022656

run [1600]:
Style Loss : 0.765487 Content Loss: 0.022707

run [1650]:
Style Loss : 0.759851 Content Loss: 0.022754

run [1700]:
Style Loss : 0.754262 Content Loss: 0.022799

run [1750]:
Style Loss : 0.748813 Content Loss: 0.022837

run [1800]:
Style Loss : 0.744069 Content Loss: 0.022879

run [1850]:
Style Loss : 0.739324 Content Loss: 0.022933

run [1900]:
Style Loss : 0.734415 Content Loss: 0.022989

run [1950]:
Style Loss : 0.729497 Content Loss: 0.023040

run [2000]:
Style Loss : 0.724674 Content Loss: 0.023101

run [2050]:
Style Loss : 0.719970 Content Loss: 0.023157

run [2100]:
Style Loss : 0.715637 Content Loss: 0.023207

run [2150]:
Style Loss : 0.711809 Content Loss: 0.023242

run [2200]:
Style Loss : 0.708364 Content Loss: 0.023272

run [2250]:
Style Loss : 0.705229 Content Loss: 0.023316

run [2300]:
Style Loss : 0.702036 Content Loss: 0.023366

run [2350]:
Style Loss : 0.698535 Content Loss: 0.023412

run [2400]:
Style Loss : 0.695500 Content Loss: 0.023454

run [2450]:
Style Loss : 0.692496 Content Loss: 0.023505

run [2500]:
Style Loss : 0.689571 Content Loss: 0.023549

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.783796 Content Loss: 0.006575

run [100]:
Style Loss : 1.849367 Content Loss: 0.006155

run [150]:
Style Loss : 1.356254 Content Loss: 0.006400

run [200]:
Style Loss : 1.049200 Content Loss: 0.006982

run [250]:
Style Loss : 0.869976 Content Loss: 0.007657

run [300]:
Style Loss : 0.728479 Content Loss: 0.008964

run [350]:
Style Loss : 0.602827 Content Loss: 0.011001

run [400]:
Style Loss : 0.487323 Content Loss: 0.013846

run [450]:
Style Loss : 0.396673 Content Loss: 0.016900

run [500]:
Style Loss : 0.334699 Content Loss: 0.019861

run [550]:
Style Loss : 0.299227 Content Loss: 0.021774

run [600]:
Style Loss : 0.276155 Content Loss: 0.023087

run [650]:
Style Loss : 0.259992 Content Loss: 0.023776

run [700]:
Style Loss : 0.248532 Content Loss: 0.024114

run [750]:
Style Loss : 0.239668 Content Loss: 0.024261

run [800]:
Style Loss : 0.232023 Content Loss: 0.024430

run [850]:
Style Loss : 0.224654 Content Loss: 0.024545

run [900]:
Style Loss : 0.219199 Content Loss: 0.024583

run [950]:
Style Loss : 0.214650 Content Loss: 0.024668

run [1000]:
Style Loss : 0.210282 Content Loss: 0.024790

run [1050]:
Style Loss : 0.206201 Content Loss: 0.024854

run [1100]:
Style Loss : 0.202290 Content Loss: 0.024918

run [1150]:
Style Loss : 0.198025 Content Loss: 0.025042

run [1200]:
Style Loss : 0.194072 Content Loss: 0.025137

run [1250]:
Style Loss : 0.192736 Content Loss: 0.025200

run [1300]:
Style Loss : 0.186261 Content Loss: 0.025381

run [1350]:
Style Loss : 0.182556 Content Loss: 0.025471

run [1400]:
Style Loss : 0.178767 Content Loss: 0.025538

run [1450]:
Style Loss : 0.175437 Content Loss: 0.025632

run [1500]:
Style Loss : 0.175817 Content Loss: 0.025675

run [1550]:
Style Loss : 0.169126 Content Loss: 0.025821

run [1600]:
Style Loss : 0.164592 Content Loss: 0.026021

run [1650]:
Style Loss : 0.160730 Content Loss: 0.026102

run [1700]:
Style Loss : 0.157814 Content Loss: 0.026187

run [1750]:
Style Loss : 0.154875 Content Loss: 0.026266

run [1800]:
Style Loss : 0.152380 Content Loss: 0.026347

run [1850]:
Style Loss : 0.150243 Content Loss: 0.026442

run [1900]:
Style Loss : 0.147998 Content Loss: 0.026498

run [1950]:
Style Loss : 0.146180 Content Loss: 0.026591

run [2000]:
Style Loss : 0.143362 Content Loss: 0.026659

run [2050]:
Style Loss : 0.141560 Content Loss: 0.026766

run [2100]:
Style Loss : 0.142870 Content Loss: 0.026861

run [2150]:
Style Loss : 0.143505 Content Loss: 0.026980

run [2200]:
Style Loss : 0.138647 Content Loss: 0.027003

run [2250]:
Style Loss : 0.405335 Content Loss: 0.027666

run [2300]:
Style Loss : 0.139157 Content Loss: 0.027214

run [2350]:
Style Loss : 0.134334 Content Loss: 0.027305

run [2400]:
Style Loss : 0.131837 Content Loss: 0.027451

run [2450]:
Style Loss : 0.130224 Content Loss: 0.027517

run [2500]:
Style Loss : 0.128957 Content Loss: 0.027580

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.545994 Content Loss: 0.002842

run [100]:
Style Loss : 1.016746 Content Loss: 0.003297

run [150]:
Style Loss : 0.829461 Content Loss: 0.004035

run [200]:
Style Loss : 0.721448 Content Loss: 0.005092

run [250]:
Style Loss : 0.641605 Content Loss: 0.006230

run [300]:
Style Loss : 0.576713 Content Loss: 0.007524

run [350]:
Style Loss : 0.525046 Content Loss: 0.008952

run [400]:
Style Loss : 0.482226 Content Loss: 0.010497

run [450]:
Style Loss : 0.446926 Content Loss: 0.011946

run [500]:
Style Loss : 0.420332 Content Loss: 0.013156

run [550]:
Style Loss : 0.402655 Content Loss: 0.014223

run [600]:
Style Loss : 0.388358 Content Loss: 0.014964

run [650]:
Style Loss : 0.377700 Content Loss: 0.015485

run [700]:
Style Loss : 0.370017 Content Loss: 0.015824

run [750]:
Style Loss : 0.364369 Content Loss: 0.016058

run [800]:
Style Loss : 0.360054 Content Loss: 0.016222

run [850]:
Style Loss : 0.356320 Content Loss: 0.016327

run [900]:
Style Loss : 0.352855 Content Loss: 0.016436

run [950]:
Style Loss : 0.349536 Content Loss: 0.016520

run [1000]:
Style Loss : 0.346676 Content Loss: 0.016580

run [1050]:
Style Loss : 0.344279 Content Loss: 0.016631

run [1100]:
Style Loss : 0.342135 Content Loss: 0.016677

run [1150]:
Style Loss : 0.340415 Content Loss: 0.016720

run [1200]:
Style Loss : 0.338789 Content Loss: 0.016751

run [1250]:
Style Loss : 0.337303 Content Loss: 0.016779

run [1300]:
Style Loss : 0.335922 Content Loss: 0.016798

run [1350]:
Style Loss : 0.334668 Content Loss: 0.016817

run [1400]:
Style Loss : 0.333611 Content Loss: 0.016840

run [1450]:
Style Loss : 0.332697 Content Loss: 0.016859

run [1500]:
Style Loss : 0.331705 Content Loss: 0.016887

run [1550]:
Style Loss : 0.330785 Content Loss: 0.016911

run [1600]:
Style Loss : 0.329972 Content Loss: 0.016928

run [1650]:
Style Loss : 0.329194 Content Loss: 0.016954

run [1700]:
Style Loss : 0.328373 Content Loss: 0.016979

run [1750]:
Style Loss : 0.327569 Content Loss: 0.016999

run [1800]:
Style Loss : 0.326730 Content Loss: 0.017023

run [1850]:
Style Loss : 0.326002 Content Loss: 0.017044

run [1900]:
Style Loss : 0.325274 Content Loss: 0.017065

run [1950]:
Style Loss : 0.324602 Content Loss: 0.017084

run [2000]:
Style Loss : 0.323935 Content Loss: 0.017102

run [2050]:
Style Loss : 0.323223 Content Loss: 0.017122

run [2100]:
Style Loss : 0.322522 Content Loss: 0.017143

run [2150]:
Style Loss : 0.321913 Content Loss: 0.017161

run [2200]:
Style Loss : 0.321293 Content Loss: 0.017183

run [2250]:
Style Loss : 0.320549 Content Loss: 0.017205

run [2300]:
Style Loss : 0.319972 Content Loss: 0.017222

run [2350]:
Style Loss : 0.319439 Content Loss: 0.017238

run [2400]:
Style Loss : 0.318940 Content Loss: 0.017257

run [2450]:
Style Loss : 0.318482 Content Loss: 0.017276

run [2500]:
Style Loss : 0.318030 Content Loss: 0.017291

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.012875 Content Loss: 0.002002

run [100]:
Style Loss : 0.675092 Content Loss: 0.002055

run [150]:
Style Loss : 0.546463 Content Loss: 0.002366

run [200]:
Style Loss : 0.476661 Content Loss: 0.002747

run [250]:
Style Loss : 0.428689 Content Loss: 0.003180

run [300]:
Style Loss : 0.391852 Content Loss: 0.003674

run [350]:
Style Loss : 0.317129 Content Loss: 0.004206

run [400]:
Style Loss : 0.287681 Content Loss: 0.004786

run [450]:
Style Loss : 0.266344 Content Loss: 0.005432

run [500]:
Style Loss : 0.248700 Content Loss: 0.006190

run [550]:
Style Loss : 0.234015 Content Loss: 0.006925

run [600]:
Style Loss : 0.222460 Content Loss: 0.007641

run [650]:
Style Loss : 0.213408 Content Loss: 0.008211

run [700]:
Style Loss : 0.206665 Content Loss: 0.008647

run [750]:
Style Loss : 0.201682 Content Loss: 0.008989

run [800]:
Style Loss : 0.197736 Content Loss: 0.009212

run [850]:
Style Loss : 0.194451 Content Loss: 0.009414

run [900]:
Style Loss : 0.191392 Content Loss: 0.009570

run [950]:
Style Loss : 0.188617 Content Loss: 0.009685

run [1000]:
Style Loss : 0.186245 Content Loss: 0.009769

run [1050]:
Style Loss : 0.184028 Content Loss: 0.009867

run [1100]:
Style Loss : 0.182035 Content Loss: 0.009920

run [1150]:
Style Loss : 0.180247 Content Loss: 0.009970

run [1200]:
Style Loss : 0.178562 Content Loss: 0.010022

run [1250]:
Style Loss : 0.177039 Content Loss: 0.010077

run [1300]:
Style Loss : 0.175443 Content Loss: 0.010127

run [1350]:
Style Loss : 0.173728 Content Loss: 0.010176

run [1400]:
Style Loss : 0.172371 Content Loss: 0.010225

run [1450]:
Style Loss : 0.171055 Content Loss: 0.010270

run [1500]:
Style Loss : 0.169831 Content Loss: 0.010317

run [1550]:
Style Loss : 0.168601 Content Loss: 0.010358

run [1600]:
Style Loss : 0.167208 Content Loss: 0.010414

run [1650]:
Style Loss : 0.165810 Content Loss: 0.010470

run [1700]:
Style Loss : 0.164422 Content Loss: 0.010515

run [1750]:
Style Loss : 0.162971 Content Loss: 0.010571

run [1800]:
Style Loss : 0.161586 Content Loss: 0.010619

run [1850]:
Style Loss : 0.160387 Content Loss: 0.010664

run [1900]:
Style Loss : 0.159284 Content Loss: 0.010708

run [1950]:
Style Loss : 0.158162 Content Loss: 0.010757

run [2000]:
Style Loss : 0.157069 Content Loss: 0.010801

run [2050]:
Style Loss : 0.156009 Content Loss: 0.010843

run [2100]:
Style Loss : 0.155042 Content Loss: 0.010880

run [2150]:
Style Loss : 0.154182 Content Loss: 0.010922

run [2200]:
Style Loss : 0.153388 Content Loss: 0.010966

run [2250]:
Style Loss : 0.152554 Content Loss: 0.011008

run [2300]:
Style Loss : 0.151804 Content Loss: 0.011050

run [2350]:
Style Loss : 0.151077 Content Loss: 0.011085

run [2400]:
Style Loss : 0.150356 Content Loss: 0.011120

run [2450]:
Style Loss : 0.149724 Content Loss: 0.011150

run [2500]:
Style Loss : 0.149131 Content Loss: 0.011180

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.094826 Content Loss: 0.002597

run [100]:
Style Loss : 0.758209 Content Loss: 0.004083

run [150]:
Style Loss : 0.591615 Content Loss: 0.005948

run [200]:
Style Loss : 0.482033 Content Loss: 0.008529

run [250]:
Style Loss : 0.393724 Content Loss: 0.011448

run [300]:
Style Loss : 0.335527 Content Loss: 0.014423

run [350]:
Style Loss : 0.297672 Content Loss: 0.016974

run [400]:
Style Loss : 0.275390 Content Loss: 0.018473

run [450]:
Style Loss : 0.260488 Content Loss: 0.019353

run [500]:
Style Loss : 0.247870 Content Loss: 0.019808

run [550]:
Style Loss : 0.237645 Content Loss: 0.020173

run [600]:
Style Loss : 0.228338 Content Loss: 0.020618

run [650]:
Style Loss : 0.219455 Content Loss: 0.021061

run [700]:
Style Loss : 0.211621 Content Loss: 0.021452

run [750]:
Style Loss : 0.204041 Content Loss: 0.021826

run [800]:
Style Loss : 0.196315 Content Loss: 0.022155

run [850]:
Style Loss : 0.189105 Content Loss: 0.022520

run [900]:
Style Loss : 0.182175 Content Loss: 0.022958

run [950]:
Style Loss : 0.175496 Content Loss: 0.023421

run [1000]:
Style Loss : 0.169077 Content Loss: 0.023927

run [1050]:
Style Loss : 0.162963 Content Loss: 0.024553

run [1100]:
Style Loss : 0.156799 Content Loss: 0.025266

run [1150]:
Style Loss : 0.150711 Content Loss: 0.025883

run [1200]:
Style Loss : 0.144954 Content Loss: 0.026582

run [1250]:
Style Loss : 0.139692 Content Loss: 0.027262

run [1300]:
Style Loss : 0.134311 Content Loss: 0.027834

run [1350]:
Style Loss : 0.130083 Content Loss: 0.028532

run [1400]:
Style Loss : 0.127186 Content Loss: 0.029329

run [1450]:
Style Loss : 0.122649 Content Loss: 0.029800

run [1500]:
Style Loss : 0.117807 Content Loss: 0.030136

run [1550]:
Style Loss : 0.114610 Content Loss: 0.030615

run [1600]:
Style Loss : 0.111879 Content Loss: 0.030998

run [1650]:
Style Loss : 0.109115 Content Loss: 0.031277

run [1700]:
Style Loss : 0.106553 Content Loss: 0.031471

run [1750]:
Style Loss : 0.104673 Content Loss: 0.031657

run [1800]:
Style Loss : 0.103070 Content Loss: 0.031791

run [1850]:
Style Loss : 0.101141 Content Loss: 0.031851

run [1900]:
Style Loss : 0.099936 Content Loss: 0.031902

run [1950]:
Style Loss : 0.098701 Content Loss: 0.031909

run [2000]:
Style Loss : 0.097669 Content Loss: 0.031900

run [2050]:
Style Loss : 0.096836 Content Loss: 0.031876

run [2100]:
Style Loss : 0.095987 Content Loss: 0.031824

run [2150]:
Style Loss : 0.095259 Content Loss: 0.031773

run [2200]:
Style Loss : 0.094597 Content Loss: 0.031706

run [2250]:
Style Loss : 0.094030 Content Loss: 0.031622

run [2300]:
Style Loss : 0.093533 Content Loss: 0.031537

run [2350]:
Style Loss : 0.092919 Content Loss: 0.031454

run [2400]:
Style Loss : 0.092504 Content Loss: 0.031350

run [2450]:
Style Loss : 0.092103 Content Loss: 0.031252

run [2500]:
Style Loss : 0.091692 Content Loss: 0.031142

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.791001 Content Loss: 0.001216

run [100]:
Style Loss : 0.547587 Content Loss: 0.001455

run [150]:
Style Loss : 0.449425 Content Loss: 0.001797

run [200]:
Style Loss : 0.390382 Content Loss: 0.002309

run [250]:
Style Loss : 0.344700 Content Loss: 0.002821

run [300]:
Style Loss : 0.308874 Content Loss: 0.003462

run [350]:
Style Loss : 0.279998 Content Loss: 0.004148

run [400]:
Style Loss : 0.254229 Content Loss: 0.004906

run [450]:
Style Loss : 0.233407 Content Loss: 0.005640

run [500]:
Style Loss : 0.216913 Content Loss: 0.006399

run [550]:
Style Loss : 0.204777 Content Loss: 0.007116

run [600]:
Style Loss : 0.194751 Content Loss: 0.007771

run [650]:
Style Loss : 0.186856 Content Loss: 0.008347

run [700]:
Style Loss : 0.180400 Content Loss: 0.008791

run [750]:
Style Loss : 0.175285 Content Loss: 0.009153

run [800]:
Style Loss : 0.171150 Content Loss: 0.009433

run [850]:
Style Loss : 0.167477 Content Loss: 0.009653

run [900]:
Style Loss : 0.164247 Content Loss: 0.009835

run [950]:
Style Loss : 0.161524 Content Loss: 0.009977

run [1000]:
Style Loss : 0.158786 Content Loss: 0.010101

run [1050]:
Style Loss : 0.156347 Content Loss: 0.010197

run [1100]:
Style Loss : 0.154070 Content Loss: 0.010280

run [1150]:
Style Loss : 0.151976 Content Loss: 0.010385

run [1200]:
Style Loss : 0.150079 Content Loss: 0.010462

run [1250]:
Style Loss : 0.148267 Content Loss: 0.010538

run [1300]:
Style Loss : 0.146694 Content Loss: 0.010609

run [1350]:
Style Loss : 0.145255 Content Loss: 0.010677

run [1400]:
Style Loss : 0.143991 Content Loss: 0.010729

run [1450]:
Style Loss : 0.142790 Content Loss: 0.010785

run [1500]:
Style Loss : 0.141646 Content Loss: 0.010843

run [1550]:
Style Loss : 0.140499 Content Loss: 0.010911

run [1600]:
Style Loss : 0.139431 Content Loss: 0.010967

run [1650]:
Style Loss : 0.138440 Content Loss: 0.011018

run [1700]:
Style Loss : 0.137415 Content Loss: 0.011076

run [1750]:
Style Loss : 0.136404 Content Loss: 0.011137

run [1800]:
Style Loss : 0.135361 Content Loss: 0.011199

run [1850]:
Style Loss : 0.134332 Content Loss: 0.011251

run [1900]:
Style Loss : 0.133316 Content Loss: 0.011307

run [1950]:
Style Loss : 0.132428 Content Loss: 0.011356

run [2000]:
Style Loss : 0.131566 Content Loss: 0.011406

run [2050]:
Style Loss : 0.130783 Content Loss: 0.011448

run [2100]:
Style Loss : 0.130059 Content Loss: 0.011491

run [2150]:
Style Loss : 0.129271 Content Loss: 0.011533

run [2200]:
Style Loss : 0.128432 Content Loss: 0.011572

run [2250]:
Style Loss : 0.120737 Content Loss: 0.011633

run [2300]:
Style Loss : 0.119135 Content Loss: 0.011641

run [2350]:
Style Loss : 0.118048 Content Loss: 0.011665

run [2400]:
Style Loss : 0.117149 Content Loss: 0.011692

run [2450]:
Style Loss : 0.116406 Content Loss: 0.011722

run [2500]:
Style Loss : 0.115741 Content Loss: 0.011748

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.470288 Content Loss: 0.003553

run [100]:
Style Loss : 1.658695 Content Loss: 0.002707

run [150]:
Style Loss : 1.274887 Content Loss: 0.002627

run [200]:
Style Loss : 1.103319 Content Loss: 0.002754

run [250]:
Style Loss : 0.998898 Content Loss: 0.002945

run [300]:
Style Loss : 0.923609 Content Loss: 0.003160

run [350]:
Style Loss : 0.868704 Content Loss: 0.003444

run [400]:
Style Loss : 0.824740 Content Loss: 0.003772

run [450]:
Style Loss : 0.786270 Content Loss: 0.004151

run [500]:
Style Loss : 0.752102 Content Loss: 0.004649

run [550]:
Style Loss : 0.720286 Content Loss: 0.005192

run [600]:
Style Loss : 0.690877 Content Loss: 0.005908

run [650]:
Style Loss : 0.663066 Content Loss: 0.006795

run [700]:
Style Loss : 0.637161 Content Loss: 0.007791

run [750]:
Style Loss : 0.612295 Content Loss: 0.008879

run [800]:
Style Loss : 0.590501 Content Loss: 0.009932

run [850]:
Style Loss : 0.572529 Content Loss: 0.010893

run [900]:
Style Loss : 0.558354 Content Loss: 0.011631

run [950]:
Style Loss : 0.546892 Content Loss: 0.012218

run [1000]:
Style Loss : 0.537504 Content Loss: 0.012706

run [1050]:
Style Loss : 0.530000 Content Loss: 0.013030

run [1100]:
Style Loss : 0.523542 Content Loss: 0.013308

run [1150]:
Style Loss : 0.518338 Content Loss: 0.013510

run [1200]:
Style Loss : 0.513524 Content Loss: 0.013687

run [1250]:
Style Loss : 0.508843 Content Loss: 0.013825

run [1300]:
Style Loss : 0.504495 Content Loss: 0.013950

run [1350]:
Style Loss : 0.500520 Content Loss: 0.014036

run [1400]:
Style Loss : 0.496714 Content Loss: 0.014114

run [1450]:
Style Loss : 0.493041 Content Loss: 0.014181

run [1500]:
Style Loss : 0.489591 Content Loss: 0.014238

run [1550]:
Style Loss : 0.486080 Content Loss: 0.014301

run [1600]:
Style Loss : 0.482621 Content Loss: 0.014353

run [1650]:
Style Loss : 0.478978 Content Loss: 0.014416

run [1700]:
Style Loss : 0.475347 Content Loss: 0.014469

run [1750]:
Style Loss : 0.471836 Content Loss: 0.014525

run [1800]:
Style Loss : 0.468194 Content Loss: 0.014587

run [1850]:
Style Loss : 0.464756 Content Loss: 0.014647

run [1900]:
Style Loss : 0.461030 Content Loss: 0.014732

run [1950]:
Style Loss : 0.457371 Content Loss: 0.014805

run [2000]:
Style Loss : 0.453559 Content Loss: 0.014905

run [2050]:
Style Loss : 0.449717 Content Loss: 0.015002

run [2100]:
Style Loss : 0.445775 Content Loss: 0.015138

run [2150]:
Style Loss : 0.441787 Content Loss: 0.015288

run [2200]:
Style Loss : 0.437646 Content Loss: 0.015443

run [2250]:
Style Loss : 0.433713 Content Loss: 0.015631

run [2300]:
Style Loss : 0.429765 Content Loss: 0.015830

run [2350]:
Style Loss : 0.425727 Content Loss: 0.016046

run [2400]:
Style Loss : 0.421612 Content Loss: 0.016291

run [2450]:
Style Loss : 0.417578 Content Loss: 0.016548

run [2500]:
Style Loss : 0.413751 Content Loss: 0.016784

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.900649 Content Loss: 0.001992

run [100]:
Style Loss : 0.612703 Content Loss: 0.003018

run [150]:
Style Loss : 0.454679 Content Loss: 0.004235

run [200]:
Style Loss : 0.357165 Content Loss: 0.005768

run [250]:
Style Loss : 0.285059 Content Loss: 0.007572

run [300]:
Style Loss : 0.231159 Content Loss: 0.009890

run [350]:
Style Loss : 0.196034 Content Loss: 0.011895

run [400]:
Style Loss : 0.175036 Content Loss: 0.013331

run [450]:
Style Loss : 0.161185 Content Loss: 0.014001

run [500]:
Style Loss : 0.151677 Content Loss: 0.014388

run [550]:
Style Loss : 0.144064 Content Loss: 0.014573

run [600]:
Style Loss : 0.137753 Content Loss: 0.014751

run [650]:
Style Loss : 0.131601 Content Loss: 0.014951

run [700]:
Style Loss : 0.125829 Content Loss: 0.015146

run [750]:
Style Loss : 0.120421 Content Loss: 0.015317

run [800]:
Style Loss : 0.115612 Content Loss: 0.015494

run [850]:
Style Loss : 0.110957 Content Loss: 0.015695

run [900]:
Style Loss : 0.106902 Content Loss: 0.015856

run [950]:
Style Loss : 0.103117 Content Loss: 0.016039

run [1000]:
Style Loss : 0.099564 Content Loss: 0.016238

run [1050]:
Style Loss : 0.096213 Content Loss: 0.016434

run [1100]:
Style Loss : 0.093158 Content Loss: 0.016613

run [1150]:
Style Loss : 0.090340 Content Loss: 0.016778

run [1200]:
Style Loss : 0.087962 Content Loss: 0.016904

run [1250]:
Style Loss : 0.085866 Content Loss: 0.017026

run [1300]:
Style Loss : 0.083843 Content Loss: 0.017143

run [1350]:
Style Loss : 0.081946 Content Loss: 0.017247

run [1400]:
Style Loss : 0.080148 Content Loss: 0.017331

run [1450]:
Style Loss : 0.078704 Content Loss: 0.017413

run [1500]:
Style Loss : 0.077459 Content Loss: 0.017488

run [1550]:
Style Loss : 0.076359 Content Loss: 0.017555

run [1600]:
Style Loss : 0.075313 Content Loss: 0.017619

run [1650]:
Style Loss : 0.074369 Content Loss: 0.017678

run [1700]:
Style Loss : 0.073483 Content Loss: 0.017721

run [1750]:
Style Loss : 0.072726 Content Loss: 0.017765

run [1800]:
Style Loss : 0.072028 Content Loss: 0.017804

run [1850]:
Style Loss : 0.071396 Content Loss: 0.017838

run [1900]:
Style Loss : 0.070798 Content Loss: 0.017868

run [1950]:
Style Loss : 0.070286 Content Loss: 0.017882

run [2000]:
Style Loss : 0.069787 Content Loss: 0.017912

run [2050]:
Style Loss : 0.069296 Content Loss: 0.017939

run [2100]:
Style Loss : 0.068818 Content Loss: 0.017957

run [2150]:
Style Loss : 0.068343 Content Loss: 0.017975

run [2200]:
Style Loss : 0.067895 Content Loss: 0.017991

run [2250]:
Style Loss : 0.067427 Content Loss: 0.018001

run [2300]:
Style Loss : 0.066972 Content Loss: 0.018024

run [2350]:
Style Loss : 0.066589 Content Loss: 0.018036

run [2400]:
Style Loss : 0.066222 Content Loss: 0.018050

run [2450]:
Style Loss : 0.065869 Content Loss: 0.018068

run [2500]:
Style Loss : 0.065523 Content Loss: 0.018082

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.944092 Content Loss: 0.002445

run [100]:
Style Loss : 1.343788 Content Loss: 0.002942

run [150]:
Style Loss : 1.115868 Content Loss: 0.003478

run [200]:
Style Loss : 0.976389 Content Loss: 0.004340

run [250]:
Style Loss : 0.867423 Content Loss: 0.005503

run [300]:
Style Loss : 0.778834 Content Loss: 0.006942

run [350]:
Style Loss : 0.699335 Content Loss: 0.008889

run [400]:
Style Loss : 0.629506 Content Loss: 0.011300

run [450]:
Style Loss : 0.571230 Content Loss: 0.013821

run [500]:
Style Loss : 0.528095 Content Loss: 0.016090

run [550]:
Style Loss : 0.499183 Content Loss: 0.017682

run [600]:
Style Loss : 0.479452 Content Loss: 0.018801

run [650]:
Style Loss : 0.464736 Content Loss: 0.019466

run [700]:
Style Loss : 0.452444 Content Loss: 0.019978

run [750]:
Style Loss : 0.440869 Content Loss: 0.020339

run [800]:
Style Loss : 0.430219 Content Loss: 0.020579

run [850]:
Style Loss : 0.421034 Content Loss: 0.020701

run [900]:
Style Loss : 0.411969 Content Loss: 0.020888

run [950]:
Style Loss : 0.403039 Content Loss: 0.021036

run [1000]:
Style Loss : 0.394616 Content Loss: 0.021162

run [1050]:
Style Loss : 0.387352 Content Loss: 0.021301

run [1100]:
Style Loss : 0.380802 Content Loss: 0.021405

run [1150]:
Style Loss : 0.375214 Content Loss: 0.021481

run [1200]:
Style Loss : 0.370243 Content Loss: 0.021591

run [1250]:
Style Loss : 0.365225 Content Loss: 0.021697

run [1300]:
Style Loss : 0.360716 Content Loss: 0.021801

run [1350]:
Style Loss : 0.356607 Content Loss: 0.021904

run [1400]:
Style Loss : 0.352650 Content Loss: 0.022030

run [1450]:
Style Loss : 0.349009 Content Loss: 0.022126

run [1500]:
Style Loss : 0.345431 Content Loss: 0.022237

run [1550]:
Style Loss : 0.341959 Content Loss: 0.022362

run [1600]:
Style Loss : 0.338694 Content Loss: 0.022464

run [1650]:
Style Loss : 0.335473 Content Loss: 0.022599

run [1700]:
Style Loss : 0.332344 Content Loss: 0.022738

run [1750]:
Style Loss : 0.329419 Content Loss: 0.022866

run [1800]:
Style Loss : 0.326562 Content Loss: 0.023006

run [1850]:
Style Loss : 0.323732 Content Loss: 0.023135

run [1900]:
Style Loss : 0.321145 Content Loss: 0.023259

run [1950]:
Style Loss : 0.318519 Content Loss: 0.023381

run [2000]:
Style Loss : 0.316035 Content Loss: 0.023499

run [2050]:
Style Loss : 0.313626 Content Loss: 0.023611

run [2100]:
Style Loss : 0.311339 Content Loss: 0.023731

run [2150]:
Style Loss : 0.308526 Content Loss: 0.023831

run [2200]:
Style Loss : 0.305902 Content Loss: 0.023933

run [2250]:
Style Loss : 0.303478 Content Loss: 0.024023

run [2300]:
Style Loss : 0.301406 Content Loss: 0.024098

run [2350]:
Style Loss : 0.299528 Content Loss: 0.024170

run [2400]:
Style Loss : 0.297625 Content Loss: 0.024240

run [2450]:
Style Loss : 0.295697 Content Loss: 0.024316

run [2500]:
Style Loss : 0.293896 Content Loss: 0.024383

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.580475 Content Loss: 0.003784

run [100]:
Style Loss : 0.954506 Content Loss: 0.007112

run [150]:
Style Loss : 0.746859 Content Loss: 0.009625

run [200]:
Style Loss : 0.609418 Content Loss: 0.011550

run [250]:
Style Loss : 0.518244 Content Loss: 0.013626

run [300]:
Style Loss : 0.454726 Content Loss: 0.015688

run [350]:
Style Loss : 0.405183 Content Loss: 0.017623

run [400]:
Style Loss : 0.367396 Content Loss: 0.019316

run [450]:
Style Loss : 0.339357 Content Loss: 0.020698

run [500]:
Style Loss : 0.319705 Content Loss: 0.021705

run [550]:
Style Loss : 0.305436 Content Loss: 0.022432

run [600]:
Style Loss : 0.294762 Content Loss: 0.022934

run [650]:
Style Loss : 0.285531 Content Loss: 0.023246

run [700]:
Style Loss : 0.276492 Content Loss: 0.023466

run [750]:
Style Loss : 0.268891 Content Loss: 0.023712

run [800]:
Style Loss : 0.262446 Content Loss: 0.023914

run [850]:
Style Loss : 0.256914 Content Loss: 0.024089

run [900]:
Style Loss : 0.252229 Content Loss: 0.024250

run [950]:
Style Loss : 0.248323 Content Loss: 0.024373

run [1000]:
Style Loss : 0.244141 Content Loss: 0.024492

run [1050]:
Style Loss : 0.240573 Content Loss: 0.024596

run [1100]:
Style Loss : 0.237572 Content Loss: 0.024683

run [1150]:
Style Loss : 0.235175 Content Loss: 0.024763

run [1200]:
Style Loss : 0.233018 Content Loss: 0.024843

run [1250]:
Style Loss : 0.231081 Content Loss: 0.024919

run [1300]:
Style Loss : 0.229255 Content Loss: 0.024989

run [1350]:
Style Loss : 0.227509 Content Loss: 0.025064

run [1400]:
Style Loss : 0.225449 Content Loss: 0.025142

run [1450]:
Style Loss : 0.223085 Content Loss: 0.025201

run [1500]:
Style Loss : 0.221289 Content Loss: 0.025251

run [1550]:
Style Loss : 0.219860 Content Loss: 0.025298

run [1600]:
Style Loss : 0.218500 Content Loss: 0.025348

run [1650]:
Style Loss : 0.217222 Content Loss: 0.025399

run [1700]:
Style Loss : 0.216037 Content Loss: 0.025437

run [1750]:
Style Loss : 0.214894 Content Loss: 0.025486

run [1800]:
Style Loss : 0.213855 Content Loss: 0.025527

run [1850]:
Style Loss : 0.212725 Content Loss: 0.025586

run [1900]:
Style Loss : 0.211738 Content Loss: 0.025638

run [1950]:
Style Loss : 0.210778 Content Loss: 0.025685

run [2000]:
Style Loss : 0.209876 Content Loss: 0.025728

run [2050]:
Style Loss : 0.209039 Content Loss: 0.025764

run [2100]:
Style Loss : 0.208174 Content Loss: 0.025804

run [2150]:
Style Loss : 0.207369 Content Loss: 0.025850

run [2200]:
Style Loss : 0.206632 Content Loss: 0.025881

run [2250]:
Style Loss : 0.205969 Content Loss: 0.025913

run [2300]:
Style Loss : 0.205305 Content Loss: 0.025944

run [2350]:
Style Loss : 0.204648 Content Loss: 0.025974

run [2400]:
Style Loss : 0.204060 Content Loss: 0.026002

run [2450]:
Style Loss : 0.203515 Content Loss: 0.026024

run [2500]:
Style Loss : 0.202999 Content Loss: 0.026043

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.599285 Content Loss: 0.004248

run [100]:
Style Loss : 0.840153 Content Loss: 0.007760

run [150]:
Style Loss : 0.645331 Content Loss: 0.009776

run [200]:
Style Loss : 0.529720 Content Loss: 0.011781

run [250]:
Style Loss : 0.445309 Content Loss: 0.013923

run [300]:
Style Loss : 0.377969 Content Loss: 0.016563

run [350]:
Style Loss : 0.324359 Content Loss: 0.019079

run [400]:
Style Loss : 0.284360 Content Loss: 0.021498

run [450]:
Style Loss : 0.257176 Content Loss: 0.023384

run [500]:
Style Loss : 0.237864 Content Loss: 0.024870

run [550]:
Style Loss : 0.224825 Content Loss: 0.025583

run [600]:
Style Loss : 0.214852 Content Loss: 0.026070

run [650]:
Style Loss : 0.206608 Content Loss: 0.026362

run [700]:
Style Loss : 0.200195 Content Loss: 0.026522

run [750]:
Style Loss : 0.194659 Content Loss: 0.026633

run [800]:
Style Loss : 0.189692 Content Loss: 0.026660

run [850]:
Style Loss : 0.185407 Content Loss: 0.026793

run [900]:
Style Loss : 0.181693 Content Loss: 0.026922

run [950]:
Style Loss : 0.178201 Content Loss: 0.027090

run [1000]:
Style Loss : 0.175188 Content Loss: 0.027230

run [1050]:
Style Loss : 0.172372 Content Loss: 0.027384

run [1100]:
Style Loss : 0.169926 Content Loss: 0.027514

run [1150]:
Style Loss : 0.167722 Content Loss: 0.027650

run [1200]:
Style Loss : 0.165579 Content Loss: 0.027783

run [1250]:
Style Loss : 0.163651 Content Loss: 0.027915

run [1300]:
Style Loss : 0.161844 Content Loss: 0.028042

run [1350]:
Style Loss : 0.160157 Content Loss: 0.028194

run [1400]:
Style Loss : 0.158547 Content Loss: 0.028330

run [1450]:
Style Loss : 0.156933 Content Loss: 0.028465

run [1500]:
Style Loss : 0.155353 Content Loss: 0.028598

run [1550]:
Style Loss : 0.153875 Content Loss: 0.028740

run [1600]:
Style Loss : 0.152417 Content Loss: 0.028889

run [1650]:
Style Loss : 0.150973 Content Loss: 0.029034

run [1700]:
Style Loss : 0.149580 Content Loss: 0.029175

run [1750]:
Style Loss : 0.148302 Content Loss: 0.029311

run [1800]:
Style Loss : 0.147054 Content Loss: 0.029436

run [1850]:
Style Loss : 0.145796 Content Loss: 0.029578

run [1900]:
Style Loss : 0.144618 Content Loss: 0.029700

run [1950]:
Style Loss : 0.143490 Content Loss: 0.029822

run [2000]:
Style Loss : 0.142469 Content Loss: 0.029938

run [2050]:
Style Loss : 0.141519 Content Loss: 0.030079

run [2100]:
Style Loss : 0.140541 Content Loss: 0.030197

run [2150]:
Style Loss : 0.139662 Content Loss: 0.030334

run [2200]:
Style Loss : 0.138814 Content Loss: 0.030458

run [2250]:
Style Loss : 0.137964 Content Loss: 0.030605

run [2300]:
Style Loss : 0.137181 Content Loss: 0.030744

run [2350]:
Style Loss : 0.136406 Content Loss: 0.030877

run [2400]:
Style Loss : 0.135703 Content Loss: 0.031001

run [2450]:
Style Loss : 0.135024 Content Loss: 0.031106

run [2500]:
Style Loss : 0.134426 Content Loss: 0.031228

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.480237 Content Loss: 0.004906

run [100]:
Style Loss : 1.340776 Content Loss: 0.008749

run [150]:
Style Loss : 1.010671 Content Loss: 0.010636

run [200]:
Style Loss : 0.815369 Content Loss: 0.011908

run [250]:
Style Loss : 0.706595 Content Loss: 0.012972

run [300]:
Style Loss : 0.627369 Content Loss: 0.013964

run [350]:
Style Loss : 0.573074 Content Loss: 0.014914

run [400]:
Style Loss : 0.530504 Content Loss: 0.015801

run [450]:
Style Loss : 0.496025 Content Loss: 0.016839

run [500]:
Style Loss : 0.468465 Content Loss: 0.017872

run [550]:
Style Loss : 0.444683 Content Loss: 0.018988

run [600]:
Style Loss : 0.425388 Content Loss: 0.020105

run [650]:
Style Loss : 0.409838 Content Loss: 0.020997

run [700]:
Style Loss : 0.395270 Content Loss: 0.021812

run [750]:
Style Loss : 0.384305 Content Loss: 0.022381

run [800]:
Style Loss : 0.375753 Content Loss: 0.022872

run [850]:
Style Loss : 0.368643 Content Loss: 0.023248

run [900]:
Style Loss : 0.363171 Content Loss: 0.023518

run [950]:
Style Loss : 0.358430 Content Loss: 0.023724

run [1000]:
Style Loss : 0.354134 Content Loss: 0.023908

run [1050]:
Style Loss : 0.350560 Content Loss: 0.024061

run [1100]:
Style Loss : 0.347045 Content Loss: 0.024204

run [1150]:
Style Loss : 0.343853 Content Loss: 0.024306

run [1200]:
Style Loss : 0.340921 Content Loss: 0.024384

run [1250]:
Style Loss : 0.337800 Content Loss: 0.024491

run [1300]:
Style Loss : 0.334717 Content Loss: 0.024577

run [1350]:
Style Loss : 0.331715 Content Loss: 0.024666

run [1400]:
Style Loss : 0.328979 Content Loss: 0.024751

run [1450]:
Style Loss : 0.326406 Content Loss: 0.024832

run [1500]:
Style Loss : 0.323957 Content Loss: 0.024904

run [1550]:
Style Loss : 0.321682 Content Loss: 0.024976

run [1600]:
Style Loss : 0.319443 Content Loss: 0.025044

run [1650]:
Style Loss : 0.316936 Content Loss: 0.025115

run [1700]:
Style Loss : 0.314487 Content Loss: 0.025181

run [1750]:
Style Loss : 0.312248 Content Loss: 0.025245

run [1800]:
Style Loss : 0.310208 Content Loss: 0.025307

run [1850]:
Style Loss : 0.308303 Content Loss: 0.025364

run [1900]:
Style Loss : 0.306479 Content Loss: 0.025430

run [1950]:
Style Loss : 0.304557 Content Loss: 0.025504

run [2000]:
Style Loss : 0.302709 Content Loss: 0.025581

run [2050]:
Style Loss : 0.301065 Content Loss: 0.025651

run [2100]:
Style Loss : 0.299573 Content Loss: 0.025739

run [2150]:
Style Loss : 0.298120 Content Loss: 0.025819

run [2200]:
Style Loss : 0.296724 Content Loss: 0.025903

run [2250]:
Style Loss : 0.295123 Content Loss: 0.026001

run [2300]:
Style Loss : 0.293636 Content Loss: 0.026104

run [2350]:
Style Loss : 0.292194 Content Loss: 0.026200

run [2400]:
Style Loss : 0.290760 Content Loss: 0.026311

run [2450]:
Style Loss : 0.289265 Content Loss: 0.026444

run [2500]:
Style Loss : 0.287750 Content Loss: 0.026575

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.916980 Content Loss: 0.006860

run [100]:
Style Loss : 0.511703 Content Loss: 0.009981

run [150]:
Style Loss : 0.344308 Content Loss: 0.012504

run [200]:
Style Loss : 0.251297 Content Loss: 0.015882

run [250]:
Style Loss : 0.207506 Content Loss: 0.018200

run [300]:
Style Loss : 0.186456 Content Loss: 0.019342

run [350]:
Style Loss : 0.173243 Content Loss: 0.019754

run [400]:
Style Loss : 0.163695 Content Loss: 0.020029

run [450]:
Style Loss : 0.156694 Content Loss: 0.020372

run [500]:
Style Loss : 0.150674 Content Loss: 0.020592

run [550]:
Style Loss : 0.145343 Content Loss: 0.020832

run [600]:
Style Loss : 0.140597 Content Loss: 0.021010

run [650]:
Style Loss : 0.136921 Content Loss: 0.021207

run [700]:
Style Loss : 0.134280 Content Loss: 0.021357

run [750]:
Style Loss : 0.132220 Content Loss: 0.021445

run [800]:
Style Loss : 0.130550 Content Loss: 0.021517

run [850]:
Style Loss : 0.129098 Content Loss: 0.021572

run [900]:
Style Loss : 0.128016 Content Loss: 0.021621

run [950]:
Style Loss : 0.127096 Content Loss: 0.021641

run [1000]:
Style Loss : 0.126344 Content Loss: 0.021670

run [1050]:
Style Loss : 0.125692 Content Loss: 0.021674

run [1100]:
Style Loss : 0.125151 Content Loss: 0.021683

run [1150]:
Style Loss : 0.124663 Content Loss: 0.021690

run [1200]:
Style Loss : 0.124200 Content Loss: 0.021692

run [1250]:
Style Loss : 0.123715 Content Loss: 0.021703

run [1300]:
Style Loss : 0.123251 Content Loss: 0.021710

run [1350]:
Style Loss : 0.122845 Content Loss: 0.021720

run [1400]:
Style Loss : 0.122475 Content Loss: 0.021719

run [1450]:
Style Loss : 0.122154 Content Loss: 0.021722

run [1500]:
Style Loss : 0.121839 Content Loss: 0.021723

run [1550]:
Style Loss : 0.121572 Content Loss: 0.021722

run [1600]:
Style Loss : 0.121309 Content Loss: 0.021723

run [1650]:
Style Loss : 0.121065 Content Loss: 0.021724

run [1700]:
Style Loss : 0.120818 Content Loss: 0.021723

run [1750]:
Style Loss : 0.120596 Content Loss: 0.021723

run [1800]:
Style Loss : 0.120349 Content Loss: 0.021721

run [1850]:
Style Loss : 0.120131 Content Loss: 0.021725

run [1900]:
Style Loss : 0.119912 Content Loss: 0.021727

run [1950]:
Style Loss : 0.119711 Content Loss: 0.021727

run [2000]:
Style Loss : 0.119507 Content Loss: 0.021726

run [2050]:
Style Loss : 0.119324 Content Loss: 0.021727

run [2100]:
Style Loss : 0.119152 Content Loss: 0.021729

run [2150]:
Style Loss : 0.118981 Content Loss: 0.021735

run [2200]:
Style Loss : 0.118831 Content Loss: 0.021739

run [2250]:
Style Loss : 0.118686 Content Loss: 0.021745

run [2300]:
Style Loss : 0.118522 Content Loss: 0.021746

run [2350]:
Style Loss : 0.118366 Content Loss: 0.021752

run [2400]:
Style Loss : 0.118215 Content Loss: 0.021754

run [2450]:
Style Loss : 0.118069 Content Loss: 0.021756

run [2500]:
Style Loss : 0.117919 Content Loss: 0.021760

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.813114 Content Loss: 0.007145

run [100]:
Style Loss : 0.432230 Content Loss: 0.011261

run [150]:
Style Loss : 0.299931 Content Loss: 0.015170

run [200]:
Style Loss : 0.233070 Content Loss: 0.019049

run [250]:
Style Loss : 0.200156 Content Loss: 0.021432

run [300]:
Style Loss : 0.182299 Content Loss: 0.022614

run [350]:
Style Loss : 0.171186 Content Loss: 0.023406

run [400]:
Style Loss : 0.155690 Content Loss: 0.023819

run [450]:
Style Loss : 0.147744 Content Loss: 0.024369

run [500]:
Style Loss : 0.140509 Content Loss: 0.024833

run [550]:
Style Loss : 0.135942 Content Loss: 0.025163

run [600]:
Style Loss : 0.132531 Content Loss: 0.025456

run [650]:
Style Loss : 0.129245 Content Loss: 0.025726

run [700]:
Style Loss : 0.126690 Content Loss: 0.025921

run [750]:
Style Loss : 0.124585 Content Loss: 0.026082

run [800]:
Style Loss : 0.122848 Content Loss: 0.026203

run [850]:
Style Loss : 0.121300 Content Loss: 0.026300

run [900]:
Style Loss : 0.119861 Content Loss: 0.026365

run [950]:
Style Loss : 0.118672 Content Loss: 0.026404

run [1000]:
Style Loss : 0.117703 Content Loss: 0.026422

run [1050]:
Style Loss : 0.116889 Content Loss: 0.026449

run [1100]:
Style Loss : 0.116100 Content Loss: 0.026486

run [1150]:
Style Loss : 0.115371 Content Loss: 0.026525

run [1200]:
Style Loss : 0.114648 Content Loss: 0.026580

run [1250]:
Style Loss : 0.113995 Content Loss: 0.026626

run [1300]:
Style Loss : 0.113360 Content Loss: 0.026664

run [1350]:
Style Loss : 0.112768 Content Loss: 0.026692

run [1400]:
Style Loss : 0.112185 Content Loss: 0.026728

run [1450]:
Style Loss : 0.111238 Content Loss: 0.026761

run [1500]:
Style Loss : 0.110288 Content Loss: 0.026794

run [1550]:
Style Loss : 0.109531 Content Loss: 0.026829

run [1600]:
Style Loss : 0.108845 Content Loss: 0.026872

run [1650]:
Style Loss : 0.108231 Content Loss: 0.026899

run [1700]:
Style Loss : 0.107664 Content Loss: 0.026951

run [1750]:
Style Loss : 0.107128 Content Loss: 0.026997

run [1800]:
Style Loss : 0.106599 Content Loss: 0.027066

run [1850]:
Style Loss : 0.106070 Content Loss: 0.027123

run [1900]:
Style Loss : 0.105611 Content Loss: 0.027178

run [1950]:
Style Loss : 0.105155 Content Loss: 0.027237

run [2000]:
Style Loss : 0.104691 Content Loss: 0.027284

run [2050]:
Style Loss : 0.104179 Content Loss: 0.027332

run [2100]:
Style Loss : 0.103678 Content Loss: 0.027376

run [2150]:
Style Loss : 0.103202 Content Loss: 0.027436

run [2200]:
Style Loss : 0.102775 Content Loss: 0.027487

run [2250]:
Style Loss : 0.102348 Content Loss: 0.027508

run [2300]:
Style Loss : 0.102012 Content Loss: 0.027520

run [2350]:
Style Loss : 0.101721 Content Loss: 0.027562

run [2400]:
Style Loss : 0.101560 Content Loss: 0.027606

run [2450]:
Style Loss : 0.101113 Content Loss: 0.027612

run [2500]:
Style Loss : 0.100910 Content Loss: 0.027632

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.125873 Content Loss: 0.007194

run [100]:
Style Loss : 1.329501 Content Loss: 0.013416

run [150]:
Style Loss : 0.963683 Content Loss: 0.019508

run [200]:
Style Loss : 0.783857 Content Loss: 0.024047

run [250]:
Style Loss : 0.690399 Content Loss: 0.026523

run [300]:
Style Loss : 0.630717 Content Loss: 0.028128

run [350]:
Style Loss : 0.587835 Content Loss: 0.029336

run [400]:
Style Loss : 0.555749 Content Loss: 0.030369

run [450]:
Style Loss : 0.530471 Content Loss: 0.031348

run [500]:
Style Loss : 0.511297 Content Loss: 0.032035

run [550]:
Style Loss : 0.497001 Content Loss: 0.032642

run [600]:
Style Loss : 0.485416 Content Loss: 0.033187

run [650]:
Style Loss : 0.475898 Content Loss: 0.033549

run [700]:
Style Loss : 0.467808 Content Loss: 0.033869

run [750]:
Style Loss : 0.460589 Content Loss: 0.034163

run [800]:
Style Loss : 0.453869 Content Loss: 0.034397

run [850]:
Style Loss : 0.448102 Content Loss: 0.034612

run [900]:
Style Loss : 0.442621 Content Loss: 0.034816

run [950]:
Style Loss : 0.437884 Content Loss: 0.035008

run [1000]:
Style Loss : 0.433105 Content Loss: 0.035153

run [1050]:
Style Loss : 0.428993 Content Loss: 0.035279

run [1100]:
Style Loss : 0.425536 Content Loss: 0.035414

run [1150]:
Style Loss : 0.422576 Content Loss: 0.035539

run [1200]:
Style Loss : 0.420168 Content Loss: 0.035628

run [1250]:
Style Loss : 0.417695 Content Loss: 0.035683

run [1300]:
Style Loss : 0.415543 Content Loss: 0.035740

run [1350]:
Style Loss : 0.413713 Content Loss: 0.035793

run [1400]:
Style Loss : 0.411934 Content Loss: 0.035835

run [1450]:
Style Loss : 0.410352 Content Loss: 0.035883

run [1500]:
Style Loss : 0.408882 Content Loss: 0.035924

run [1550]:
Style Loss : 0.407477 Content Loss: 0.035978

run [1600]:
Style Loss : 0.406130 Content Loss: 0.036014

run [1650]:
Style Loss : 0.404913 Content Loss: 0.036053

run [1700]:
Style Loss : 0.403732 Content Loss: 0.036081

run [1750]:
Style Loss : 0.402725 Content Loss: 0.036120

run [1800]:
Style Loss : 0.401647 Content Loss: 0.036154

run [1850]:
Style Loss : 0.400720 Content Loss: 0.036183

run [1900]:
Style Loss : 0.399839 Content Loss: 0.036210

run [1950]:
Style Loss : 0.398956 Content Loss: 0.036249

run [2000]:
Style Loss : 0.398146 Content Loss: 0.036266

run [2050]:
Style Loss : 0.397359 Content Loss: 0.036282

run [2100]:
Style Loss : 0.396616 Content Loss: 0.036308

run [2150]:
Style Loss : 0.395873 Content Loss: 0.036321

run [2200]:
Style Loss : 0.395027 Content Loss: 0.036341

run [2250]:
Style Loss : 0.394258 Content Loss: 0.036352

run [2300]:
Style Loss : 0.393452 Content Loss: 0.036363

run [2350]:
Style Loss : 0.392684 Content Loss: 0.036391

run [2400]:
Style Loss : 0.391925 Content Loss: 0.036407

run [2450]:
Style Loss : 0.391172 Content Loss: 0.036425

run [2500]:
Style Loss : 0.390499 Content Loss: 0.036432

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.757574 Content Loss: 0.003766

run [100]:
Style Loss : 0.955893 Content Loss: 0.007658

run [150]:
Style Loss : 0.717589 Content Loss: 0.010320

run [200]:
Style Loss : 0.569087 Content Loss: 0.012972

run [250]:
Style Loss : 0.452050 Content Loss: 0.016026

run [300]:
Style Loss : 0.365676 Content Loss: 0.019285

run [350]:
Style Loss : 0.303072 Content Loss: 0.022493

run [400]:
Style Loss : 0.262754 Content Loss: 0.025087

run [450]:
Style Loss : 0.237756 Content Loss: 0.026534

run [500]:
Style Loss : 0.220917 Content Loss: 0.027273

run [550]:
Style Loss : 0.209984 Content Loss: 0.027623

run [600]:
Style Loss : 0.201798 Content Loss: 0.027880

run [650]:
Style Loss : 0.195308 Content Loss: 0.027988

run [700]:
Style Loss : 0.189880 Content Loss: 0.028130

run [750]:
Style Loss : 0.185285 Content Loss: 0.028238

run [800]:
Style Loss : 0.181235 Content Loss: 0.028406

run [850]:
Style Loss : 0.177435 Content Loss: 0.028574

run [900]:
Style Loss : 0.174074 Content Loss: 0.028687

run [950]:
Style Loss : 0.170794 Content Loss: 0.028811

run [1000]:
Style Loss : 0.167992 Content Loss: 0.028917

run [1050]:
Style Loss : 0.165430 Content Loss: 0.029036

run [1100]:
Style Loss : 0.162834 Content Loss: 0.029161

run [1150]:
Style Loss : 0.160474 Content Loss: 0.029288

run [1200]:
Style Loss : 0.158301 Content Loss: 0.029411

run [1250]:
Style Loss : 0.156105 Content Loss: 0.029525

run [1300]:
Style Loss : 0.154059 Content Loss: 0.029640

run [1350]:
Style Loss : 0.152197 Content Loss: 0.029733

run [1400]:
Style Loss : 0.150555 Content Loss: 0.029810

run [1450]:
Style Loss : 0.149066 Content Loss: 0.029889

run [1500]:
Style Loss : 0.147664 Content Loss: 0.029973

run [1550]:
Style Loss : 0.146500 Content Loss: 0.030043

run [1600]:
Style Loss : 0.145459 Content Loss: 0.030101

run [1650]:
Style Loss : 0.144595 Content Loss: 0.030148

run [1700]:
Style Loss : 0.143739 Content Loss: 0.030200

run [1750]:
Style Loss : 0.142970 Content Loss: 0.030238

run [1800]:
Style Loss : 0.142251 Content Loss: 0.030280

run [1850]:
Style Loss : 0.141567 Content Loss: 0.030325

run [1900]:
Style Loss : 0.140954 Content Loss: 0.030364

run [1950]:
Style Loss : 0.140337 Content Loss: 0.030396

run [2000]:
Style Loss : 0.139738 Content Loss: 0.030438

run [2050]:
Style Loss : 0.139126 Content Loss: 0.030483

run [2100]:
Style Loss : 0.138501 Content Loss: 0.030531

run [2150]:
Style Loss : 0.137914 Content Loss: 0.030578

run [2200]:
Style Loss : 0.137346 Content Loss: 0.030622

run [2250]:
Style Loss : 0.136797 Content Loss: 0.030676

run [2300]:
Style Loss : 0.136173 Content Loss: 0.030715

run [2350]:
Style Loss : 0.135601 Content Loss: 0.030772

run [2400]:
Style Loss : 0.134998 Content Loss: 0.030812

run [2450]:
Style Loss : 0.134300 Content Loss: 0.030851

run [2500]:
Style Loss : 0.133697 Content Loss: 0.030917

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.284273 Content Loss: 0.006593

run [100]:
Style Loss : 0.786398 Content Loss: 0.011026

run [150]:
Style Loss : 0.585171 Content Loss: 0.015429

run [200]:
Style Loss : 0.453572 Content Loss: 0.020447

run [250]:
Style Loss : 0.357785 Content Loss: 0.024642

run [300]:
Style Loss : 0.300627 Content Loss: 0.027482

run [350]:
Style Loss : 0.266483 Content Loss: 0.029071

run [400]:
Style Loss : 0.245969 Content Loss: 0.029883

run [450]:
Style Loss : 0.231400 Content Loss: 0.030069

run [500]:
Style Loss : 0.219554 Content Loss: 0.030241

run [550]:
Style Loss : 0.209532 Content Loss: 0.030387

run [600]:
Style Loss : 0.201715 Content Loss: 0.030482

run [650]:
Style Loss : 0.195161 Content Loss: 0.030607

run [700]:
Style Loss : 0.189812 Content Loss: 0.030721

run [750]:
Style Loss : 0.184860 Content Loss: 0.030804

run [800]:
Style Loss : 0.180542 Content Loss: 0.030906

run [850]:
Style Loss : 0.176809 Content Loss: 0.030984

run [900]:
Style Loss : 0.173459 Content Loss: 0.031065

run [950]:
Style Loss : 0.170606 Content Loss: 0.031170

run [1000]:
Style Loss : 0.167831 Content Loss: 0.031267

run [1050]:
Style Loss : 0.165287 Content Loss: 0.031367

run [1100]:
Style Loss : 0.162868 Content Loss: 0.031468

run [1150]:
Style Loss : 0.160318 Content Loss: 0.031581

run [1200]:
Style Loss : 0.158095 Content Loss: 0.031677

run [1250]:
Style Loss : 0.155988 Content Loss: 0.031782

run [1300]:
Style Loss : 0.153937 Content Loss: 0.031889

run [1350]:
Style Loss : 0.152009 Content Loss: 0.032002

run [1400]:
Style Loss : 0.150213 Content Loss: 0.032103

run [1450]:
Style Loss : 0.148637 Content Loss: 0.032202

run [1500]:
Style Loss : 0.147210 Content Loss: 0.032291

run [1550]:
Style Loss : 0.145770 Content Loss: 0.032383

run [1600]:
Style Loss : 0.144045 Content Loss: 0.032502

run [1650]:
Style Loss : 0.142300 Content Loss: 0.032606

run [1700]:
Style Loss : 0.140750 Content Loss: 0.032706

run [1750]:
Style Loss : 0.139403 Content Loss: 0.032785

run [1800]:
Style Loss : 0.138162 Content Loss: 0.032873

run [1850]:
Style Loss : 0.137011 Content Loss: 0.032967

run [1900]:
Style Loss : 0.135924 Content Loss: 0.033055

run [1950]:
Style Loss : 0.135016 Content Loss: 0.033126

run [2000]:
Style Loss : 0.134186 Content Loss: 0.033207

run [2050]:
Style Loss : 0.133390 Content Loss: 0.033283

run [2100]:
Style Loss : 0.132681 Content Loss: 0.033339

run [2150]:
Style Loss : 0.131987 Content Loss: 0.033402

run [2200]:
Style Loss : 0.131355 Content Loss: 0.033462

run [2250]:
Style Loss : 0.130852 Content Loss: 0.033511

run [2300]:
Style Loss : 0.130339 Content Loss: 0.033541

run [2350]:
Style Loss : 0.129908 Content Loss: 0.033591

run [2400]:
Style Loss : 0.129452 Content Loss: 0.033618

run [2450]:
Style Loss : 0.129073 Content Loss: 0.033640

run [2500]:
Style Loss : 0.128682 Content Loss: 0.033668

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.731034 Content Loss: 0.005406

run [100]:
Style Loss : 0.794749 Content Loss: 0.008527

run [150]:
Style Loss : 0.524635 Content Loss: 0.010551

run [200]:
Style Loss : 0.407261 Content Loss: 0.012523

run [250]:
Style Loss : 0.328613 Content Loss: 0.014441

run [300]:
Style Loss : 0.267482 Content Loss: 0.016831

run [350]:
Style Loss : 0.221240 Content Loss: 0.019249

run [400]:
Style Loss : 0.187211 Content Loss: 0.021325

run [450]:
Style Loss : 0.163352 Content Loss: 0.023089

run [500]:
Style Loss : 0.146989 Content Loss: 0.024292

run [550]:
Style Loss : 0.137177 Content Loss: 0.024961

run [600]:
Style Loss : 0.130847 Content Loss: 0.025245

run [650]:
Style Loss : 0.125934 Content Loss: 0.025279

run [700]:
Style Loss : 0.121983 Content Loss: 0.025323

run [750]:
Style Loss : 0.118737 Content Loss: 0.025380

run [800]:
Style Loss : 0.116040 Content Loss: 0.025447

run [850]:
Style Loss : 0.113662 Content Loss: 0.025485

run [900]:
Style Loss : 0.111366 Content Loss: 0.025555

run [950]:
Style Loss : 0.109341 Content Loss: 0.025622

run [1000]:
Style Loss : 0.107456 Content Loss: 0.025688

run [1050]:
Style Loss : 0.105850 Content Loss: 0.025740

run [1100]:
Style Loss : 0.104107 Content Loss: 0.025806

run [1150]:
Style Loss : 0.102733 Content Loss: 0.025862

run [1200]:
Style Loss : 0.101653 Content Loss: 0.025919

run [1250]:
Style Loss : 0.100620 Content Loss: 0.025984

run [1300]:
Style Loss : 0.099733 Content Loss: 0.026048

run [1350]:
Style Loss : 0.098796 Content Loss: 0.026116

run [1400]:
Style Loss : 0.097887 Content Loss: 0.026186

run [1450]:
Style Loss : 0.097068 Content Loss: 0.026255

run [1500]:
Style Loss : 0.096321 Content Loss: 0.026308

run [1550]:
Style Loss : 0.095642 Content Loss: 0.026358

run [1600]:
Style Loss : 0.094933 Content Loss: 0.026407

run [1650]:
Style Loss : 0.094289 Content Loss: 0.026445

run [1700]:
Style Loss : 0.093722 Content Loss: 0.026474

run [1750]:
Style Loss : 0.093246 Content Loss: 0.026507

run [1800]:
Style Loss : 0.092792 Content Loss: 0.026538

run [1850]:
Style Loss : 0.092360 Content Loss: 0.026564

run [1900]:
Style Loss : 0.091922 Content Loss: 0.026585

run [1950]:
Style Loss : 0.091502 Content Loss: 0.026604

run [2000]:
Style Loss : 0.091075 Content Loss: 0.026622

run [2050]:
Style Loss : 0.090661 Content Loss: 0.026638

run [2100]:
Style Loss : 0.090267 Content Loss: 0.026649

run [2150]:
Style Loss : 0.089910 Content Loss: 0.026664

run [2200]:
Style Loss : 0.089590 Content Loss: 0.026675

run [2250]:
Style Loss : 0.089304 Content Loss: 0.026686

run [2300]:
Style Loss : 0.088971 Content Loss: 0.026690

run [2350]:
Style Loss : 0.088653 Content Loss: 0.026698

run [2400]:
Style Loss : 0.088365 Content Loss: 0.026706

run [2450]:
Style Loss : 0.088085 Content Loss: 0.026709

run [2500]:
Style Loss : 0.087803 Content Loss: 0.026715

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.974540 Content Loss: 0.006877

run [100]:
Style Loss : 1.215230 Content Loss: 0.014474

run [150]:
Style Loss : 0.764933 Content Loss: 0.025836

run [200]:
Style Loss : 0.498793 Content Loss: 0.036731

run [250]:
Style Loss : 0.393404 Content Loss: 0.042040

run [300]:
Style Loss : 0.344974 Content Loss: 0.043628

run [350]:
Style Loss : 0.316456 Content Loss: 0.044006

run [400]:
Style Loss : 0.297152 Content Loss: 0.044499

run [450]:
Style Loss : 0.281195 Content Loss: 0.044910

run [500]:
Style Loss : 0.268347 Content Loss: 0.045346

run [550]:
Style Loss : 0.257515 Content Loss: 0.045728

run [600]:
Style Loss : 0.247257 Content Loss: 0.046144

run [650]:
Style Loss : 0.238523 Content Loss: 0.046464

run [700]:
Style Loss : 0.231121 Content Loss: 0.046830

run [750]:
Style Loss : 0.224948 Content Loss: 0.047136

run [800]:
Style Loss : 0.219664 Content Loss: 0.047452

run [850]:
Style Loss : 0.215316 Content Loss: 0.047655

run [900]:
Style Loss : 0.211825 Content Loss: 0.047818

run [950]:
Style Loss : 0.206721 Content Loss: 0.047961

run [1000]:
Style Loss : 0.203528 Content Loss: 0.048121

run [1050]:
Style Loss : 0.200711 Content Loss: 0.048270

run [1100]:
Style Loss : 0.198092 Content Loss: 0.048444

run [1150]:
Style Loss : 0.194074 Content Loss: 0.048660

run [1200]:
Style Loss : 0.191029 Content Loss: 0.048810

run [1250]:
Style Loss : 0.189415 Content Loss: 0.048961

run [1300]:
Style Loss : 0.187487 Content Loss: 0.049152

run [1350]:
Style Loss : 0.187029 Content Loss: 0.049342

run [1400]:
Style Loss : 0.185543 Content Loss: 0.049452

run [1450]:
Style Loss : 0.185078 Content Loss: 0.049717

run [1500]:
Style Loss : 0.182962 Content Loss: 0.049831

run [1550]:
Style Loss : 0.182615 Content Loss: 0.050052

run [1600]:
Style Loss : 0.181051 Content Loss: 0.050185

run [1650]:
Style Loss : 0.183662 Content Loss: 0.050566

run [1700]:
Style Loss : 0.181811 Content Loss: 0.050753

run [1750]:
Style Loss : 0.237789 Content Loss: 0.051392

run [1800]:
Style Loss : 0.178612 Content Loss: 0.050971

run [1850]:
Style Loss : 0.178275 Content Loss: 0.051093

run [1900]:
Style Loss : 0.176967 Content Loss: 0.051244

run [1950]:
Style Loss : 0.176160 Content Loss: 0.051337

run [2000]:
Style Loss : 0.175940 Content Loss: 0.051382

run [2050]:
Style Loss : 0.174830 Content Loss: 0.051401

run [2100]:
Style Loss : 0.482762 Content Loss: 0.053256

run [2150]:
Style Loss : 0.264213 Content Loss: 0.052927

run [2200]:
Style Loss : 0.218924 Content Loss: 0.053501

run [2250]:
Style Loss : 0.200285 Content Loss: 0.053882

run [2300]:
Style Loss : 0.190022 Content Loss: 0.053908

run [2350]:
Style Loss : 0.183831 Content Loss: 0.053726

run [2400]:
Style Loss : 0.179585 Content Loss: 0.053452

run [2450]:
Style Loss : 0.176580 Content Loss: 0.053108

run [2500]:
Style Loss : 0.174436 Content Loss: 0.052784

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.133331 Content Loss: 0.007787

run [100]:
Style Loss : 0.632925 Content Loss: 0.015002

run [150]:
Style Loss : 0.364676 Content Loss: 0.023857

run [200]:
Style Loss : 0.256160 Content Loss: 0.029231

run [250]:
Style Loss : 0.211494 Content Loss: 0.030702

run [300]:
Style Loss : 0.187599 Content Loss: 0.030841

run [350]:
Style Loss : 0.171579 Content Loss: 0.030754

run [400]:
Style Loss : 0.160779 Content Loss: 0.030948

run [450]:
Style Loss : 0.152443 Content Loss: 0.031076

run [500]:
Style Loss : 0.145431 Content Loss: 0.031167

run [550]:
Style Loss : 0.139112 Content Loss: 0.031313

run [600]:
Style Loss : 0.134197 Content Loss: 0.031399

run [650]:
Style Loss : 0.129931 Content Loss: 0.031521

run [700]:
Style Loss : 0.126551 Content Loss: 0.031631

run [750]:
Style Loss : 0.123790 Content Loss: 0.031705

run [800]:
Style Loss : 0.121536 Content Loss: 0.031764

run [850]:
Style Loss : 0.119526 Content Loss: 0.031824

run [900]:
Style Loss : 0.117762 Content Loss: 0.031884

run [950]:
Style Loss : 0.115880 Content Loss: 0.031930

run [1000]:
Style Loss : 0.113899 Content Loss: 0.032000

run [1050]:
Style Loss : 0.112558 Content Loss: 0.032039

run [1100]:
Style Loss : 0.111308 Content Loss: 0.032088

run [1150]:
Style Loss : 0.110124 Content Loss: 0.032113

run [1200]:
Style Loss : 0.108979 Content Loss: 0.032130

run [1250]:
Style Loss : 0.108068 Content Loss: 0.032149

run [1300]:
Style Loss : 0.107252 Content Loss: 0.032147

run [1350]:
Style Loss : 0.106529 Content Loss: 0.032158

run [1400]:
Style Loss : 0.105894 Content Loss: 0.032161

run [1450]:
Style Loss : 0.105239 Content Loss: 0.032151

run [1500]:
Style Loss : 0.104692 Content Loss: 0.032150

run [1550]:
Style Loss : 0.104213 Content Loss: 0.032152

run [1600]:
Style Loss : 0.103766 Content Loss: 0.032143

run [1650]:
Style Loss : 0.103276 Content Loss: 0.032135

run [1700]:
Style Loss : 0.102797 Content Loss: 0.032131

run [1750]:
Style Loss : 0.102364 Content Loss: 0.032135

run [1800]:
Style Loss : 0.101952 Content Loss: 0.032152

run [1850]:
Style Loss : 0.101549 Content Loss: 0.032151

run [1900]:
Style Loss : 0.101171 Content Loss: 0.032159

run [1950]:
Style Loss : 0.100763 Content Loss: 0.032165

run [2000]:
Style Loss : 0.100402 Content Loss: 0.032167

run [2050]:
Style Loss : 0.100020 Content Loss: 0.032162

run [2100]:
Style Loss : 0.099713 Content Loss: 0.032160

run [2150]:
Style Loss : 0.099411 Content Loss: 0.032159

run [2200]:
Style Loss : 0.098903 Content Loss: 0.032158

run [2250]:
Style Loss : 0.098492 Content Loss: 0.032160

run [2300]:
Style Loss : 0.098130 Content Loss: 0.032161

run [2350]:
Style Loss : 0.097798 Content Loss: 0.032157

run [2400]:
Style Loss : 0.097491 Content Loss: 0.032163

run [2450]:
Style Loss : 0.097156 Content Loss: 0.032170

run [2500]:
Style Loss : 0.096833 Content Loss: 0.032174

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.426492 Content Loss: 0.003499

run [100]:
Style Loss : 1.548177 Content Loss: 0.006450

run [150]:
Style Loss : 1.206186 Content Loss: 0.008862

run [200]:
Style Loss : 1.012675 Content Loss: 0.011484

run [250]:
Style Loss : 0.858913 Content Loss: 0.014619

run [300]:
Style Loss : 0.736031 Content Loss: 0.017995

run [350]:
Style Loss : 0.640255 Content Loss: 0.021355

run [400]:
Style Loss : 0.574603 Content Loss: 0.024420

run [450]:
Style Loss : 0.529050 Content Loss: 0.026725

run [500]:
Style Loss : 0.498087 Content Loss: 0.028322

run [550]:
Style Loss : 0.475425 Content Loss: 0.029246

run [600]:
Style Loss : 0.458563 Content Loss: 0.029904

run [650]:
Style Loss : 0.446068 Content Loss: 0.030279

run [700]:
Style Loss : 0.436106 Content Loss: 0.030661

run [750]:
Style Loss : 0.428438 Content Loss: 0.030890

run [800]:
Style Loss : 0.421794 Content Loss: 0.031122

run [850]:
Style Loss : 0.416131 Content Loss: 0.031315

run [900]:
Style Loss : 0.411226 Content Loss: 0.031488

run [950]:
Style Loss : 0.406831 Content Loss: 0.031629

run [1000]:
Style Loss : 0.402896 Content Loss: 0.031756

run [1050]:
Style Loss : 0.399049 Content Loss: 0.031872

run [1100]:
Style Loss : 0.395711 Content Loss: 0.031968

run [1150]:
Style Loss : 0.392771 Content Loss: 0.032068

run [1200]:
Style Loss : 0.390098 Content Loss: 0.032172

run [1250]:
Style Loss : 0.387780 Content Loss: 0.032268

run [1300]:
Style Loss : 0.385304 Content Loss: 0.032358

run [1350]:
Style Loss : 0.383102 Content Loss: 0.032440

run [1400]:
Style Loss : 0.381163 Content Loss: 0.032498

run [1450]:
Style Loss : 0.379377 Content Loss: 0.032559

run [1500]:
Style Loss : 0.377756 Content Loss: 0.032614

run [1550]:
Style Loss : 0.375720 Content Loss: 0.032685

run [1600]:
Style Loss : 0.374017 Content Loss: 0.032741

run [1650]:
Style Loss : 0.372634 Content Loss: 0.032783

run [1700]:
Style Loss : 0.371464 Content Loss: 0.032828

run [1750]:
Style Loss : 0.370273 Content Loss: 0.032877

run [1800]:
Style Loss : 0.369137 Content Loss: 0.032928

run [1850]:
Style Loss : 0.368098 Content Loss: 0.032982

run [1900]:
Style Loss : 0.367030 Content Loss: 0.033037

run [1950]:
Style Loss : 0.366099 Content Loss: 0.033086

run [2000]:
Style Loss : 0.365220 Content Loss: 0.033129

run [2050]:
Style Loss : 0.364358 Content Loss: 0.033172

run [2100]:
Style Loss : 0.363518 Content Loss: 0.033211

run [2150]:
Style Loss : 0.362594 Content Loss: 0.033255

run [2200]:
Style Loss : 0.361543 Content Loss: 0.033301

run [2250]:
Style Loss : 0.360547 Content Loss: 0.033345

run [2300]:
Style Loss : 0.359546 Content Loss: 0.033382

run [2350]:
Style Loss : 0.358703 Content Loss: 0.033410

run [2400]:
Style Loss : 0.357906 Content Loss: 0.033437

run [2450]:
Style Loss : 0.357088 Content Loss: 0.033470

run [2500]:
Style Loss : 0.356315 Content Loss: 0.033500

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.668084 Content Loss: 0.003462

run [100]:
Style Loss : 1.392327 Content Loss: 0.006113

run [150]:
Style Loss : 1.018468 Content Loss: 0.008276

run [200]:
Style Loss : 0.839131 Content Loss: 0.010179

run [250]:
Style Loss : 0.730059 Content Loss: 0.011797

run [300]:
Style Loss : 0.638906 Content Loss: 0.013666

run [350]:
Style Loss : 0.562999 Content Loss: 0.015583

run [400]:
Style Loss : 0.496244 Content Loss: 0.017810

run [450]:
Style Loss : 0.441266 Content Loss: 0.020102

run [500]:
Style Loss : 0.395721 Content Loss: 0.022329

run [550]:
Style Loss : 0.362362 Content Loss: 0.024398

run [600]:
Style Loss : 0.336134 Content Loss: 0.026127

run [650]:
Style Loss : 0.317382 Content Loss: 0.027353

run [700]:
Style Loss : 0.302641 Content Loss: 0.028258

run [750]:
Style Loss : 0.290713 Content Loss: 0.028747

run [800]:
Style Loss : 0.280751 Content Loss: 0.029044

run [850]:
Style Loss : 0.272886 Content Loss: 0.029188

run [900]:
Style Loss : 0.265803 Content Loss: 0.029317

run [950]:
Style Loss : 0.259495 Content Loss: 0.029390

run [1000]:
Style Loss : 0.253544 Content Loss: 0.029438

run [1050]:
Style Loss : 0.248002 Content Loss: 0.029466

run [1100]:
Style Loss : 0.243174 Content Loss: 0.029537

run [1150]:
Style Loss : 0.238533 Content Loss: 0.029612

run [1200]:
Style Loss : 0.234026 Content Loss: 0.029698

run [1250]:
Style Loss : 0.229788 Content Loss: 0.029793

run [1300]:
Style Loss : 0.225842 Content Loss: 0.029905

run [1350]:
Style Loss : 0.221804 Content Loss: 0.030025

run [1400]:
Style Loss : 0.217724 Content Loss: 0.030171

run [1450]:
Style Loss : 0.213914 Content Loss: 0.030313

run [1500]:
Style Loss : 0.209989 Content Loss: 0.030476

run [1550]:
Style Loss : 0.206126 Content Loss: 0.030664

run [1600]:
Style Loss : 0.202372 Content Loss: 0.030879

run [1650]:
Style Loss : 0.198662 Content Loss: 0.031097

run [1700]:
Style Loss : 0.195261 Content Loss: 0.031293

run [1750]:
Style Loss : 0.191896 Content Loss: 0.031497

run [1800]:
Style Loss : 0.188679 Content Loss: 0.031742

run [1850]:
Style Loss : 0.185569 Content Loss: 0.032003

run [1900]:
Style Loss : 0.182547 Content Loss: 0.032267

run [1950]:
Style Loss : 0.179570 Content Loss: 0.032537

run [2000]:
Style Loss : 0.176839 Content Loss: 0.032792

run [2050]:
Style Loss : 0.174283 Content Loss: 0.033044

run [2100]:
Style Loss : 0.171619 Content Loss: 0.033312

run [2150]:
Style Loss : 0.169349 Content Loss: 0.033578

run [2200]:
Style Loss : 0.167105 Content Loss: 0.033866

run [2250]:
Style Loss : 0.164953 Content Loss: 0.034133

run [2300]:
Style Loss : 0.162818 Content Loss: 0.034352

run [2350]:
Style Loss : 0.161109 Content Loss: 0.034651

run [2400]:
Style Loss : 0.160810 Content Loss: 0.035027

run [2450]:
Style Loss : 0.156972 Content Loss: 0.035027

run [2500]:
Style Loss : 0.156648 Content Loss: 0.035363

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.434330 Content Loss: 0.004694

run [100]:
Style Loss : 1.307789 Content Loss: 0.007987

run [150]:
Style Loss : 0.990291 Content Loss: 0.011125

run [200]:
Style Loss : 0.787986 Content Loss: 0.013982

run [250]:
Style Loss : 0.644098 Content Loss: 0.016979

run [300]:
Style Loss : 0.534929 Content Loss: 0.019456

run [350]:
Style Loss : 0.455920 Content Loss: 0.021847

run [400]:
Style Loss : 0.400084 Content Loss: 0.023712

run [450]:
Style Loss : 0.364178 Content Loss: 0.024963

run [500]:
Style Loss : 0.341041 Content Loss: 0.025978

run [550]:
Style Loss : 0.324097 Content Loss: 0.026597

run [600]:
Style Loss : 0.310934 Content Loss: 0.027010

run [650]:
Style Loss : 0.301178 Content Loss: 0.027357

run [700]:
Style Loss : 0.293703 Content Loss: 0.027623

run [750]:
Style Loss : 0.287981 Content Loss: 0.027823

run [800]:
Style Loss : 0.283121 Content Loss: 0.027986

run [850]:
Style Loss : 0.278188 Content Loss: 0.028149

run [900]:
Style Loss : 0.274145 Content Loss: 0.028308

run [950]:
Style Loss : 0.270283 Content Loss: 0.028450

run [1000]:
Style Loss : 0.266595 Content Loss: 0.028607

run [1050]:
Style Loss : 0.262916 Content Loss: 0.028731

run [1100]:
Style Loss : 0.259964 Content Loss: 0.028870

run [1150]:
Style Loss : 0.257017 Content Loss: 0.028993

run [1200]:
Style Loss : 0.254322 Content Loss: 0.029133

run [1250]:
Style Loss : 0.251876 Content Loss: 0.029251

run [1300]:
Style Loss : 0.249318 Content Loss: 0.029380

run [1350]:
Style Loss : 0.246993 Content Loss: 0.029499

run [1400]:
Style Loss : 0.244958 Content Loss: 0.029614

run [1450]:
Style Loss : 0.243038 Content Loss: 0.029733

run [1500]:
Style Loss : 0.240964 Content Loss: 0.029856

run [1550]:
Style Loss : 0.238549 Content Loss: 0.029995

run [1600]:
Style Loss : 0.236195 Content Loss: 0.030110

run [1650]:
Style Loss : 0.234134 Content Loss: 0.030232

run [1700]:
Style Loss : 0.232237 Content Loss: 0.030330

run [1750]:
Style Loss : 0.230495 Content Loss: 0.030428

run [1800]:
Style Loss : 0.228851 Content Loss: 0.030539

run [1850]:
Style Loss : 0.227100 Content Loss: 0.030639

run [1900]:
Style Loss : 0.225464 Content Loss: 0.030746

run [1950]:
Style Loss : 0.223819 Content Loss: 0.030857

run [2000]:
Style Loss : 0.222152 Content Loss: 0.030945

run [2050]:
Style Loss : 0.220726 Content Loss: 0.031020

run [2100]:
Style Loss : 0.219384 Content Loss: 0.031092

run [2150]:
Style Loss : 0.218088 Content Loss: 0.031170

run [2200]:
Style Loss : 0.216757 Content Loss: 0.031232

run [2250]:
Style Loss : 0.215420 Content Loss: 0.031298

run [2300]:
Style Loss : 0.214298 Content Loss: 0.031364

run [2350]:
Style Loss : 0.213188 Content Loss: 0.031441

run [2400]:
Style Loss : 0.212222 Content Loss: 0.031512

run [2450]:
Style Loss : 0.211262 Content Loss: 0.031588

run [2500]:
Style Loss : 0.210302 Content Loss: 0.031651

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.117706 Content Loss: 0.004031

run [100]:
Style Loss : 1.783091 Content Loss: 0.006364

run [150]:
Style Loss : 1.334276 Content Loss: 0.008249

run [200]:
Style Loss : 1.125520 Content Loss: 0.009455

run [250]:
Style Loss : 0.984169 Content Loss: 0.010438

run [300]:
Style Loss : 0.888297 Content Loss: 0.011325

run [350]:
Style Loss : 0.818552 Content Loss: 0.012082

run [400]:
Style Loss : 0.762706 Content Loss: 0.012959

run [450]:
Style Loss : 0.711952 Content Loss: 0.013794

run [500]:
Style Loss : 0.672055 Content Loss: 0.014654

run [550]:
Style Loss : 0.638737 Content Loss: 0.015536

run [600]:
Style Loss : 0.609337 Content Loss: 0.016471

run [650]:
Style Loss : 0.583010 Content Loss: 0.017394

run [700]:
Style Loss : 0.562270 Content Loss: 0.018224

run [750]:
Style Loss : 0.544290 Content Loss: 0.019015

run [800]:
Style Loss : 0.529626 Content Loss: 0.019725

run [850]:
Style Loss : 0.517741 Content Loss: 0.020371

run [900]:
Style Loss : 0.507341 Content Loss: 0.020872

run [950]:
Style Loss : 0.498995 Content Loss: 0.021312

run [1000]:
Style Loss : 0.491874 Content Loss: 0.021694

run [1050]:
Style Loss : 0.486173 Content Loss: 0.022007

run [1100]:
Style Loss : 0.481138 Content Loss: 0.022281

run [1150]:
Style Loss : 0.476757 Content Loss: 0.022509

run [1200]:
Style Loss : 0.472646 Content Loss: 0.022709

run [1250]:
Style Loss : 0.468920 Content Loss: 0.022874

run [1300]:
Style Loss : 0.465425 Content Loss: 0.022996

run [1350]:
Style Loss : 0.462136 Content Loss: 0.023116

run [1400]:
Style Loss : 0.459045 Content Loss: 0.023216

run [1450]:
Style Loss : 0.456355 Content Loss: 0.023304

run [1500]:
Style Loss : 0.453985 Content Loss: 0.023378

run [1550]:
Style Loss : 0.451754 Content Loss: 0.023456

run [1600]:
Style Loss : 0.449761 Content Loss: 0.023514

run [1650]:
Style Loss : 0.447810 Content Loss: 0.023559

run [1700]:
Style Loss : 0.446007 Content Loss: 0.023609

run [1750]:
Style Loss : 0.444191 Content Loss: 0.023652

run [1800]:
Style Loss : 0.442159 Content Loss: 0.023695

run [1850]:
Style Loss : 0.440102 Content Loss: 0.023738

run [1900]:
Style Loss : 0.438350 Content Loss: 0.023772

run [1950]:
Style Loss : 0.436834 Content Loss: 0.023801

run [2000]:
Style Loss : 0.435415 Content Loss: 0.023831

run [2050]:
Style Loss : 0.433993 Content Loss: 0.023854

run [2100]:
Style Loss : 0.432760 Content Loss: 0.023871

run [2150]:
Style Loss : 0.431610 Content Loss: 0.023890

run [2200]:
Style Loss : 0.430549 Content Loss: 0.023907

run [2250]:
Style Loss : 0.429539 Content Loss: 0.023923

run [2300]:
Style Loss : 0.428539 Content Loss: 0.023941

run [2350]:
Style Loss : 0.427548 Content Loss: 0.023958

run [2400]:
Style Loss : 0.426571 Content Loss: 0.023976

run [2450]:
Style Loss : 0.425586 Content Loss: 0.023994

run [2500]:
Style Loss : 0.424689 Content Loss: 0.024011

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.082511 Content Loss: 0.003906

run [100]:
Style Loss : 1.729293 Content Loss: 0.006378

run [150]:
Style Loss : 1.249116 Content Loss: 0.008218

run [200]:
Style Loss : 1.025434 Content Loss: 0.009732

run [250]:
Style Loss : 0.886847 Content Loss: 0.011062

run [300]:
Style Loss : 0.784792 Content Loss: 0.012582

run [350]:
Style Loss : 0.705642 Content Loss: 0.014010

run [400]:
Style Loss : 0.639637 Content Loss: 0.015320

run [450]:
Style Loss : 0.584763 Content Loss: 0.016536

run [500]:
Style Loss : 0.540756 Content Loss: 0.017636

run [550]:
Style Loss : 0.506604 Content Loss: 0.018738

run [600]:
Style Loss : 0.480733 Content Loss: 0.019759

run [650]:
Style Loss : 0.461798 Content Loss: 0.020495

run [700]:
Style Loss : 0.447757 Content Loss: 0.021166

run [750]:
Style Loss : 0.436132 Content Loss: 0.021734

run [800]:
Style Loss : 0.425929 Content Loss: 0.022150

run [850]:
Style Loss : 0.417914 Content Loss: 0.022442

run [900]:
Style Loss : 0.410712 Content Loss: 0.022717

run [950]:
Style Loss : 0.403785 Content Loss: 0.022942

run [1000]:
Style Loss : 0.396475 Content Loss: 0.023158

run [1050]:
Style Loss : 0.390006 Content Loss: 0.023328

run [1100]:
Style Loss : 0.384395 Content Loss: 0.023459

run [1150]:
Style Loss : 0.379330 Content Loss: 0.023603

run [1200]:
Style Loss : 0.374933 Content Loss: 0.023729

run [1250]:
Style Loss : 0.370932 Content Loss: 0.023851

run [1300]:
Style Loss : 0.367369 Content Loss: 0.023966

run [1350]:
Style Loss : 0.364219 Content Loss: 0.024080

run [1400]:
Style Loss : 0.361182 Content Loss: 0.024194

run [1450]:
Style Loss : 0.358416 Content Loss: 0.024298

run [1500]:
Style Loss : 0.355971 Content Loss: 0.024387

run [1550]:
Style Loss : 0.353612 Content Loss: 0.024497

run [1600]:
Style Loss : 0.351341 Content Loss: 0.024598

run [1650]:
Style Loss : 0.349160 Content Loss: 0.024688

run [1700]:
Style Loss : 0.347166 Content Loss: 0.024767

run [1750]:
Style Loss : 0.345277 Content Loss: 0.024843

run [1800]:
Style Loss : 0.343641 Content Loss: 0.024921

run [1850]:
Style Loss : 0.342117 Content Loss: 0.024973

run [1900]:
Style Loss : 0.340617 Content Loss: 0.025045

run [1950]:
Style Loss : 0.339265 Content Loss: 0.025104

run [2000]:
Style Loss : 0.337969 Content Loss: 0.025172

run [2050]:
Style Loss : 0.336744 Content Loss: 0.025234

run [2100]:
Style Loss : 0.335506 Content Loss: 0.025300

run [2150]:
Style Loss : 0.334340 Content Loss: 0.025359

run [2200]:
Style Loss : 0.333115 Content Loss: 0.025424

run [2250]:
Style Loss : 0.331931 Content Loss: 0.025484

run [2300]:
Style Loss : 0.330900 Content Loss: 0.025532

run [2350]:
Style Loss : 0.329828 Content Loss: 0.025584

run [2400]:
Style Loss : 0.328872 Content Loss: 0.025631

run [2450]:
Style Loss : 0.327997 Content Loss: 0.025670

run [2500]:
Style Loss : 0.327187 Content Loss: 0.025706

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.891945 Content Loss: 0.003201

run [100]:
Style Loss : 2.483699 Content Loss: 0.004557

run [150]:
Style Loss : 1.907945 Content Loss: 0.006575

run [200]:
Style Loss : 1.617475 Content Loss: 0.008063

run [250]:
Style Loss : 1.437762 Content Loss: 0.009814

run [300]:
Style Loss : 1.302773 Content Loss: 0.011592

run [350]:
Style Loss : 1.193846 Content Loss: 0.013141

run [400]:
Style Loss : 1.108932 Content Loss: 0.014610

run [450]:
Style Loss : 1.041927 Content Loss: 0.016024

run [500]:
Style Loss : 0.981894 Content Loss: 0.017268

run [550]:
Style Loss : 0.939610 Content Loss: 0.018346

run [600]:
Style Loss : 0.903621 Content Loss: 0.019577

run [650]:
Style Loss : 0.874205 Content Loss: 0.020373

run [700]:
Style Loss : 0.850208 Content Loss: 0.021053

run [750]:
Style Loss : 0.829571 Content Loss: 0.021560

run [800]:
Style Loss : 0.812833 Content Loss: 0.022027

run [850]:
Style Loss : 0.798723 Content Loss: 0.022399

run [900]:
Style Loss : 0.786713 Content Loss: 0.022748

run [950]:
Style Loss : 0.776268 Content Loss: 0.023026

run [1000]:
Style Loss : 0.766160 Content Loss: 0.023315

run [1050]:
Style Loss : 0.757240 Content Loss: 0.023536

run [1100]:
Style Loss : 0.748554 Content Loss: 0.023770

run [1150]:
Style Loss : 0.741078 Content Loss: 0.023982

run [1200]:
Style Loss : 0.733592 Content Loss: 0.024147

run [1250]:
Style Loss : 0.726752 Content Loss: 0.024302

run [1300]:
Style Loss : 0.719593 Content Loss: 0.024497

run [1350]:
Style Loss : 0.713311 Content Loss: 0.024618

run [1400]:
Style Loss : 0.707707 Content Loss: 0.024763

run [1450]:
Style Loss : 0.702571 Content Loss: 0.024862

run [1500]:
Style Loss : 0.697953 Content Loss: 0.024940

run [1550]:
Style Loss : 0.693763 Content Loss: 0.025024

run [1600]:
Style Loss : 0.689848 Content Loss: 0.025114

run [1650]:
Style Loss : 0.686048 Content Loss: 0.025186

run [1700]:
Style Loss : 0.682352 Content Loss: 0.025274

run [1750]:
Style Loss : 0.678664 Content Loss: 0.025341

run [1800]:
Style Loss : 0.675603 Content Loss: 0.025432

run [1850]:
Style Loss : 0.672609 Content Loss: 0.025495

run [1900]:
Style Loss : 0.669588 Content Loss: 0.025568

run [1950]:
Style Loss : 0.666966 Content Loss: 0.025638

run [2000]:
Style Loss : 0.664513 Content Loss: 0.025692

run [2050]:
Style Loss : 0.662553 Content Loss: 0.025745

run [2100]:
Style Loss : 0.660526 Content Loss: 0.025808

run [2150]:
Style Loss : 0.658551 Content Loss: 0.025857

run [2200]:
Style Loss : 0.656673 Content Loss: 0.025920

run [2250]:
Style Loss : 0.654750 Content Loss: 0.025971

run [2300]:
Style Loss : 0.652995 Content Loss: 0.026022

run [2350]:
Style Loss : 0.651282 Content Loss: 0.026065

run [2400]:
Style Loss : 0.649773 Content Loss: 0.026120

run [2450]:
Style Loss : 0.648275 Content Loss: 0.026164

run [2500]:
Style Loss : 0.646899 Content Loss: 0.026213

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.537908 Content Loss: 0.003100

run [100]:
Style Loss : 1.406256 Content Loss: 0.004608

run [150]:
Style Loss : 1.030047 Content Loss: 0.006482

run [200]:
Style Loss : 0.848979 Content Loss: 0.008807

run [250]:
Style Loss : 0.707958 Content Loss: 0.011154

run [300]:
Style Loss : 0.597776 Content Loss: 0.013998

run [350]:
Style Loss : 0.517975 Content Loss: 0.016585

run [400]:
Style Loss : 0.453972 Content Loss: 0.018545

run [450]:
Style Loss : 0.404367 Content Loss: 0.020886

run [500]:
Style Loss : 0.362202 Content Loss: 0.022428

run [550]:
Style Loss : 0.334852 Content Loss: 0.023870

run [600]:
Style Loss : 0.311758 Content Loss: 0.024831

run [650]:
Style Loss : 0.296695 Content Loss: 0.025485

run [700]:
Style Loss : 0.284898 Content Loss: 0.025850

run [750]:
Style Loss : 0.274928 Content Loss: 0.026019

run [800]:
Style Loss : 0.264818 Content Loss: 0.026133

run [850]:
Style Loss : 0.255706 Content Loss: 0.026193

run [900]:
Style Loss : 0.248579 Content Loss: 0.026226

run [950]:
Style Loss : 0.242163 Content Loss: 0.026259

run [1000]:
Style Loss : 0.236103 Content Loss: 0.026293

run [1050]:
Style Loss : 0.231371 Content Loss: 0.026374

run [1100]:
Style Loss : 0.227686 Content Loss: 0.026434

run [1150]:
Style Loss : 0.224178 Content Loss: 0.026495

run [1200]:
Style Loss : 0.220643 Content Loss: 0.026549

run [1250]:
Style Loss : 0.217377 Content Loss: 0.026593

run [1300]:
Style Loss : 0.214360 Content Loss: 0.026649

run [1350]:
Style Loss : 0.211677 Content Loss: 0.026685

run [1400]:
Style Loss : 0.209061 Content Loss: 0.026736

run [1450]:
Style Loss : 0.206594 Content Loss: 0.026790

run [1500]:
Style Loss : 0.204296 Content Loss: 0.026836

run [1550]:
Style Loss : 0.202272 Content Loss: 0.026872

run [1600]:
Style Loss : 0.200138 Content Loss: 0.026914

run [1650]:
Style Loss : 0.197601 Content Loss: 0.026948

run [1700]:
Style Loss : 0.195562 Content Loss: 0.026982

run [1750]:
Style Loss : 0.193826 Content Loss: 0.027019

run [1800]:
Style Loss : 0.192258 Content Loss: 0.027052

run [1850]:
Style Loss : 0.190784 Content Loss: 0.027090

run [1900]:
Style Loss : 0.189380 Content Loss: 0.027122

run [1950]:
Style Loss : 0.188038 Content Loss: 0.027144

run [2000]:
Style Loss : 0.186928 Content Loss: 0.027175

run [2050]:
Style Loss : 0.185895 Content Loss: 0.027183

run [2100]:
Style Loss : 0.184957 Content Loss: 0.027190

run [2150]:
Style Loss : 0.184045 Content Loss: 0.027206

run [2200]:
Style Loss : 0.183217 Content Loss: 0.027216

run [2250]:
Style Loss : 0.182385 Content Loss: 0.027227

run [2300]:
Style Loss : 0.181620 Content Loss: 0.027231

run [2350]:
Style Loss : 0.180916 Content Loss: 0.027234

run [2400]:
Style Loss : 0.180277 Content Loss: 0.027238

run [2450]:
Style Loss : 0.179508 Content Loss: 0.027242

run [2500]:
Style Loss : 0.178842 Content Loss: 0.027243

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.351603 Content Loss: 0.004600

run [100]:
Style Loss : 1.258954 Content Loss: 0.008072

run [150]:
Style Loss : 0.912122 Content Loss: 0.010068

run [200]:
Style Loss : 0.739857 Content Loss: 0.011504

run [250]:
Style Loss : 0.646188 Content Loss: 0.012953

run [300]:
Style Loss : 0.578732 Content Loss: 0.014508

run [350]:
Style Loss : 0.524941 Content Loss: 0.015989

run [400]:
Style Loss : 0.488385 Content Loss: 0.017297

run [450]:
Style Loss : 0.462552 Content Loss: 0.018570

run [500]:
Style Loss : 0.442324 Content Loss: 0.019633

run [550]:
Style Loss : 0.427434 Content Loss: 0.020468

run [600]:
Style Loss : 0.414613 Content Loss: 0.021106

run [650]:
Style Loss : 0.404823 Content Loss: 0.021632

run [700]:
Style Loss : 0.396866 Content Loss: 0.022069

run [750]:
Style Loss : 0.389658 Content Loss: 0.022451

run [800]:
Style Loss : 0.383347 Content Loss: 0.022766

run [850]:
Style Loss : 0.377879 Content Loss: 0.023029

run [900]:
Style Loss : 0.373278 Content Loss: 0.023231

run [950]:
Style Loss : 0.369148 Content Loss: 0.023427

run [1000]:
Style Loss : 0.365529 Content Loss: 0.023585

run [1050]:
Style Loss : 0.362248 Content Loss: 0.023733

run [1100]:
Style Loss : 0.358586 Content Loss: 0.023896

run [1150]:
Style Loss : 0.355148 Content Loss: 0.024027

run [1200]:
Style Loss : 0.351980 Content Loss: 0.024171

run [1250]:
Style Loss : 0.348784 Content Loss: 0.024348

run [1300]:
Style Loss : 0.345923 Content Loss: 0.024475

run [1350]:
Style Loss : 0.343371 Content Loss: 0.024601

run [1400]:
Style Loss : 0.341112 Content Loss: 0.024730

run [1450]:
Style Loss : 0.339151 Content Loss: 0.024843

run [1500]:
Style Loss : 0.337348 Content Loss: 0.024957

run [1550]:
Style Loss : 0.335652 Content Loss: 0.025085

run [1600]:
Style Loss : 0.333930 Content Loss: 0.025205

run [1650]:
Style Loss : 0.332359 Content Loss: 0.025309

run [1700]:
Style Loss : 0.330754 Content Loss: 0.025443

run [1750]:
Style Loss : 0.329116 Content Loss: 0.025563

run [1800]:
Style Loss : 0.327404 Content Loss: 0.025691

run [1850]:
Style Loss : 0.325754 Content Loss: 0.025818

run [1900]:
Style Loss : 0.324184 Content Loss: 0.025952

run [1950]:
Style Loss : 0.322730 Content Loss: 0.026072

run [2000]:
Style Loss : 0.321330 Content Loss: 0.026212

run [2050]:
Style Loss : 0.319974 Content Loss: 0.026349

run [2100]:
Style Loss : 0.318731 Content Loss: 0.026488

run [2150]:
Style Loss : 0.317422 Content Loss: 0.026612

run [2200]:
Style Loss : 0.316109 Content Loss: 0.026734

run [2250]:
Style Loss : 0.314873 Content Loss: 0.026896

run [2300]:
Style Loss : 0.313589 Content Loss: 0.027046

run [2350]:
Style Loss : 0.312364 Content Loss: 0.027221

run [2400]:
Style Loss : 0.311178 Content Loss: 0.027399

run [2450]:
Style Loss : 0.310033 Content Loss: 0.027544

run [2500]:
Style Loss : 0.308968 Content Loss: 0.027714

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.506003 Content Loss: 0.005227

run [100]:
Style Loss : 0.806322 Content Loss: 0.007717

run [150]:
Style Loss : 0.623129 Content Loss: 0.009296

run [200]:
Style Loss : 0.535880 Content Loss: 0.010386

run [250]:
Style Loss : 0.477696 Content Loss: 0.011488

run [300]:
Style Loss : 0.433578 Content Loss: 0.012393

run [350]:
Style Loss : 0.401299 Content Loss: 0.013291

run [400]:
Style Loss : 0.375727 Content Loss: 0.014052

run [450]:
Style Loss : 0.355615 Content Loss: 0.014688

run [500]:
Style Loss : 0.339549 Content Loss: 0.015342

run [550]:
Style Loss : 0.325437 Content Loss: 0.015913

run [600]:
Style Loss : 0.314936 Content Loss: 0.016293

run [650]:
Style Loss : 0.307413 Content Loss: 0.016584

run [700]:
Style Loss : 0.301577 Content Loss: 0.016816

run [750]:
Style Loss : 0.296495 Content Loss: 0.017032

run [800]:
Style Loss : 0.292090 Content Loss: 0.017212

run [850]:
Style Loss : 0.288208 Content Loss: 0.017349

run [900]:
Style Loss : 0.284727 Content Loss: 0.017489

run [950]:
Style Loss : 0.281074 Content Loss: 0.017640

run [1000]:
Style Loss : 0.277686 Content Loss: 0.017776

run [1050]:
Style Loss : 0.274704 Content Loss: 0.017900

run [1100]:
Style Loss : 0.272268 Content Loss: 0.018010

run [1150]:
Style Loss : 0.269909 Content Loss: 0.018139

run [1200]:
Style Loss : 0.267747 Content Loss: 0.018246

run [1250]:
Style Loss : 0.265765 Content Loss: 0.018343

run [1300]:
Style Loss : 0.263873 Content Loss: 0.018432

run [1350]:
Style Loss : 0.262040 Content Loss: 0.018535

run [1400]:
Style Loss : 0.259973 Content Loss: 0.018640

run [1450]:
Style Loss : 0.256815 Content Loss: 0.018727

run [1500]:
Style Loss : 0.254487 Content Loss: 0.018828

run [1550]:
Style Loss : 0.252279 Content Loss: 0.018958

run [1600]:
Style Loss : 0.250201 Content Loss: 0.019064

run [1650]:
Style Loss : 0.248273 Content Loss: 0.019187

run [1700]:
Style Loss : 0.246589 Content Loss: 0.019300

run [1750]:
Style Loss : 0.244871 Content Loss: 0.019434

run [1800]:
Style Loss : 0.243102 Content Loss: 0.019585

run [1850]:
Style Loss : 0.241251 Content Loss: 0.019723

run [1900]:
Style Loss : 0.239432 Content Loss: 0.019890

run [1950]:
Style Loss : 0.237842 Content Loss: 0.020039

run [2000]:
Style Loss : 0.236376 Content Loss: 0.020183

run [2050]:
Style Loss : 0.234839 Content Loss: 0.020355

run [2100]:
Style Loss : 0.233373 Content Loss: 0.020503

run [2150]:
Style Loss : 0.232012 Content Loss: 0.020666

run [2200]:
Style Loss : 0.230581 Content Loss: 0.020815

run [2250]:
Style Loss : 0.228778 Content Loss: 0.020985

run [2300]:
Style Loss : 0.226979 Content Loss: 0.021153

run [2350]:
Style Loss : 0.225385 Content Loss: 0.021370

run [2400]:
Style Loss : 0.223685 Content Loss: 0.021543

run [2450]:
Style Loss : 0.222119 Content Loss: 0.021703

run [2500]:
Style Loss : 0.220728 Content Loss: 0.021911

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.946135 Content Loss: 0.006451

run [100]:
Style Loss : 0.549063 Content Loss: 0.009566

run [150]:
Style Loss : 0.383719 Content Loss: 0.013293

run [200]:
Style Loss : 0.288456 Content Loss: 0.017252

run [250]:
Style Loss : 0.238580 Content Loss: 0.020223

run [300]:
Style Loss : 0.210596 Content Loss: 0.022028

run [350]:
Style Loss : 0.193080 Content Loss: 0.023112

run [400]:
Style Loss : 0.182007 Content Loss: 0.023772

run [450]:
Style Loss : 0.172951 Content Loss: 0.024295

run [500]:
Style Loss : 0.165541 Content Loss: 0.024734

run [550]:
Style Loss : 0.159088 Content Loss: 0.025142

run [600]:
Style Loss : 0.153436 Content Loss: 0.025473

run [650]:
Style Loss : 0.149076 Content Loss: 0.025755

run [700]:
Style Loss : 0.145406 Content Loss: 0.026011

run [750]:
Style Loss : 0.142204 Content Loss: 0.026220

run [800]:
Style Loss : 0.139400 Content Loss: 0.026389

run [850]:
Style Loss : 0.136903 Content Loss: 0.026524

run [900]:
Style Loss : 0.135547 Content Loss: 0.026711

run [950]:
Style Loss : 0.132556 Content Loss: 0.026780

run [1000]:
Style Loss : 0.130472 Content Loss: 0.026921

run [1050]:
Style Loss : 0.128773 Content Loss: 0.027011

run [1100]:
Style Loss : 0.127290 Content Loss: 0.027082

run [1150]:
Style Loss : 0.126051 Content Loss: 0.027164

run [1200]:
Style Loss : 0.124844 Content Loss: 0.027220

run [1250]:
Style Loss : 0.123663 Content Loss: 0.027258

run [1300]:
Style Loss : 0.123442 Content Loss: 0.027351

run [1350]:
Style Loss : 0.122053 Content Loss: 0.027400

run [1400]:
Style Loss : 0.120803 Content Loss: 0.027436

run [1450]:
Style Loss : 0.119989 Content Loss: 0.027485

run [1500]:
Style Loss : 0.119313 Content Loss: 0.027523

run [1550]:
Style Loss : 0.121774 Content Loss: 0.027553

run [1600]:
Style Loss : 0.117607 Content Loss: 0.027563

run [1650]:
Style Loss : 0.117059 Content Loss: 0.027611

run [1700]:
Style Loss : 0.117452 Content Loss: 0.027736

run [1750]:
Style Loss : 0.115455 Content Loss: 0.027700

run [1800]:
Style Loss : 0.114066 Content Loss: 0.027778

run [1850]:
Style Loss : 0.113310 Content Loss: 0.027824

run [1900]:
Style Loss : 0.135695 Content Loss: 0.028528

run [1950]:
Style Loss : 0.113286 Content Loss: 0.028324

run [2000]:
Style Loss : 0.110066 Content Loss: 0.028281

run [2050]:
Style Loss : 0.108541 Content Loss: 0.028230

run [2100]:
Style Loss : 0.107623 Content Loss: 0.028202

run [2150]:
Style Loss : 0.106920 Content Loss: 0.028195

run [2200]:
Style Loss : 0.106904 Content Loss: 0.028214

run [2250]:
Style Loss : 0.105808 Content Loss: 0.028208

run [2300]:
Style Loss : 0.105410 Content Loss: 0.028228

run [2350]:
Style Loss : 0.105157 Content Loss: 0.028250

run [2400]:
Style Loss : 0.109626 Content Loss: 0.028459

run [2450]:
Style Loss : 0.104326 Content Loss: 0.028333

run [2500]:
Style Loss : 0.103242 Content Loss: 0.028290

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.089275 Content Loss: 0.005429

run [100]:
Style Loss : 0.608653 Content Loss: 0.008162

run [150]:
Style Loss : 0.469764 Content Loss: 0.009542

run [200]:
Style Loss : 0.400122 Content Loss: 0.010717

run [250]:
Style Loss : 0.349801 Content Loss: 0.011735

run [300]:
Style Loss : 0.315354 Content Loss: 0.012759

run [350]:
Style Loss : 0.289474 Content Loss: 0.013750

run [400]:
Style Loss : 0.270812 Content Loss: 0.014648

run [450]:
Style Loss : 0.256516 Content Loss: 0.015407

run [500]:
Style Loss : 0.245886 Content Loss: 0.016017

run [550]:
Style Loss : 0.237949 Content Loss: 0.016461

run [600]:
Style Loss : 0.231865 Content Loss: 0.016772

run [650]:
Style Loss : 0.227214 Content Loss: 0.016998

run [700]:
Style Loss : 0.222952 Content Loss: 0.017239

run [750]:
Style Loss : 0.219424 Content Loss: 0.017410

run [800]:
Style Loss : 0.216115 Content Loss: 0.017601

run [850]:
Style Loss : 0.213298 Content Loss: 0.017754

run [900]:
Style Loss : 0.210465 Content Loss: 0.017916

run [950]:
Style Loss : 0.207679 Content Loss: 0.018042

run [1000]:
Style Loss : 0.205093 Content Loss: 0.018162

run [1050]:
Style Loss : 0.202620 Content Loss: 0.018273

run [1100]:
Style Loss : 0.200565 Content Loss: 0.018379

run [1150]:
Style Loss : 0.198728 Content Loss: 0.018487

run [1200]:
Style Loss : 0.196983 Content Loss: 0.018590

run [1250]:
Style Loss : 0.195271 Content Loss: 0.018697

run [1300]:
Style Loss : 0.193783 Content Loss: 0.018802

run [1350]:
Style Loss : 0.192261 Content Loss: 0.018901

run [1400]:
Style Loss : 0.190920 Content Loss: 0.018992

run [1450]:
Style Loss : 0.189714 Content Loss: 0.019081

run [1500]:
Style Loss : 0.188627 Content Loss: 0.019161

run [1550]:
Style Loss : 0.187536 Content Loss: 0.019255

run [1600]:
Style Loss : 0.186532 Content Loss: 0.019342

run [1650]:
Style Loss : 0.185535 Content Loss: 0.019436

run [1700]:
Style Loss : 0.184121 Content Loss: 0.019536

run [1750]:
Style Loss : 0.182452 Content Loss: 0.019657

run [1800]:
Style Loss : 0.181048 Content Loss: 0.019756

run [1850]:
Style Loss : 0.179807 Content Loss: 0.019856

run [1900]:
Style Loss : 0.178728 Content Loss: 0.019940

run [1950]:
Style Loss : 0.177717 Content Loss: 0.020024

run [2000]:
Style Loss : 0.176787 Content Loss: 0.020099

run [2050]:
Style Loss : 0.175883 Content Loss: 0.020173

run [2100]:
Style Loss : 0.174994 Content Loss: 0.020249

run [2150]:
Style Loss : 0.174229 Content Loss: 0.020305

run [2200]:
Style Loss : 0.173533 Content Loss: 0.020372

run [2250]:
Style Loss : 0.172810 Content Loss: 0.020431

run [2300]:
Style Loss : 0.172148 Content Loss: 0.020499

run [2350]:
Style Loss : 0.171497 Content Loss: 0.020567

run [2400]:
Style Loss : 0.170911 Content Loss: 0.020627

run [2450]:
Style Loss : 0.170291 Content Loss: 0.020692

run [2500]:
Style Loss : 0.169689 Content Loss: 0.020749

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.870322 Content Loss: 0.017709

run [100]:
Style Loss : 1.478088 Content Loss: 0.015415

run [150]:
Style Loss : 0.988709 Content Loss: 0.015136

run [200]:
Style Loss : 0.790563 Content Loss: 0.015293

run [250]:
Style Loss : 0.679719 Content Loss: 0.015732

run [300]:
Style Loss : 0.604511 Content Loss: 0.016198

run [350]:
Style Loss : 0.550662 Content Loss: 0.016710

run [400]:
Style Loss : 0.509770 Content Loss: 0.017280

run [450]:
Style Loss : 0.476792 Content Loss: 0.017916

run [500]:
Style Loss : 0.447684 Content Loss: 0.018535

run [550]:
Style Loss : 0.424260 Content Loss: 0.019155

run [600]:
Style Loss : 0.405185 Content Loss: 0.019796

run [650]:
Style Loss : 0.389343 Content Loss: 0.020370

run [700]:
Style Loss : 0.376308 Content Loss: 0.020944

run [750]:
Style Loss : 0.365974 Content Loss: 0.021394

run [800]:
Style Loss : 0.357673 Content Loss: 0.021801

run [850]:
Style Loss : 0.350589 Content Loss: 0.022151

run [900]:
Style Loss : 0.344448 Content Loss: 0.022447

run [950]:
Style Loss : 0.339296 Content Loss: 0.022705

run [1000]:
Style Loss : 0.334710 Content Loss: 0.022908

run [1050]:
Style Loss : 0.330699 Content Loss: 0.023059

run [1100]:
Style Loss : 0.327276 Content Loss: 0.023181

run [1150]:
Style Loss : 0.324022 Content Loss: 0.023301

run [1200]:
Style Loss : 0.320919 Content Loss: 0.023383

run [1250]:
Style Loss : 0.318014 Content Loss: 0.023464

run [1300]:
Style Loss : 0.315477 Content Loss: 0.023521

run [1350]:
Style Loss : 0.313017 Content Loss: 0.023579

run [1400]:
Style Loss : 0.310795 Content Loss: 0.023631

run [1450]:
Style Loss : 0.308698 Content Loss: 0.023678

run [1500]:
Style Loss : 0.306672 Content Loss: 0.023717

run [1550]:
Style Loss : 0.304567 Content Loss: 0.023749

run [1600]:
Style Loss : 0.302413 Content Loss: 0.023780

run [1650]:
Style Loss : 0.300424 Content Loss: 0.023794

run [1700]:
Style Loss : 0.298492 Content Loss: 0.023813

run [1750]:
Style Loss : 0.296677 Content Loss: 0.023840

run [1800]:
Style Loss : 0.294840 Content Loss: 0.023863

run [1850]:
Style Loss : 0.293060 Content Loss: 0.023893

run [1900]:
Style Loss : 0.291376 Content Loss: 0.023924

run [1950]:
Style Loss : 0.289818 Content Loss: 0.023956

run [2000]:
Style Loss : 0.288392 Content Loss: 0.023986

run [2050]:
Style Loss : 0.287022 Content Loss: 0.024019

run [2100]:
Style Loss : 0.285635 Content Loss: 0.024060

run [2150]:
Style Loss : 0.284210 Content Loss: 0.024101

run [2200]:
Style Loss : 0.282864 Content Loss: 0.024140

run [2250]:
Style Loss : 0.281519 Content Loss: 0.024183

run [2300]:
Style Loss : 0.280098 Content Loss: 0.024219

run [2350]:
Style Loss : 0.278814 Content Loss: 0.024254

run [2400]:
Style Loss : 0.277645 Content Loss: 0.024289

run [2450]:
Style Loss : 0.276549 Content Loss: 0.024329

run [2500]:
Style Loss : 0.275464 Content Loss: 0.024367

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.845365 Content Loss: 0.005490

run [100]:
Style Loss : 0.453816 Content Loss: 0.008904

run [150]:
Style Loss : 0.320335 Content Loss: 0.011318

run [200]:
Style Loss : 0.247043 Content Loss: 0.013523

run [250]:
Style Loss : 0.199312 Content Loss: 0.015664

run [300]:
Style Loss : 0.166536 Content Loss: 0.017016

run [350]:
Style Loss : 0.148332 Content Loss: 0.017991

run [400]:
Style Loss : 0.136503 Content Loss: 0.018548

run [450]:
Style Loss : 0.128111 Content Loss: 0.018877

run [500]:
Style Loss : 0.121545 Content Loss: 0.019092

run [550]:
Style Loss : 0.116107 Content Loss: 0.019350

run [600]:
Style Loss : 0.111599 Content Loss: 0.019554

run [650]:
Style Loss : 0.107655 Content Loss: 0.019761

run [700]:
Style Loss : 0.104426 Content Loss: 0.019910

run [750]:
Style Loss : 0.101748 Content Loss: 0.020058

run [800]:
Style Loss : 0.099596 Content Loss: 0.020174

run [850]:
Style Loss : 0.097707 Content Loss: 0.020308

run [900]:
Style Loss : 0.095877 Content Loss: 0.020451

run [950]:
Style Loss : 0.094218 Content Loss: 0.020579

run [1000]:
Style Loss : 0.092914 Content Loss: 0.020682

run [1050]:
Style Loss : 0.091756 Content Loss: 0.020779

run [1100]:
Style Loss : 0.090696 Content Loss: 0.020864

run [1150]:
Style Loss : 0.089734 Content Loss: 0.020944

run [1200]:
Style Loss : 0.088857 Content Loss: 0.021010

run [1250]:
Style Loss : 0.088120 Content Loss: 0.021067

run [1300]:
Style Loss : 0.087507 Content Loss: 0.021117

run [1350]:
Style Loss : 0.086941 Content Loss: 0.021166

run [1400]:
Style Loss : 0.086438 Content Loss: 0.021204

run [1450]:
Style Loss : 0.085984 Content Loss: 0.021244

run [1500]:
Style Loss : 0.085492 Content Loss: 0.021282

run [1550]:
Style Loss : 0.085032 Content Loss: 0.021316

run [1600]:
Style Loss : 0.084614 Content Loss: 0.021348

run [1650]:
Style Loss : 0.084228 Content Loss: 0.021379

run [1700]:
Style Loss : 0.083900 Content Loss: 0.021400

run [1750]:
Style Loss : 0.083565 Content Loss: 0.021423

run [1800]:
Style Loss : 0.083216 Content Loss: 0.021447

run [1850]:
Style Loss : 0.082848 Content Loss: 0.021475

run [1900]:
Style Loss : 0.082475 Content Loss: 0.021507

run [1950]:
Style Loss : 0.082094 Content Loss: 0.021533

run [2000]:
Style Loss : 0.081740 Content Loss: 0.021560

run [2050]:
Style Loss : 0.081408 Content Loss: 0.021589

run [2100]:
Style Loss : 0.081085 Content Loss: 0.021617

run [2150]:
Style Loss : 0.080807 Content Loss: 0.021642

run [2200]:
Style Loss : 0.080540 Content Loss: 0.021655

run [2250]:
Style Loss : 0.080299 Content Loss: 0.021674

run [2300]:
Style Loss : 0.080101 Content Loss: 0.021695

run [2350]:
Style Loss : 0.079833 Content Loss: 0.021717

run [2400]:
Style Loss : 0.079566 Content Loss: 0.021743

run [2450]:
Style Loss : 0.079304 Content Loss: 0.021757

run [2500]:
Style Loss : 0.079096 Content Loss: 0.021782

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.454623 Content Loss: 0.003893

run [100]:
Style Loss : 1.383784 Content Loss: 0.006974

run [150]:
Style Loss : 1.025539 Content Loss: 0.009046

run [200]:
Style Loss : 0.832312 Content Loss: 0.011129

run [250]:
Style Loss : 0.702498 Content Loss: 0.013341

run [300]:
Style Loss : 0.608440 Content Loss: 0.015906

run [350]:
Style Loss : 0.536444 Content Loss: 0.018467

run [400]:
Style Loss : 0.483039 Content Loss: 0.021228

run [450]:
Style Loss : 0.445810 Content Loss: 0.023150

run [500]:
Style Loss : 0.420296 Content Loss: 0.024628

run [550]:
Style Loss : 0.401763 Content Loss: 0.025600

run [600]:
Style Loss : 0.388327 Content Loss: 0.026191

run [650]:
Style Loss : 0.378389 Content Loss: 0.026587

run [700]:
Style Loss : 0.370453 Content Loss: 0.026927

run [750]:
Style Loss : 0.364184 Content Loss: 0.027141

run [800]:
Style Loss : 0.359007 Content Loss: 0.027325

run [850]:
Style Loss : 0.354555 Content Loss: 0.027487

run [900]:
Style Loss : 0.350736 Content Loss: 0.027603

run [950]:
Style Loss : 0.347446 Content Loss: 0.027715

run [1000]:
Style Loss : 0.344643 Content Loss: 0.027833

run [1050]:
Style Loss : 0.341944 Content Loss: 0.027949

run [1100]:
Style Loss : 0.339346 Content Loss: 0.028060

run [1150]:
Style Loss : 0.336898 Content Loss: 0.028145

run [1200]:
Style Loss : 0.334762 Content Loss: 0.028234

run [1250]:
Style Loss : 0.332804 Content Loss: 0.028314

run [1300]:
Style Loss : 0.330927 Content Loss: 0.028397

run [1350]:
Style Loss : 0.329141 Content Loss: 0.028479

run [1400]:
Style Loss : 0.327547 Content Loss: 0.028547

run [1450]:
Style Loss : 0.326092 Content Loss: 0.028615

run [1500]:
Style Loss : 0.324749 Content Loss: 0.028682

run [1550]:
Style Loss : 0.323471 Content Loss: 0.028741

run [1600]:
Style Loss : 0.322327 Content Loss: 0.028805

run [1650]:
Style Loss : 0.321217 Content Loss: 0.028865

run [1700]:
Style Loss : 0.320098 Content Loss: 0.028928

run [1750]:
Style Loss : 0.319123 Content Loss: 0.028983

run [1800]:
Style Loss : 0.318131 Content Loss: 0.029043

run [1850]:
Style Loss : 0.317154 Content Loss: 0.029105

run [1900]:
Style Loss : 0.316210 Content Loss: 0.029153

run [1950]:
Style Loss : 0.315431 Content Loss: 0.029200

run [2000]:
Style Loss : 0.314704 Content Loss: 0.029244

run [2050]:
Style Loss : 0.313997 Content Loss: 0.029287

run [2100]:
Style Loss : 0.313269 Content Loss: 0.029330

run [2150]:
Style Loss : 0.312620 Content Loss: 0.029369

run [2200]:
Style Loss : 0.311912 Content Loss: 0.029404

run [2250]:
Style Loss : 0.311291 Content Loss: 0.029431

run [2300]:
Style Loss : 0.310692 Content Loss: 0.029466

run [2350]:
Style Loss : 0.310154 Content Loss: 0.029493

run [2400]:
Style Loss : 0.309649 Content Loss: 0.029518

run [2450]:
Style Loss : 0.309171 Content Loss: 0.029545

run [2500]:
Style Loss : 0.308715 Content Loss: 0.029569

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.466255 Content Loss: 0.001842

run [100]:
Style Loss : 0.875588 Content Loss: 0.002988

run [150]:
Style Loss : 0.671341 Content Loss: 0.004106

run [200]:
Style Loss : 0.568593 Content Loss: 0.005145

run [250]:
Style Loss : 0.497480 Content Loss: 0.006133

run [300]:
Style Loss : 0.448968 Content Loss: 0.007087

run [350]:
Style Loss : 0.411877 Content Loss: 0.007823

run [400]:
Style Loss : 0.384506 Content Loss: 0.008393

run [450]:
Style Loss : 0.364276 Content Loss: 0.008951

run [500]:
Style Loss : 0.347981 Content Loss: 0.009451

run [550]:
Style Loss : 0.334460 Content Loss: 0.009892

run [600]:
Style Loss : 0.323109 Content Loss: 0.010318

run [650]:
Style Loss : 0.313236 Content Loss: 0.010658

run [700]:
Style Loss : 0.304912 Content Loss: 0.010972

run [750]:
Style Loss : 0.298294 Content Loss: 0.011265

run [800]:
Style Loss : 0.291872 Content Loss: 0.011527

run [850]:
Style Loss : 0.286185 Content Loss: 0.011764

run [900]:
Style Loss : 0.281431 Content Loss: 0.011964

run [950]:
Style Loss : 0.277420 Content Loss: 0.012136

run [1000]:
Style Loss : 0.273709 Content Loss: 0.012302

run [1050]:
Style Loss : 0.270230 Content Loss: 0.012453

run [1100]:
Style Loss : 0.266979 Content Loss: 0.012588

run [1150]:
Style Loss : 0.264196 Content Loss: 0.012703

run [1200]:
Style Loss : 0.261893 Content Loss: 0.012816

run [1250]:
Style Loss : 0.259872 Content Loss: 0.012913

run [1300]:
Style Loss : 0.258072 Content Loss: 0.013009

run [1350]:
Style Loss : 0.256417 Content Loss: 0.013086

run [1400]:
Style Loss : 0.254986 Content Loss: 0.013166

run [1450]:
Style Loss : 0.253671 Content Loss: 0.013235

run [1500]:
Style Loss : 0.252496 Content Loss: 0.013294

run [1550]:
Style Loss : 0.251308 Content Loss: 0.013358

run [1600]:
Style Loss : 0.250215 Content Loss: 0.013414

run [1650]:
Style Loss : 0.249055 Content Loss: 0.013478

run [1700]:
Style Loss : 0.247921 Content Loss: 0.013542

run [1750]:
Style Loss : 0.246847 Content Loss: 0.013598

run [1800]:
Style Loss : 0.245867 Content Loss: 0.013648

run [1850]:
Style Loss : 0.244981 Content Loss: 0.013697

run [1900]:
Style Loss : 0.244148 Content Loss: 0.013741

run [1950]:
Style Loss : 0.243361 Content Loss: 0.013786

run [2000]:
Style Loss : 0.242571 Content Loss: 0.013841

run [2050]:
Style Loss : 0.241774 Content Loss: 0.013892

run [2100]:
Style Loss : 0.240934 Content Loss: 0.013937

run [2150]:
Style Loss : 0.240104 Content Loss: 0.013982

run [2200]:
Style Loss : 0.239177 Content Loss: 0.014024

run [2250]:
Style Loss : 0.238315 Content Loss: 0.014070

run [2300]:
Style Loss : 0.237535 Content Loss: 0.014106

run [2350]:
Style Loss : 0.236784 Content Loss: 0.014147

run [2400]:
Style Loss : 0.236084 Content Loss: 0.014184

run [2450]:
Style Loss : 0.235367 Content Loss: 0.014221

run [2500]:
Style Loss : 0.234736 Content Loss: 0.014256

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.677041 Content Loss: 0.001416

run [100]:
Style Loss : 0.929506 Content Loss: 0.002876

run [150]:
Style Loss : 0.636112 Content Loss: 0.003883

run [200]:
Style Loss : 0.517534 Content Loss: 0.004774

run [250]:
Style Loss : 0.445697 Content Loss: 0.005636

run [300]:
Style Loss : 0.394555 Content Loss: 0.006467

run [350]:
Style Loss : 0.357633 Content Loss: 0.007110

run [400]:
Style Loss : 0.327961 Content Loss: 0.007825

run [450]:
Style Loss : 0.303668 Content Loss: 0.008490

run [500]:
Style Loss : 0.284168 Content Loss: 0.009015

run [550]:
Style Loss : 0.268707 Content Loss: 0.009529

run [600]:
Style Loss : 0.256755 Content Loss: 0.009999

run [650]:
Style Loss : 0.246831 Content Loss: 0.010403

run [700]:
Style Loss : 0.239038 Content Loss: 0.010718

run [750]:
Style Loss : 0.232519 Content Loss: 0.010958

run [800]:
Style Loss : 0.227096 Content Loss: 0.011177

run [850]:
Style Loss : 0.222365 Content Loss: 0.011354

run [900]:
Style Loss : 0.218517 Content Loss: 0.011488

run [950]:
Style Loss : 0.214917 Content Loss: 0.011642

run [1000]:
Style Loss : 0.211533 Content Loss: 0.011759

run [1050]:
Style Loss : 0.208337 Content Loss: 0.011873

run [1100]:
Style Loss : 0.205307 Content Loss: 0.011975

run [1150]:
Style Loss : 0.202574 Content Loss: 0.012085

run [1200]:
Style Loss : 0.199923 Content Loss: 0.012176

run [1250]:
Style Loss : 0.197268 Content Loss: 0.012263

run [1300]:
Style Loss : 0.194845 Content Loss: 0.012345

run [1350]:
Style Loss : 0.192562 Content Loss: 0.012418

run [1400]:
Style Loss : 0.190369 Content Loss: 0.012500

run [1450]:
Style Loss : 0.188239 Content Loss: 0.012591

run [1500]:
Style Loss : 0.186304 Content Loss: 0.012674

run [1550]:
Style Loss : 0.184309 Content Loss: 0.012769

run [1600]:
Style Loss : 0.182445 Content Loss: 0.012860

run [1650]:
Style Loss : 0.180638 Content Loss: 0.012947

run [1700]:
Style Loss : 0.178936 Content Loss: 0.013038

run [1750]:
Style Loss : 0.177290 Content Loss: 0.013130

run [1800]:
Style Loss : 0.175792 Content Loss: 0.013212

run [1850]:
Style Loss : 0.174330 Content Loss: 0.013299

run [1900]:
Style Loss : 0.172951 Content Loss: 0.013383

run [1950]:
Style Loss : 0.171617 Content Loss: 0.013459

run [2000]:
Style Loss : 0.170302 Content Loss: 0.013539

run [2050]:
Style Loss : 0.169140 Content Loss: 0.013612

run [2100]:
Style Loss : 0.167969 Content Loss: 0.013681

run [2150]:
Style Loss : 0.166798 Content Loss: 0.013760

run [2200]:
Style Loss : 0.165657 Content Loss: 0.013839

run [2250]:
Style Loss : 0.164589 Content Loss: 0.013916

run [2300]:
Style Loss : 0.163535 Content Loss: 0.013992

run [2350]:
Style Loss : 0.162579 Content Loss: 0.014064

run [2400]:
Style Loss : 0.161615 Content Loss: 0.014138

run [2450]:
Style Loss : 0.160631 Content Loss: 0.014210

run [2500]:
Style Loss : 0.159634 Content Loss: 0.014287

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.308992 Content Loss: 0.001536

run [100]:
Style Loss : 1.363722 Content Loss: 0.002976

run [150]:
Style Loss : 0.991698 Content Loss: 0.004080

run [200]:
Style Loss : 0.797595 Content Loss: 0.004802

run [250]:
Style Loss : 0.677438 Content Loss: 0.005448

run [300]:
Style Loss : 0.587559 Content Loss: 0.005965

run [350]:
Style Loss : 0.529224 Content Loss: 0.006353

run [400]:
Style Loss : 0.486600 Content Loss: 0.006731

run [450]:
Style Loss : 0.453858 Content Loss: 0.007033

run [500]:
Style Loss : 0.429276 Content Loss: 0.007299

run [550]:
Style Loss : 0.410802 Content Loss: 0.007549

run [600]:
Style Loss : 0.395454 Content Loss: 0.007771

run [650]:
Style Loss : 0.381750 Content Loss: 0.007961

run [700]:
Style Loss : 0.368856 Content Loss: 0.008148

run [750]:
Style Loss : 0.359098 Content Loss: 0.008331

run [800]:
Style Loss : 0.349440 Content Loss: 0.008506

run [850]:
Style Loss : 0.342080 Content Loss: 0.008673

run [900]:
Style Loss : 0.335964 Content Loss: 0.008828

run [950]:
Style Loss : 0.330575 Content Loss: 0.008977

run [1000]:
Style Loss : 0.325993 Content Loss: 0.009119

run [1050]:
Style Loss : 0.321885 Content Loss: 0.009256

run [1100]:
Style Loss : 0.318319 Content Loss: 0.009385

run [1150]:
Style Loss : 0.314985 Content Loss: 0.009500

run [1200]:
Style Loss : 0.312243 Content Loss: 0.009592

run [1250]:
Style Loss : 0.309757 Content Loss: 0.009694

run [1300]:
Style Loss : 0.307467 Content Loss: 0.009785

run [1350]:
Style Loss : 0.305329 Content Loss: 0.009874

run [1400]:
Style Loss : 0.303363 Content Loss: 0.009956

run [1450]:
Style Loss : 0.301367 Content Loss: 0.010042

run [1500]:
Style Loss : 0.299478 Content Loss: 0.010111

run [1550]:
Style Loss : 0.297656 Content Loss: 0.010186

run [1600]:
Style Loss : 0.295986 Content Loss: 0.010255

run [1650]:
Style Loss : 0.294414 Content Loss: 0.010331

run [1700]:
Style Loss : 0.292782 Content Loss: 0.010411

run [1750]:
Style Loss : 0.291189 Content Loss: 0.010481

run [1800]:
Style Loss : 0.289518 Content Loss: 0.010549

run [1850]:
Style Loss : 0.287943 Content Loss: 0.010626

run [1900]:
Style Loss : 0.286321 Content Loss: 0.010697

run [1950]:
Style Loss : 0.284863 Content Loss: 0.010777

run [2000]:
Style Loss : 0.283425 Content Loss: 0.010839

run [2050]:
Style Loss : 0.281988 Content Loss: 0.010907

run [2100]:
Style Loss : 0.280584 Content Loss: 0.010980

run [2150]:
Style Loss : 0.279140 Content Loss: 0.011057

run [2200]:
Style Loss : 0.277616 Content Loss: 0.011133

run [2250]:
Style Loss : 0.276114 Content Loss: 0.011203

run [2300]:
Style Loss : 0.274824 Content Loss: 0.011264

run [2350]:
Style Loss : 0.273560 Content Loss: 0.011323

run [2400]:
Style Loss : 0.272329 Content Loss: 0.011390

run [2450]:
Style Loss : 0.271208 Content Loss: 0.011462

run [2500]:
Style Loss : 0.269990 Content Loss: 0.011527

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.818449 Content Loss: 0.002989

run [100]:
Style Loss : 0.435255 Content Loss: 0.005149

run [150]:
Style Loss : 0.321081 Content Loss: 0.006714

run [200]:
Style Loss : 0.272272 Content Loss: 0.007780

run [250]:
Style Loss : 0.243352 Content Loss: 0.008578

run [300]:
Style Loss : 0.223749 Content Loss: 0.009205

run [350]:
Style Loss : 0.206486 Content Loss: 0.009676

run [400]:
Style Loss : 0.191069 Content Loss: 0.009985

run [450]:
Style Loss : 0.178952 Content Loss: 0.010296

run [500]:
Style Loss : 0.168722 Content Loss: 0.010540

run [550]:
Style Loss : 0.159976 Content Loss: 0.010750

run [600]:
Style Loss : 0.153315 Content Loss: 0.010984

run [650]:
Style Loss : 0.147241 Content Loss: 0.011148

run [700]:
Style Loss : 0.142667 Content Loss: 0.011265

run [750]:
Style Loss : 0.138805 Content Loss: 0.011394

run [800]:
Style Loss : 0.135727 Content Loss: 0.011493

run [850]:
Style Loss : 0.132638 Content Loss: 0.011596

run [900]:
Style Loss : 0.130452 Content Loss: 0.011667

run [950]:
Style Loss : 0.128694 Content Loss: 0.011738

run [1000]:
Style Loss : 0.127269 Content Loss: 0.011793

run [1050]:
Style Loss : 0.125637 Content Loss: 0.011865

run [1100]:
Style Loss : 0.124418 Content Loss: 0.011924

run [1150]:
Style Loss : 0.123007 Content Loss: 0.011992

run [1200]:
Style Loss : 0.121181 Content Loss: 0.012079

run [1250]:
Style Loss : 0.119095 Content Loss: 0.012164

run [1300]:
Style Loss : 0.117435 Content Loss: 0.012227

run [1350]:
Style Loss : 0.116275 Content Loss: 0.012271

run [1400]:
Style Loss : 0.115390 Content Loss: 0.012315

run [1450]:
Style Loss : 0.114454 Content Loss: 0.012362

run [1500]:
Style Loss : 0.113242 Content Loss: 0.012391

run [1550]:
Style Loss : 0.112349 Content Loss: 0.012424

run [1600]:
Style Loss : 0.111587 Content Loss: 0.012461

run [1650]:
Style Loss : 0.110911 Content Loss: 0.012476

run [1700]:
Style Loss : 0.110316 Content Loss: 0.012499

run [1750]:
Style Loss : 0.109813 Content Loss: 0.012524

run [1800]:
Style Loss : 0.109310 Content Loss: 0.012551

run [1850]:
Style Loss : 0.108881 Content Loss: 0.012574

run [1900]:
Style Loss : 0.108435 Content Loss: 0.012583

run [1950]:
Style Loss : 0.108031 Content Loss: 0.012608

run [2000]:
Style Loss : 0.107578 Content Loss: 0.012633

run [2050]:
Style Loss : 0.107156 Content Loss: 0.012660

run [2100]:
Style Loss : 0.106817 Content Loss: 0.012692

run [2150]:
Style Loss : 0.106515 Content Loss: 0.012717

run [2200]:
Style Loss : 0.106126 Content Loss: 0.012742

run [2250]:
Style Loss : 0.105682 Content Loss: 0.012775

run [2300]:
Style Loss : 0.105455 Content Loss: 0.012810

run [2350]:
Style Loss : 0.105017 Content Loss: 0.012844

run [2400]:
Style Loss : 0.104623 Content Loss: 0.012851

run [2450]:
Style Loss : 0.104319 Content Loss: 0.012889

run [2500]:
Style Loss : 0.104043 Content Loss: 0.012904

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.750084 Content Loss: 0.003621

run [100]:
Style Loss : 0.449678 Content Loss: 0.007023

run [150]:
Style Loss : 0.349047 Content Loss: 0.009772

run [200]:
Style Loss : 0.300659 Content Loss: 0.012079

run [250]:
Style Loss : 0.265080 Content Loss: 0.013881

run [300]:
Style Loss : 0.239866 Content Loss: 0.015344

run [350]:
Style Loss : 0.219620 Content Loss: 0.016741

run [400]:
Style Loss : 0.206671 Content Loss: 0.017677

run [450]:
Style Loss : 0.197275 Content Loss: 0.018363

run [500]:
Style Loss : 0.191047 Content Loss: 0.018787

run [550]:
Style Loss : 0.185824 Content Loss: 0.019133

run [600]:
Style Loss : 0.181459 Content Loss: 0.019340

run [650]:
Style Loss : 0.177841 Content Loss: 0.019517

run [700]:
Style Loss : 0.174823 Content Loss: 0.019573

run [750]:
Style Loss : 0.172472 Content Loss: 0.019646

run [800]:
Style Loss : 0.170486 Content Loss: 0.019727

run [850]:
Style Loss : 0.168830 Content Loss: 0.019754

run [900]:
Style Loss : 0.167258 Content Loss: 0.019801

run [950]:
Style Loss : 0.166022 Content Loss: 0.019834

run [1000]:
Style Loss : 0.164872 Content Loss: 0.019873

run [1050]:
Style Loss : 0.163743 Content Loss: 0.019915

run [1100]:
Style Loss : 0.162636 Content Loss: 0.019945

run [1150]:
Style Loss : 0.161607 Content Loss: 0.019983

run [1200]:
Style Loss : 0.160613 Content Loss: 0.020027

run [1250]:
Style Loss : 0.159556 Content Loss: 0.020076

run [1300]:
Style Loss : 0.158684 Content Loss: 0.020121

run [1350]:
Style Loss : 0.157904 Content Loss: 0.020168

run [1400]:
Style Loss : 0.157242 Content Loss: 0.020191

run [1450]:
Style Loss : 0.156541 Content Loss: 0.020220

run [1500]:
Style Loss : 0.155985 Content Loss: 0.020247

run [1550]:
Style Loss : 0.155470 Content Loss: 0.020272

run [1600]:
Style Loss : 0.154692 Content Loss: 0.020294

run [1650]:
Style Loss : 0.153417 Content Loss: 0.020326

run [1700]:
Style Loss : 0.152817 Content Loss: 0.020345

run [1750]:
Style Loss : 0.152330 Content Loss: 0.020361

run [1800]:
Style Loss : 0.151832 Content Loss: 0.020385

run [1850]:
Style Loss : 0.151344 Content Loss: 0.020407

run [1900]:
Style Loss : 0.150868 Content Loss: 0.020441

run [1950]:
Style Loss : 0.150389 Content Loss: 0.020451

run [2000]:
Style Loss : 0.149937 Content Loss: 0.020482

run [2050]:
Style Loss : 0.149542 Content Loss: 0.020489

run [2100]:
Style Loss : 0.149189 Content Loss: 0.020511

run [2150]:
Style Loss : 0.148869 Content Loss: 0.020528

run [2200]:
Style Loss : 0.148520 Content Loss: 0.020543

run [2250]:
Style Loss : 0.148224 Content Loss: 0.020555

run [2300]:
Style Loss : 0.147869 Content Loss: 0.020567

run [2350]:
Style Loss : 0.147540 Content Loss: 0.020575

run [2400]:
Style Loss : 0.147297 Content Loss: 0.020592

run [2450]:
Style Loss : 0.146949 Content Loss: 0.020598

run [2500]:
Style Loss : 0.146620 Content Loss: 0.020616

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.370446 Content Loss: 0.011185

run [100]:
Style Loss : 1.323466 Content Loss: 0.015252

run [150]:
Style Loss : 1.011478 Content Loss: 0.017916

run [200]:
Style Loss : 0.858938 Content Loss: 0.020162

run [250]:
Style Loss : 0.770245 Content Loss: 0.021402

run [300]:
Style Loss : 0.713956 Content Loss: 0.022514

run [350]:
Style Loss : 0.667740 Content Loss: 0.023327

run [400]:
Style Loss : 0.634086 Content Loss: 0.023995

run [450]:
Style Loss : 0.607791 Content Loss: 0.024716

run [500]:
Style Loss : 0.586180 Content Loss: 0.025292

run [550]:
Style Loss : 0.568799 Content Loss: 0.025711

run [600]:
Style Loss : 0.554452 Content Loss: 0.026084

run [650]:
Style Loss : 0.543370 Content Loss: 0.026492

run [700]:
Style Loss : 0.533543 Content Loss: 0.026862

run [750]:
Style Loss : 0.524907 Content Loss: 0.027135

run [800]:
Style Loss : 0.516981 Content Loss: 0.027327

run [850]:
Style Loss : 0.509165 Content Loss: 0.027568

run [900]:
Style Loss : 0.502660 Content Loss: 0.027764

run [950]:
Style Loss : 0.496703 Content Loss: 0.027902

run [1000]:
Style Loss : 0.491523 Content Loss: 0.028112

run [1050]:
Style Loss : 0.487293 Content Loss: 0.028239

run [1100]:
Style Loss : 0.483447 Content Loss: 0.028335

run [1150]:
Style Loss : 0.480264 Content Loss: 0.028434

run [1200]:
Style Loss : 0.476894 Content Loss: 0.028560

run [1250]:
Style Loss : 0.473187 Content Loss: 0.028694

run [1300]:
Style Loss : 0.469636 Content Loss: 0.028775

run [1350]:
Style Loss : 0.466813 Content Loss: 0.028870

run [1400]:
Style Loss : 0.464209 Content Loss: 0.028926

run [1450]:
Style Loss : 0.461815 Content Loss: 0.029014

run [1500]:
Style Loss : 0.459403 Content Loss: 0.029076

run [1550]:
Style Loss : 0.457351 Content Loss: 0.029165

run [1600]:
Style Loss : 0.455442 Content Loss: 0.029219

run [1650]:
Style Loss : 0.453298 Content Loss: 0.029280

run [1700]:
Style Loss : 0.450593 Content Loss: 0.029327

run [1750]:
Style Loss : 0.448404 Content Loss: 0.029380

run [1800]:
Style Loss : 0.446770 Content Loss: 0.029452

run [1850]:
Style Loss : 0.445029 Content Loss: 0.029466

run [1900]:
Style Loss : 0.443524 Content Loss: 0.029491

run [1950]:
Style Loss : 0.442224 Content Loss: 0.029541

run [2000]:
Style Loss : 0.441107 Content Loss: 0.029571

run [2050]:
Style Loss : 0.440344 Content Loss: 0.029615

run [2100]:
Style Loss : 0.439107 Content Loss: 0.029617

run [2150]:
Style Loss : 0.438331 Content Loss: 0.029637

run [2200]:
Style Loss : 0.437315 Content Loss: 0.029684

run [2250]:
Style Loss : 0.436448 Content Loss: 0.029681

run [2300]:
Style Loss : 0.435530 Content Loss: 0.029727

run [2350]:
Style Loss : 0.434678 Content Loss: 0.029730

run [2400]:
Style Loss : 0.433971 Content Loss: 0.029794

run [2450]:
Style Loss : 0.433117 Content Loss: 0.029802

run [2500]:
Style Loss : 0.432254 Content Loss: 0.029809

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.594314 Content Loss: 0.001565

run [100]:
Style Loss : 0.900150 Content Loss: 0.003006

run [150]:
Style Loss : 0.647121 Content Loss: 0.004210

run [200]:
Style Loss : 0.536171 Content Loss: 0.005410

run [250]:
Style Loss : 0.457753 Content Loss: 0.006493

run [300]:
Style Loss : 0.397748 Content Loss: 0.007639

run [350]:
Style Loss : 0.355360 Content Loss: 0.008642

run [400]:
Style Loss : 0.321660 Content Loss: 0.009597

run [450]:
Style Loss : 0.297611 Content Loss: 0.010357

run [500]:
Style Loss : 0.281025 Content Loss: 0.010954

run [550]:
Style Loss : 0.268696 Content Loss: 0.011422

run [600]:
Style Loss : 0.259332 Content Loss: 0.011764

run [650]:
Style Loss : 0.251383 Content Loss: 0.012063

run [700]:
Style Loss : 0.244548 Content Loss: 0.012262

run [750]:
Style Loss : 0.238566 Content Loss: 0.012437

run [800]:
Style Loss : 0.233270 Content Loss: 0.012573

run [850]:
Style Loss : 0.228255 Content Loss: 0.012702

run [900]:
Style Loss : 0.224378 Content Loss: 0.012814

run [950]:
Style Loss : 0.221174 Content Loss: 0.012913

run [1000]:
Style Loss : 0.218492 Content Loss: 0.013011

run [1050]:
Style Loss : 0.215963 Content Loss: 0.013101

run [1100]:
Style Loss : 0.213412 Content Loss: 0.013185

run [1150]:
Style Loss : 0.211024 Content Loss: 0.013261

run [1200]:
Style Loss : 0.209060 Content Loss: 0.013338

run [1250]:
Style Loss : 0.207263 Content Loss: 0.013423

run [1300]:
Style Loss : 0.205641 Content Loss: 0.013497

run [1350]:
Style Loss : 0.204141 Content Loss: 0.013576

run [1400]:
Style Loss : 0.202821 Content Loss: 0.013650

run [1450]:
Style Loss : 0.201511 Content Loss: 0.013736

run [1500]:
Style Loss : 0.200279 Content Loss: 0.013815

run [1550]:
Style Loss : 0.199134 Content Loss: 0.013892

run [1600]:
Style Loss : 0.198029 Content Loss: 0.013960

run [1650]:
Style Loss : 0.196935 Content Loss: 0.014033

run [1700]:
Style Loss : 0.195724 Content Loss: 0.014116

run [1750]:
Style Loss : 0.194479 Content Loss: 0.014178

run [1800]:
Style Loss : 0.193411 Content Loss: 0.014247

run [1850]:
Style Loss : 0.192374 Content Loss: 0.014312

run [1900]:
Style Loss : 0.191410 Content Loss: 0.014374

run [1950]:
Style Loss : 0.190499 Content Loss: 0.014431

run [2000]:
Style Loss : 0.189627 Content Loss: 0.014492

run [2050]:
Style Loss : 0.188809 Content Loss: 0.014552

run [2100]:
Style Loss : 0.188037 Content Loss: 0.014602

run [2150]:
Style Loss : 0.187351 Content Loss: 0.014650

run [2200]:
Style Loss : 0.186637 Content Loss: 0.014708

run [2250]:
Style Loss : 0.185949 Content Loss: 0.014762

run [2300]:
Style Loss : 0.185202 Content Loss: 0.014814

run [2350]:
Style Loss : 0.184477 Content Loss: 0.014865

run [2400]:
Style Loss : 0.183767 Content Loss: 0.014910

run [2450]:
Style Loss : 0.183114 Content Loss: 0.014964

run [2500]:
Style Loss : 0.182501 Content Loss: 0.015015

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.270703 Content Loss: 0.001880

run [100]:
Style Loss : 0.739816 Content Loss: 0.004230

run [150]:
Style Loss : 0.535652 Content Loss: 0.006406

run [200]:
Style Loss : 0.421959 Content Loss: 0.008678

run [250]:
Style Loss : 0.356519 Content Loss: 0.010289

run [300]:
Style Loss : 0.316406 Content Loss: 0.011616

run [350]:
Style Loss : 0.290595 Content Loss: 0.012519

run [400]:
Style Loss : 0.272527 Content Loss: 0.013101

run [450]:
Style Loss : 0.258944 Content Loss: 0.013517

run [500]:
Style Loss : 0.248617 Content Loss: 0.013785

run [550]:
Style Loss : 0.240639 Content Loss: 0.013994

run [600]:
Style Loss : 0.233871 Content Loss: 0.014175

run [650]:
Style Loss : 0.227821 Content Loss: 0.014341

run [700]:
Style Loss : 0.222495 Content Loss: 0.014464

run [750]:
Style Loss : 0.217661 Content Loss: 0.014614

run [800]:
Style Loss : 0.213019 Content Loss: 0.014744

run [850]:
Style Loss : 0.208556 Content Loss: 0.014869

run [900]:
Style Loss : 0.203835 Content Loss: 0.015000

run [950]:
Style Loss : 0.198145 Content Loss: 0.015133

run [1000]:
Style Loss : 0.193177 Content Loss: 0.015258

run [1050]:
Style Loss : 0.189493 Content Loss: 0.015368

run [1100]:
Style Loss : 0.186226 Content Loss: 0.015487

run [1150]:
Style Loss : 0.183288 Content Loss: 0.015605

run [1200]:
Style Loss : 0.180323 Content Loss: 0.015728

run [1250]:
Style Loss : 0.177771 Content Loss: 0.015844

run [1300]:
Style Loss : 0.175479 Content Loss: 0.015944

run [1350]:
Style Loss : 0.173471 Content Loss: 0.016023

run [1400]:
Style Loss : 0.171646 Content Loss: 0.016109

run [1450]:
Style Loss : 0.169967 Content Loss: 0.016199

run [1500]:
Style Loss : 0.168399 Content Loss: 0.016278

run [1550]:
Style Loss : 0.167028 Content Loss: 0.016364

run [1600]:
Style Loss : 0.165675 Content Loss: 0.016440

run [1650]:
Style Loss : 0.164412 Content Loss: 0.016524

run [1700]:
Style Loss : 0.163252 Content Loss: 0.016587

run [1750]:
Style Loss : 0.162201 Content Loss: 0.016655

run [1800]:
Style Loss : 0.161164 Content Loss: 0.016716

run [1850]:
Style Loss : 0.160156 Content Loss: 0.016790

run [1900]:
Style Loss : 0.159167 Content Loss: 0.016854

run [1950]:
Style Loss : 0.158222 Content Loss: 0.016929

run [2000]:
Style Loss : 0.157348 Content Loss: 0.016986

run [2050]:
Style Loss : 0.156446 Content Loss: 0.017059

run [2100]:
Style Loss : 0.155536 Content Loss: 0.017108

run [2150]:
Style Loss : 0.154650 Content Loss: 0.017160

run [2200]:
Style Loss : 0.153813 Content Loss: 0.017206

run [2250]:
Style Loss : 0.153059 Content Loss: 0.017254

run [2300]:
Style Loss : 0.152352 Content Loss: 0.017282

run [2350]:
Style Loss : 0.151727 Content Loss: 0.017319

run [2400]:
Style Loss : 0.151075 Content Loss: 0.017354

run [2450]:
Style Loss : 0.150463 Content Loss: 0.017392

run [2500]:
Style Loss : 0.149791 Content Loss: 0.017424

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.279583 Content Loss: 0.001677

run [100]:
Style Loss : 0.619226 Content Loss: 0.003505

run [150]:
Style Loss : 0.419507 Content Loss: 0.004645

run [200]:
Style Loss : 0.323830 Content Loss: 0.005517

run [250]:
Style Loss : 0.266136 Content Loss: 0.006317

run [300]:
Style Loss : 0.228063 Content Loss: 0.006993

run [350]:
Style Loss : 0.199507 Content Loss: 0.007671

run [400]:
Style Loss : 0.177343 Content Loss: 0.008396

run [450]:
Style Loss : 0.160332 Content Loss: 0.008944

run [500]:
Style Loss : 0.145251 Content Loss: 0.009369

run [550]:
Style Loss : 0.134150 Content Loss: 0.009741

run [600]:
Style Loss : 0.125874 Content Loss: 0.010054

run [650]:
Style Loss : 0.119639 Content Loss: 0.010273

run [700]:
Style Loss : 0.114867 Content Loss: 0.010471

run [750]:
Style Loss : 0.110236 Content Loss: 0.010619

run [800]:
Style Loss : 0.106186 Content Loss: 0.010725

run [850]:
Style Loss : 0.102716 Content Loss: 0.010811

run [900]:
Style Loss : 0.099629 Content Loss: 0.010884

run [950]:
Style Loss : 0.097031 Content Loss: 0.010960

run [1000]:
Style Loss : 0.094674 Content Loss: 0.011042

run [1050]:
Style Loss : 0.092677 Content Loss: 0.011123

run [1100]:
Style Loss : 0.090922 Content Loss: 0.011179

run [1150]:
Style Loss : 0.089455 Content Loss: 0.011245

run [1200]:
Style Loss : 0.088149 Content Loss: 0.011300

run [1250]:
Style Loss : 0.086884 Content Loss: 0.011351

run [1300]:
Style Loss : 0.085814 Content Loss: 0.011398

run [1350]:
Style Loss : 0.084877 Content Loss: 0.011439

run [1400]:
Style Loss : 0.084069 Content Loss: 0.011483

run [1450]:
Style Loss : 0.083299 Content Loss: 0.011520

run [1500]:
Style Loss : 0.082585 Content Loss: 0.011560

run [1550]:
Style Loss : 0.081871 Content Loss: 0.011594

run [1600]:
Style Loss : 0.081208 Content Loss: 0.011628

run [1650]:
Style Loss : 0.080638 Content Loss: 0.011659

run [1700]:
Style Loss : 0.080061 Content Loss: 0.011692

run [1750]:
Style Loss : 0.079527 Content Loss: 0.011717

run [1800]:
Style Loss : 0.078997 Content Loss: 0.011749

run [1850]:
Style Loss : 0.078527 Content Loss: 0.011774

run [1900]:
Style Loss : 0.078109 Content Loss: 0.011802

run [1950]:
Style Loss : 0.077718 Content Loss: 0.011825

run [2000]:
Style Loss : 0.077344 Content Loss: 0.011852

run [2050]:
Style Loss : 0.077015 Content Loss: 0.011873

run [2100]:
Style Loss : 0.076703 Content Loss: 0.011895

run [2150]:
Style Loss : 0.076398 Content Loss: 0.011923

run [2200]:
Style Loss : 0.076125 Content Loss: 0.011942

run [2250]:
Style Loss : 0.075874 Content Loss: 0.011963

run [2300]:
Style Loss : 0.075636 Content Loss: 0.011986

run [2350]:
Style Loss : 0.075419 Content Loss: 0.011999

run [2400]:
Style Loss : 0.075229 Content Loss: 0.012016

run [2450]:
Style Loss : 0.075050 Content Loss: 0.012032

run [2500]:
Style Loss : 0.074882 Content Loss: 0.012046

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.674475 Content Loss: 0.003697

run [100]:
Style Loss : 1.058761 Content Loss: 0.006436

run [150]:
Style Loss : 0.774022 Content Loss: 0.009803

run [200]:
Style Loss : 0.579934 Content Loss: 0.014724

run [250]:
Style Loss : 0.461882 Content Loss: 0.019205

run [300]:
Style Loss : 0.401220 Content Loss: 0.021814

run [350]:
Style Loss : 0.364312 Content Loss: 0.023112

run [400]:
Style Loss : 0.340121 Content Loss: 0.023754

run [450]:
Style Loss : 0.321863 Content Loss: 0.024318

run [500]:
Style Loss : 0.306896 Content Loss: 0.024848

run [550]:
Style Loss : 0.294184 Content Loss: 0.025423

run [600]:
Style Loss : 0.284206 Content Loss: 0.025893

run [650]:
Style Loss : 0.275724 Content Loss: 0.026337

run [700]:
Style Loss : 0.268356 Content Loss: 0.026724

run [750]:
Style Loss : 0.262266 Content Loss: 0.027160

run [800]:
Style Loss : 0.256953 Content Loss: 0.027479

run [850]:
Style Loss : 0.251858 Content Loss: 0.027767

run [900]:
Style Loss : 0.247249 Content Loss: 0.028062

run [950]:
Style Loss : 0.243334 Content Loss: 0.028256

run [1000]:
Style Loss : 0.239852 Content Loss: 0.028428

run [1050]:
Style Loss : 0.236922 Content Loss: 0.028567

run [1100]:
Style Loss : 0.233845 Content Loss: 0.028722

run [1150]:
Style Loss : 0.231504 Content Loss: 0.028870

run [1200]:
Style Loss : 0.228771 Content Loss: 0.029001

run [1250]:
Style Loss : 0.226637 Content Loss: 0.029144

run [1300]:
Style Loss : 0.224475 Content Loss: 0.029266

run [1350]:
Style Loss : 0.222649 Content Loss: 0.029386

run [1400]:
Style Loss : 0.220916 Content Loss: 0.029516

run [1450]:
Style Loss : 0.219173 Content Loss: 0.029605

run [1500]:
Style Loss : 0.217747 Content Loss: 0.029743

run [1550]:
Style Loss : 0.216442 Content Loss: 0.029864

run [1600]:
Style Loss : 0.215121 Content Loss: 0.029985

run [1650]:
Style Loss : 0.214818 Content Loss: 0.030140

run [1700]:
Style Loss : 0.213240 Content Loss: 0.030210

run [1750]:
Style Loss : 0.211846 Content Loss: 0.030363

run [1800]:
Style Loss : 0.210831 Content Loss: 0.030429

run [1850]:
Style Loss : 0.209475 Content Loss: 0.030565

run [1900]:
Style Loss : 0.208283 Content Loss: 0.030625

run [1950]:
Style Loss : 0.207167 Content Loss: 0.030745

run [2000]:
Style Loss : 0.206188 Content Loss: 0.030837

run [2050]:
Style Loss : 0.205208 Content Loss: 0.030915

run [2100]:
Style Loss : 0.205240 Content Loss: 0.031061

run [2150]:
Style Loss : 0.203081 Content Loss: 0.031062

run [2200]:
Style Loss : 0.203562 Content Loss: 0.031242

run [2250]:
Style Loss : 0.201992 Content Loss: 0.031313

run [2300]:
Style Loss : 0.200384 Content Loss: 0.031377

run [2350]:
Style Loss : 0.199367 Content Loss: 0.031434

run [2400]:
Style Loss : 0.198467 Content Loss: 0.031539

run [2450]:
Style Loss : 0.198017 Content Loss: 0.031550

run [2500]:
Style Loss : 0.197090 Content Loss: 0.031603

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.972047 Content Loss: 0.005268

run [100]:
Style Loss : 0.463918 Content Loss: 0.009621

run [150]:
Style Loss : 0.292399 Content Loss: 0.013148

run [200]:
Style Loss : 0.215470 Content Loss: 0.015612

run [250]:
Style Loss : 0.178354 Content Loss: 0.016880

run [300]:
Style Loss : 0.157466 Content Loss: 0.017570

run [350]:
Style Loss : 0.142103 Content Loss: 0.017850

run [400]:
Style Loss : 0.130994 Content Loss: 0.018176

run [450]:
Style Loss : 0.121411 Content Loss: 0.018438

run [500]:
Style Loss : 0.113753 Content Loss: 0.018579

run [550]:
Style Loss : 0.107193 Content Loss: 0.018788

run [600]:
Style Loss : 0.101685 Content Loss: 0.018944

run [650]:
Style Loss : 0.097091 Content Loss: 0.019066

run [700]:
Style Loss : 0.093415 Content Loss: 0.019177

run [750]:
Style Loss : 0.089956 Content Loss: 0.019271

run [800]:
Style Loss : 0.087025 Content Loss: 0.019372

run [850]:
Style Loss : 0.084646 Content Loss: 0.019417

run [900]:
Style Loss : 0.082575 Content Loss: 0.019460

run [950]:
Style Loss : 0.080862 Content Loss: 0.019515

run [1000]:
Style Loss : 0.079314 Content Loss: 0.019562

run [1050]:
Style Loss : 0.077915 Content Loss: 0.019618

run [1100]:
Style Loss : 0.076697 Content Loss: 0.019648

run [1150]:
Style Loss : 0.075619 Content Loss: 0.019669

run [1200]:
Style Loss : 0.074677 Content Loss: 0.019700

run [1250]:
Style Loss : 0.073821 Content Loss: 0.019714

run [1300]:
Style Loss : 0.072999 Content Loss: 0.019741

run [1350]:
Style Loss : 0.072234 Content Loss: 0.019760

run [1400]:
Style Loss : 0.071577 Content Loss: 0.019775

run [1450]:
Style Loss : 0.070886 Content Loss: 0.019798

run [1500]:
Style Loss : 0.070199 Content Loss: 0.019827

run [1550]:
Style Loss : 0.069615 Content Loss: 0.019856

run [1600]:
Style Loss : 0.068966 Content Loss: 0.019878

run [1650]:
Style Loss : 0.068409 Content Loss: 0.019889

run [1700]:
Style Loss : 0.067901 Content Loss: 0.019912

run [1750]:
Style Loss : 0.067436 Content Loss: 0.019934

run [1800]:
Style Loss : 0.067004 Content Loss: 0.019954

run [1850]:
Style Loss : 0.066627 Content Loss: 0.019982

run [1900]:
Style Loss : 0.066249 Content Loss: 0.019990

run [1950]:
Style Loss : 0.065893 Content Loss: 0.020011

run [2000]:
Style Loss : 0.065551 Content Loss: 0.020021

run [2050]:
Style Loss : 0.065207 Content Loss: 0.020038

run [2100]:
Style Loss : 0.064896 Content Loss: 0.020046

run [2150]:
Style Loss : 0.064570 Content Loss: 0.020059

run [2200]:
Style Loss : 0.064280 Content Loss: 0.020072

run [2250]:
Style Loss : 0.064013 Content Loss: 0.020075

run [2300]:
Style Loss : 0.063742 Content Loss: 0.020086

run [2350]:
Style Loss : 0.063503 Content Loss: 0.020088

run [2400]:
Style Loss : 0.063266 Content Loss: 0.020089

run [2450]:
Style Loss : 0.063017 Content Loss: 0.020097

run [2500]:
Style Loss : 0.062763 Content Loss: 0.020096

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.854876 Content Loss: 0.001818

run [100]:
Style Loss : 1.707925 Content Loss: 0.003141

run [150]:
Style Loss : 1.250409 Content Loss: 0.004379

run [200]:
Style Loss : 1.033643 Content Loss: 0.005563

run [250]:
Style Loss : 0.901160 Content Loss: 0.006601

run [300]:
Style Loss : 0.801785 Content Loss: 0.007677

run [350]:
Style Loss : 0.715111 Content Loss: 0.008824

run [400]:
Style Loss : 0.643709 Content Loss: 0.009949

run [450]:
Style Loss : 0.589479 Content Loss: 0.010980

run [500]:
Style Loss : 0.549793 Content Loss: 0.011943

run [550]:
Style Loss : 0.519428 Content Loss: 0.012864

run [600]:
Style Loss : 0.494799 Content Loss: 0.013505

run [650]:
Style Loss : 0.477072 Content Loss: 0.014091

run [700]:
Style Loss : 0.463080 Content Loss: 0.014576

run [750]:
Style Loss : 0.452519 Content Loss: 0.014966

run [800]:
Style Loss : 0.444075 Content Loss: 0.015296

run [850]:
Style Loss : 0.437472 Content Loss: 0.015528

run [900]:
Style Loss : 0.431869 Content Loss: 0.015736

run [950]:
Style Loss : 0.426822 Content Loss: 0.015903

run [1000]:
Style Loss : 0.421794 Content Loss: 0.016072

run [1050]:
Style Loss : 0.417427 Content Loss: 0.016197

run [1100]:
Style Loss : 0.413440 Content Loss: 0.016331

run [1150]:
Style Loss : 0.409511 Content Loss: 0.016439

run [1200]:
Style Loss : 0.406030 Content Loss: 0.016554

run [1250]:
Style Loss : 0.402830 Content Loss: 0.016646

run [1300]:
Style Loss : 0.400093 Content Loss: 0.016731

run [1350]:
Style Loss : 0.397586 Content Loss: 0.016802

run [1400]:
Style Loss : 0.395351 Content Loss: 0.016877

run [1450]:
Style Loss : 0.393115 Content Loss: 0.016961

run [1500]:
Style Loss : 0.390892 Content Loss: 0.017046

run [1550]:
Style Loss : 0.388799 Content Loss: 0.017102

run [1600]:
Style Loss : 0.386900 Content Loss: 0.017161

run [1650]:
Style Loss : 0.385152 Content Loss: 0.017220

run [1700]:
Style Loss : 0.383597 Content Loss: 0.017279

run [1750]:
Style Loss : 0.382065 Content Loss: 0.017332

run [1800]:
Style Loss : 0.380586 Content Loss: 0.017384

run [1850]:
Style Loss : 0.379351 Content Loss: 0.017431

run [1900]:
Style Loss : 0.378203 Content Loss: 0.017475

run [1950]:
Style Loss : 0.377123 Content Loss: 0.017521

run [2000]:
Style Loss : 0.376070 Content Loss: 0.017560

run [2050]:
Style Loss : 0.375139 Content Loss: 0.017597

run [2100]:
Style Loss : 0.374251 Content Loss: 0.017638

run [2150]:
Style Loss : 0.373378 Content Loss: 0.017676

run [2200]:
Style Loss : 0.372549 Content Loss: 0.017713

run [2250]:
Style Loss : 0.371747 Content Loss: 0.017750

run [2300]:
Style Loss : 0.370961 Content Loss: 0.017783

run [2350]:
Style Loss : 0.370171 Content Loss: 0.017817

run [2400]:
Style Loss : 0.369391 Content Loss: 0.017847

run [2450]:
Style Loss : 0.368730 Content Loss: 0.017874

run [2500]:
Style Loss : 0.368073 Content Loss: 0.017901

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.186470 Content Loss: 0.002060

run [100]:
Style Loss : 1.271645 Content Loss: 0.002674

run [150]:
Style Loss : 0.947171 Content Loss: 0.003454

run [200]:
Style Loss : 0.768585 Content Loss: 0.004324

run [250]:
Style Loss : 0.660278 Content Loss: 0.004874

run [300]:
Style Loss : 0.581834 Content Loss: 0.005566

run [350]:
Style Loss : 0.525814 Content Loss: 0.006176

run [400]:
Style Loss : 0.480255 Content Loss: 0.006842

run [450]:
Style Loss : 0.442127 Content Loss: 0.007356

run [500]:
Style Loss : 0.409394 Content Loss: 0.007983

run [550]:
Style Loss : 0.382405 Content Loss: 0.008615

run [600]:
Style Loss : 0.359333 Content Loss: 0.009187

run [650]:
Style Loss : 0.339889 Content Loss: 0.009726

run [700]:
Style Loss : 0.323468 Content Loss: 0.010285

run [750]:
Style Loss : 0.309782 Content Loss: 0.010770

run [800]:
Style Loss : 0.299080 Content Loss: 0.011160

run [850]:
Style Loss : 0.290621 Content Loss: 0.011557

run [900]:
Style Loss : 0.283716 Content Loss: 0.011774

run [950]:
Style Loss : 0.277267 Content Loss: 0.012019

run [1000]:
Style Loss : 0.271510 Content Loss: 0.012213

run [1050]:
Style Loss : 0.266596 Content Loss: 0.012368

run [1100]:
Style Loss : 0.261415 Content Loss: 0.012534

run [1150]:
Style Loss : 0.256730 Content Loss: 0.012668

run [1200]:
Style Loss : 0.252433 Content Loss: 0.012764

run [1250]:
Style Loss : 0.248447 Content Loss: 0.012854

run [1300]:
Style Loss : 0.244864 Content Loss: 0.012920

run [1350]:
Style Loss : 0.241465 Content Loss: 0.012983

run [1400]:
Style Loss : 0.238216 Content Loss: 0.013053

run [1450]:
Style Loss : 0.235155 Content Loss: 0.013124

run [1500]:
Style Loss : 0.232161 Content Loss: 0.013194

run [1550]:
Style Loss : 0.229190 Content Loss: 0.013260

run [1600]:
Style Loss : 0.226293 Content Loss: 0.013327

run [1650]:
Style Loss : 0.223472 Content Loss: 0.013389

run [1700]:
Style Loss : 0.220874 Content Loss: 0.013456

run [1750]:
Style Loss : 0.218351 Content Loss: 0.013518

run [1800]:
Style Loss : 0.215943 Content Loss: 0.013568

run [1850]:
Style Loss : 0.213720 Content Loss: 0.013633

run [1900]:
Style Loss : 0.211381 Content Loss: 0.013708

run [1950]:
Style Loss : 0.209049 Content Loss: 0.013784

run [2000]:
Style Loss : 0.206822 Content Loss: 0.013856

run [2050]:
Style Loss : 0.204460 Content Loss: 0.013957

run [2100]:
Style Loss : 0.202046 Content Loss: 0.014064

run [2150]:
Style Loss : 0.199807 Content Loss: 0.014157

run [2200]:
Style Loss : 0.197586 Content Loss: 0.014256

run [2250]:
Style Loss : 0.195184 Content Loss: 0.014381

run [2300]:
Style Loss : 0.192868 Content Loss: 0.014491

run [2350]:
Style Loss : 0.190498 Content Loss: 0.014620

run [2400]:
Style Loss : 0.188103 Content Loss: 0.014759

run [2450]:
Style Loss : 0.185796 Content Loss: 0.014909

run [2500]:
Style Loss : 0.183598 Content Loss: 0.015041

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.610553 Content Loss: 0.002939

run [100]:
Style Loss : 1.241531 Content Loss: 0.004125

run [150]:
Style Loss : 0.859434 Content Loss: 0.005544

run [200]:
Style Loss : 0.672401 Content Loss: 0.007098

run [250]:
Style Loss : 0.572096 Content Loss: 0.008430

run [300]:
Style Loss : 0.508847 Content Loss: 0.009618

run [350]:
Style Loss : 0.462394 Content Loss: 0.010610

run [400]:
Style Loss : 0.425849 Content Loss: 0.011517

run [450]:
Style Loss : 0.398633 Content Loss: 0.012120

run [500]:
Style Loss : 0.377085 Content Loss: 0.012698

run [550]:
Style Loss : 0.361404 Content Loss: 0.013271

run [600]:
Style Loss : 0.349123 Content Loss: 0.013766

run [650]:
Style Loss : 0.339084 Content Loss: 0.014191

run [700]:
Style Loss : 0.329202 Content Loss: 0.014577

run [750]:
Style Loss : 0.320954 Content Loss: 0.014871

run [800]:
Style Loss : 0.312910 Content Loss: 0.015148

run [850]:
Style Loss : 0.305664 Content Loss: 0.015410

run [900]:
Style Loss : 0.299374 Content Loss: 0.015616

run [950]:
Style Loss : 0.294200 Content Loss: 0.015834

run [1000]:
Style Loss : 0.289328 Content Loss: 0.016060

run [1050]:
Style Loss : 0.284858 Content Loss: 0.016244

run [1100]:
Style Loss : 0.280908 Content Loss: 0.016433

run [1150]:
Style Loss : 0.277542 Content Loss: 0.016608

run [1200]:
Style Loss : 0.274432 Content Loss: 0.016777

run [1250]:
Style Loss : 0.271351 Content Loss: 0.016938

run [1300]:
Style Loss : 0.268537 Content Loss: 0.017064

run [1350]:
Style Loss : 0.265904 Content Loss: 0.017206

run [1400]:
Style Loss : 0.263579 Content Loss: 0.017317

run [1450]:
Style Loss : 0.261350 Content Loss: 0.017426

run [1500]:
Style Loss : 0.259017 Content Loss: 0.017544

run [1550]:
Style Loss : 0.256921 Content Loss: 0.017633

run [1600]:
Style Loss : 0.255014 Content Loss: 0.017718

run [1650]:
Style Loss : 0.253245 Content Loss: 0.017805

run [1700]:
Style Loss : 0.251766 Content Loss: 0.017864

run [1750]:
Style Loss : 0.250327 Content Loss: 0.017941

run [1800]:
Style Loss : 0.248926 Content Loss: 0.018015

run [1850]:
Style Loss : 0.247578 Content Loss: 0.018094

run [1900]:
Style Loss : 0.246246 Content Loss: 0.018157

run [1950]:
Style Loss : 0.245050 Content Loss: 0.018228

run [2000]:
Style Loss : 0.243893 Content Loss: 0.018303

run [2050]:
Style Loss : 0.242739 Content Loss: 0.018379

run [2100]:
Style Loss : 0.241600 Content Loss: 0.018446

run [2150]:
Style Loss : 0.240532 Content Loss: 0.018497

run [2200]:
Style Loss : 0.239503 Content Loss: 0.018562

run [2250]:
Style Loss : 0.238490 Content Loss: 0.018628

run [2300]:
Style Loss : 0.237501 Content Loss: 0.018688

run [2350]:
Style Loss : 0.236594 Content Loss: 0.018736

run [2400]:
Style Loss : 0.235726 Content Loss: 0.018793

run [2450]:
Style Loss : 0.234911 Content Loss: 0.018849

run [2500]:
Style Loss : 0.234129 Content Loss: 0.018902

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.301655 Content Loss: 0.001755

run [100]:
Style Loss : 1.831504 Content Loss: 0.002423

run [150]:
Style Loss : 1.337663 Content Loss: 0.003183

run [200]:
Style Loss : 1.076860 Content Loss: 0.003968

run [250]:
Style Loss : 0.923088 Content Loss: 0.004585

run [300]:
Style Loss : 0.828752 Content Loss: 0.005098

run [350]:
Style Loss : 0.765907 Content Loss: 0.005494

run [400]:
Style Loss : 0.715409 Content Loss: 0.005954

run [450]:
Style Loss : 0.677539 Content Loss: 0.006273

run [500]:
Style Loss : 0.646720 Content Loss: 0.006582

run [550]:
Style Loss : 0.621818 Content Loss: 0.006890

run [600]:
Style Loss : 0.601889 Content Loss: 0.007086

run [650]:
Style Loss : 0.584066 Content Loss: 0.007310

run [700]:
Style Loss : 0.569795 Content Loss: 0.007511

run [750]:
Style Loss : 0.556370 Content Loss: 0.007711

run [800]:
Style Loss : 0.542906 Content Loss: 0.007892

run [850]:
Style Loss : 0.532013 Content Loss: 0.008052

run [900]:
Style Loss : 0.521603 Content Loss: 0.008207

run [950]:
Style Loss : 0.513538 Content Loss: 0.008352

run [1000]:
Style Loss : 0.505353 Content Loss: 0.008481

run [1050]:
Style Loss : 0.498050 Content Loss: 0.008621

run [1100]:
Style Loss : 0.491940 Content Loss: 0.008727

run [1150]:
Style Loss : 0.485999 Content Loss: 0.008839

run [1200]:
Style Loss : 0.479766 Content Loss: 0.008962

run [1250]:
Style Loss : 0.473463 Content Loss: 0.009069

run [1300]:
Style Loss : 0.467668 Content Loss: 0.009182

run [1350]:
Style Loss : 0.461974 Content Loss: 0.009301

run [1400]:
Style Loss : 0.456081 Content Loss: 0.009397

run [1450]:
Style Loss : 0.450115 Content Loss: 0.009500

run [1500]:
Style Loss : 0.445664 Content Loss: 0.009583

run [1550]:
Style Loss : 0.441629 Content Loss: 0.009669

run [1600]:
Style Loss : 0.438174 Content Loss: 0.009746

run [1650]:
Style Loss : 0.434871 Content Loss: 0.009824

run [1700]:
Style Loss : 0.431896 Content Loss: 0.009899

run [1750]:
Style Loss : 0.429044 Content Loss: 0.009970

run [1800]:
Style Loss : 0.426072 Content Loss: 0.010037

run [1850]:
Style Loss : 0.423219 Content Loss: 0.010100

run [1900]:
Style Loss : 0.420716 Content Loss: 0.010163

run [1950]:
Style Loss : 0.418178 Content Loss: 0.010217

run [2000]:
Style Loss : 0.415923 Content Loss: 0.010273

run [2050]:
Style Loss : 0.413726 Content Loss: 0.010333

run [2100]:
Style Loss : 0.411621 Content Loss: 0.010382

run [2150]:
Style Loss : 0.409543 Content Loss: 0.010425

run [2200]:
Style Loss : 0.407641 Content Loss: 0.010479

run [2250]:
Style Loss : 0.405908 Content Loss: 0.010528

run [2300]:
Style Loss : 0.404147 Content Loss: 0.010568

run [2350]:
Style Loss : 0.402423 Content Loss: 0.010614

run [2400]:
Style Loss : 0.400881 Content Loss: 0.010655

run [2450]:
Style Loss : 0.399320 Content Loss: 0.010698

run [2500]:
Style Loss : 0.397817 Content Loss: 0.010734

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.523097 Content Loss: 0.003891

run [100]:
Style Loss : 1.815620 Content Loss: 0.004060

run [150]:
Style Loss : 1.317593 Content Loss: 0.004809

run [200]:
Style Loss : 1.081511 Content Loss: 0.005610

run [250]:
Style Loss : 0.923456 Content Loss: 0.006248

run [300]:
Style Loss : 0.822154 Content Loss: 0.006815

run [350]:
Style Loss : 0.750892 Content Loss: 0.007314

run [400]:
Style Loss : 0.697764 Content Loss: 0.007821

run [450]:
Style Loss : 0.657832 Content Loss: 0.008227

run [500]:
Style Loss : 0.631032 Content Loss: 0.008573

run [550]:
Style Loss : 0.610282 Content Loss: 0.008891

run [600]:
Style Loss : 0.592044 Content Loss: 0.009239

run [650]:
Style Loss : 0.577299 Content Loss: 0.009522

run [700]:
Style Loss : 0.565106 Content Loss: 0.009809

run [750]:
Style Loss : 0.554532 Content Loss: 0.010074

run [800]:
Style Loss : 0.545495 Content Loss: 0.010299

run [850]:
Style Loss : 0.536897 Content Loss: 0.010511

run [900]:
Style Loss : 0.529092 Content Loss: 0.010705

run [950]:
Style Loss : 0.522218 Content Loss: 0.010901

run [1000]:
Style Loss : 0.516000 Content Loss: 0.011073

run [1050]:
Style Loss : 0.510863 Content Loss: 0.011203

run [1100]:
Style Loss : 0.505981 Content Loss: 0.011343

run [1150]:
Style Loss : 0.500668 Content Loss: 0.011495

run [1200]:
Style Loss : 0.496125 Content Loss: 0.011609

run [1250]:
Style Loss : 0.491776 Content Loss: 0.011730

run [1300]:
Style Loss : 0.488032 Content Loss: 0.011798

run [1350]:
Style Loss : 0.484851 Content Loss: 0.011882

run [1400]:
Style Loss : 0.481389 Content Loss: 0.011976

run [1450]:
Style Loss : 0.478114 Content Loss: 0.012066

run [1500]:
Style Loss : 0.475138 Content Loss: 0.012132

run [1550]:
Style Loss : 0.472559 Content Loss: 0.012203

run [1600]:
Style Loss : 0.470038 Content Loss: 0.012271

run [1650]:
Style Loss : 0.467813 Content Loss: 0.012328

run [1700]:
Style Loss : 0.465501 Content Loss: 0.012387

run [1750]:
Style Loss : 0.463487 Content Loss: 0.012429

run [1800]:
Style Loss : 0.461594 Content Loss: 0.012479

run [1850]:
Style Loss : 0.459389 Content Loss: 0.012537

run [1900]:
Style Loss : 0.457350 Content Loss: 0.012580

run [1950]:
Style Loss : 0.455538 Content Loss: 0.012618

run [2000]:
Style Loss : 0.453896 Content Loss: 0.012662

run [2050]:
Style Loss : 0.452299 Content Loss: 0.012694

run [2100]:
Style Loss : 0.450876 Content Loss: 0.012735

run [2150]:
Style Loss : 0.449476 Content Loss: 0.012777

run [2200]:
Style Loss : 0.448659 Content Loss: 0.012855

run [2250]:
Style Loss : 0.447114 Content Loss: 0.012850

run [2300]:
Style Loss : 0.445862 Content Loss: 0.012885

run [2350]:
Style Loss : 0.444808 Content Loss: 0.012919

run [2400]:
Style Loss : 0.443680 Content Loss: 0.012958

run [2450]:
Style Loss : 0.442590 Content Loss: 0.013001

run [2500]:
Style Loss : 0.441515 Content Loss: 0.013024

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.617942 Content Loss: 0.005090

run [100]:
Style Loss : 2.220698 Content Loss: 0.005184

run [150]:
Style Loss : 1.723878 Content Loss: 0.005951

run [200]:
Style Loss : 1.475018 Content Loss: 0.006727

run [250]:
Style Loss : 1.297649 Content Loss: 0.007519

run [300]:
Style Loss : 1.128703 Content Loss: 0.008404

run [350]:
Style Loss : 1.022031 Content Loss: 0.008875

run [400]:
Style Loss : 0.944906 Content Loss: 0.009464

run [450]:
Style Loss : 0.886954 Content Loss: 0.010001

run [500]:
Style Loss : 0.844715 Content Loss: 0.010500

run [550]:
Style Loss : 0.810852 Content Loss: 0.010906

run [600]:
Style Loss : 0.783513 Content Loss: 0.011281

run [650]:
Style Loss : 0.761875 Content Loss: 0.011619

run [700]:
Style Loss : 0.740674 Content Loss: 0.011980

run [750]:
Style Loss : 0.721258 Content Loss: 0.012289

run [800]:
Style Loss : 0.704998 Content Loss: 0.012566

run [850]:
Style Loss : 0.690853 Content Loss: 0.012799

run [900]:
Style Loss : 0.679096 Content Loss: 0.012984

run [950]:
Style Loss : 0.668735 Content Loss: 0.013174

run [1000]:
Style Loss : 0.659290 Content Loss: 0.013290

run [1050]:
Style Loss : 0.651588 Content Loss: 0.013459

run [1100]:
Style Loss : 0.644461 Content Loss: 0.013620

run [1150]:
Style Loss : 0.637666 Content Loss: 0.013737

run [1200]:
Style Loss : 0.631737 Content Loss: 0.013887

run [1250]:
Style Loss : 0.626400 Content Loss: 0.014014

run [1300]:
Style Loss : 0.621271 Content Loss: 0.014137

run [1350]:
Style Loss : 0.616631 Content Loss: 0.014237

run [1400]:
Style Loss : 0.611674 Content Loss: 0.014357

run [1450]:
Style Loss : 0.607086 Content Loss: 0.014443

run [1500]:
Style Loss : 0.603230 Content Loss: 0.014522

run [1550]:
Style Loss : 0.599485 Content Loss: 0.014617

run [1600]:
Style Loss : 0.596114 Content Loss: 0.014701

run [1650]:
Style Loss : 0.593040 Content Loss: 0.014771

run [1700]:
Style Loss : 0.590098 Content Loss: 0.014857

run [1750]:
Style Loss : 0.587539 Content Loss: 0.014926

run [1800]:
Style Loss : 0.585060 Content Loss: 0.014997

run [1850]:
Style Loss : 0.582658 Content Loss: 0.015059

run [1900]:
Style Loss : 0.580576 Content Loss: 0.015141

run [1950]:
Style Loss : 0.578549 Content Loss: 0.015187

run [2000]:
Style Loss : 0.576682 Content Loss: 0.015246

run [2050]:
Style Loss : 0.574939 Content Loss: 0.015304

run [2100]:
Style Loss : 0.572986 Content Loss: 0.015342

run [2150]:
Style Loss : 0.571246 Content Loss: 0.015393

run [2200]:
Style Loss : 0.569574 Content Loss: 0.015440

run [2250]:
Style Loss : 0.567841 Content Loss: 0.015481

run [2300]:
Style Loss : 0.566435 Content Loss: 0.015528

run [2350]:
Style Loss : 0.564880 Content Loss: 0.015553

run [2400]:
Style Loss : 0.563606 Content Loss: 0.015602

run [2450]:
Style Loss : 0.562415 Content Loss: 0.015653

run [2500]:
Style Loss : 0.561239 Content Loss: 0.015679

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.581053 Content Loss: 0.002808

run [100]:
Style Loss : 1.389680 Content Loss: 0.003484

run [150]:
Style Loss : 1.000733 Content Loss: 0.004494

run [200]:
Style Loss : 0.783333 Content Loss: 0.005346

run [250]:
Style Loss : 0.647575 Content Loss: 0.006144

run [300]:
Style Loss : 0.552335 Content Loss: 0.006801

run [350]:
Style Loss : 0.486025 Content Loss: 0.007478

run [400]:
Style Loss : 0.430983 Content Loss: 0.008324

run [450]:
Style Loss : 0.388921 Content Loss: 0.008949

run [500]:
Style Loss : 0.354789 Content Loss: 0.009553

run [550]:
Style Loss : 0.331316 Content Loss: 0.010031

run [600]:
Style Loss : 0.314231 Content Loss: 0.010462

run [650]:
Style Loss : 0.302231 Content Loss: 0.010839

run [700]:
Style Loss : 0.290845 Content Loss: 0.011204

run [750]:
Style Loss : 0.281609 Content Loss: 0.011476

run [800]:
Style Loss : 0.274491 Content Loss: 0.011693

run [850]:
Style Loss : 0.268761 Content Loss: 0.011861

run [900]:
Style Loss : 0.263441 Content Loss: 0.012058

run [950]:
Style Loss : 0.258263 Content Loss: 0.012182

run [1000]:
Style Loss : 0.253841 Content Loss: 0.012299

run [1050]:
Style Loss : 0.250217 Content Loss: 0.012359

run [1100]:
Style Loss : 0.247024 Content Loss: 0.012423

run [1150]:
Style Loss : 0.244084 Content Loss: 0.012502

run [1200]:
Style Loss : 0.241462 Content Loss: 0.012535

run [1250]:
Style Loss : 0.239036 Content Loss: 0.012587

run [1300]:
Style Loss : 0.237027 Content Loss: 0.012599

run [1350]:
Style Loss : 0.235220 Content Loss: 0.012637

run [1400]:
Style Loss : 0.233602 Content Loss: 0.012653

run [1450]:
Style Loss : 0.232089 Content Loss: 0.012686

run [1500]:
Style Loss : 0.230685 Content Loss: 0.012705

run [1550]:
Style Loss : 0.229255 Content Loss: 0.012726

run [1600]:
Style Loss : 0.227846 Content Loss: 0.012754

run [1650]:
Style Loss : 0.226437 Content Loss: 0.012775

run [1700]:
Style Loss : 0.224945 Content Loss: 0.012795

run [1750]:
Style Loss : 0.223456 Content Loss: 0.012813

run [1800]:
Style Loss : 0.222084 Content Loss: 0.012837

run [1850]:
Style Loss : 0.220830 Content Loss: 0.012852

run [1900]:
Style Loss : 0.219518 Content Loss: 0.012874

run [1950]:
Style Loss : 0.218304 Content Loss: 0.012899

run [2000]:
Style Loss : 0.217256 Content Loss: 0.012922

run [2050]:
Style Loss : 0.216160 Content Loss: 0.012947

run [2100]:
Style Loss : 0.215110 Content Loss: 0.012963

run [2150]:
Style Loss : 0.214149 Content Loss: 0.012978

run [2200]:
Style Loss : 0.213453 Content Loss: 0.013001

run [2250]:
Style Loss : 0.212081 Content Loss: 0.013014

run [2300]:
Style Loss : 0.211175 Content Loss: 0.013033

run [2350]:
Style Loss : 0.210297 Content Loss: 0.013053

run [2400]:
Style Loss : 0.209483 Content Loss: 0.013067

run [2450]:
Style Loss : 0.208717 Content Loss: 0.013088

run [2500]:
Style Loss : 0.208475 Content Loss: 0.013112

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.084100 Content Loss: 0.002700

run [100]:
Style Loss : 1.182687 Content Loss: 0.004181

run [150]:
Style Loss : 0.881941 Content Loss: 0.005297

run [200]:
Style Loss : 0.719480 Content Loss: 0.006348

run [250]:
Style Loss : 0.624217 Content Loss: 0.007195

run [300]:
Style Loss : 0.568580 Content Loss: 0.007910

run [350]:
Style Loss : 0.529806 Content Loss: 0.008557

run [400]:
Style Loss : 0.502984 Content Loss: 0.009097

run [450]:
Style Loss : 0.482615 Content Loss: 0.009663

run [500]:
Style Loss : 0.465352 Content Loss: 0.010138

run [550]:
Style Loss : 0.450661 Content Loss: 0.010530

run [600]:
Style Loss : 0.438407 Content Loss: 0.010866

run [650]:
Style Loss : 0.428667 Content Loss: 0.011218

run [700]:
Style Loss : 0.420192 Content Loss: 0.011506

run [750]:
Style Loss : 0.412660 Content Loss: 0.011839

run [800]:
Style Loss : 0.405819 Content Loss: 0.012115

run [850]:
Style Loss : 0.399571 Content Loss: 0.012389

run [900]:
Style Loss : 0.394022 Content Loss: 0.012605

run [950]:
Style Loss : 0.388829 Content Loss: 0.012810

run [1000]:
Style Loss : 0.384712 Content Loss: 0.012971

run [1050]:
Style Loss : 0.381052 Content Loss: 0.013131

run [1100]:
Style Loss : 0.378003 Content Loss: 0.013284

run [1150]:
Style Loss : 0.374948 Content Loss: 0.013413

run [1200]:
Style Loss : 0.372142 Content Loss: 0.013547

run [1250]:
Style Loss : 0.369675 Content Loss: 0.013650

run [1300]:
Style Loss : 0.367222 Content Loss: 0.013759

run [1350]:
Style Loss : 0.365094 Content Loss: 0.013866

run [1400]:
Style Loss : 0.362991 Content Loss: 0.013948

run [1450]:
Style Loss : 0.361125 Content Loss: 0.014033

run [1500]:
Style Loss : 0.359374 Content Loss: 0.014128

run [1550]:
Style Loss : 0.357574 Content Loss: 0.014209

run [1600]:
Style Loss : 0.355666 Content Loss: 0.014311

run [1650]:
Style Loss : 0.353716 Content Loss: 0.014394

run [1700]:
Style Loss : 0.351933 Content Loss: 0.014477

run [1750]:
Style Loss : 0.350314 Content Loss: 0.014531

run [1800]:
Style Loss : 0.348562 Content Loss: 0.014605

run [1850]:
Style Loss : 0.347038 Content Loss: 0.014670

run [1900]:
Style Loss : 0.345511 Content Loss: 0.014742

run [1950]:
Style Loss : 0.344018 Content Loss: 0.014829

run [2000]:
Style Loss : 0.342734 Content Loss: 0.014894

run [2050]:
Style Loss : 0.341585 Content Loss: 0.014964

run [2100]:
Style Loss : 0.340538 Content Loss: 0.015022

run [2150]:
Style Loss : 0.339503 Content Loss: 0.015083

run [2200]:
Style Loss : 0.338568 Content Loss: 0.015152

run [2250]:
Style Loss : 0.337605 Content Loss: 0.015217

run [2300]:
Style Loss : 0.336737 Content Loss: 0.015276

run [2350]:
Style Loss : 0.335772 Content Loss: 0.015349

run [2400]:
Style Loss : 0.334732 Content Loss: 0.015411

run [2450]:
Style Loss : 0.333781 Content Loss: 0.015476

run [2500]:
Style Loss : 0.332895 Content Loss: 0.015552

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.487804 Content Loss: 0.001883

run [100]:
Style Loss : 0.835936 Content Loss: 0.003012

run [150]:
Style Loss : 0.592019 Content Loss: 0.003843

run [200]:
Style Loss : 0.485829 Content Loss: 0.004427

run [250]:
Style Loss : 0.434184 Content Loss: 0.004886

run [300]:
Style Loss : 0.403152 Content Loss: 0.005296

run [350]:
Style Loss : 0.382046 Content Loss: 0.005630

run [400]:
Style Loss : 0.363964 Content Loss: 0.005888

run [450]:
Style Loss : 0.347500 Content Loss: 0.006133

run [500]:
Style Loss : 0.334740 Content Loss: 0.006332

run [550]:
Style Loss : 0.324304 Content Loss: 0.006543

run [600]:
Style Loss : 0.315665 Content Loss: 0.006708

run [650]:
Style Loss : 0.307239 Content Loss: 0.006873

run [700]:
Style Loss : 0.299865 Content Loss: 0.007026

run [750]:
Style Loss : 0.293666 Content Loss: 0.007166

run [800]:
Style Loss : 0.288286 Content Loss: 0.007291

run [850]:
Style Loss : 0.283544 Content Loss: 0.007399

run [900]:
Style Loss : 0.279344 Content Loss: 0.007524

run [950]:
Style Loss : 0.275895 Content Loss: 0.007623

run [1000]:
Style Loss : 0.272744 Content Loss: 0.007726

run [1050]:
Style Loss : 0.269448 Content Loss: 0.007838

run [1100]:
Style Loss : 0.266766 Content Loss: 0.007918

run [1150]:
Style Loss : 0.264024 Content Loss: 0.008023

run [1200]:
Style Loss : 0.261528 Content Loss: 0.008104

run [1250]:
Style Loss : 0.258568 Content Loss: 0.008201

run [1300]:
Style Loss : 0.256243 Content Loss: 0.008266

run [1350]:
Style Loss : 0.254114 Content Loss: 0.008347

run [1400]:
Style Loss : 0.252352 Content Loss: 0.008410

run [1450]:
Style Loss : 0.250730 Content Loss: 0.008478

run [1500]:
Style Loss : 0.249240 Content Loss: 0.008545

run [1550]:
Style Loss : 0.247786 Content Loss: 0.008608

run [1600]:
Style Loss : 0.246422 Content Loss: 0.008680

run [1650]:
Style Loss : 0.245058 Content Loss: 0.008754

run [1700]:
Style Loss : 0.243754 Content Loss: 0.008817

run [1750]:
Style Loss : 0.242433 Content Loss: 0.008878

run [1800]:
Style Loss : 0.241227 Content Loss: 0.008944

run [1850]:
Style Loss : 0.240138 Content Loss: 0.009002

run [1900]:
Style Loss : 0.239154 Content Loss: 0.009059

run [1950]:
Style Loss : 0.238154 Content Loss: 0.009127

run [2000]:
Style Loss : 0.237239 Content Loss: 0.009190

run [2050]:
Style Loss : 0.236271 Content Loss: 0.009246

run [2100]:
Style Loss : 0.235324 Content Loss: 0.009310

run [2150]:
Style Loss : 0.234408 Content Loss: 0.009367

run [2200]:
Style Loss : 0.233492 Content Loss: 0.009436

run [2250]:
Style Loss : 0.232619 Content Loss: 0.009490

run [2300]:
Style Loss : 0.231812 Content Loss: 0.009535

run [2350]:
Style Loss : 0.231072 Content Loss: 0.009587

run [2400]:
Style Loss : 0.230331 Content Loss: 0.009642

run [2450]:
Style Loss : 0.229626 Content Loss: 0.009695

run [2500]:
Style Loss : 0.228924 Content Loss: 0.009759

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.849943 Content Loss: 0.002688

run [100]:
Style Loss : 0.437382 Content Loss: 0.004804

run [150]:
Style Loss : 0.326111 Content Loss: 0.006478

run [200]:
Style Loss : 0.268204 Content Loss: 0.007706

run [250]:
Style Loss : 0.235801 Content Loss: 0.008878

run [300]:
Style Loss : 0.213038 Content Loss: 0.009850

run [350]:
Style Loss : 0.196931 Content Loss: 0.010616

run [400]:
Style Loss : 0.183231 Content Loss: 0.011175

run [450]:
Style Loss : 0.173143 Content Loss: 0.011657

run [500]:
Style Loss : 0.165182 Content Loss: 0.011967

run [550]:
Style Loss : 0.158644 Content Loss: 0.012338

run [600]:
Style Loss : 0.152980 Content Loss: 0.012621

run [650]:
Style Loss : 0.148221 Content Loss: 0.012891

run [700]:
Style Loss : 0.144170 Content Loss: 0.013140

run [750]:
Style Loss : 0.140446 Content Loss: 0.013370

run [800]:
Style Loss : 0.137421 Content Loss: 0.013561

run [850]:
Style Loss : 0.134932 Content Loss: 0.013769

run [900]:
Style Loss : 0.132635 Content Loss: 0.013969

run [950]:
Style Loss : 0.130459 Content Loss: 0.014176

run [1000]:
Style Loss : 0.128414 Content Loss: 0.014364

run [1050]:
Style Loss : 0.126898 Content Loss: 0.014630

run [1100]:
Style Loss : 0.124847 Content Loss: 0.014798

run [1150]:
Style Loss : 0.123312 Content Loss: 0.014976

run [1200]:
Style Loss : 0.121970 Content Loss: 0.015179

run [1250]:
Style Loss : 0.120668 Content Loss: 0.015352

run [1300]:
Style Loss : 0.118676 Content Loss: 0.015513

run [1350]:
Style Loss : 0.117836 Content Loss: 0.015726

run [1400]:
Style Loss : 0.130851 Content Loss: 0.015784

run [1450]:
Style Loss : 0.115061 Content Loss: 0.016020

run [1500]:
Style Loss : 0.114239 Content Loss: 0.016199

run [1550]:
Style Loss : 0.115368 Content Loss: 0.016530

run [1600]:
Style Loss : 0.112661 Content Loss: 0.016655

run [1650]:
Style Loss : 0.111429 Content Loss: 0.016784

run [1700]:
Style Loss : 0.124970 Content Loss: 0.017711

run [1750]:
Style Loss : 0.111273 Content Loss: 0.017441

run [1800]:
Style Loss : 0.108810 Content Loss: 0.017443

run [1850]:
Style Loss : 0.108822 Content Loss: 0.017560

run [1900]:
Style Loss : 0.109076 Content Loss: 0.017579

run [1950]:
Style Loss : 0.111031 Content Loss: 0.017910

run [2000]:
Style Loss : 0.105319 Content Loss: 0.017810

run [2050]:
Style Loss : 0.105362 Content Loss: 0.017903

run [2100]:
Style Loss : 0.156939 Content Loss: 0.018049

run [2150]:
Style Loss : 0.102932 Content Loss: 0.017955

run [2200]:
Style Loss : 0.116471 Content Loss: 0.018114

run [2250]:
Style Loss : 0.101578 Content Loss: 0.017993

run [2300]:
Style Loss : 0.101111 Content Loss: 0.018016

run [2350]:
Style Loss : 0.100830 Content Loss: 0.018034

run [2400]:
Style Loss : 0.104982 Content Loss: 0.018016

run [2450]:
Style Loss : 0.099574 Content Loss: 0.017999

run [2500]:
Style Loss : 0.110363 Content Loss: 0.018203

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.185108 Content Loss: 0.001779

run [100]:
Style Loss : 0.583618 Content Loss: 0.002948

run [150]:
Style Loss : 0.429755 Content Loss: 0.003762

run [200]:
Style Loss : 0.367924 Content Loss: 0.004342

run [250]:
Style Loss : 0.329308 Content Loss: 0.004805

run [300]:
Style Loss : 0.301101 Content Loss: 0.005201

run [350]:
Style Loss : 0.280357 Content Loss: 0.005570

run [400]:
Style Loss : 0.263603 Content Loss: 0.005838

run [450]:
Style Loss : 0.246659 Content Loss: 0.006088

run [500]:
Style Loss : 0.236226 Content Loss: 0.006326

run [550]:
Style Loss : 0.228305 Content Loss: 0.006529

run [600]:
Style Loss : 0.221117 Content Loss: 0.006747

run [650]:
Style Loss : 0.214702 Content Loss: 0.006961

run [700]:
Style Loss : 0.209216 Content Loss: 0.007163

run [750]:
Style Loss : 0.203883 Content Loss: 0.007344

run [800]:
Style Loss : 0.199163 Content Loss: 0.007535

run [850]:
Style Loss : 0.194692 Content Loss: 0.007688

run [900]:
Style Loss : 0.190768 Content Loss: 0.007830

run [950]:
Style Loss : 0.187242 Content Loss: 0.007985

run [1000]:
Style Loss : 0.183810 Content Loss: 0.008132

run [1050]:
Style Loss : 0.179996 Content Loss: 0.008273

run [1100]:
Style Loss : 0.176956 Content Loss: 0.008395

run [1150]:
Style Loss : 0.174343 Content Loss: 0.008505

run [1200]:
Style Loss : 0.172085 Content Loss: 0.008619

run [1250]:
Style Loss : 0.170145 Content Loss: 0.008704

run [1300]:
Style Loss : 0.168415 Content Loss: 0.008792

run [1350]:
Style Loss : 0.166851 Content Loss: 0.008879

run [1400]:
Style Loss : 0.165396 Content Loss: 0.008951

run [1450]:
Style Loss : 0.164029 Content Loss: 0.009030

run [1500]:
Style Loss : 0.162685 Content Loss: 0.009111

run [1550]:
Style Loss : 0.161379 Content Loss: 0.009203

run [1600]:
Style Loss : 0.160114 Content Loss: 0.009276

run [1650]:
Style Loss : 0.158998 Content Loss: 0.009357

run [1700]:
Style Loss : 0.157999 Content Loss: 0.009430

run [1750]:
Style Loss : 0.157016 Content Loss: 0.009493

run [1800]:
Style Loss : 0.156162 Content Loss: 0.009562

run [1850]:
Style Loss : 0.155346 Content Loss: 0.009626

run [1900]:
Style Loss : 0.154529 Content Loss: 0.009699

run [1950]:
Style Loss : 0.153671 Content Loss: 0.009753

run [2000]:
Style Loss : 0.152873 Content Loss: 0.009817

run [2050]:
Style Loss : 0.152092 Content Loss: 0.009884

run [2100]:
Style Loss : 0.151370 Content Loss: 0.009937

run [2150]:
Style Loss : 0.150647 Content Loss: 0.009998

run [2200]:
Style Loss : 0.149925 Content Loss: 0.010058

run [2250]:
Style Loss : 0.149121 Content Loss: 0.010127

run [2300]:
Style Loss : 0.148440 Content Loss: 0.010184

run [2350]:
Style Loss : 0.147736 Content Loss: 0.010263

run [2400]:
Style Loss : 0.147033 Content Loss: 0.010330

run [2450]:
Style Loss : 0.146329 Content Loss: 0.010398

run [2500]:
Style Loss : 0.145700 Content Loss: 0.010454

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.456829 Content Loss: 0.001559

run [100]:
Style Loss : 1.413610 Content Loss: 0.002116

run [150]:
Style Loss : 1.022825 Content Loss: 0.002888

run [200]:
Style Loss : 0.829137 Content Loss: 0.003522

run [250]:
Style Loss : 0.713805 Content Loss: 0.004140

run [300]:
Style Loss : 0.638857 Content Loss: 0.004662

run [350]:
Style Loss : 0.591506 Content Loss: 0.005102

run [400]:
Style Loss : 0.552933 Content Loss: 0.005526

run [450]:
Style Loss : 0.521558 Content Loss: 0.005833

run [500]:
Style Loss : 0.498055 Content Loss: 0.006099

run [550]:
Style Loss : 0.479328 Content Loss: 0.006327

run [600]:
Style Loss : 0.463253 Content Loss: 0.006535

run [650]:
Style Loss : 0.450414 Content Loss: 0.006742

run [700]:
Style Loss : 0.438615 Content Loss: 0.006934

run [750]:
Style Loss : 0.428397 Content Loss: 0.007089

run [800]:
Style Loss : 0.419157 Content Loss: 0.007224

run [850]:
Style Loss : 0.410764 Content Loss: 0.007371

run [900]:
Style Loss : 0.403445 Content Loss: 0.007483

run [950]:
Style Loss : 0.396607 Content Loss: 0.007635

run [1000]:
Style Loss : 0.390095 Content Loss: 0.007770

run [1050]:
Style Loss : 0.384195 Content Loss: 0.007872

run [1100]:
Style Loss : 0.378953 Content Loss: 0.007984

run [1150]:
Style Loss : 0.374452 Content Loss: 0.008094

run [1200]:
Style Loss : 0.369979 Content Loss: 0.008192

run [1250]:
Style Loss : 0.366023 Content Loss: 0.008298

run [1300]:
Style Loss : 0.362534 Content Loss: 0.008380

run [1350]:
Style Loss : 0.359223 Content Loss: 0.008462

run [1400]:
Style Loss : 0.356115 Content Loss: 0.008546

run [1450]:
Style Loss : 0.353059 Content Loss: 0.008611

run [1500]:
Style Loss : 0.350095 Content Loss: 0.008698

run [1550]:
Style Loss : 0.347411 Content Loss: 0.008781

run [1600]:
Style Loss : 0.344841 Content Loss: 0.008863

run [1650]:
Style Loss : 0.342544 Content Loss: 0.008910

run [1700]:
Style Loss : 0.340437 Content Loss: 0.008979

run [1750]:
Style Loss : 0.338278 Content Loss: 0.009038

run [1800]:
Style Loss : 0.336523 Content Loss: 0.009094

run [1850]:
Style Loss : 0.334789 Content Loss: 0.009152

run [1900]:
Style Loss : 0.333341 Content Loss: 0.009205

run [1950]:
Style Loss : 0.332430 Content Loss: 0.009279

run [2000]:
Style Loss : 0.331068 Content Loss: 0.009328

run [2050]:
Style Loss : 0.357013 Content Loss: 0.009582

run [2100]:
Style Loss : 0.329827 Content Loss: 0.009489

run [2150]:
Style Loss : 0.327049 Content Loss: 0.009468

run [2200]:
Style Loss : 0.325680 Content Loss: 0.009474

run [2250]:
Style Loss : 0.325419 Content Loss: 0.009513

run [2300]:
Style Loss : 0.324981 Content Loss: 0.009553

run [2350]:
Style Loss : 0.813809 Content Loss: 0.009541

run [2400]:
Style Loss : 0.322352 Content Loss: 0.009648

run [2450]:
Style Loss : 0.320472 Content Loss: 0.009642

run [2500]:
Style Loss : 0.319705 Content Loss: 0.009658

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.694503 Content Loss: 0.002182

run [100]:
Style Loss : 0.363141 Content Loss: 0.004215

run [150]:
Style Loss : 0.256844 Content Loss: 0.005514

run [200]:
Style Loss : 0.207250 Content Loss: 0.006311

run [250]:
Style Loss : 0.177308 Content Loss: 0.006946

run [300]:
Style Loss : 0.159081 Content Loss: 0.007481

run [350]:
Style Loss : 0.146154 Content Loss: 0.007927

run [400]:
Style Loss : 0.137451 Content Loss: 0.008234

run [450]:
Style Loss : 0.130408 Content Loss: 0.008528

run [500]:
Style Loss : 0.124919 Content Loss: 0.008761

run [550]:
Style Loss : 0.120659 Content Loss: 0.008985

run [600]:
Style Loss : 0.117284 Content Loss: 0.009167

run [650]:
Style Loss : 0.114073 Content Loss: 0.009330

run [700]:
Style Loss : 0.110982 Content Loss: 0.009493

run [750]:
Style Loss : 0.108388 Content Loss: 0.009615

run [800]:
Style Loss : 0.106032 Content Loss: 0.009748

run [850]:
Style Loss : 0.104051 Content Loss: 0.009842

run [900]:
Style Loss : 0.102244 Content Loss: 0.009952

run [950]:
Style Loss : 0.100742 Content Loss: 0.010017

run [1000]:
Style Loss : 0.099545 Content Loss: 0.010080

run [1050]:
Style Loss : 0.098469 Content Loss: 0.010139

run [1100]:
Style Loss : 0.097468 Content Loss: 0.010206

run [1150]:
Style Loss : 0.096510 Content Loss: 0.010274

run [1200]:
Style Loss : 0.095637 Content Loss: 0.010345

run [1250]:
Style Loss : 0.094734 Content Loss: 0.010405

run [1300]:
Style Loss : 0.093882 Content Loss: 0.010489

run [1350]:
Style Loss : 0.093090 Content Loss: 0.010557

run [1400]:
Style Loss : 0.092385 Content Loss: 0.010616

run [1450]:
Style Loss : 0.091757 Content Loss: 0.010668

run [1500]:
Style Loss : 0.091118 Content Loss: 0.010724

run [1550]:
Style Loss : 0.090471 Content Loss: 0.010777

run [1600]:
Style Loss : 0.089925 Content Loss: 0.010828

run [1650]:
Style Loss : 0.089438 Content Loss: 0.010865

run [1700]:
Style Loss : 0.088968 Content Loss: 0.010904

run [1750]:
Style Loss : 0.088494 Content Loss: 0.010934

run [1800]:
Style Loss : 0.088073 Content Loss: 0.010976

run [1850]:
Style Loss : 0.087666 Content Loss: 0.011003

run [1900]:
Style Loss : 0.087316 Content Loss: 0.011022

run [1950]:
Style Loss : 0.087023 Content Loss: 0.011040

run [2000]:
Style Loss : 0.086734 Content Loss: 0.011059

run [2050]:
Style Loss : 0.086475 Content Loss: 0.011078

run [2100]:
Style Loss : 0.086197 Content Loss: 0.011097

run [2150]:
Style Loss : 0.085915 Content Loss: 0.011115

run [2200]:
Style Loss : 0.085649 Content Loss: 0.011136

run [2250]:
Style Loss : 0.085381 Content Loss: 0.011161

run [2300]:
Style Loss : 0.085136 Content Loss: 0.011195

run [2350]:
Style Loss : 0.084884 Content Loss: 0.011210

run [2400]:
Style Loss : 0.084626 Content Loss: 0.011239

run [2450]:
Style Loss : 0.084376 Content Loss: 0.011263

run [2500]:
Style Loss : 0.084044 Content Loss: 0.011276

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.910583 Content Loss: 0.001778

run [100]:
Style Loss : 1.232747 Content Loss: 0.003009

run [150]:
Style Loss : 0.951109 Content Loss: 0.004246

run [200]:
Style Loss : 0.784100 Content Loss: 0.005353

run [250]:
Style Loss : 0.674616 Content Loss: 0.006227

run [300]:
Style Loss : 0.601646 Content Loss: 0.006992

run [350]:
Style Loss : 0.549404 Content Loss: 0.007707

run [400]:
Style Loss : 0.508127 Content Loss: 0.008454

run [450]:
Style Loss : 0.479439 Content Loss: 0.009054

run [500]:
Style Loss : 0.456855 Content Loss: 0.009659

run [550]:
Style Loss : 0.440380 Content Loss: 0.010162

run [600]:
Style Loss : 0.426949 Content Loss: 0.010610

run [650]:
Style Loss : 0.415595 Content Loss: 0.010961

run [700]:
Style Loss : 0.406205 Content Loss: 0.011291

run [750]:
Style Loss : 0.398439 Content Loss: 0.011533

run [800]:
Style Loss : 0.391341 Content Loss: 0.011742

run [850]:
Style Loss : 0.385085 Content Loss: 0.011943

run [900]:
Style Loss : 0.379382 Content Loss: 0.012111

run [950]:
Style Loss : 0.374195 Content Loss: 0.012267

run [1000]:
Style Loss : 0.369353 Content Loss: 0.012416

run [1050]:
Style Loss : 0.364521 Content Loss: 0.012523

run [1100]:
Style Loss : 0.360263 Content Loss: 0.012631

run [1150]:
Style Loss : 0.356785 Content Loss: 0.012718

run [1200]:
Style Loss : 0.353622 Content Loss: 0.012805

run [1250]:
Style Loss : 0.350829 Content Loss: 0.012873

run [1300]:
Style Loss : 0.348470 Content Loss: 0.012930

run [1350]:
Style Loss : 0.346332 Content Loss: 0.012986

run [1400]:
Style Loss : 0.344395 Content Loss: 0.013038

run [1450]:
Style Loss : 0.342562 Content Loss: 0.013094

run [1500]:
Style Loss : 0.340770 Content Loss: 0.013152

run [1550]:
Style Loss : 0.338984 Content Loss: 0.013195

run [1600]:
Style Loss : 0.337258 Content Loss: 0.013242

run [1650]:
Style Loss : 0.335614 Content Loss: 0.013286

run [1700]:
Style Loss : 0.334178 Content Loss: 0.013330

run [1750]:
Style Loss : 0.332961 Content Loss: 0.013370

run [1800]:
Style Loss : 0.331855 Content Loss: 0.013406

run [1850]:
Style Loss : 0.330693 Content Loss: 0.013448

run [1900]:
Style Loss : 0.329645 Content Loss: 0.013489

run [1950]:
Style Loss : 0.328646 Content Loss: 0.013530

run [2000]:
Style Loss : 0.327656 Content Loss: 0.013567

run [2050]:
Style Loss : 0.326756 Content Loss: 0.013601

run [2100]:
Style Loss : 0.325850 Content Loss: 0.013634

run [2150]:
Style Loss : 0.325024 Content Loss: 0.013666

run [2200]:
Style Loss : 0.324200 Content Loss: 0.013696

run [2250]:
Style Loss : 0.323420 Content Loss: 0.013726

run [2300]:
Style Loss : 0.322646 Content Loss: 0.013758

run [2350]:
Style Loss : 0.321885 Content Loss: 0.013788

run [2400]:
Style Loss : 0.321102 Content Loss: 0.013814

run [2450]:
Style Loss : 0.320421 Content Loss: 0.013845

run [2500]:
Style Loss : 0.319760 Content Loss: 0.013873

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.364417 Content Loss: 0.001805

run [100]:
Style Loss : 0.857081 Content Loss: 0.002868

run [150]:
Style Loss : 0.661010 Content Loss: 0.004165

run [200]:
Style Loss : 0.549688 Content Loss: 0.005245

run [250]:
Style Loss : 0.484076 Content Loss: 0.006069

run [300]:
Style Loss : 0.438407 Content Loss: 0.006825

run [350]:
Style Loss : 0.400518 Content Loss: 0.007520

run [400]:
Style Loss : 0.372846 Content Loss: 0.008095

run [450]:
Style Loss : 0.352604 Content Loss: 0.008547

run [500]:
Style Loss : 0.335981 Content Loss: 0.008999

run [550]:
Style Loss : 0.322097 Content Loss: 0.009406

run [600]:
Style Loss : 0.310707 Content Loss: 0.009773

run [650]:
Style Loss : 0.300721 Content Loss: 0.010120

run [700]:
Style Loss : 0.292397 Content Loss: 0.010402

run [750]:
Style Loss : 0.285211 Content Loss: 0.010692

run [800]:
Style Loss : 0.278519 Content Loss: 0.010966

run [850]:
Style Loss : 0.272351 Content Loss: 0.011225

run [900]:
Style Loss : 0.266370 Content Loss: 0.011470

run [950]:
Style Loss : 0.260523 Content Loss: 0.011693

run [1000]:
Style Loss : 0.255107 Content Loss: 0.011895

run [1050]:
Style Loss : 0.250040 Content Loss: 0.012092

run [1100]:
Style Loss : 0.245470 Content Loss: 0.012272

run [1150]:
Style Loss : 0.241246 Content Loss: 0.012450

run [1200]:
Style Loss : 0.237247 Content Loss: 0.012624

run [1250]:
Style Loss : 0.233892 Content Loss: 0.012781

run [1300]:
Style Loss : 0.230641 Content Loss: 0.012972

run [1350]:
Style Loss : 0.227663 Content Loss: 0.013137

run [1400]:
Style Loss : 0.224861 Content Loss: 0.013307

run [1450]:
Style Loss : 0.222139 Content Loss: 0.013474

run [1500]:
Style Loss : 0.219547 Content Loss: 0.013647

run [1550]:
Style Loss : 0.217040 Content Loss: 0.013817

run [1600]:
Style Loss : 0.214596 Content Loss: 0.013998

run [1650]:
Style Loss : 0.212184 Content Loss: 0.014188

run [1700]:
Style Loss : 0.209901 Content Loss: 0.014366

run [1750]:
Style Loss : 0.207690 Content Loss: 0.014537

run [1800]:
Style Loss : 0.205648 Content Loss: 0.014720

run [1850]:
Style Loss : 0.203679 Content Loss: 0.014906

run [1900]:
Style Loss : 0.201767 Content Loss: 0.015076

run [1950]:
Style Loss : 0.200065 Content Loss: 0.015240

run [2000]:
Style Loss : 0.198480 Content Loss: 0.015407

run [2050]:
Style Loss : 0.197020 Content Loss: 0.015575

run [2100]:
Style Loss : 0.195655 Content Loss: 0.015734

run [2150]:
Style Loss : 0.194348 Content Loss: 0.015884

run [2200]:
Style Loss : 0.193095 Content Loss: 0.016014

run [2250]:
Style Loss : 0.191874 Content Loss: 0.016154

run [2300]:
Style Loss : 0.190748 Content Loss: 0.016281

run [2350]:
Style Loss : 0.189686 Content Loss: 0.016410

run [2400]:
Style Loss : 0.188740 Content Loss: 0.016518

run [2450]:
Style Loss : 0.187918 Content Loss: 0.016620

run [2500]:
Style Loss : 0.187181 Content Loss: 0.016708

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.231019 Content Loss: 0.001694

run [100]:
Style Loss : 0.668655 Content Loss: 0.003073

run [150]:
Style Loss : 0.476267 Content Loss: 0.004621

run [200]:
Style Loss : 0.381953 Content Loss: 0.005905

run [250]:
Style Loss : 0.329041 Content Loss: 0.006857

run [300]:
Style Loss : 0.291481 Content Loss: 0.007730

run [350]:
Style Loss : 0.264647 Content Loss: 0.008596

run [400]:
Style Loss : 0.242888 Content Loss: 0.009311

run [450]:
Style Loss : 0.224086 Content Loss: 0.009923

run [500]:
Style Loss : 0.208966 Content Loss: 0.010424

run [550]:
Style Loss : 0.197065 Content Loss: 0.010835

run [600]:
Style Loss : 0.187102 Content Loss: 0.011152

run [650]:
Style Loss : 0.179649 Content Loss: 0.011400

run [700]:
Style Loss : 0.173980 Content Loss: 0.011581

run [750]:
Style Loss : 0.169747 Content Loss: 0.011721

run [800]:
Style Loss : 0.166182 Content Loss: 0.011842

run [850]:
Style Loss : 0.162395 Content Loss: 0.011954

run [900]:
Style Loss : 0.159112 Content Loss: 0.012046

run [950]:
Style Loss : 0.156074 Content Loss: 0.012124

run [1000]:
Style Loss : 0.153528 Content Loss: 0.012192

run [1050]:
Style Loss : 0.151397 Content Loss: 0.012240

run [1100]:
Style Loss : 0.149417 Content Loss: 0.012295

run [1150]:
Style Loss : 0.147569 Content Loss: 0.012361

run [1200]:
Style Loss : 0.145830 Content Loss: 0.012417

run [1250]:
Style Loss : 0.144226 Content Loss: 0.012466

run [1300]:
Style Loss : 0.142722 Content Loss: 0.012514

run [1350]:
Style Loss : 0.141329 Content Loss: 0.012563

run [1400]:
Style Loss : 0.140087 Content Loss: 0.012607

run [1450]:
Style Loss : 0.138883 Content Loss: 0.012643

run [1500]:
Style Loss : 0.137838 Content Loss: 0.012684

run [1550]:
Style Loss : 0.136633 Content Loss: 0.012736

run [1600]:
Style Loss : 0.135531 Content Loss: 0.012789

run [1650]:
Style Loss : 0.134265 Content Loss: 0.012836

run [1700]:
Style Loss : 0.133177 Content Loss: 0.012881

run [1750]:
Style Loss : 0.132095 Content Loss: 0.012925

run [1800]:
Style Loss : 0.131174 Content Loss: 0.012966

run [1850]:
Style Loss : 0.130235 Content Loss: 0.013018

run [1900]:
Style Loss : 0.129319 Content Loss: 0.013056

run [1950]:
Style Loss : 0.128539 Content Loss: 0.013100

run [2000]:
Style Loss : 0.127707 Content Loss: 0.013143

run [2050]:
Style Loss : 0.126960 Content Loss: 0.013174

run [2100]:
Style Loss : 0.126288 Content Loss: 0.013207

run [2150]:
Style Loss : 0.125640 Content Loss: 0.013236

run [2200]:
Style Loss : 0.124994 Content Loss: 0.013269

run [2250]:
Style Loss : 0.124391 Content Loss: 0.013302

run [2300]:
Style Loss : 0.123888 Content Loss: 0.013336

run [2350]:
Style Loss : 0.123417 Content Loss: 0.013360

run [2400]:
Style Loss : 0.122984 Content Loss: 0.013385

run [2450]:
Style Loss : 0.122548 Content Loss: 0.013413

run [2500]:
Style Loss : 0.122172 Content Loss: 0.013437

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.007614 Content Loss: 0.002067

run [100]:
Style Loss : 1.180978 Content Loss: 0.003701

run [150]:
Style Loss : 0.886325 Content Loss: 0.005345

run [200]:
Style Loss : 0.731470 Content Loss: 0.006504

run [250]:
Style Loss : 0.624303 Content Loss: 0.007359

run [300]:
Style Loss : 0.555137 Content Loss: 0.007987

run [350]:
Style Loss : 0.510433 Content Loss: 0.008473

run [400]:
Style Loss : 0.472465 Content Loss: 0.008945

run [450]:
Style Loss : 0.444923 Content Loss: 0.009295

run [500]:
Style Loss : 0.421705 Content Loss: 0.009590

run [550]:
Style Loss : 0.403112 Content Loss: 0.009829

run [600]:
Style Loss : 0.387542 Content Loss: 0.010060

run [650]:
Style Loss : 0.375036 Content Loss: 0.010258

run [700]:
Style Loss : 0.365287 Content Loss: 0.010451

run [750]:
Style Loss : 0.356191 Content Loss: 0.010627

run [800]:
Style Loss : 0.348381 Content Loss: 0.010788

run [850]:
Style Loss : 0.341997 Content Loss: 0.010938

run [900]:
Style Loss : 0.336564 Content Loss: 0.011073

run [950]:
Style Loss : 0.331736 Content Loss: 0.011189

run [1000]:
Style Loss : 0.327488 Content Loss: 0.011295

run [1050]:
Style Loss : 0.323709 Content Loss: 0.011392

run [1100]:
Style Loss : 0.320088 Content Loss: 0.011491

run [1150]:
Style Loss : 0.316739 Content Loss: 0.011575

run [1200]:
Style Loss : 0.313409 Content Loss: 0.011654

run [1250]:
Style Loss : 0.310716 Content Loss: 0.011734

run [1300]:
Style Loss : 0.307538 Content Loss: 0.011809

run [1350]:
Style Loss : 0.305050 Content Loss: 0.011866

run [1400]:
Style Loss : 0.302864 Content Loss: 0.011922

run [1450]:
Style Loss : 0.300779 Content Loss: 0.011969

run [1500]:
Style Loss : 0.298947 Content Loss: 0.012008

run [1550]:
Style Loss : 0.297148 Content Loss: 0.012046

run [1600]:
Style Loss : 0.295211 Content Loss: 0.012086

run [1650]:
Style Loss : 0.293433 Content Loss: 0.012130

run [1700]:
Style Loss : 0.291703 Content Loss: 0.012166

run [1750]:
Style Loss : 0.290167 Content Loss: 0.012192

run [1800]:
Style Loss : 0.288825 Content Loss: 0.012218

run [1850]:
Style Loss : 0.287611 Content Loss: 0.012250

run [1900]:
Style Loss : 0.286314 Content Loss: 0.012281

run [1950]:
Style Loss : 0.285216 Content Loss: 0.012309

run [2000]:
Style Loss : 0.284109 Content Loss: 0.012330

run [2050]:
Style Loss : 0.283043 Content Loss: 0.012351

run [2100]:
Style Loss : 0.282113 Content Loss: 0.012371

run [2150]:
Style Loss : 0.281216 Content Loss: 0.012391

run [2200]:
Style Loss : 0.280385 Content Loss: 0.012409

run [2250]:
Style Loss : 0.279559 Content Loss: 0.012431

run [2300]:
Style Loss : 0.278739 Content Loss: 0.012456

run [2350]:
Style Loss : 0.277835 Content Loss: 0.012482

run [2400]:
Style Loss : 0.276969 Content Loss: 0.012509

run [2450]:
Style Loss : 0.276111 Content Loss: 0.012534

run [2500]:
Style Loss : 0.275277 Content Loss: 0.012562

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.706305 Content Loss: 0.003225

run [100]:
Style Loss : 0.426837 Content Loss: 0.005040

run [150]:
Style Loss : 0.326711 Content Loss: 0.006113

run [200]:
Style Loss : 0.279393 Content Loss: 0.007178

run [250]:
Style Loss : 0.252073 Content Loss: 0.007991

run [300]:
Style Loss : 0.233385 Content Loss: 0.008667

run [350]:
Style Loss : 0.220803 Content Loss: 0.009256

run [400]:
Style Loss : 0.210563 Content Loss: 0.009788

run [450]:
Style Loss : 0.202687 Content Loss: 0.010236

run [500]:
Style Loss : 0.193793 Content Loss: 0.010623

run [550]:
Style Loss : 0.186886 Content Loss: 0.011015

run [600]:
Style Loss : 0.179188 Content Loss: 0.011404

run [650]:
Style Loss : 0.172390 Content Loss: 0.011816

run [700]:
Style Loss : 0.166502 Content Loss: 0.012230

run [750]:
Style Loss : 0.161339 Content Loss: 0.012637

run [800]:
Style Loss : 0.156852 Content Loss: 0.013047

run [850]:
Style Loss : 0.152351 Content Loss: 0.013455

run [900]:
Style Loss : 0.148706 Content Loss: 0.013801

run [950]:
Style Loss : 0.145416 Content Loss: 0.014113

run [1000]:
Style Loss : 0.142659 Content Loss: 0.014405

run [1050]:
Style Loss : 0.140247 Content Loss: 0.014652

run [1100]:
Style Loss : 0.138278 Content Loss: 0.014849

run [1150]:
Style Loss : 0.136168 Content Loss: 0.015113

run [1200]:
Style Loss : 0.128608 Content Loss: 0.015172

run [1250]:
Style Loss : 0.125272 Content Loss: 0.015280

run [1300]:
Style Loss : 0.122791 Content Loss: 0.015411

run [1350]:
Style Loss : 0.121044 Content Loss: 0.015516

run [1400]:
Style Loss : 0.119752 Content Loss: 0.015577

run [1450]:
Style Loss : 0.118704 Content Loss: 0.015625

run [1500]:
Style Loss : 0.117784 Content Loss: 0.015681

run [1550]:
Style Loss : 0.116987 Content Loss: 0.015730

run [1600]:
Style Loss : 0.116307 Content Loss: 0.015768

run [1650]:
Style Loss : 0.115707 Content Loss: 0.015806

run [1700]:
Style Loss : 0.115108 Content Loss: 0.015843

run [1750]:
Style Loss : 0.114559 Content Loss: 0.015871

run [1800]:
Style Loss : 0.114045 Content Loss: 0.015894

run [1850]:
Style Loss : 0.113508 Content Loss: 0.015918

run [1900]:
Style Loss : 0.112980 Content Loss: 0.015950

run [1950]:
Style Loss : 0.112559 Content Loss: 0.015977

run [2000]:
Style Loss : 0.112132 Content Loss: 0.016003

run [2050]:
Style Loss : 0.111775 Content Loss: 0.016033

run [2100]:
Style Loss : 0.111408 Content Loss: 0.016057

run [2150]:
Style Loss : 0.111051 Content Loss: 0.016084

run [2200]:
Style Loss : 0.110620 Content Loss: 0.016098

run [2250]:
Style Loss : 0.110268 Content Loss: 0.016135

run [2300]:
Style Loss : 0.109886 Content Loss: 0.016171

run [2350]:
Style Loss : 0.109542 Content Loss: 0.016198

run [2400]:
Style Loss : 0.109138 Content Loss: 0.016219

run [2450]:
Style Loss : 0.108781 Content Loss: 0.016233

run [2500]:
Style Loss : 0.108474 Content Loss: 0.016246

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.740486 Content Loss: 0.004137

run [100]:
Style Loss : 0.445202 Content Loss: 0.007284

run [150]:
Style Loss : 0.311489 Content Loss: 0.009930

run [200]:
Style Loss : 0.254831 Content Loss: 0.012524

run [250]:
Style Loss : 0.217776 Content Loss: 0.014695

run [300]:
Style Loss : 0.190538 Content Loss: 0.016631

run [350]:
Style Loss : 0.173744 Content Loss: 0.018075

run [400]:
Style Loss : 0.162820 Content Loss: 0.019012

run [450]:
Style Loss : 0.154432 Content Loss: 0.019528

run [500]:
Style Loss : 0.147092 Content Loss: 0.019849

run [550]:
Style Loss : 0.140954 Content Loss: 0.020132

run [600]:
Style Loss : 0.135966 Content Loss: 0.020419

run [650]:
Style Loss : 0.131575 Content Loss: 0.020791

run [700]:
Style Loss : 0.127123 Content Loss: 0.021152

run [750]:
Style Loss : 0.122364 Content Loss: 0.021555

run [800]:
Style Loss : 0.118500 Content Loss: 0.021913

run [850]:
Style Loss : 0.114966 Content Loss: 0.022301

run [900]:
Style Loss : 0.111993 Content Loss: 0.022679

run [950]:
Style Loss : 0.109497 Content Loss: 0.023062

run [1000]:
Style Loss : 0.107360 Content Loss: 0.023434

run [1050]:
Style Loss : 0.105487 Content Loss: 0.023810

run [1100]:
Style Loss : 0.103844 Content Loss: 0.024100

run [1150]:
Style Loss : 0.102526 Content Loss: 0.024318

run [1200]:
Style Loss : 0.101223 Content Loss: 0.024539

run [1250]:
Style Loss : 0.099861 Content Loss: 0.024710

run [1300]:
Style Loss : 0.098764 Content Loss: 0.024842

run [1350]:
Style Loss : 0.097904 Content Loss: 0.024957

run [1400]:
Style Loss : 0.097209 Content Loss: 0.025026

run [1450]:
Style Loss : 0.096634 Content Loss: 0.025092

run [1500]:
Style Loss : 0.096117 Content Loss: 0.025142

run [1550]:
Style Loss : 0.095632 Content Loss: 0.025182

run [1600]:
Style Loss : 0.095211 Content Loss: 0.025218

run [1650]:
Style Loss : 0.094846 Content Loss: 0.025242

run [1700]:
Style Loss : 0.094482 Content Loss: 0.025257

run [1750]:
Style Loss : 0.094158 Content Loss: 0.025254

run [1800]:
Style Loss : 0.093852 Content Loss: 0.025262

run [1850]:
Style Loss : 0.093531 Content Loss: 0.025254

run [1900]:
Style Loss : 0.093223 Content Loss: 0.025242

run [1950]:
Style Loss : 0.092933 Content Loss: 0.025231

run [2000]:
Style Loss : 0.092659 Content Loss: 0.025226

run [2050]:
Style Loss : 0.092419 Content Loss: 0.025217

run [2100]:
Style Loss : 0.092162 Content Loss: 0.025206

run [2150]:
Style Loss : 0.091931 Content Loss: 0.025187

run [2200]:
Style Loss : 0.091727 Content Loss: 0.025167

run [2250]:
Style Loss : 0.091529 Content Loss: 0.025142

run [2300]:
Style Loss : 0.091309 Content Loss: 0.025116

run [2350]:
Style Loss : 0.091149 Content Loss: 0.025086

run [2400]:
Style Loss : 0.090968 Content Loss: 0.025062

run [2450]:
Style Loss : 0.090802 Content Loss: 0.025038

run [2500]:
Style Loss : 0.090653 Content Loss: 0.025013

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.944390 Content Loss: 0.011541

run [100]:
Style Loss : 1.128708 Content Loss: 0.014094

run [150]:
Style Loss : 0.878985 Content Loss: 0.016018

run [200]:
Style Loss : 0.747624 Content Loss: 0.017682

run [250]:
Style Loss : 0.669161 Content Loss: 0.019053

run [300]:
Style Loss : 0.616062 Content Loss: 0.020149

run [350]:
Style Loss : 0.579038 Content Loss: 0.020934

run [400]:
Style Loss : 0.551361 Content Loss: 0.021652

run [450]:
Style Loss : 0.528818 Content Loss: 0.022310

run [500]:
Style Loss : 0.509821 Content Loss: 0.022889

run [550]:
Style Loss : 0.493477 Content Loss: 0.023445

run [600]:
Style Loss : 0.478856 Content Loss: 0.023976

run [650]:
Style Loss : 0.465842 Content Loss: 0.024528

run [700]:
Style Loss : 0.454937 Content Loss: 0.025067

run [750]:
Style Loss : 0.445224 Content Loss: 0.025576

run [800]:
Style Loss : 0.436578 Content Loss: 0.026028

run [850]:
Style Loss : 0.428350 Content Loss: 0.026478

run [900]:
Style Loss : 0.421073 Content Loss: 0.026898

run [950]:
Style Loss : 0.414401 Content Loss: 0.027315

run [1000]:
Style Loss : 0.408926 Content Loss: 0.027693

run [1050]:
Style Loss : 0.403786 Content Loss: 0.028070

run [1100]:
Style Loss : 0.398610 Content Loss: 0.028403

run [1150]:
Style Loss : 0.394373 Content Loss: 0.028695

run [1200]:
Style Loss : 0.390435 Content Loss: 0.029030

run [1250]:
Style Loss : 0.386515 Content Loss: 0.029314

run [1300]:
Style Loss : 0.382917 Content Loss: 0.029566

run [1350]:
Style Loss : 0.378962 Content Loss: 0.029838

run [1400]:
Style Loss : 0.374955 Content Loss: 0.030068

run [1450]:
Style Loss : 0.370921 Content Loss: 0.030248

run [1500]:
Style Loss : 0.367253 Content Loss: 0.030474

run [1550]:
Style Loss : 0.363618 Content Loss: 0.030625

run [1600]:
Style Loss : 0.360643 Content Loss: 0.030815

run [1650]:
Style Loss : 0.357569 Content Loss: 0.030912

run [1700]:
Style Loss : 0.355083 Content Loss: 0.031027

run [1750]:
Style Loss : 0.352855 Content Loss: 0.031112

run [1800]:
Style Loss : 0.350795 Content Loss: 0.031206

run [1850]:
Style Loss : 0.348850 Content Loss: 0.031285

run [1900]:
Style Loss : 0.346983 Content Loss: 0.031375

run [1950]:
Style Loss : 0.345387 Content Loss: 0.031445

run [2000]:
Style Loss : 0.344030 Content Loss: 0.031520

run [2050]:
Style Loss : 0.342678 Content Loss: 0.031552

run [2100]:
Style Loss : 0.341417 Content Loss: 0.031605

run [2150]:
Style Loss : 0.340249 Content Loss: 0.031613

run [2200]:
Style Loss : 0.338832 Content Loss: 0.031653

run [2250]:
Style Loss : 0.337667 Content Loss: 0.031678

run [2300]:
Style Loss : 0.336449 Content Loss: 0.031723

run [2350]:
Style Loss : 0.335407 Content Loss: 0.031749

run [2400]:
Style Loss : 0.334522 Content Loss: 0.031791

run [2450]:
Style Loss : 0.333694 Content Loss: 0.031822

run [2500]:
Style Loss : 0.332909 Content Loss: 0.031851

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.088841 Content Loss: 0.002013

run [100]:
Style Loss : 0.676994 Content Loss: 0.003772

run [150]:
Style Loss : 0.532438 Content Loss: 0.005462

run [200]:
Style Loss : 0.447978 Content Loss: 0.006694

run [250]:
Style Loss : 0.390503 Content Loss: 0.007750

run [300]:
Style Loss : 0.348006 Content Loss: 0.008829

run [350]:
Style Loss : 0.316700 Content Loss: 0.009826

run [400]:
Style Loss : 0.292485 Content Loss: 0.010710

run [450]:
Style Loss : 0.274767 Content Loss: 0.011485

run [500]:
Style Loss : 0.262263 Content Loss: 0.011980

run [550]:
Style Loss : 0.252656 Content Loss: 0.012334

run [600]:
Style Loss : 0.245056 Content Loss: 0.012544

run [650]:
Style Loss : 0.238613 Content Loss: 0.012714

run [700]:
Style Loss : 0.232798 Content Loss: 0.012846

run [750]:
Style Loss : 0.227678 Content Loss: 0.012923

run [800]:
Style Loss : 0.223037 Content Loss: 0.013040

run [850]:
Style Loss : 0.218812 Content Loss: 0.013171

run [900]:
Style Loss : 0.214495 Content Loss: 0.013289

run [950]:
Style Loss : 0.210074 Content Loss: 0.013400

run [1000]:
Style Loss : 0.206343 Content Loss: 0.013504

run [1050]:
Style Loss : 0.203043 Content Loss: 0.013587

run [1100]:
Style Loss : 0.200330 Content Loss: 0.013687

run [1150]:
Style Loss : 0.197865 Content Loss: 0.013788

run [1200]:
Style Loss : 0.195525 Content Loss: 0.013905

run [1250]:
Style Loss : 0.193308 Content Loss: 0.014035

run [1300]:
Style Loss : 0.191212 Content Loss: 0.014171

run [1350]:
Style Loss : 0.189094 Content Loss: 0.014315

run [1400]:
Style Loss : 0.186951 Content Loss: 0.014470

run [1450]:
Style Loss : 0.184755 Content Loss: 0.014654

run [1500]:
Style Loss : 0.182484 Content Loss: 0.014830

run [1550]:
Style Loss : 0.180423 Content Loss: 0.015005

run [1600]:
Style Loss : 0.178525 Content Loss: 0.015182

run [1650]:
Style Loss : 0.176791 Content Loss: 0.015357

run [1700]:
Style Loss : 0.175445 Content Loss: 0.015515

run [1750]:
Style Loss : 0.174037 Content Loss: 0.015657

run [1800]:
Style Loss : 0.172620 Content Loss: 0.015807

run [1850]:
Style Loss : 0.171337 Content Loss: 0.015960

run [1900]:
Style Loss : 0.170083 Content Loss: 0.016106

run [1950]:
Style Loss : 0.169015 Content Loss: 0.016254

run [2000]:
Style Loss : 0.168007 Content Loss: 0.016367

run [2050]:
Style Loss : 0.167027 Content Loss: 0.016556

run [2100]:
Style Loss : 0.166182 Content Loss: 0.016696

run [2150]:
Style Loss : 0.165482 Content Loss: 0.016875

run [2200]:
Style Loss : 0.164501 Content Loss: 0.016988

run [2250]:
Style Loss : 0.165953 Content Loss: 0.017164

run [2300]:
Style Loss : 13.650901 Content Loss: 0.038006

run [2350]:
Style Loss : 1.274293 Content Loss: 0.025578

run [2400]:
Style Loss : 0.644348 Content Loss: 0.024076

run [2450]:
Style Loss : 0.471208 Content Loss: 0.024061

run [2500]:
Style Loss : 0.383618 Content Loss: 0.024277

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.844271 Content Loss: 0.002350

run [100]:
Style Loss : 0.479277 Content Loss: 0.004805

run [150]:
Style Loss : 0.341466 Content Loss: 0.007590

run [200]:
Style Loss : 0.269277 Content Loss: 0.009880

run [250]:
Style Loss : 0.221102 Content Loss: 0.011672

run [300]:
Style Loss : 0.188636 Content Loss: 0.012737

run [350]:
Style Loss : 0.168688 Content Loss: 0.013392

run [400]:
Style Loss : 0.156582 Content Loss: 0.013696

run [450]:
Style Loss : 0.148180 Content Loss: 0.013825

run [500]:
Style Loss : 0.141713 Content Loss: 0.013927

run [550]:
Style Loss : 0.136814 Content Loss: 0.013928

run [600]:
Style Loss : 0.132240 Content Loss: 0.014008

run [650]:
Style Loss : 0.127554 Content Loss: 0.014091

run [700]:
Style Loss : 0.122476 Content Loss: 0.014175

run [750]:
Style Loss : 0.118124 Content Loss: 0.014225

run [800]:
Style Loss : 0.114148 Content Loss: 0.014289

run [850]:
Style Loss : 0.110726 Content Loss: 0.014328

run [900]:
Style Loss : 0.107488 Content Loss: 0.014396

run [950]:
Style Loss : 0.104698 Content Loss: 0.014461

run [1000]:
Style Loss : 0.102275 Content Loss: 0.014513

run [1050]:
Style Loss : 0.100069 Content Loss: 0.014561

run [1100]:
Style Loss : 0.098041 Content Loss: 0.014612

run [1150]:
Style Loss : 0.096286 Content Loss: 0.014658

run [1200]:
Style Loss : 0.094576 Content Loss: 0.014707

run [1250]:
Style Loss : 0.092845 Content Loss: 0.014758

run [1300]:
Style Loss : 0.091118 Content Loss: 0.014796

run [1350]:
Style Loss : 0.089736 Content Loss: 0.014831

run [1400]:
Style Loss : 0.088403 Content Loss: 0.014869

run [1450]:
Style Loss : 0.087165 Content Loss: 0.014911

run [1500]:
Style Loss : 0.086011 Content Loss: 0.014953

run [1550]:
Style Loss : 0.084969 Content Loss: 0.014990

run [1600]:
Style Loss : 0.083912 Content Loss: 0.015027

run [1650]:
Style Loss : 0.083051 Content Loss: 0.015069

run [1700]:
Style Loss : 0.082341 Content Loss: 0.015097

run [1750]:
Style Loss : 0.081725 Content Loss: 0.015119

run [1800]:
Style Loss : 0.081225 Content Loss: 0.015141

run [1850]:
Style Loss : 0.080708 Content Loss: 0.015166

run [1900]:
Style Loss : 0.080229 Content Loss: 0.015193

run [1950]:
Style Loss : 0.079786 Content Loss: 0.015217

run [2000]:
Style Loss : 0.079392 Content Loss: 0.015238

run [2050]:
Style Loss : 0.079025 Content Loss: 0.015259

run [2100]:
Style Loss : 0.078670 Content Loss: 0.015279

run [2150]:
Style Loss : 0.078365 Content Loss: 0.015295

run [2200]:
Style Loss : 0.077965 Content Loss: 0.015309

run [2250]:
Style Loss : 0.077616 Content Loss: 0.015320

run [2300]:
Style Loss : 0.077297 Content Loss: 0.015332

run [2350]:
Style Loss : 0.077007 Content Loss: 0.015351

run [2400]:
Style Loss : 0.076744 Content Loss: 0.015364

run [2450]:
Style Loss : 0.076508 Content Loss: 0.015373

run [2500]:
Style Loss : 0.076293 Content Loss: 0.015383

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.856171 Content Loss: 0.001771

run [100]:
Style Loss : 0.438085 Content Loss: 0.003653

run [150]:
Style Loss : 0.323330 Content Loss: 0.005277

run [200]:
Style Loss : 0.264906 Content Loss: 0.006524

run [250]:
Style Loss : 0.229866 Content Loss: 0.007487

run [300]:
Style Loss : 0.203811 Content Loss: 0.008415

run [350]:
Style Loss : 0.183248 Content Loss: 0.009164

run [400]:
Style Loss : 0.168124 Content Loss: 0.009853

run [450]:
Style Loss : 0.157024 Content Loss: 0.010348

run [500]:
Style Loss : 0.149228 Content Loss: 0.010720

run [550]:
Style Loss : 0.143957 Content Loss: 0.010935

run [600]:
Style Loss : 0.139808 Content Loss: 0.011080

run [650]:
Style Loss : 0.136166 Content Loss: 0.011183

run [700]:
Style Loss : 0.133017 Content Loss: 0.011266

run [750]:
Style Loss : 0.130051 Content Loss: 0.011332

run [800]:
Style Loss : 0.126998 Content Loss: 0.011416

run [850]:
Style Loss : 0.124375 Content Loss: 0.011499

run [900]:
Style Loss : 0.121627 Content Loss: 0.011613

run [950]:
Style Loss : 0.119031 Content Loss: 0.011735

run [1000]:
Style Loss : 0.116392 Content Loss: 0.011868

run [1050]:
Style Loss : 0.113725 Content Loss: 0.012030

run [1100]:
Style Loss : 0.111014 Content Loss: 0.012197

run [1150]:
Style Loss : 0.108349 Content Loss: 0.012370

run [1200]:
Style Loss : 0.105833 Content Loss: 0.012557

run [1250]:
Style Loss : 0.103493 Content Loss: 0.012745

run [1300]:
Style Loss : 0.101153 Content Loss: 0.012965

run [1350]:
Style Loss : 0.099067 Content Loss: 0.013172

run [1400]:
Style Loss : 0.097012 Content Loss: 0.013398

run [1450]:
Style Loss : 0.095278 Content Loss: 0.013584

run [1500]:
Style Loss : 0.093642 Content Loss: 0.013773

run [1550]:
Style Loss : 0.092074 Content Loss: 0.013966

run [1600]:
Style Loss : 0.090692 Content Loss: 0.014131

run [1650]:
Style Loss : 0.089389 Content Loss: 0.014291

run [1700]:
Style Loss : 0.088224 Content Loss: 0.014453

run [1750]:
Style Loss : 0.087191 Content Loss: 0.014596

run [1800]:
Style Loss : 0.086306 Content Loss: 0.014730

run [1850]:
Style Loss : 0.085491 Content Loss: 0.014852

run [1900]:
Style Loss : 0.084769 Content Loss: 0.014944

run [1950]:
Style Loss : 0.084127 Content Loss: 0.015028

run [2000]:
Style Loss : 0.083359 Content Loss: 0.015115

run [2050]:
Style Loss : 0.082690 Content Loss: 0.015189

run [2100]:
Style Loss : 0.082106 Content Loss: 0.015263

run [2150]:
Style Loss : 0.081603 Content Loss: 0.015316

run [2200]:
Style Loss : 0.081178 Content Loss: 0.015358

run [2250]:
Style Loss : 0.080772 Content Loss: 0.015412

run [2300]:
Style Loss : 0.080418 Content Loss: 0.015455

run [2350]:
Style Loss : 0.080095 Content Loss: 0.015493

run [2400]:
Style Loss : 0.079796 Content Loss: 0.015527

run [2450]:
Style Loss : 0.079507 Content Loss: 0.015558

run [2500]:
Style Loss : 0.079248 Content Loss: 0.015590

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.415208 Content Loss: 0.003999

run [100]:
Style Loss : 0.866873 Content Loss: 0.006949

run [150]:
Style Loss : 0.611660 Content Loss: 0.011478

run [200]:
Style Loss : 0.449984 Content Loss: 0.016531

run [250]:
Style Loss : 0.366891 Content Loss: 0.020148

run [300]:
Style Loss : 0.327615 Content Loss: 0.021825

run [350]:
Style Loss : 0.306586 Content Loss: 0.022225

run [400]:
Style Loss : 0.291342 Content Loss: 0.022362

run [450]:
Style Loss : 0.280129 Content Loss: 0.022552

run [500]:
Style Loss : 0.271673 Content Loss: 0.022814

run [550]:
Style Loss : 0.264558 Content Loss: 0.023070

run [600]:
Style Loss : 0.258336 Content Loss: 0.023367

run [650]:
Style Loss : 0.253435 Content Loss: 0.023593

run [700]:
Style Loss : 0.249380 Content Loss: 0.023837

run [750]:
Style Loss : 0.245761 Content Loss: 0.024062

run [800]:
Style Loss : 0.242613 Content Loss: 0.024253

run [850]:
Style Loss : 0.239874 Content Loss: 0.024430

run [900]:
Style Loss : 0.237408 Content Loss: 0.024616

run [950]:
Style Loss : 0.234966 Content Loss: 0.024791

run [1000]:
Style Loss : 0.232758 Content Loss: 0.024931

run [1050]:
Style Loss : 0.230684 Content Loss: 0.025075

run [1100]:
Style Loss : 0.228734 Content Loss: 0.025222

run [1150]:
Style Loss : 0.226812 Content Loss: 0.025391

run [1200]:
Style Loss : 0.224805 Content Loss: 0.025515

run [1250]:
Style Loss : 0.223162 Content Loss: 0.025624

run [1300]:
Style Loss : 0.221686 Content Loss: 0.025734

run [1350]:
Style Loss : 0.220422 Content Loss: 0.025835

run [1400]:
Style Loss : 0.219416 Content Loss: 0.025936

run [1450]:
Style Loss : 0.218342 Content Loss: 0.026017

run [1500]:
Style Loss : 0.217264 Content Loss: 0.026102

run [1550]:
Style Loss : 0.216223 Content Loss: 0.026191

run [1600]:
Style Loss : 0.215374 Content Loss: 0.026277

run [1650]:
Style Loss : 0.214412 Content Loss: 0.026380

run [1700]:
Style Loss : 0.213568 Content Loss: 0.026458

run [1750]:
Style Loss : 0.212682 Content Loss: 0.026554

run [1800]:
Style Loss : 0.211786 Content Loss: 0.026646

run [1850]:
Style Loss : 0.210964 Content Loss: 0.026721

run [1900]:
Style Loss : 0.210579 Content Loss: 0.026897

run [1950]:
Style Loss : 0.210062 Content Loss: 0.026977

run [2000]:
Style Loss : 0.208926 Content Loss: 0.027016

run [2050]:
Style Loss : 0.208497 Content Loss: 0.027111

run [2100]:
Style Loss : 0.207885 Content Loss: 0.027185

run [2150]:
Style Loss : 0.207177 Content Loss: 0.027260

run [2200]:
Style Loss : 0.206582 Content Loss: 0.027318

run [2250]:
Style Loss : 0.206076 Content Loss: 0.027399

run [2300]:
Style Loss : 0.206541 Content Loss: 0.027622

run [2350]:
Style Loss : 0.205015 Content Loss: 0.027623

run [2400]:
Style Loss : 0.204395 Content Loss: 0.027657

run [2450]:
Style Loss : 0.204262 Content Loss: 0.027743

run [2500]:
Style Loss : 0.203563 Content Loss: 0.027776

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.932545 Content Loss: 0.006439

run [100]:
Style Loss : 0.511775 Content Loss: 0.010699

run [150]:
Style Loss : 0.351807 Content Loss: 0.014182

run [200]:
Style Loss : 0.280806 Content Loss: 0.016459

run [250]:
Style Loss : 0.241318 Content Loss: 0.017823

run [300]:
Style Loss : 0.218846 Content Loss: 0.018593

run [350]:
Style Loss : 0.201490 Content Loss: 0.018888

run [400]:
Style Loss : 0.180425 Content Loss: 0.019099

run [450]:
Style Loss : 0.170601 Content Loss: 0.019393

run [500]:
Style Loss : 0.163377 Content Loss: 0.019589

run [550]:
Style Loss : 0.156953 Content Loss: 0.019882

run [600]:
Style Loss : 0.151539 Content Loss: 0.020101

run [650]:
Style Loss : 0.146911 Content Loss: 0.020302

run [700]:
Style Loss : 0.142390 Content Loss: 0.020474

run [750]:
Style Loss : 0.135407 Content Loss: 0.020561

run [800]:
Style Loss : 0.131755 Content Loss: 0.020665

run [850]:
Style Loss : 0.128425 Content Loss: 0.020766

run [900]:
Style Loss : 0.125760 Content Loss: 0.020818

run [950]:
Style Loss : 0.122675 Content Loss: 0.020900

run [1000]:
Style Loss : 0.120203 Content Loss: 0.020967

run [1050]:
Style Loss : 0.118115 Content Loss: 0.021006

run [1100]:
Style Loss : 0.115623 Content Loss: 0.021047

run [1150]:
Style Loss : 0.112908 Content Loss: 0.021086

run [1200]:
Style Loss : 0.110918 Content Loss: 0.021113

run [1250]:
Style Loss : 0.109343 Content Loss: 0.021126

run [1300]:
Style Loss : 0.107372 Content Loss: 0.021146

run [1350]:
Style Loss : 0.105537 Content Loss: 0.021166

run [1400]:
Style Loss : 0.104153 Content Loss: 0.021169

run [1450]:
Style Loss : 0.103067 Content Loss: 0.021176

run [1500]:
Style Loss : 0.102120 Content Loss: 0.021178

run [1550]:
Style Loss : 0.101234 Content Loss: 0.021164

run [1600]:
Style Loss : 0.100482 Content Loss: 0.021161

run [1650]:
Style Loss : 0.099785 Content Loss: 0.021165

run [1700]:
Style Loss : 0.099145 Content Loss: 0.021158

run [1750]:
Style Loss : 0.098565 Content Loss: 0.021158

run [1800]:
Style Loss : 0.098008 Content Loss: 0.021161

run [1850]:
Style Loss : 0.097475 Content Loss: 0.021167

run [1900]:
Style Loss : 0.096977 Content Loss: 0.021167

run [1950]:
Style Loss : 0.096548 Content Loss: 0.021164

run [2000]:
Style Loss : 0.096136 Content Loss: 0.021161

run [2050]:
Style Loss : 0.095779 Content Loss: 0.021150

run [2100]:
Style Loss : 0.095410 Content Loss: 0.021152

run [2150]:
Style Loss : 0.095096 Content Loss: 0.021144

run [2200]:
Style Loss : 0.094816 Content Loss: 0.021142

run [2250]:
Style Loss : 0.094557 Content Loss: 0.021140

run [2300]:
Style Loss : 0.094308 Content Loss: 0.021138

run [2350]:
Style Loss : 0.094062 Content Loss: 0.021133

run [2400]:
Style Loss : 0.093839 Content Loss: 0.021128

run [2450]:
Style Loss : 0.093595 Content Loss: 0.021125

run [2500]:
Style Loss : 0.093369 Content Loss: 0.021124

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.207244 Content Loss: 0.002426

run [100]:
Style Loss : 1.438677 Content Loss: 0.003588

run [150]:
Style Loss : 1.126872 Content Loss: 0.004843

run [200]:
Style Loss : 0.960371 Content Loss: 0.005997

run [250]:
Style Loss : 0.850703 Content Loss: 0.007196

run [300]:
Style Loss : 0.768551 Content Loss: 0.008231

run [350]:
Style Loss : 0.700786 Content Loss: 0.009357

run [400]:
Style Loss : 0.645102 Content Loss: 0.010487

run [450]:
Style Loss : 0.597862 Content Loss: 0.011457

run [500]:
Style Loss : 0.561548 Content Loss: 0.012296

run [550]:
Style Loss : 0.535865 Content Loss: 0.012918

run [600]:
Style Loss : 0.516127 Content Loss: 0.013521

run [650]:
Style Loss : 0.501004 Content Loss: 0.013980

run [700]:
Style Loss : 0.488644 Content Loss: 0.014385

run [750]:
Style Loss : 0.477680 Content Loss: 0.014714

run [800]:
Style Loss : 0.468204 Content Loss: 0.014972

run [850]:
Style Loss : 0.459845 Content Loss: 0.015232

run [900]:
Style Loss : 0.451995 Content Loss: 0.015465

run [950]:
Style Loss : 0.444299 Content Loss: 0.015676

run [1000]:
Style Loss : 0.437186 Content Loss: 0.015856

run [1050]:
Style Loss : 0.430289 Content Loss: 0.016052

run [1100]:
Style Loss : 0.423588 Content Loss: 0.016216

run [1150]:
Style Loss : 0.417587 Content Loss: 0.016394

run [1200]:
Style Loss : 0.412173 Content Loss: 0.016522

run [1250]:
Style Loss : 0.407248 Content Loss: 0.016681

run [1300]:
Style Loss : 0.402442 Content Loss: 0.016828

run [1350]:
Style Loss : 0.398133 Content Loss: 0.016980

run [1400]:
Style Loss : 0.393809 Content Loss: 0.017141

run [1450]:
Style Loss : 0.389902 Content Loss: 0.017282

run [1500]:
Style Loss : 0.386001 Content Loss: 0.017438

run [1550]:
Style Loss : 0.382104 Content Loss: 0.017566

run [1600]:
Style Loss : 0.378553 Content Loss: 0.017695

run [1650]:
Style Loss : 0.375148 Content Loss: 0.017817

run [1700]:
Style Loss : 0.372124 Content Loss: 0.017942

run [1750]:
Style Loss : 0.369299 Content Loss: 0.018060

run [1800]:
Style Loss : 0.366592 Content Loss: 0.018204

run [1850]:
Style Loss : 0.364035 Content Loss: 0.018342

run [1900]:
Style Loss : 0.361584 Content Loss: 0.018481

run [1950]:
Style Loss : 0.359201 Content Loss: 0.018622

run [2000]:
Style Loss : 0.356971 Content Loss: 0.018750

run [2050]:
Style Loss : 0.354973 Content Loss: 0.018859

run [2100]:
Style Loss : 0.353049 Content Loss: 0.018993

run [2150]:
Style Loss : 0.351048 Content Loss: 0.019115

run [2200]:
Style Loss : 0.349271 Content Loss: 0.019220

run [2250]:
Style Loss : 0.347545 Content Loss: 0.019333

run [2300]:
Style Loss : 0.345910 Content Loss: 0.019432

run [2350]:
Style Loss : 0.344465 Content Loss: 0.019530

run [2400]:
Style Loss : 0.343039 Content Loss: 0.019622

run [2450]:
Style Loss : 0.341715 Content Loss: 0.019715

run [2500]:
Style Loss : 0.340451 Content Loss: 0.019803

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.125556 Content Loss: 0.002533

run [100]:
Style Loss : 1.242726 Content Loss: 0.003381

run [150]:
Style Loss : 0.888710 Content Loss: 0.004449

run [200]:
Style Loss : 0.715260 Content Loss: 0.005491

run [250]:
Style Loss : 0.606970 Content Loss: 0.006563

run [300]:
Style Loss : 0.524095 Content Loss: 0.007404

run [350]:
Style Loss : 0.455401 Content Loss: 0.008190

run [400]:
Style Loss : 0.407077 Content Loss: 0.008809

run [450]:
Style Loss : 0.368798 Content Loss: 0.009520

run [500]:
Style Loss : 0.335585 Content Loss: 0.010216

run [550]:
Style Loss : 0.306769 Content Loss: 0.010868

run [600]:
Style Loss : 0.283094 Content Loss: 0.011482

run [650]:
Style Loss : 0.264182 Content Loss: 0.012039

run [700]:
Style Loss : 0.250065 Content Loss: 0.012468

run [750]:
Style Loss : 0.238598 Content Loss: 0.012879

run [800]:
Style Loss : 0.228559 Content Loss: 0.013094

run [850]:
Style Loss : 0.220464 Content Loss: 0.013293

run [900]:
Style Loss : 0.214056 Content Loss: 0.013452

run [950]:
Style Loss : 0.208707 Content Loss: 0.013626

run [1000]:
Style Loss : 0.204451 Content Loss: 0.013720

run [1050]:
Style Loss : 0.200560 Content Loss: 0.013806

run [1100]:
Style Loss : 0.196692 Content Loss: 0.013851

run [1150]:
Style Loss : 0.193370 Content Loss: 0.013903

run [1200]:
Style Loss : 0.190466 Content Loss: 0.013927

run [1250]:
Style Loss : 0.187517 Content Loss: 0.013953

run [1300]:
Style Loss : 0.184901 Content Loss: 0.013965

run [1350]:
Style Loss : 0.182764 Content Loss: 0.013967

run [1400]:
Style Loss : 0.180747 Content Loss: 0.013960

run [1450]:
Style Loss : 0.179021 Content Loss: 0.013955

run [1500]:
Style Loss : 0.177386 Content Loss: 0.013958

run [1550]:
Style Loss : 0.175739 Content Loss: 0.013958

run [1600]:
Style Loss : 0.174326 Content Loss: 0.013958

run [1650]:
Style Loss : 0.173031 Content Loss: 0.013955

run [1700]:
Style Loss : 0.171775 Content Loss: 0.013955

run [1750]:
Style Loss : 0.170687 Content Loss: 0.013960

run [1800]:
Style Loss : 0.169654 Content Loss: 0.013966

run [1850]:
Style Loss : 0.168680 Content Loss: 0.013972

run [1900]:
Style Loss : 0.167865 Content Loss: 0.013979

run [1950]:
Style Loss : 0.166989 Content Loss: 0.013987

run [2000]:
Style Loss : 0.166180 Content Loss: 0.014001

run [2050]:
Style Loss : 0.165404 Content Loss: 0.014013

run [2100]:
Style Loss : 0.164656 Content Loss: 0.014026

run [2150]:
Style Loss : 0.164000 Content Loss: 0.014039

run [2200]:
Style Loss : 0.163377 Content Loss: 0.014051

run [2250]:
Style Loss : 0.162742 Content Loss: 0.014065

run [2300]:
Style Loss : 0.162167 Content Loss: 0.014078

run [2350]:
Style Loss : 0.161632 Content Loss: 0.014089

run [2400]:
Style Loss : 0.161087 Content Loss: 0.014098

run [2450]:
Style Loss : 0.160551 Content Loss: 0.014110

run [2500]:
Style Loss : 0.160063 Content Loss: 0.014121

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.917173 Content Loss: 0.003395

run [100]:
Style Loss : 1.178039 Content Loss: 0.004422

run [150]:
Style Loss : 0.888077 Content Loss: 0.005692

run [200]:
Style Loss : 0.744318 Content Loss: 0.006765

run [250]:
Style Loss : 0.658687 Content Loss: 0.007689

run [300]:
Style Loss : 0.590052 Content Loss: 0.008616

run [350]:
Style Loss : 0.536951 Content Loss: 0.009229

run [400]:
Style Loss : 0.495450 Content Loss: 0.009788

run [450]:
Style Loss : 0.461728 Content Loss: 0.010370

run [500]:
Style Loss : 0.437141 Content Loss: 0.010810

run [550]:
Style Loss : 0.417591 Content Loss: 0.011234

run [600]:
Style Loss : 0.401668 Content Loss: 0.011655

run [650]:
Style Loss : 0.388625 Content Loss: 0.011991

run [700]:
Style Loss : 0.377532 Content Loss: 0.012282

run [750]:
Style Loss : 0.367567 Content Loss: 0.012597

run [800]:
Style Loss : 0.358415 Content Loss: 0.012842

run [850]:
Style Loss : 0.349452 Content Loss: 0.013059

run [900]:
Style Loss : 0.340516 Content Loss: 0.013263

run [950]:
Style Loss : 0.332988 Content Loss: 0.013435

run [1000]:
Style Loss : 0.326986 Content Loss: 0.013594

run [1050]:
Style Loss : 0.321395 Content Loss: 0.013759

run [1100]:
Style Loss : 0.316387 Content Loss: 0.013915

run [1150]:
Style Loss : 0.311920 Content Loss: 0.014068

run [1200]:
Style Loss : 0.307964 Content Loss: 0.014201

run [1250]:
Style Loss : 0.304574 Content Loss: 0.014315

run [1300]:
Style Loss : 0.301552 Content Loss: 0.014415

run [1350]:
Style Loss : 0.298863 Content Loss: 0.014516

run [1400]:
Style Loss : 0.296529 Content Loss: 0.014606

run [1450]:
Style Loss : 0.294395 Content Loss: 0.014701

run [1500]:
Style Loss : 0.292456 Content Loss: 0.014773

run [1550]:
Style Loss : 0.290507 Content Loss: 0.014860

run [1600]:
Style Loss : 0.288754 Content Loss: 0.014931

run [1650]:
Style Loss : 0.287239 Content Loss: 0.014998

run [1700]:
Style Loss : 0.285787 Content Loss: 0.015058

run [1750]:
Style Loss : 0.284270 Content Loss: 0.015127

run [1800]:
Style Loss : 0.282850 Content Loss: 0.015188

run [1850]:
Style Loss : 0.281452 Content Loss: 0.015256

run [1900]:
Style Loss : 0.280107 Content Loss: 0.015327

run [1950]:
Style Loss : 0.278841 Content Loss: 0.015399

run [2000]:
Style Loss : 0.277547 Content Loss: 0.015475

run [2050]:
Style Loss : 0.276374 Content Loss: 0.015534

run [2100]:
Style Loss : 0.275274 Content Loss: 0.015584

run [2150]:
Style Loss : 0.274286 Content Loss: 0.015633

run [2200]:
Style Loss : 0.273296 Content Loss: 0.015680

run [2250]:
Style Loss : 0.272361 Content Loss: 0.015736

run [2300]:
Style Loss : 0.271496 Content Loss: 0.015770

run [2350]:
Style Loss : 0.270681 Content Loss: 0.015811

run [2400]:
Style Loss : 0.269908 Content Loss: 0.015850

run [2450]:
Style Loss : 0.269136 Content Loss: 0.015886

run [2500]:
Style Loss : 0.268428 Content Loss: 0.015931

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.795700 Content Loss: 0.001876

run [100]:
Style Loss : 1.617686 Content Loss: 0.002742

run [150]:
Style Loss : 1.186716 Content Loss: 0.003795

run [200]:
Style Loss : 0.980633 Content Loss: 0.004872

run [250]:
Style Loss : 0.857140 Content Loss: 0.005768

run [300]:
Style Loss : 0.761689 Content Loss: 0.006452

run [350]:
Style Loss : 0.691089 Content Loss: 0.007011

run [400]:
Style Loss : 0.640784 Content Loss: 0.007478

run [450]:
Style Loss : 0.603661 Content Loss: 0.007818

run [500]:
Style Loss : 0.573381 Content Loss: 0.008108

run [550]:
Style Loss : 0.548122 Content Loss: 0.008398

run [600]:
Style Loss : 0.527152 Content Loss: 0.008665

run [650]:
Style Loss : 0.509400 Content Loss: 0.008895

run [700]:
Style Loss : 0.494251 Content Loss: 0.009146

run [750]:
Style Loss : 0.481098 Content Loss: 0.009342

run [800]:
Style Loss : 0.469476 Content Loss: 0.009527

run [850]:
Style Loss : 0.458619 Content Loss: 0.009710

run [900]:
Style Loss : 0.449980 Content Loss: 0.009832

run [950]:
Style Loss : 0.441881 Content Loss: 0.009976

run [1000]:
Style Loss : 0.433891 Content Loss: 0.010120

run [1050]:
Style Loss : 0.427047 Content Loss: 0.010252

run [1100]:
Style Loss : 0.420054 Content Loss: 0.010386

run [1150]:
Style Loss : 0.413716 Content Loss: 0.010499

run [1200]:
Style Loss : 0.408529 Content Loss: 0.010595

run [1250]:
Style Loss : 0.403683 Content Loss: 0.010699

run [1300]:
Style Loss : 0.398975 Content Loss: 0.010792

run [1350]:
Style Loss : 0.394618 Content Loss: 0.010867

run [1400]:
Style Loss : 0.390711 Content Loss: 0.010935

run [1450]:
Style Loss : 0.386992 Content Loss: 0.011009

run [1500]:
Style Loss : 0.383364 Content Loss: 0.011083

run [1550]:
Style Loss : 0.380085 Content Loss: 0.011153

run [1600]:
Style Loss : 0.377194 Content Loss: 0.011219

run [1650]:
Style Loss : 0.374555 Content Loss: 0.011282

run [1700]:
Style Loss : 0.372110 Content Loss: 0.011335

run [1750]:
Style Loss : 0.369756 Content Loss: 0.011391

run [1800]:
Style Loss : 0.367492 Content Loss: 0.011445

run [1850]:
Style Loss : 0.365505 Content Loss: 0.011491

run [1900]:
Style Loss : 0.363163 Content Loss: 0.011552

run [1950]:
Style Loss : 0.360791 Content Loss: 0.011605

run [2000]:
Style Loss : 0.358560 Content Loss: 0.011650

run [2050]:
Style Loss : 0.356505 Content Loss: 0.011683

run [2100]:
Style Loss : 0.354775 Content Loss: 0.011713

run [2150]:
Style Loss : 0.353140 Content Loss: 0.011745

run [2200]:
Style Loss : 0.351645 Content Loss: 0.011776

run [2250]:
Style Loss : 0.350003 Content Loss: 0.011816

run [2300]:
Style Loss : 0.348480 Content Loss: 0.011838

run [2350]:
Style Loss : 0.347027 Content Loss: 0.011866

run [2400]:
Style Loss : 0.345362 Content Loss: 0.011900

run [2450]:
Style Loss : 0.343729 Content Loss: 0.011937

run [2500]:
Style Loss : 0.342346 Content Loss: 0.011966

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.939825 Content Loss: 0.004038

run [100]:
Style Loss : 1.482974 Content Loss: 0.004258

run [150]:
Style Loss : 1.102334 Content Loss: 0.005180

run [200]:
Style Loss : 0.934425 Content Loss: 0.005911

run [250]:
Style Loss : 0.839431 Content Loss: 0.006719

run [300]:
Style Loss : 0.774047 Content Loss: 0.007253

run [350]:
Style Loss : 0.731561 Content Loss: 0.007802

run [400]:
Style Loss : 0.695713 Content Loss: 0.008240

run [450]:
Style Loss : 0.667030 Content Loss: 0.008589

run [500]:
Style Loss : 0.641723 Content Loss: 0.008936

run [550]:
Style Loss : 0.620204 Content Loss: 0.009254

run [600]:
Style Loss : 0.601496 Content Loss: 0.009509

run [650]:
Style Loss : 0.586478 Content Loss: 0.009741

run [700]:
Style Loss : 0.571892 Content Loss: 0.010006

run [750]:
Style Loss : 0.559126 Content Loss: 0.010210

run [800]:
Style Loss : 0.546529 Content Loss: 0.010409

run [850]:
Style Loss : 0.535638 Content Loss: 0.010589

run [900]:
Style Loss : 0.525749 Content Loss: 0.010749

run [950]:
Style Loss : 0.517384 Content Loss: 0.010883

run [1000]:
Style Loss : 0.510055 Content Loss: 0.011035

run [1050]:
Style Loss : 0.503405 Content Loss: 0.011166

run [1100]:
Style Loss : 0.497500 Content Loss: 0.011296

run [1150]:
Style Loss : 0.492261 Content Loss: 0.011400

run [1200]:
Style Loss : 0.487203 Content Loss: 0.011515

run [1250]:
Style Loss : 0.482862 Content Loss: 0.011613

run [1300]:
Style Loss : 0.478882 Content Loss: 0.011715

run [1350]:
Style Loss : 0.475099 Content Loss: 0.011814

run [1400]:
Style Loss : 0.471870 Content Loss: 0.011903

run [1450]:
Style Loss : 0.468841 Content Loss: 0.011989

run [1500]:
Style Loss : 0.465918 Content Loss: 0.012064

run [1550]:
Style Loss : 0.463164 Content Loss: 0.012155

run [1600]:
Style Loss : 0.460385 Content Loss: 0.012234

run [1650]:
Style Loss : 0.457491 Content Loss: 0.012332

run [1700]:
Style Loss : 0.454543 Content Loss: 0.012424

run [1750]:
Style Loss : 0.450006 Content Loss: 0.012509

run [1800]:
Style Loss : 0.446284 Content Loss: 0.012584

run [1850]:
Style Loss : 0.443551 Content Loss: 0.012639

run [1900]:
Style Loss : 0.440708 Content Loss: 0.012705

run [1950]:
Style Loss : 0.438150 Content Loss: 0.012756

run [2000]:
Style Loss : 0.435800 Content Loss: 0.012806

run [2050]:
Style Loss : 0.433710 Content Loss: 0.012854

run [2100]:
Style Loss : 0.431619 Content Loss: 0.012897

run [2150]:
Style Loss : 0.429614 Content Loss: 0.012946

run [2200]:
Style Loss : 0.427776 Content Loss: 0.012985

run [2250]:
Style Loss : 0.425979 Content Loss: 0.013021

run [2300]:
Style Loss : 0.424279 Content Loss: 0.013059

run [2350]:
Style Loss : 0.422743 Content Loss: 0.013089

run [2400]:
Style Loss : 0.421219 Content Loss: 0.013126

run [2450]:
Style Loss : 0.419690 Content Loss: 0.013162

run [2500]:
Style Loss : 0.418211 Content Loss: 0.013196

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.532833 Content Loss: 0.004718

run [100]:
Style Loss : 2.112324 Content Loss: 0.005292

run [150]:
Style Loss : 1.657846 Content Loss: 0.006278

run [200]:
Style Loss : 1.413359 Content Loss: 0.007241

run [250]:
Style Loss : 1.246876 Content Loss: 0.008120

run [300]:
Style Loss : 1.136997 Content Loss: 0.008880

run [350]:
Style Loss : 1.058928 Content Loss: 0.009478

run [400]:
Style Loss : 0.997891 Content Loss: 0.010077

run [450]:
Style Loss : 0.947186 Content Loss: 0.010575

run [500]:
Style Loss : 0.907081 Content Loss: 0.010989

run [550]:
Style Loss : 0.871744 Content Loss: 0.011407

run [600]:
Style Loss : 0.839516 Content Loss: 0.011743

run [650]:
Style Loss : 0.811196 Content Loss: 0.012030

run [700]:
Style Loss : 0.783312 Content Loss: 0.012341

run [750]:
Style Loss : 0.758461 Content Loss: 0.012559

run [800]:
Style Loss : 0.735066 Content Loss: 0.012812

run [850]:
Style Loss : 0.714179 Content Loss: 0.013010

run [900]:
Style Loss : 0.694588 Content Loss: 0.013171

run [950]:
Style Loss : 0.676986 Content Loss: 0.013313

run [1000]:
Style Loss : 0.660187 Content Loss: 0.013479

run [1050]:
Style Loss : 0.644913 Content Loss: 0.013626

run [1100]:
Style Loss : 0.631369 Content Loss: 0.013775

run [1150]:
Style Loss : 0.619711 Content Loss: 0.013910

run [1200]:
Style Loss : 0.608792 Content Loss: 0.014031

run [1250]:
Style Loss : 0.597696 Content Loss: 0.014156

run [1300]:
Style Loss : 0.587538 Content Loss: 0.014247

run [1350]:
Style Loss : 0.578476 Content Loss: 0.014327

run [1400]:
Style Loss : 0.570240 Content Loss: 0.014425

run [1450]:
Style Loss : 0.562664 Content Loss: 0.014524

run [1500]:
Style Loss : 0.555648 Content Loss: 0.014627

run [1550]:
Style Loss : 0.549147 Content Loss: 0.014727

run [1600]:
Style Loss : 0.543031 Content Loss: 0.014810

run [1650]:
Style Loss : 0.536707 Content Loss: 0.014923

run [1700]:
Style Loss : 0.529542 Content Loss: 0.015007

run [1750]:
Style Loss : 0.523780 Content Loss: 0.015084

run [1800]:
Style Loss : 0.518382 Content Loss: 0.015176

run [1850]:
Style Loss : 0.513102 Content Loss: 0.015272

run [1900]:
Style Loss : 0.508134 Content Loss: 0.015353

run [1950]:
Style Loss : 0.503059 Content Loss: 0.015417

run [2000]:
Style Loss : 0.497990 Content Loss: 0.015496

run [2050]:
Style Loss : 0.492270 Content Loss: 0.015579

run [2100]:
Style Loss : 0.487494 Content Loss: 0.015639

run [2150]:
Style Loss : 0.483015 Content Loss: 0.015709

run [2200]:
Style Loss : 0.479064 Content Loss: 0.015791

run [2250]:
Style Loss : 0.475538 Content Loss: 0.015863

run [2300]:
Style Loss : 0.472252 Content Loss: 0.015934

run [2350]:
Style Loss : 0.469176 Content Loss: 0.015993

run [2400]:
Style Loss : 0.466300 Content Loss: 0.016046

run [2450]:
Style Loss : 0.463477 Content Loss: 0.016110

run [2500]:
Style Loss : 0.460698 Content Loss: 0.016176

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.428298 Content Loss: 0.004696

run [100]:
Style Loss : 1.693089 Content Loss: 0.005044

run [150]:
Style Loss : 1.214925 Content Loss: 0.005931

run [200]:
Style Loss : 0.996395 Content Loss: 0.006811

run [250]:
Style Loss : 0.869293 Content Loss: 0.007878

run [300]:
Style Loss : 0.777929 Content Loss: 0.008816

run [350]:
Style Loss : 0.714169 Content Loss: 0.009642

run [400]:
Style Loss : 0.664907 Content Loss: 0.010511

run [450]:
Style Loss : 0.620311 Content Loss: 0.011212

run [500]:
Style Loss : 0.585451 Content Loss: 0.011903

run [550]:
Style Loss : 0.554749 Content Loss: 0.012507

run [600]:
Style Loss : 0.532718 Content Loss: 0.012951

run [650]:
Style Loss : 0.514571 Content Loss: 0.013300

run [700]:
Style Loss : 0.500606 Content Loss: 0.013609

run [750]:
Style Loss : 0.486034 Content Loss: 0.013915

run [800]:
Style Loss : 0.472352 Content Loss: 0.014152

run [850]:
Style Loss : 0.460048 Content Loss: 0.014394

run [900]:
Style Loss : 0.450788 Content Loss: 0.014537

run [950]:
Style Loss : 0.440155 Content Loss: 0.014709

run [1000]:
Style Loss : 0.431263 Content Loss: 0.014843

run [1050]:
Style Loss : 0.422663 Content Loss: 0.014974

run [1100]:
Style Loss : 0.414773 Content Loss: 0.015105

run [1150]:
Style Loss : 0.407066 Content Loss: 0.015207

run [1200]:
Style Loss : 0.400734 Content Loss: 0.015303

run [1250]:
Style Loss : 0.393958 Content Loss: 0.015420

run [1300]:
Style Loss : 0.387128 Content Loss: 0.015530

run [1350]:
Style Loss : 0.381012 Content Loss: 0.015637

run [1400]:
Style Loss : 0.376129 Content Loss: 0.015733

run [1450]:
Style Loss : 0.371215 Content Loss: 0.015823

run [1500]:
Style Loss : 0.366585 Content Loss: 0.015936

run [1550]:
Style Loss : 0.362058 Content Loss: 0.016018

run [1600]:
Style Loss : 0.357303 Content Loss: 0.016126

run [1650]:
Style Loss : 0.353286 Content Loss: 0.016209

run [1700]:
Style Loss : 0.349224 Content Loss: 0.016293

run [1750]:
Style Loss : 0.345701 Content Loss: 0.016357

run [1800]:
Style Loss : 0.341957 Content Loss: 0.016436

run [1850]:
Style Loss : 0.338369 Content Loss: 0.016513

run [1900]:
Style Loss : 0.334624 Content Loss: 0.016596

run [1950]:
Style Loss : 0.331304 Content Loss: 0.016667

run [2000]:
Style Loss : 0.328195 Content Loss: 0.016730

run [2050]:
Style Loss : 0.325024 Content Loss: 0.016822

run [2100]:
Style Loss : 0.320650 Content Loss: 0.016906

run [2150]:
Style Loss : 0.316547 Content Loss: 0.016978

run [2200]:
Style Loss : 0.312967 Content Loss: 0.017054

run [2250]:
Style Loss : 0.310035 Content Loss: 0.017120

run [2300]:
Style Loss : 0.307199 Content Loss: 0.017196

run [2350]:
Style Loss : 0.304482 Content Loss: 0.017264

run [2400]:
Style Loss : 0.301805 Content Loss: 0.017324

run [2450]:
Style Loss : 0.299477 Content Loss: 0.017381

run [2500]:
Style Loss : 0.296969 Content Loss: 0.017448

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.454351 Content Loss: 0.002245

run [100]:
Style Loss : 0.906085 Content Loss: 0.003411

run [150]:
Style Loss : 0.721221 Content Loss: 0.004655

run [200]:
Style Loss : 0.616741 Content Loss: 0.005562

run [250]:
Style Loss : 0.555652 Content Loss: 0.006301

run [300]:
Style Loss : 0.513709 Content Loss: 0.006938

run [350]:
Style Loss : 0.481637 Content Loss: 0.007472

run [400]:
Style Loss : 0.458735 Content Loss: 0.007855

run [450]:
Style Loss : 0.441605 Content Loss: 0.008267

run [500]:
Style Loss : 0.426559 Content Loss: 0.008591

run [550]:
Style Loss : 0.412768 Content Loss: 0.008889

run [600]:
Style Loss : 0.401515 Content Loss: 0.009116

run [650]:
Style Loss : 0.393535 Content Loss: 0.009333

run [700]:
Style Loss : 0.386742 Content Loss: 0.009526

run [750]:
Style Loss : 0.380836 Content Loss: 0.009698

run [800]:
Style Loss : 0.375724 Content Loss: 0.009859

run [850]:
Style Loss : 0.371251 Content Loss: 0.010019

run [900]:
Style Loss : 0.367298 Content Loss: 0.010160

run [950]:
Style Loss : 0.363684 Content Loss: 0.010293

run [1000]:
Style Loss : 0.359742 Content Loss: 0.010437

run [1050]:
Style Loss : 0.356729 Content Loss: 0.010536

run [1100]:
Style Loss : 0.354223 Content Loss: 0.010614

run [1150]:
Style Loss : 0.351736 Content Loss: 0.010693

run [1200]:
Style Loss : 0.349466 Content Loss: 0.010769

run [1250]:
Style Loss : 0.347405 Content Loss: 0.010850

run [1300]:
Style Loss : 0.345639 Content Loss: 0.010912

run [1350]:
Style Loss : 0.343901 Content Loss: 0.010987

run [1400]:
Style Loss : 0.342254 Content Loss: 0.011067

run [1450]:
Style Loss : 0.340746 Content Loss: 0.011134

run [1500]:
Style Loss : 0.339364 Content Loss: 0.011199

run [1550]:
Style Loss : 0.337964 Content Loss: 0.011253

run [1600]:
Style Loss : 0.336671 Content Loss: 0.011308

run [1650]:
Style Loss : 0.335424 Content Loss: 0.011364

run [1700]:
Style Loss : 0.334073 Content Loss: 0.011417

run [1750]:
Style Loss : 0.332766 Content Loss: 0.011473

run [1800]:
Style Loss : 0.331515 Content Loss: 0.011516

run [1850]:
Style Loss : 0.330274 Content Loss: 0.011557

run [1900]:
Style Loss : 0.329241 Content Loss: 0.011598

run [1950]:
Style Loss : 0.328254 Content Loss: 0.011643

run [2000]:
Style Loss : 0.327345 Content Loss: 0.011683

run [2050]:
Style Loss : 0.325794 Content Loss: 0.011730

run [2100]:
Style Loss : 0.324672 Content Loss: 0.011767

run [2150]:
Style Loss : 0.323460 Content Loss: 0.011807

run [2200]:
Style Loss : 0.322470 Content Loss: 0.011846

run [2250]:
Style Loss : 0.321481 Content Loss: 0.011893

run [2300]:
Style Loss : 0.320573 Content Loss: 0.011924

run [2350]:
Style Loss : 0.319588 Content Loss: 0.011956

run [2400]:
Style Loss : 0.318633 Content Loss: 0.011989

run [2450]:
Style Loss : 0.317627 Content Loss: 0.012020

run [2500]:
Style Loss : 0.316731 Content Loss: 0.012046

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.018470 Content Loss: 0.002207

run [100]:
Style Loss : 0.578408 Content Loss: 0.003558

run [150]:
Style Loss : 0.436798 Content Loss: 0.004667

run [200]:
Style Loss : 0.356690 Content Loss: 0.005226

run [250]:
Style Loss : 0.310276 Content Loss: 0.005570

run [300]:
Style Loss : 0.285710 Content Loss: 0.005937

run [350]:
Style Loss : 0.269264 Content Loss: 0.006195

run [400]:
Style Loss : 0.256007 Content Loss: 0.006463

run [450]:
Style Loss : 0.244977 Content Loss: 0.006686

run [500]:
Style Loss : 0.236230 Content Loss: 0.006863

run [550]:
Style Loss : 0.229114 Content Loss: 0.007004

run [600]:
Style Loss : 0.221462 Content Loss: 0.007138

run [650]:
Style Loss : 0.215615 Content Loss: 0.007261

run [700]:
Style Loss : 0.210255 Content Loss: 0.007406

run [750]:
Style Loss : 0.205498 Content Loss: 0.007524

run [800]:
Style Loss : 0.200658 Content Loss: 0.007645

run [850]:
Style Loss : 0.196825 Content Loss: 0.007737

run [900]:
Style Loss : 0.193736 Content Loss: 0.007824

run [950]:
Style Loss : 0.189625 Content Loss: 0.007919

run [1000]:
Style Loss : 0.186840 Content Loss: 0.007980

run [1050]:
Style Loss : 0.184604 Content Loss: 0.008055

run [1100]:
Style Loss : 0.182775 Content Loss: 0.008108

run [1150]:
Style Loss : 0.181260 Content Loss: 0.008187

run [1200]:
Style Loss : 0.179718 Content Loss: 0.008237

run [1250]:
Style Loss : 0.178383 Content Loss: 0.008301

run [1300]:
Style Loss : 0.177133 Content Loss: 0.008358

run [1350]:
Style Loss : 0.176021 Content Loss: 0.008407

run [1400]:
Style Loss : 0.174992 Content Loss: 0.008453

run [1450]:
Style Loss : 0.174047 Content Loss: 0.008502

run [1500]:
Style Loss : 0.173102 Content Loss: 0.008553

run [1550]:
Style Loss : 0.172156 Content Loss: 0.008599

run [1600]:
Style Loss : 0.171288 Content Loss: 0.008645

run [1650]:
Style Loss : 0.170477 Content Loss: 0.008695

run [1700]:
Style Loss : 0.169761 Content Loss: 0.008727

run [1750]:
Style Loss : 0.169136 Content Loss: 0.008763

run [1800]:
Style Loss : 0.168517 Content Loss: 0.008799

run [1850]:
Style Loss : 0.167919 Content Loss: 0.008838

run [1900]:
Style Loss : 0.167260 Content Loss: 0.008862

run [1950]:
Style Loss : 0.166681 Content Loss: 0.008890

run [2000]:
Style Loss : 0.166155 Content Loss: 0.008913

run [2050]:
Style Loss : 0.165626 Content Loss: 0.008934

run [2100]:
Style Loss : 0.165157 Content Loss: 0.008952

run [2150]:
Style Loss : 0.164726 Content Loss: 0.008973

run [2200]:
Style Loss : 0.164327 Content Loss: 0.008993

run [2250]:
Style Loss : 0.163949 Content Loss: 0.009012

run [2300]:
Style Loss : 0.163579 Content Loss: 0.009030

run [2350]:
Style Loss : 0.163222 Content Loss: 0.009049

run [2400]:
Style Loss : 0.162803 Content Loss: 0.009072

run [2450]:
Style Loss : 0.162397 Content Loss: 0.009089

run [2500]:
Style Loss : 0.162016 Content Loss: 0.009108

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.623477 Content Loss: 0.002418

run [100]:
Style Loss : 0.388379 Content Loss: 0.003817

run [150]:
Style Loss : 0.310126 Content Loss: 0.005019

run [200]:
Style Loss : 0.267992 Content Loss: 0.006006

run [250]:
Style Loss : 0.241546 Content Loss: 0.006874

run [300]:
Style Loss : 0.222238 Content Loss: 0.007683

run [350]:
Style Loss : 0.208009 Content Loss: 0.008449

run [400]:
Style Loss : 0.196479 Content Loss: 0.009011

run [450]:
Style Loss : 0.186384 Content Loss: 0.009581

run [500]:
Style Loss : 0.177272 Content Loss: 0.010145

run [550]:
Style Loss : 0.168743 Content Loss: 0.010663

run [600]:
Style Loss : 0.160509 Content Loss: 0.011174

run [650]:
Style Loss : 0.152990 Content Loss: 0.011735

run [700]:
Style Loss : 0.146207 Content Loss: 0.012267

run [750]:
Style Loss : 0.139949 Content Loss: 0.012824

run [800]:
Style Loss : 0.134279 Content Loss: 0.013456

run [850]:
Style Loss : 0.128991 Content Loss: 0.014075

run [900]:
Style Loss : 0.124095 Content Loss: 0.014848

run [950]:
Style Loss : 0.119682 Content Loss: 0.015677

run [1000]:
Style Loss : 0.116149 Content Loss: 0.016373

run [1050]:
Style Loss : 0.113443 Content Loss: 0.017139

run [1100]:
Style Loss : 0.111470 Content Loss: 0.017989

run [1150]:
Style Loss : 0.108489 Content Loss: 0.018575

run [1200]:
Style Loss : 0.107603 Content Loss: 0.019354

run [1250]:
Style Loss : 0.105541 Content Loss: 0.019934

run [1300]:
Style Loss : 0.104008 Content Loss: 0.020483

run [1350]:
Style Loss : 0.102268 Content Loss: 0.020919

run [1400]:
Style Loss : 0.101241 Content Loss: 0.021502

run [1450]:
Style Loss : 0.099940 Content Loss: 0.021938

run [1500]:
Style Loss : 0.098667 Content Loss: 0.022270

run [1550]:
Style Loss : 0.097989 Content Loss: 0.022605

run [1600]:
Style Loss : 0.098842 Content Loss: 0.022980

run [1650]:
Style Loss : 0.096068 Content Loss: 0.022971

run [1700]:
Style Loss : 0.095413 Content Loss: 0.023089

run [1750]:
Style Loss : 0.094713 Content Loss: 0.023136

run [1800]:
Style Loss : 0.094190 Content Loss: 0.023182

run [1850]:
Style Loss : 0.093878 Content Loss: 0.023259

run [1900]:
Style Loss : 0.092358 Content Loss: 0.023174

run [1950]:
Style Loss : 0.093740 Content Loss: 0.023158

run [2000]:
Style Loss : 0.091372 Content Loss: 0.023051

run [2050]:
Style Loss : 0.091177 Content Loss: 0.023003

run [2100]:
Style Loss : 0.093081 Content Loss: 0.022887

run [2150]:
Style Loss : 0.089879 Content Loss: 0.022769

run [2200]:
Style Loss : 0.090852 Content Loss: 0.022659

run [2250]:
Style Loss : 0.089180 Content Loss: 0.022526

run [2300]:
Style Loss : 0.089085 Content Loss: 0.022394

run [2350]:
Style Loss : 0.088787 Content Loss: 0.022263

run [2400]:
Style Loss : 0.088177 Content Loss: 0.022147

run [2450]:
Style Loss : 0.088095 Content Loss: 0.021994

run [2500]:
Style Loss : 0.087523 Content Loss: 0.021851

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.781362 Content Loss: 0.001386

run [100]:
Style Loss : 0.444068 Content Loss: 0.002644

run [150]:
Style Loss : 0.340958 Content Loss: 0.003674

run [200]:
Style Loss : 0.290606 Content Loss: 0.004302

run [250]:
Style Loss : 0.261884 Content Loss: 0.004724

run [300]:
Style Loss : 0.243804 Content Loss: 0.005025

run [350]:
Style Loss : 0.231305 Content Loss: 0.005313

run [400]:
Style Loss : 0.222310 Content Loss: 0.005533

run [450]:
Style Loss : 0.214992 Content Loss: 0.005731

run [500]:
Style Loss : 0.208995 Content Loss: 0.005913

run [550]:
Style Loss : 0.203856 Content Loss: 0.006075

run [600]:
Style Loss : 0.199343 Content Loss: 0.006221

run [650]:
Style Loss : 0.190459 Content Loss: 0.006381

run [700]:
Style Loss : 0.186248 Content Loss: 0.006483

run [750]:
Style Loss : 0.182832 Content Loss: 0.006587

run [800]:
Style Loss : 0.179974 Content Loss: 0.006697

run [850]:
Style Loss : 0.177711 Content Loss: 0.006788

run [900]:
Style Loss : 0.175766 Content Loss: 0.006870

run [950]:
Style Loss : 0.174000 Content Loss: 0.006932

run [1000]:
Style Loss : 0.172524 Content Loss: 0.007003

run [1050]:
Style Loss : 0.171194 Content Loss: 0.007071

run [1100]:
Style Loss : 0.170016 Content Loss: 0.007133

run [1150]:
Style Loss : 0.168861 Content Loss: 0.007194

run [1200]:
Style Loss : 0.167731 Content Loss: 0.007248

run [1250]:
Style Loss : 0.166763 Content Loss: 0.007292

run [1300]:
Style Loss : 0.165780 Content Loss: 0.007345

run [1350]:
Style Loss : 0.164908 Content Loss: 0.007386

run [1400]:
Style Loss : 0.164093 Content Loss: 0.007430

run [1450]:
Style Loss : 0.163347 Content Loss: 0.007473

run [1500]:
Style Loss : 0.162641 Content Loss: 0.007514

run [1550]:
Style Loss : 0.161929 Content Loss: 0.007548

run [1600]:
Style Loss : 0.161304 Content Loss: 0.007584

run [1650]:
Style Loss : 0.160690 Content Loss: 0.007617

run [1700]:
Style Loss : 0.160084 Content Loss: 0.007649

run [1750]:
Style Loss : 0.159540 Content Loss: 0.007680

run [1800]:
Style Loss : 0.159049 Content Loss: 0.007711

run [1850]:
Style Loss : 0.158580 Content Loss: 0.007737

run [1900]:
Style Loss : 0.158173 Content Loss: 0.007765

run [1950]:
Style Loss : 0.157742 Content Loss: 0.007791

run [2000]:
Style Loss : 0.157360 Content Loss: 0.007815

run [2050]:
Style Loss : 0.156991 Content Loss: 0.007839

run [2100]:
Style Loss : 0.156609 Content Loss: 0.007862

run [2150]:
Style Loss : 0.156243 Content Loss: 0.007884

run [2200]:
Style Loss : 0.155896 Content Loss: 0.007904

run [2250]:
Style Loss : 0.155555 Content Loss: 0.007929

run [2300]:
Style Loss : 0.155219 Content Loss: 0.007952

run [2350]:
Style Loss : 0.154881 Content Loss: 0.007972

run [2400]:
Style Loss : 0.154542 Content Loss: 0.007989

run [2450]:
Style Loss : 0.154235 Content Loss: 0.008008

run [2500]:
Style Loss : 0.153945 Content Loss: 0.008028

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.944833 Content Loss: 0.003316

run [100]:
Style Loss : 2.067888 Content Loss: 0.003421

run [150]:
Style Loss : 1.412389 Content Loss: 0.004131

run [200]:
Style Loss : 1.069424 Content Loss: 0.004945

run [250]:
Style Loss : 0.889901 Content Loss: 0.005633

run [300]:
Style Loss : 0.783564 Content Loss: 0.006226

run [350]:
Style Loss : 0.710705 Content Loss: 0.006765

run [400]:
Style Loss : 0.657108 Content Loss: 0.007266

run [450]:
Style Loss : 0.615634 Content Loss: 0.007696

run [500]:
Style Loss : 0.580148 Content Loss: 0.008114

run [550]:
Style Loss : 0.550850 Content Loss: 0.008407

run [600]:
Style Loss : 0.527225 Content Loss: 0.008675

run [650]:
Style Loss : 0.507423 Content Loss: 0.008926

run [700]:
Style Loss : 0.490560 Content Loss: 0.009139

run [750]:
Style Loss : 0.476665 Content Loss: 0.009344

run [800]:
Style Loss : 0.464999 Content Loss: 0.009507

run [850]:
Style Loss : 0.453596 Content Loss: 0.009731

run [900]:
Style Loss : 0.443562 Content Loss: 0.009891

run [950]:
Style Loss : 0.435176 Content Loss: 0.010061

run [1000]:
Style Loss : 0.427518 Content Loss: 0.010213

run [1050]:
Style Loss : 0.420976 Content Loss: 0.010358

run [1100]:
Style Loss : 0.414795 Content Loss: 0.010513

run [1150]:
Style Loss : 0.408870 Content Loss: 0.010657

run [1200]:
Style Loss : 0.403504 Content Loss: 0.010797

run [1250]:
Style Loss : 0.398690 Content Loss: 0.010927

run [1300]:
Style Loss : 0.394028 Content Loss: 0.011044

run [1350]:
Style Loss : 0.389473 Content Loss: 0.011175

run [1400]:
Style Loss : 0.385022 Content Loss: 0.011307

run [1450]:
Style Loss : 0.380931 Content Loss: 0.011416

run [1500]:
Style Loss : 0.377235 Content Loss: 0.011519

run [1550]:
Style Loss : 0.373670 Content Loss: 0.011623

run [1600]:
Style Loss : 0.370288 Content Loss: 0.011731

run [1650]:
Style Loss : 0.367022 Content Loss: 0.011812

run [1700]:
Style Loss : 0.363670 Content Loss: 0.011912

run [1750]:
Style Loss : 0.360401 Content Loss: 0.012009

run [1800]:
Style Loss : 0.357275 Content Loss: 0.012099

run [1850]:
Style Loss : 0.354225 Content Loss: 0.012206

run [1900]:
Style Loss : 0.351334 Content Loss: 0.012304

run [1950]:
Style Loss : 0.348706 Content Loss: 0.012382

run [2000]:
Style Loss : 0.347297 Content Loss: 0.012541

run [2050]:
Style Loss : 0.343915 Content Loss: 0.012586

run [2100]:
Style Loss : 0.343676 Content Loss: 0.012663

run [2150]:
Style Loss : 0.340006 Content Loss: 0.012739

run [2200]:
Style Loss : 0.337379 Content Loss: 0.012806

run [2250]:
Style Loss : 0.334778 Content Loss: 0.012896

run [2300]:
Style Loss : 0.332381 Content Loss: 0.013006

run [2350]:
Style Loss : 0.329936 Content Loss: 0.013110

run [2400]:
Style Loss : 676.336304 Content Loss: 0.422891

run [2450]:
Style Loss : 368.800842 Content Loss: 0.268707

run [2500]:
Style Loss : 6.250764 Content Loss: 0.033514

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.601954 Content Loss: 0.002592

run [100]:
Style Loss : 0.347269 Content Loss: 0.004820

run [150]:
Style Loss : 0.255926 Content Loss: 0.005859

run [200]:
Style Loss : 0.210229 Content Loss: 0.006639

run [250]:
Style Loss : 0.182082 Content Loss: 0.007111

run [300]:
Style Loss : 0.164203 Content Loss: 0.007527

run [350]:
Style Loss : 0.148676 Content Loss: 0.007960

run [400]:
Style Loss : 0.130581 Content Loss: 0.008249

run [450]:
Style Loss : 0.119444 Content Loss: 0.008519

run [500]:
Style Loss : 0.110964 Content Loss: 0.008746

run [550]:
Style Loss : 0.103871 Content Loss: 0.008926

run [600]:
Style Loss : 0.098186 Content Loss: 0.009083

run [650]:
Style Loss : 0.093036 Content Loss: 0.009185

run [700]:
Style Loss : 0.089177 Content Loss: 0.009288

run [750]:
Style Loss : 0.085942 Content Loss: 0.009383

run [800]:
Style Loss : 0.083203 Content Loss: 0.009472

run [850]:
Style Loss : 0.080853 Content Loss: 0.009557

run [900]:
Style Loss : 0.078622 Content Loss: 0.009636

run [950]:
Style Loss : 0.074781 Content Loss: 0.009715

run [1000]:
Style Loss : 0.072617 Content Loss: 0.009797

run [1050]:
Style Loss : 0.070739 Content Loss: 0.009891

run [1100]:
Style Loss : 0.069023 Content Loss: 0.009987

run [1150]:
Style Loss : 0.067539 Content Loss: 0.010064

run [1200]:
Style Loss : 0.066247 Content Loss: 0.010146

run [1250]:
Style Loss : 0.064929 Content Loss: 0.010233

run [1300]:
Style Loss : 0.063687 Content Loss: 0.010325

run [1350]:
Style Loss : 0.062615 Content Loss: 0.010394

run [1400]:
Style Loss : 0.061731 Content Loss: 0.010455

run [1450]:
Style Loss : 0.060944 Content Loss: 0.010513

run [1500]:
Style Loss : 0.060267 Content Loss: 0.010567

run [1550]:
Style Loss : 0.059660 Content Loss: 0.010616

run [1600]:
Style Loss : 0.059183 Content Loss: 0.010652

run [1650]:
Style Loss : 0.058749 Content Loss: 0.010683

run [1700]:
Style Loss : 0.058340 Content Loss: 0.010711

run [1750]:
Style Loss : 0.057925 Content Loss: 0.010743

run [1800]:
Style Loss : 0.057547 Content Loss: 0.010766

run [1850]:
Style Loss : 0.057213 Content Loss: 0.010792

run [1900]:
Style Loss : 0.056870 Content Loss: 0.010819

run [1950]:
Style Loss : 0.056500 Content Loss: 0.010849

run [2000]:
Style Loss : 0.056142 Content Loss: 0.010879

run [2050]:
Style Loss : 0.055820 Content Loss: 0.010900

run [2100]:
Style Loss : 0.055537 Content Loss: 0.010920

run [2150]:
Style Loss : 0.055238 Content Loss: 0.010950

run [2200]:
Style Loss : 0.054948 Content Loss: 0.010976

run [2250]:
Style Loss : 0.054649 Content Loss: 0.011006

run [2300]:
Style Loss : 0.054283 Content Loss: 0.011039

run [2350]:
Style Loss : 0.053978 Content Loss: 0.011064

run [2400]:
Style Loss : 0.053699 Content Loss: 0.011088

run [2450]:
Style Loss : 0.053415 Content Loss: 0.011115

run [2500]:
Style Loss : 0.053134 Content Loss: 0.011138

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.554589 Content Loss: 0.002111

run [100]:
Style Loss : 0.966952 Content Loss: 0.003404

run [150]:
Style Loss : 0.747111 Content Loss: 0.004799

run [200]:
Style Loss : 0.612125 Content Loss: 0.005657

run [250]:
Style Loss : 0.532132 Content Loss: 0.006370

run [300]:
Style Loss : 0.480242 Content Loss: 0.007102

run [350]:
Style Loss : 0.441813 Content Loss: 0.007829

run [400]:
Style Loss : 0.411169 Content Loss: 0.008528

run [450]:
Style Loss : 0.386516 Content Loss: 0.009175

run [500]:
Style Loss : 0.367876 Content Loss: 0.009729

run [550]:
Style Loss : 0.353139 Content Loss: 0.010283

run [600]:
Style Loss : 0.341962 Content Loss: 0.010711

run [650]:
Style Loss : 0.332912 Content Loss: 0.011108

run [700]:
Style Loss : 0.325169 Content Loss: 0.011443

run [750]:
Style Loss : 0.315386 Content Loss: 0.011733

run [800]:
Style Loss : 0.307477 Content Loss: 0.011944

run [850]:
Style Loss : 0.300673 Content Loss: 0.012137

run [900]:
Style Loss : 0.294678 Content Loss: 0.012311

run [950]:
Style Loss : 0.289535 Content Loss: 0.012447

run [1000]:
Style Loss : 0.284527 Content Loss: 0.012607

run [1050]:
Style Loss : 0.279628 Content Loss: 0.012748

run [1100]:
Style Loss : 0.275693 Content Loss: 0.012858

run [1150]:
Style Loss : 0.271751 Content Loss: 0.012972

run [1200]:
Style Loss : 0.268094 Content Loss: 0.013075

run [1250]:
Style Loss : 0.265053 Content Loss: 0.013160

run [1300]:
Style Loss : 0.262274 Content Loss: 0.013247

run [1350]:
Style Loss : 0.259390 Content Loss: 0.013352

run [1400]:
Style Loss : 0.256208 Content Loss: 0.013452

run [1450]:
Style Loss : 0.253419 Content Loss: 0.013533

run [1500]:
Style Loss : 0.250937 Content Loss: 0.013608

run [1550]:
Style Loss : 0.248422 Content Loss: 0.013679

run [1600]:
Style Loss : 0.246361 Content Loss: 0.013748

run [1650]:
Style Loss : 0.244420 Content Loss: 0.013821

run [1700]:
Style Loss : 0.242608 Content Loss: 0.013903

run [1750]:
Style Loss : 0.240902 Content Loss: 0.013975

run [1800]:
Style Loss : 0.239166 Content Loss: 0.014043

run [1850]:
Style Loss : 0.237470 Content Loss: 0.014117

run [1900]:
Style Loss : 0.235882 Content Loss: 0.014190

run [1950]:
Style Loss : 0.234335 Content Loss: 0.014267

run [2000]:
Style Loss : 0.232899 Content Loss: 0.014333

run [2050]:
Style Loss : 0.231582 Content Loss: 0.014399

run [2100]:
Style Loss : 0.230355 Content Loss: 0.014453

run [2150]:
Style Loss : 0.229009 Content Loss: 0.014520

run [2200]:
Style Loss : 0.227750 Content Loss: 0.014582

run [2250]:
Style Loss : 0.226626 Content Loss: 0.014639

run [2300]:
Style Loss : 0.225507 Content Loss: 0.014697

run [2350]:
Style Loss : 0.224513 Content Loss: 0.014747

run [2400]:
Style Loss : 0.223594 Content Loss: 0.014800

run [2450]:
Style Loss : 0.222549 Content Loss: 0.014862

run [2500]:
Style Loss : 0.221589 Content Loss: 0.014919

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.600849 Content Loss: 0.002060

run [100]:
Style Loss : 1.106895 Content Loss: 0.003493

run [150]:
Style Loss : 0.845344 Content Loss: 0.006121

run [200]:
Style Loss : 0.696879 Content Loss: 0.009268

run [250]:
Style Loss : 0.605469 Content Loss: 0.011864

run [300]:
Style Loss : 0.541821 Content Loss: 0.014342

run [350]:
Style Loss : 0.492743 Content Loss: 0.016225

run [400]:
Style Loss : 0.454566 Content Loss: 0.017337

run [450]:
Style Loss : 0.422877 Content Loss: 0.018235

run [500]:
Style Loss : 0.397226 Content Loss: 0.019134

run [550]:
Style Loss : 0.377077 Content Loss: 0.019899

run [600]:
Style Loss : 0.360769 Content Loss: 0.020633

run [650]:
Style Loss : 0.347248 Content Loss: 0.021302

run [700]:
Style Loss : 0.336193 Content Loss: 0.021822

run [750]:
Style Loss : 0.327169 Content Loss: 0.022356

run [800]:
Style Loss : 0.319820 Content Loss: 0.022774

run [850]:
Style Loss : 0.313372 Content Loss: 0.023209

run [900]:
Style Loss : 0.308155 Content Loss: 0.023543

run [950]:
Style Loss : 0.303184 Content Loss: 0.023886

run [1000]:
Style Loss : 0.298380 Content Loss: 0.024156

run [1050]:
Style Loss : 0.293986 Content Loss: 0.024398

run [1100]:
Style Loss : 0.290136 Content Loss: 0.024610

run [1150]:
Style Loss : 0.286462 Content Loss: 0.024829

run [1200]:
Style Loss : 0.283028 Content Loss: 0.025007

run [1250]:
Style Loss : 0.279972 Content Loss: 0.025159

run [1300]:
Style Loss : 0.277395 Content Loss: 0.025293

run [1350]:
Style Loss : 0.275105 Content Loss: 0.025423

run [1400]:
Style Loss : 0.273009 Content Loss: 0.025543

run [1450]:
Style Loss : 0.271037 Content Loss: 0.025658

run [1500]:
Style Loss : 0.269111 Content Loss: 0.025777

run [1550]:
Style Loss : 0.267246 Content Loss: 0.025894

run [1600]:
Style Loss : 0.265290 Content Loss: 0.026017

run [1650]:
Style Loss : 0.263491 Content Loss: 0.026113

run [1700]:
Style Loss : 0.261842 Content Loss: 0.026218

run [1750]:
Style Loss : 0.260238 Content Loss: 0.026315

run [1800]:
Style Loss : 0.258776 Content Loss: 0.026410

run [1850]:
Style Loss : 0.257389 Content Loss: 0.026500

run [1900]:
Style Loss : 0.256081 Content Loss: 0.026585

run [1950]:
Style Loss : 0.254884 Content Loss: 0.026658

run [2000]:
Style Loss : 0.253706 Content Loss: 0.026737

run [2050]:
Style Loss : 0.252572 Content Loss: 0.026817

run [2100]:
Style Loss : 0.251447 Content Loss: 0.026883

run [2150]:
Style Loss : 0.250416 Content Loss: 0.026950

run [2200]:
Style Loss : 0.249384 Content Loss: 0.027011

run [2250]:
Style Loss : 0.248400 Content Loss: 0.027077

run [2300]:
Style Loss : 0.247478 Content Loss: 0.027138

run [2350]:
Style Loss : 0.246639 Content Loss: 0.027201

run [2400]:
Style Loss : 0.245766 Content Loss: 0.027259

run [2450]:
Style Loss : 0.244906 Content Loss: 0.027323

run [2500]:
Style Loss : 0.244022 Content Loss: 0.027384

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.301520 Content Loss: 0.001383

run [100]:
Style Loss : 0.872823 Content Loss: 0.002322

run [150]:
Style Loss : 0.685018 Content Loss: 0.004038

run [200]:
Style Loss : 0.554589 Content Loss: 0.006544

run [250]:
Style Loss : 0.460608 Content Loss: 0.009314

run [300]:
Style Loss : 0.390906 Content Loss: 0.011959

run [350]:
Style Loss : 0.334730 Content Loss: 0.014165

run [400]:
Style Loss : 0.293884 Content Loss: 0.016211

run [450]:
Style Loss : 0.262375 Content Loss: 0.017779

run [500]:
Style Loss : 0.237783 Content Loss: 0.018933

run [550]:
Style Loss : 0.217180 Content Loss: 0.019987

run [600]:
Style Loss : 0.201134 Content Loss: 0.020910

run [650]:
Style Loss : 0.189099 Content Loss: 0.021601

run [700]:
Style Loss : 0.179680 Content Loss: 0.022319

run [750]:
Style Loss : 0.172574 Content Loss: 0.022877

run [800]:
Style Loss : 0.166881 Content Loss: 0.023379

run [850]:
Style Loss : 0.161942 Content Loss: 0.023802

run [900]:
Style Loss : 0.157859 Content Loss: 0.024092

run [950]:
Style Loss : 0.154155 Content Loss: 0.024421

run [1000]:
Style Loss : 0.150757 Content Loss: 0.024748

run [1050]:
Style Loss : 0.147829 Content Loss: 0.025028

run [1100]:
Style Loss : 0.145323 Content Loss: 0.025249

run [1150]:
Style Loss : 0.142987 Content Loss: 0.025508

run [1200]:
Style Loss : 0.140969 Content Loss: 0.025725

run [1250]:
Style Loss : 0.139132 Content Loss: 0.025954

run [1300]:
Style Loss : 0.137299 Content Loss: 0.026173

run [1350]:
Style Loss : 0.135599 Content Loss: 0.026377

run [1400]:
Style Loss : 0.134037 Content Loss: 0.026561

run [1450]:
Style Loss : 0.132615 Content Loss: 0.026733

run [1500]:
Style Loss : 0.131268 Content Loss: 0.026885

run [1550]:
Style Loss : 0.130066 Content Loss: 0.027043

run [1600]:
Style Loss : 0.128923 Content Loss: 0.027217

run [1650]:
Style Loss : 0.127938 Content Loss: 0.027361

run [1700]:
Style Loss : 0.126961 Content Loss: 0.027495

run [1750]:
Style Loss : 0.126021 Content Loss: 0.027635

run [1800]:
Style Loss : 0.125183 Content Loss: 0.027768

run [1850]:
Style Loss : 0.124361 Content Loss: 0.027880

run [1900]:
Style Loss : 0.123629 Content Loss: 0.027991

run [1950]:
Style Loss : 0.122952 Content Loss: 0.028104

run [2000]:
Style Loss : 0.122286 Content Loss: 0.028208

run [2050]:
Style Loss : 0.121674 Content Loss: 0.028313

run [2100]:
Style Loss : 0.121127 Content Loss: 0.028400

run [2150]:
Style Loss : 0.120571 Content Loss: 0.028477

run [2200]:
Style Loss : 0.120110 Content Loss: 0.028564

run [2250]:
Style Loss : 0.119751 Content Loss: 0.028642

run [2300]:
Style Loss : 0.119149 Content Loss: 0.028683

run [2350]:
Style Loss : 0.118694 Content Loss: 0.028751

run [2400]:
Style Loss : 0.118307 Content Loss: 0.028837

run [2450]:
Style Loss : 0.117836 Content Loss: 0.028891

run [2500]:
Style Loss : 0.117784 Content Loss: 0.028965

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.916419 Content Loss: 0.001712

run [100]:
Style Loss : 1.186405 Content Loss: 0.002731

run [150]:
Style Loss : 0.884133 Content Loss: 0.004014

run [200]:
Style Loss : 0.716416 Content Loss: 0.005283

run [250]:
Style Loss : 0.611663 Content Loss: 0.006627

run [300]:
Style Loss : 0.538804 Content Loss: 0.008231

run [350]:
Style Loss : 0.482825 Content Loss: 0.009691

run [400]:
Style Loss : 0.441960 Content Loss: 0.011094

run [450]:
Style Loss : 0.408099 Content Loss: 0.012415

run [500]:
Style Loss : 0.381781 Content Loss: 0.013566

run [550]:
Style Loss : 0.359926 Content Loss: 0.014588

run [600]:
Style Loss : 0.340734 Content Loss: 0.015597

run [650]:
Style Loss : 0.324799 Content Loss: 0.016298

run [700]:
Style Loss : 0.311814 Content Loss: 0.016989

run [750]:
Style Loss : 0.300956 Content Loss: 0.017583

run [800]:
Style Loss : 0.292097 Content Loss: 0.018167

run [850]:
Style Loss : 0.285036 Content Loss: 0.018650

run [900]:
Style Loss : 0.279582 Content Loss: 0.019042

run [950]:
Style Loss : 0.274882 Content Loss: 0.019418

run [1000]:
Style Loss : 0.271036 Content Loss: 0.019701

run [1050]:
Style Loss : 0.267571 Content Loss: 0.019977

run [1100]:
Style Loss : 0.264390 Content Loss: 0.020229

run [1150]:
Style Loss : 0.261349 Content Loss: 0.020445

run [1200]:
Style Loss : 0.258346 Content Loss: 0.020611

run [1250]:
Style Loss : 0.255749 Content Loss: 0.020767

run [1300]:
Style Loss : 0.253413 Content Loss: 0.020896

run [1350]:
Style Loss : 0.251164 Content Loss: 0.021042

run [1400]:
Style Loss : 0.249144 Content Loss: 0.021144

run [1450]:
Style Loss : 0.246872 Content Loss: 0.021273

run [1500]:
Style Loss : 0.244877 Content Loss: 0.021384

run [1550]:
Style Loss : 0.243078 Content Loss: 0.021466

run [1600]:
Style Loss : 0.241342 Content Loss: 0.021556

run [1650]:
Style Loss : 0.239701 Content Loss: 0.021623

run [1700]:
Style Loss : 0.238188 Content Loss: 0.021700

run [1750]:
Style Loss : 0.236755 Content Loss: 0.021774

run [1800]:
Style Loss : 0.235087 Content Loss: 0.021853

run [1850]:
Style Loss : 0.233650 Content Loss: 0.021917

run [1900]:
Style Loss : 0.232410 Content Loss: 0.021975

run [1950]:
Style Loss : 0.231114 Content Loss: 0.022034

run [2000]:
Style Loss : 0.229840 Content Loss: 0.022093

run [2050]:
Style Loss : 0.228673 Content Loss: 0.022161

run [2100]:
Style Loss : 0.227370 Content Loss: 0.022216

run [2150]:
Style Loss : 0.226277 Content Loss: 0.022268

run [2200]:
Style Loss : 0.225269 Content Loss: 0.022321

run [2250]:
Style Loss : 0.224244 Content Loss: 0.022392

run [2300]:
Style Loss : 0.223317 Content Loss: 0.022453

run [2350]:
Style Loss : 0.222308 Content Loss: 0.022509

run [2400]:
Style Loss : 0.221426 Content Loss: 0.022581

run [2450]:
Style Loss : 0.220605 Content Loss: 0.022646

run [2500]:
Style Loss : 0.219746 Content Loss: 0.022722

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.001249 Content Loss: 0.003861

run [100]:
Style Loss : 0.573304 Content Loss: 0.007545

run [150]:
Style Loss : 0.433028 Content Loss: 0.010972

run [200]:
Style Loss : 0.365868 Content Loss: 0.013695

run [250]:
Style Loss : 0.326613 Content Loss: 0.015434

run [300]:
Style Loss : 0.302825 Content Loss: 0.016712

run [350]:
Style Loss : 0.287181 Content Loss: 0.017718

run [400]:
Style Loss : 0.275943 Content Loss: 0.018389

run [450]:
Style Loss : 0.267344 Content Loss: 0.018915

run [500]:
Style Loss : 0.261039 Content Loss: 0.019408

run [550]:
Style Loss : 0.256269 Content Loss: 0.019826

run [600]:
Style Loss : 0.252120 Content Loss: 0.020231

run [650]:
Style Loss : 0.248660 Content Loss: 0.020575

run [700]:
Style Loss : 0.245767 Content Loss: 0.020873

run [750]:
Style Loss : 0.243490 Content Loss: 0.021102

run [800]:
Style Loss : 0.241533 Content Loss: 0.021298

run [850]:
Style Loss : 0.239769 Content Loss: 0.021503

run [900]:
Style Loss : 0.238041 Content Loss: 0.021697

run [950]:
Style Loss : 0.236480 Content Loss: 0.021859

run [1000]:
Style Loss : 0.235034 Content Loss: 0.022032

run [1050]:
Style Loss : 0.233651 Content Loss: 0.022151

run [1100]:
Style Loss : 0.232377 Content Loss: 0.022279

run [1150]:
Style Loss : 0.231113 Content Loss: 0.022425

run [1200]:
Style Loss : 0.229852 Content Loss: 0.022556

run [1250]:
Style Loss : 0.228615 Content Loss: 0.022654

run [1300]:
Style Loss : 0.367818 Content Loss: 0.023120

run [1350]:
Style Loss : 0.173796 Content Loss: 0.023006

run [1400]:
Style Loss : 0.164458 Content Loss: 0.023013

run [1450]:
Style Loss : 0.159161 Content Loss: 0.023066

run [1500]:
Style Loss : 0.155415 Content Loss: 0.023154

run [1550]:
Style Loss : 0.151682 Content Loss: 0.023237

run [1600]:
Style Loss : 0.149193 Content Loss: 0.023309

run [1650]:
Style Loss : 0.147052 Content Loss: 0.023366

run [1700]:
Style Loss : 0.145319 Content Loss: 0.023421

run [1750]:
Style Loss : 0.143917 Content Loss: 0.023460

run [1800]:
Style Loss : 0.142636 Content Loss: 0.023492

run [1850]:
Style Loss : 0.141666 Content Loss: 0.023508

run [1900]:
Style Loss : 0.140799 Content Loss: 0.023525

run [1950]:
Style Loss : 0.140070 Content Loss: 0.023543

run [2000]:
Style Loss : 0.139303 Content Loss: 0.023569

run [2050]:
Style Loss : 0.138607 Content Loss: 0.023580

run [2100]:
Style Loss : 0.137957 Content Loss: 0.023599

run [2150]:
Style Loss : 0.137449 Content Loss: 0.023620

run [2200]:
Style Loss : 0.136933 Content Loss: 0.023639

run [2250]:
Style Loss : 0.136447 Content Loss: 0.023663

run [2300]:
Style Loss : 0.136047 Content Loss: 0.023683

run [2350]:
Style Loss : 0.135660 Content Loss: 0.023704

run [2400]:
Style Loss : 0.135293 Content Loss: 0.023722

run [2450]:
Style Loss : 0.134962 Content Loss: 0.023738

run [2500]:
Style Loss : 0.134649 Content Loss: 0.023762

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.739633 Content Loss: 0.003012

run [100]:
Style Loss : 0.445751 Content Loss: 0.004828

run [150]:
Style Loss : 0.336116 Content Loss: 0.006802

run [200]:
Style Loss : 0.258249 Content Loss: 0.008973

run [250]:
Style Loss : 0.206568 Content Loss: 0.011102

run [300]:
Style Loss : 0.181438 Content Loss: 0.012903

run [350]:
Style Loss : 0.165881 Content Loss: 0.014184

run [400]:
Style Loss : 0.153151 Content Loss: 0.015092

run [450]:
Style Loss : 0.143567 Content Loss: 0.015754

run [500]:
Style Loss : 0.136072 Content Loss: 0.016387

run [550]:
Style Loss : 0.130139 Content Loss: 0.016964

run [600]:
Style Loss : 0.125270 Content Loss: 0.017481

run [650]:
Style Loss : 0.121018 Content Loss: 0.017952

run [700]:
Style Loss : 0.117389 Content Loss: 0.018351

run [750]:
Style Loss : 0.114140 Content Loss: 0.018716

run [800]:
Style Loss : 0.111509 Content Loss: 0.019024

run [850]:
Style Loss : 0.109150 Content Loss: 0.019289

run [900]:
Style Loss : 0.106908 Content Loss: 0.019513

run [950]:
Style Loss : 0.104988 Content Loss: 0.019725

run [1000]:
Style Loss : 0.103316 Content Loss: 0.019904

run [1050]:
Style Loss : 0.101766 Content Loss: 0.020079

run [1100]:
Style Loss : 0.100414 Content Loss: 0.020235

run [1150]:
Style Loss : 0.099322 Content Loss: 0.020351

run [1200]:
Style Loss : 0.098327 Content Loss: 0.020449

run [1250]:
Style Loss : 0.097500 Content Loss: 0.020508

run [1300]:
Style Loss : 0.096791 Content Loss: 0.020580

run [1350]:
Style Loss : 0.096066 Content Loss: 0.020629

run [1400]:
Style Loss : 0.095440 Content Loss: 0.020663

run [1450]:
Style Loss : 0.094867 Content Loss: 0.020707

run [1500]:
Style Loss : 0.094309 Content Loss: 0.020755

run [1550]:
Style Loss : 0.093767 Content Loss: 0.020806

run [1600]:
Style Loss : 0.093236 Content Loss: 0.020858

run [1650]:
Style Loss : 0.092669 Content Loss: 0.020921

run [1700]:
Style Loss : 0.092151 Content Loss: 0.020992

run [1750]:
Style Loss : 0.091536 Content Loss: 0.021054

run [1800]:
Style Loss : 0.091023 Content Loss: 0.021120

run [1850]:
Style Loss : 0.090541 Content Loss: 0.021207

run [1900]:
Style Loss : 0.089996 Content Loss: 0.021291

run [1950]:
Style Loss : 0.089557 Content Loss: 0.021363

run [2000]:
Style Loss : 0.089084 Content Loss: 0.021415

run [2050]:
Style Loss : 0.088730 Content Loss: 0.021497

run [2100]:
Style Loss : 0.088259 Content Loss: 0.021550

run [2150]:
Style Loss : 0.087936 Content Loss: 0.021641

run [2200]:
Style Loss : 0.087721 Content Loss: 0.021752

run [2250]:
Style Loss : 0.087347 Content Loss: 0.021869

run [2300]:
Style Loss : 0.086908 Content Loss: 0.021974

run [2350]:
Style Loss : 0.086688 Content Loss: 0.022131

run [2400]:
Style Loss : 0.243522 Content Loss: 0.024588

run [2450]:
Style Loss : 0.114661 Content Loss: 0.024455

run [2500]:
Style Loss : 0.096613 Content Loss: 0.024834

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.670528 Content Loss: 0.015221

run [100]:
Style Loss : 1.458220 Content Loss: 0.020854

run [150]:
Style Loss : 1.024742 Content Loss: 0.025385

run [200]:
Style Loss : 0.836344 Content Loss: 0.028998

run [250]:
Style Loss : 0.724506 Content Loss: 0.031965

run [300]:
Style Loss : 0.657859 Content Loss: 0.033890

run [350]:
Style Loss : 0.612322 Content Loss: 0.035414

run [400]:
Style Loss : 0.578441 Content Loss: 0.036580

run [450]:
Style Loss : 0.553025 Content Loss: 0.037577

run [500]:
Style Loss : 0.532419 Content Loss: 0.038474

run [550]:
Style Loss : 0.515382 Content Loss: 0.039258

run [600]:
Style Loss : 0.500642 Content Loss: 0.039975

run [650]:
Style Loss : 0.488847 Content Loss: 0.040649

run [700]:
Style Loss : 0.477356 Content Loss: 0.041164

run [750]:
Style Loss : 0.468205 Content Loss: 0.041716

run [800]:
Style Loss : 0.460536 Content Loss: 0.042200

run [850]:
Style Loss : 0.453300 Content Loss: 0.042667

run [900]:
Style Loss : 0.446634 Content Loss: 0.043058

run [950]:
Style Loss : 0.440974 Content Loss: 0.043382

run [1000]:
Style Loss : 0.435703 Content Loss: 0.043737

run [1050]:
Style Loss : 0.430219 Content Loss: 0.044022

run [1100]:
Style Loss : 0.425560 Content Loss: 0.044308

run [1150]:
Style Loss : 0.421091 Content Loss: 0.044544

run [1200]:
Style Loss : 0.416675 Content Loss: 0.044819

run [1250]:
Style Loss : 0.412466 Content Loss: 0.045057

run [1300]:
Style Loss : 0.408483 Content Loss: 0.045309

run [1350]:
Style Loss : 0.404925 Content Loss: 0.045504

run [1400]:
Style Loss : 0.401363 Content Loss: 0.045725

run [1450]:
Style Loss : 0.398138 Content Loss: 0.045881

run [1500]:
Style Loss : 0.395047 Content Loss: 0.046031

run [1550]:
Style Loss : 0.392273 Content Loss: 0.046168

run [1600]:
Style Loss : 0.389747 Content Loss: 0.046339

run [1650]:
Style Loss : 0.386860 Content Loss: 0.046402

run [1700]:
Style Loss : 0.384335 Content Loss: 0.046547

run [1750]:
Style Loss : 0.381985 Content Loss: 0.046672

run [1800]:
Style Loss : 0.379552 Content Loss: 0.046775

run [1850]:
Style Loss : 0.377470 Content Loss: 0.046877

run [1900]:
Style Loss : 0.375735 Content Loss: 0.046960

run [1950]:
Style Loss : 0.374161 Content Loss: 0.047013

run [2000]:
Style Loss : 0.372707 Content Loss: 0.047105

run [2050]:
Style Loss : 0.371214 Content Loss: 0.047155

run [2100]:
Style Loss : 0.369810 Content Loss: 0.047188

run [2150]:
Style Loss : 0.369023 Content Loss: 0.047297

run [2200]:
Style Loss : 0.367421 Content Loss: 0.047276

run [2250]:
Style Loss : 0.366305 Content Loss: 0.047355

run [2300]:
Style Loss : 0.365199 Content Loss: 0.047387

run [2350]:
Style Loss : 0.364194 Content Loss: 0.047431

run [2400]:
Style Loss : 0.363484 Content Loss: 0.047462

run [2450]:
Style Loss : 0.362860 Content Loss: 0.047499

run [2500]:
Style Loss : 0.361850 Content Loss: 0.047503

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.704281 Content Loss: 0.001606

run [100]:
Style Loss : 1.066211 Content Loss: 0.003407

run [150]:
Style Loss : 0.781140 Content Loss: 0.006300

run [200]:
Style Loss : 0.613095 Content Loss: 0.009993

run [250]:
Style Loss : 0.498729 Content Loss: 0.013864

run [300]:
Style Loss : 0.418557 Content Loss: 0.017407

run [350]:
Style Loss : 0.359832 Content Loss: 0.020109

run [400]:
Style Loss : 0.313874 Content Loss: 0.022224

run [450]:
Style Loss : 0.279017 Content Loss: 0.023896

run [500]:
Style Loss : 0.255810 Content Loss: 0.025097

run [550]:
Style Loss : 0.240136 Content Loss: 0.025993

run [600]:
Style Loss : 0.229230 Content Loss: 0.026680

run [650]:
Style Loss : 0.220758 Content Loss: 0.027145

run [700]:
Style Loss : 0.213943 Content Loss: 0.027519

run [750]:
Style Loss : 0.207925 Content Loss: 0.027861

run [800]:
Style Loss : 0.202631 Content Loss: 0.028155

run [850]:
Style Loss : 0.198297 Content Loss: 0.028459

run [900]:
Style Loss : 0.194209 Content Loss: 0.028773

run [950]:
Style Loss : 0.190590 Content Loss: 0.029066

run [1000]:
Style Loss : 0.187347 Content Loss: 0.029331

run [1050]:
Style Loss : 0.184354 Content Loss: 0.029589

run [1100]:
Style Loss : 0.181820 Content Loss: 0.029814

run [1150]:
Style Loss : 0.179576 Content Loss: 0.030079

run [1200]:
Style Loss : 0.177481 Content Loss: 0.030295

run [1250]:
Style Loss : 0.175590 Content Loss: 0.030525

run [1300]:
Style Loss : 0.173482 Content Loss: 0.030763

run [1350]:
Style Loss : 0.171433 Content Loss: 0.030985

run [1400]:
Style Loss : 0.169683 Content Loss: 0.031163

run [1450]:
Style Loss : 0.168184 Content Loss: 0.031357

run [1500]:
Style Loss : 0.166764 Content Loss: 0.031531

run [1550]:
Style Loss : 0.165528 Content Loss: 0.031732

run [1600]:
Style Loss : 0.164167 Content Loss: 0.031899

run [1650]:
Style Loss : 0.163042 Content Loss: 0.032088

run [1700]:
Style Loss : 0.161609 Content Loss: 0.032223

run [1750]:
Style Loss : 0.160580 Content Loss: 0.032393

run [1800]:
Style Loss : 0.159328 Content Loss: 0.032545

run [1850]:
Style Loss : 0.158128 Content Loss: 0.032710

run [1900]:
Style Loss : 0.157276 Content Loss: 0.032934

run [1950]:
Style Loss : 0.156050 Content Loss: 0.033115

run [2000]:
Style Loss : 0.154544 Content Loss: 0.033268

run [2050]:
Style Loss : 0.153525 Content Loss: 0.033477

run [2100]:
Style Loss : 0.152720 Content Loss: 0.033668

run [2150]:
Style Loss : 0.151482 Content Loss: 0.033814

run [2200]:
Style Loss : 0.150586 Content Loss: 0.034005

run [2250]:
Style Loss : 0.150133 Content Loss: 0.034241

run [2300]:
Style Loss : 0.149190 Content Loss: 0.034395

run [2350]:
Style Loss : 0.148143 Content Loss: 0.034556

run [2400]:
Style Loss : 0.147510 Content Loss: 0.034740

run [2450]:
Style Loss : 0.148297 Content Loss: 0.035054

run [2500]:
Style Loss : 0.147233 Content Loss: 0.035213

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.539439 Content Loss: 0.002271

run [100]:
Style Loss : 0.913077 Content Loss: 0.005362

run [150]:
Style Loss : 0.643554 Content Loss: 0.010607

run [200]:
Style Loss : 0.491050 Content Loss: 0.016140

run [250]:
Style Loss : 0.391209 Content Loss: 0.020872

run [300]:
Style Loss : 0.323609 Content Loss: 0.023903

run [350]:
Style Loss : 0.268836 Content Loss: 0.025880

run [400]:
Style Loss : 0.229621 Content Loss: 0.027482

run [450]:
Style Loss : 0.203063 Content Loss: 0.028683

run [500]:
Style Loss : 0.185300 Content Loss: 0.029554

run [550]:
Style Loss : 0.172073 Content Loss: 0.030051

run [600]:
Style Loss : 0.161420 Content Loss: 0.030435

run [650]:
Style Loss : 0.153507 Content Loss: 0.030832

run [700]:
Style Loss : 0.146856 Content Loss: 0.031152

run [750]:
Style Loss : 0.140953 Content Loss: 0.031412

run [800]:
Style Loss : 0.135776 Content Loss: 0.031623

run [850]:
Style Loss : 0.131314 Content Loss: 0.031850

run [900]:
Style Loss : 0.127176 Content Loss: 0.032037

run [950]:
Style Loss : 0.123381 Content Loss: 0.032231

run [1000]:
Style Loss : 0.120074 Content Loss: 0.032415

run [1050]:
Style Loss : 0.117178 Content Loss: 0.032573

run [1100]:
Style Loss : 0.114185 Content Loss: 0.032749

run [1150]:
Style Loss : 0.111273 Content Loss: 0.032887

run [1200]:
Style Loss : 0.109043 Content Loss: 0.033015

run [1250]:
Style Loss : 0.106913 Content Loss: 0.033140

run [1300]:
Style Loss : 0.104902 Content Loss: 0.033246

run [1350]:
Style Loss : 0.103262 Content Loss: 0.033348

run [1400]:
Style Loss : 0.101712 Content Loss: 0.033432

run [1450]:
Style Loss : 0.100325 Content Loss: 0.033504

run [1500]:
Style Loss : 0.099097 Content Loss: 0.033567

run [1550]:
Style Loss : 0.098101 Content Loss: 0.033623

run [1600]:
Style Loss : 0.097228 Content Loss: 0.033672

run [1650]:
Style Loss : 0.096424 Content Loss: 0.033713

run [1700]:
Style Loss : 0.095663 Content Loss: 0.033738

run [1750]:
Style Loss : 0.094960 Content Loss: 0.033746

run [1800]:
Style Loss : 0.094287 Content Loss: 0.033755

run [1850]:
Style Loss : 0.093540 Content Loss: 0.033756

run [1900]:
Style Loss : 0.091951 Content Loss: 0.033751

run [1950]:
Style Loss : 0.090969 Content Loss: 0.033742

run [2000]:
Style Loss : 0.090317 Content Loss: 0.033727

run [2050]:
Style Loss : 0.089723 Content Loss: 0.033719

run [2100]:
Style Loss : 0.089231 Content Loss: 0.033708

run [2150]:
Style Loss : 0.088802 Content Loss: 0.033697

run [2200]:
Style Loss : 0.088410 Content Loss: 0.033685

run [2250]:
Style Loss : 0.088063 Content Loss: 0.033665

run [2300]:
Style Loss : 0.087783 Content Loss: 0.033643

run [2350]:
Style Loss : 0.087473 Content Loss: 0.033619

run [2400]:
Style Loss : 0.087198 Content Loss: 0.033593

run [2450]:
Style Loss : 0.086907 Content Loss: 0.033570

run [2500]:
Style Loss : 0.086672 Content Loss: 0.033542

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.299047 Content Loss: 0.001671

run [100]:
Style Loss : 0.761952 Content Loss: 0.002885

run [150]:
Style Loss : 0.555990 Content Loss: 0.004825

run [200]:
Style Loss : 0.435844 Content Loss: 0.007584

run [250]:
Style Loss : 0.355791 Content Loss: 0.010502

run [300]:
Style Loss : 0.298287 Content Loss: 0.013242

run [350]:
Style Loss : 0.255402 Content Loss: 0.015759

run [400]:
Style Loss : 0.222310 Content Loss: 0.017621

run [450]:
Style Loss : 0.197219 Content Loss: 0.019097

run [500]:
Style Loss : 0.178524 Content Loss: 0.020437

run [550]:
Style Loss : 0.166117 Content Loss: 0.021321

run [600]:
Style Loss : 0.156638 Content Loss: 0.021993

run [650]:
Style Loss : 0.149396 Content Loss: 0.022441

run [700]:
Style Loss : 0.143622 Content Loss: 0.022808

run [750]:
Style Loss : 0.138955 Content Loss: 0.023110

run [800]:
Style Loss : 0.135129 Content Loss: 0.023354

run [850]:
Style Loss : 0.131705 Content Loss: 0.023551

run [900]:
Style Loss : 0.128651 Content Loss: 0.023741

run [950]:
Style Loss : 0.126017 Content Loss: 0.023929

run [1000]:
Style Loss : 0.123524 Content Loss: 0.024143

run [1050]:
Style Loss : 0.121374 Content Loss: 0.024337

run [1100]:
Style Loss : 0.119360 Content Loss: 0.024511

run [1150]:
Style Loss : 0.117461 Content Loss: 0.024707

run [1200]:
Style Loss : 0.115694 Content Loss: 0.024898

run [1250]:
Style Loss : 0.114270 Content Loss: 0.025061

run [1300]:
Style Loss : 0.112905 Content Loss: 0.025244

run [1350]:
Style Loss : 0.111597 Content Loss: 0.025413

run [1400]:
Style Loss : 0.110356 Content Loss: 0.025568

run [1450]:
Style Loss : 0.109155 Content Loss: 0.025725

run [1500]:
Style Loss : 0.108048 Content Loss: 0.025880

run [1550]:
Style Loss : 0.106945 Content Loss: 0.026019

run [1600]:
Style Loss : 0.105856 Content Loss: 0.026160

run [1650]:
Style Loss : 0.104732 Content Loss: 0.026302

run [1700]:
Style Loss : 0.103661 Content Loss: 0.026442

run [1750]:
Style Loss : 0.102580 Content Loss: 0.026571

run [1800]:
Style Loss : 0.101593 Content Loss: 0.026683

run [1850]:
Style Loss : 0.100679 Content Loss: 0.026818

run [1900]:
Style Loss : 0.099786 Content Loss: 0.026956

run [1950]:
Style Loss : 0.098921 Content Loss: 0.027051

run [2000]:
Style Loss : 0.098185 Content Loss: 0.027150

run [2050]:
Style Loss : 0.094242 Content Loss: 0.027321

run [2100]:
Style Loss : 0.085957 Content Loss: 0.027300

run [2150]:
Style Loss : 0.083851 Content Loss: 0.027360

run [2200]:
Style Loss : 0.082670 Content Loss: 0.027445

run [2250]:
Style Loss : 0.081784 Content Loss: 0.027517

run [2300]:
Style Loss : 0.080954 Content Loss: 0.027582

run [2350]:
Style Loss : 0.080161 Content Loss: 0.027678

run [2400]:
Style Loss : 0.079446 Content Loss: 0.027755

run [2450]:
Style Loss : 0.078747 Content Loss: 0.027837

run [2500]:
Style Loss : 0.078127 Content Loss: 0.027942

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.973080 Content Loss: 0.004740

run [100]:
Style Loss : 1.190491 Content Loss: 0.010776

run [150]:
Style Loss : 0.809373 Content Loss: 0.020150

run [200]:
Style Loss : 0.577387 Content Loss: 0.030064

run [250]:
Style Loss : 0.436962 Content Loss: 0.035116

run [300]:
Style Loss : 0.359444 Content Loss: 0.038278

run [350]:
Style Loss : 0.320742 Content Loss: 0.039842

run [400]:
Style Loss : 0.296335 Content Loss: 0.040590

run [450]:
Style Loss : 0.278947 Content Loss: 0.041155

run [500]:
Style Loss : 0.265717 Content Loss: 0.041971

run [550]:
Style Loss : 0.255560 Content Loss: 0.042625

run [600]:
Style Loss : 0.247778 Content Loss: 0.043240

run [650]:
Style Loss : 0.241112 Content Loss: 0.043826

run [700]:
Style Loss : 0.235510 Content Loss: 0.044224

run [750]:
Style Loss : 0.230353 Content Loss: 0.044611

run [800]:
Style Loss : 0.226563 Content Loss: 0.044989

run [850]:
Style Loss : 0.223014 Content Loss: 0.045307

run [900]:
Style Loss : 0.219827 Content Loss: 0.045549

run [950]:
Style Loss : 0.216957 Content Loss: 0.045721

run [1000]:
Style Loss : 0.214392 Content Loss: 0.045877

run [1050]:
Style Loss : 0.212199 Content Loss: 0.045981

run [1100]:
Style Loss : 0.210195 Content Loss: 0.046050

run [1150]:
Style Loss : 0.208683 Content Loss: 0.046114

run [1200]:
Style Loss : 0.207314 Content Loss: 0.046169

run [1250]:
Style Loss : 0.206052 Content Loss: 0.046229

run [1300]:
Style Loss : 0.204752 Content Loss: 0.046300

run [1350]:
Style Loss : 0.203926 Content Loss: 0.046415

run [1400]:
Style Loss : 0.202409 Content Loss: 0.046454

run [1450]:
Style Loss : 0.201360 Content Loss: 0.046528

run [1500]:
Style Loss : 0.200314 Content Loss: 0.046589

run [1550]:
Style Loss : 0.199148 Content Loss: 0.046641

run [1600]:
Style Loss : 0.198338 Content Loss: 0.046728

run [1650]:
Style Loss : 0.197026 Content Loss: 0.046829

run [1700]:
Style Loss : 0.195755 Content Loss: 0.046878

run [1750]:
Style Loss : 0.194932 Content Loss: 0.046923

run [1800]:
Style Loss : 0.194407 Content Loss: 0.047055

run [1850]:
Style Loss : 0.193047 Content Loss: 0.047105

run [1900]:
Style Loss : 0.192087 Content Loss: 0.047178

run [1950]:
Style Loss : 0.193933 Content Loss: 0.047318

run [2000]:
Style Loss : 0.190681 Content Loss: 0.047338

run [2050]:
Style Loss : 0.190001 Content Loss: 0.047445

run [2100]:
Style Loss : 0.193628 Content Loss: 0.047591

run [2150]:
Style Loss : 0.188650 Content Loss: 0.047587

run [2200]:
Style Loss : 0.188047 Content Loss: 0.047659

run [2250]:
Style Loss : 0.187767 Content Loss: 0.047722

run [2300]:
Style Loss : 0.197295 Content Loss: 0.047925

run [2350]:
Style Loss : 0.187242 Content Loss: 0.047848

run [2400]:
Style Loss : 0.186830 Content Loss: 0.048045

run [2450]:
Style Loss : 0.185148 Content Loss: 0.048095

run [2500]:
Style Loss : 0.184736 Content Loss: 0.048135

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.257898 Content Loss: 0.006299

run [100]:
Style Loss : 0.707183 Content Loss: 0.009952

run [150]:
Style Loss : 0.441869 Content Loss: 0.014787

run [200]:
Style Loss : 0.305444 Content Loss: 0.019442

run [250]:
Style Loss : 0.233351 Content Loss: 0.022876

run [300]:
Style Loss : 0.197527 Content Loss: 0.024846

run [350]:
Style Loss : 0.175968 Content Loss: 0.025821

run [400]:
Style Loss : 0.160796 Content Loss: 0.026388

run [450]:
Style Loss : 0.148895 Content Loss: 0.026891

run [500]:
Style Loss : 0.139265 Content Loss: 0.027322

run [550]:
Style Loss : 0.131823 Content Loss: 0.027792

run [600]:
Style Loss : 0.126205 Content Loss: 0.028213

run [650]:
Style Loss : 0.121814 Content Loss: 0.028593

run [700]:
Style Loss : 0.118073 Content Loss: 0.028895

run [750]:
Style Loss : 0.114826 Content Loss: 0.029187

run [800]:
Style Loss : 0.112029 Content Loss: 0.029393

run [850]:
Style Loss : 0.109495 Content Loss: 0.029605

run [900]:
Style Loss : 0.107372 Content Loss: 0.029790

run [950]:
Style Loss : 0.105432 Content Loss: 0.029947

run [1000]:
Style Loss : 0.103734 Content Loss: 0.030062

run [1050]:
Style Loss : 0.102168 Content Loss: 0.030178

run [1100]:
Style Loss : 0.100893 Content Loss: 0.030272

run [1150]:
Style Loss : 0.099788 Content Loss: 0.030327

run [1200]:
Style Loss : 0.098624 Content Loss: 0.030384

run [1250]:
Style Loss : 0.097590 Content Loss: 0.030432

run [1300]:
Style Loss : 0.096523 Content Loss: 0.030468

run [1350]:
Style Loss : 0.095687 Content Loss: 0.030490

run [1400]:
Style Loss : 0.094916 Content Loss: 0.030500

run [1450]:
Style Loss : 0.094052 Content Loss: 0.030509

run [1500]:
Style Loss : 0.093280 Content Loss: 0.030501

run [1550]:
Style Loss : 0.092434 Content Loss: 0.030503

run [1600]:
Style Loss : 0.091728 Content Loss: 0.030496

run [1650]:
Style Loss : 0.091056 Content Loss: 0.030493

run [1700]:
Style Loss : 0.090432 Content Loss: 0.030486

run [1750]:
Style Loss : 0.089799 Content Loss: 0.030483

run [1800]:
Style Loss : 0.089161 Content Loss: 0.030477

run [1850]:
Style Loss : 0.088553 Content Loss: 0.030478

run [1900]:
Style Loss : 0.087899 Content Loss: 0.030479

run [1950]:
Style Loss : 0.087364 Content Loss: 0.030471

run [2000]:
Style Loss : 0.086902 Content Loss: 0.030457

run [2050]:
Style Loss : 0.086438 Content Loss: 0.030444

run [2100]:
Style Loss : 0.086017 Content Loss: 0.030427

run [2150]:
Style Loss : 0.085614 Content Loss: 0.030421

run [2200]:
Style Loss : 0.085239 Content Loss: 0.030411

run [2250]:
Style Loss : 0.084829 Content Loss: 0.030399

run [2300]:
Style Loss : 0.084346 Content Loss: 0.030384

run [2350]:
Style Loss : 0.083904 Content Loss: 0.030371

run [2400]:
Style Loss : 0.083545 Content Loss: 0.030353

run [2450]:
Style Loss : 0.083214 Content Loss: 0.030332

run [2500]:
Style Loss : 0.082909 Content Loss: 0.030317

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.986583 Content Loss: 0.002732

run [100]:
Style Loss : 2.003370 Content Loss: 0.004139

run [150]:
Style Loss : 1.510294 Content Loss: 0.005053

run [200]:
Style Loss : 1.259681 Content Loss: 0.006298

run [250]:
Style Loss : 1.098542 Content Loss: 0.008062

run [300]:
Style Loss : 0.962966 Content Loss: 0.009897

run [350]:
Style Loss : 0.855127 Content Loss: 0.011867

run [400]:
Style Loss : 0.772687 Content Loss: 0.013837

run [450]:
Style Loss : 0.704802 Content Loss: 0.015930

run [500]:
Style Loss : 0.644881 Content Loss: 0.018066

run [550]:
Style Loss : 0.598314 Content Loss: 0.019737

run [600]:
Style Loss : 0.558624 Content Loss: 0.021398

run [650]:
Style Loss : 0.526508 Content Loss: 0.022996

run [700]:
Style Loss : 0.498770 Content Loss: 0.024203

run [750]:
Style Loss : 0.476358 Content Loss: 0.025234

run [800]:
Style Loss : 0.459008 Content Loss: 0.026039

run [850]:
Style Loss : 0.445320 Content Loss: 0.026818

run [900]:
Style Loss : 0.434031 Content Loss: 0.027402

run [950]:
Style Loss : 0.424496 Content Loss: 0.027935

run [1000]:
Style Loss : 0.416242 Content Loss: 0.028336

run [1050]:
Style Loss : 0.409307 Content Loss: 0.028708

run [1100]:
Style Loss : 0.402871 Content Loss: 0.029015

run [1150]:
Style Loss : 0.397039 Content Loss: 0.029316

run [1200]:
Style Loss : 0.392020 Content Loss: 0.029572

run [1250]:
Style Loss : 0.387251 Content Loss: 0.029834

run [1300]:
Style Loss : 0.382434 Content Loss: 0.030108

run [1350]:
Style Loss : 0.378157 Content Loss: 0.030350

run [1400]:
Style Loss : 0.374151 Content Loss: 0.030558

run [1450]:
Style Loss : 0.370640 Content Loss: 0.030788

run [1500]:
Style Loss : 0.367282 Content Loss: 0.030972

run [1550]:
Style Loss : 0.364278 Content Loss: 0.031183

run [1600]:
Style Loss : 0.361212 Content Loss: 0.031389

run [1650]:
Style Loss : 0.358264 Content Loss: 0.031584

run [1700]:
Style Loss : 0.355642 Content Loss: 0.031766

run [1750]:
Style Loss : 0.352922 Content Loss: 0.031945

run [1800]:
Style Loss : 0.350385 Content Loss: 0.032105

run [1850]:
Style Loss : 0.347957 Content Loss: 0.032264

run [1900]:
Style Loss : 0.345822 Content Loss: 0.032424

run [1950]:
Style Loss : 0.343678 Content Loss: 0.032590

run [2000]:
Style Loss : 0.341573 Content Loss: 0.032739

run [2050]:
Style Loss : 0.339524 Content Loss: 0.032895

run [2100]:
Style Loss : 0.337448 Content Loss: 0.033052

run [2150]:
Style Loss : 0.335246 Content Loss: 0.033197

run [2200]:
Style Loss : 0.333186 Content Loss: 0.033350

run [2250]:
Style Loss : 0.331243 Content Loss: 0.033479

run [2300]:
Style Loss : 0.329464 Content Loss: 0.033603

run [2350]:
Style Loss : 0.327767 Content Loss: 0.033731

run [2400]:
Style Loss : 0.326039 Content Loss: 0.033850

run [2450]:
Style Loss : 0.324450 Content Loss: 0.033959

run [2500]:
Style Loss : 0.322844 Content Loss: 0.034073

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.991756 Content Loss: 0.002531

run [100]:
Style Loss : 1.270926 Content Loss: 0.002839

run [150]:
Style Loss : 1.000211 Content Loss: 0.003579

run [200]:
Style Loss : 0.843773 Content Loss: 0.004807

run [250]:
Style Loss : 0.732950 Content Loss: 0.006529

run [300]:
Style Loss : 0.646712 Content Loss: 0.008499

run [350]:
Style Loss : 0.577813 Content Loss: 0.010673

run [400]:
Style Loss : 0.522995 Content Loss: 0.012830

run [450]:
Style Loss : 0.478048 Content Loss: 0.014748

run [500]:
Style Loss : 0.439791 Content Loss: 0.016619

run [550]:
Style Loss : 0.406598 Content Loss: 0.018157

run [600]:
Style Loss : 0.379167 Content Loss: 0.019533

run [650]:
Style Loss : 0.355840 Content Loss: 0.020849

run [700]:
Style Loss : 0.337501 Content Loss: 0.022008

run [750]:
Style Loss : 0.322563 Content Loss: 0.022829

run [800]:
Style Loss : 0.311247 Content Loss: 0.023440

run [850]:
Style Loss : 0.302413 Content Loss: 0.023955

run [900]:
Style Loss : 0.294968 Content Loss: 0.024320

run [950]:
Style Loss : 0.288844 Content Loss: 0.024707

run [1000]:
Style Loss : 0.283124 Content Loss: 0.025001

run [1050]:
Style Loss : 0.278207 Content Loss: 0.025254

run [1100]:
Style Loss : 0.273750 Content Loss: 0.025489

run [1150]:
Style Loss : 0.269487 Content Loss: 0.025679

run [1200]:
Style Loss : 0.265093 Content Loss: 0.025917

run [1250]:
Style Loss : 0.261087 Content Loss: 0.026122

run [1300]:
Style Loss : 0.257362 Content Loss: 0.026303

run [1350]:
Style Loss : 0.253932 Content Loss: 0.026467

run [1400]:
Style Loss : 0.250544 Content Loss: 0.026653

run [1450]:
Style Loss : 0.247156 Content Loss: 0.026818

run [1500]:
Style Loss : 0.243808 Content Loss: 0.026974

run [1550]:
Style Loss : 0.240587 Content Loss: 0.027127

run [1600]:
Style Loss : 0.237606 Content Loss: 0.027257

run [1650]:
Style Loss : 0.234645 Content Loss: 0.027404

run [1700]:
Style Loss : 0.232071 Content Loss: 0.027521

run [1750]:
Style Loss : 0.229541 Content Loss: 0.027662

run [1800]:
Style Loss : 0.227259 Content Loss: 0.027774

run [1850]:
Style Loss : 0.225013 Content Loss: 0.027910

run [1900]:
Style Loss : 0.222821 Content Loss: 0.028038

run [1950]:
Style Loss : 0.220718 Content Loss: 0.028157

run [2000]:
Style Loss : 0.218878 Content Loss: 0.028278

run [2050]:
Style Loss : 0.217152 Content Loss: 0.028397

run [2100]:
Style Loss : 0.215483 Content Loss: 0.028509

run [2150]:
Style Loss : 0.213815 Content Loss: 0.028628

run [2200]:
Style Loss : 0.212245 Content Loss: 0.028738

run [2250]:
Style Loss : 0.210716 Content Loss: 0.028848

run [2300]:
Style Loss : 0.208999 Content Loss: 0.028948

run [2350]:
Style Loss : 0.207347 Content Loss: 0.029058

run [2400]:
Style Loss : 0.205884 Content Loss: 0.029145

run [2450]:
Style Loss : 0.204355 Content Loss: 0.029240

run [2500]:
Style Loss : 0.202892 Content Loss: 0.029326

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.295571 Content Loss: 0.003216

run [100]:
Style Loss : 1.438885 Content Loss: 0.004797

run [150]:
Style Loss : 1.016806 Content Loss: 0.007427

run [200]:
Style Loss : 0.791377 Content Loss: 0.010789

run [250]:
Style Loss : 0.651679 Content Loss: 0.014094

run [300]:
Style Loss : 0.565030 Content Loss: 0.017015

run [350]:
Style Loss : 0.502577 Content Loss: 0.019461

run [400]:
Style Loss : 0.457281 Content Loss: 0.021119

run [450]:
Style Loss : 0.422925 Content Loss: 0.022206

run [500]:
Style Loss : 0.397684 Content Loss: 0.023224

run [550]:
Style Loss : 0.376907 Content Loss: 0.024108

run [600]:
Style Loss : 0.360980 Content Loss: 0.024873

run [650]:
Style Loss : 0.348116 Content Loss: 0.025656

run [700]:
Style Loss : 0.337945 Content Loss: 0.026295

run [750]:
Style Loss : 0.330093 Content Loss: 0.026802

run [800]:
Style Loss : 0.323212 Content Loss: 0.027308

run [850]:
Style Loss : 0.317350 Content Loss: 0.027756

run [900]:
Style Loss : 0.311960 Content Loss: 0.028149

run [950]:
Style Loss : 0.307393 Content Loss: 0.028537

run [1000]:
Style Loss : 0.302889 Content Loss: 0.028844

run [1050]:
Style Loss : 0.299299 Content Loss: 0.029095

run [1100]:
Style Loss : 0.296047 Content Loss: 0.029353

run [1150]:
Style Loss : 0.293249 Content Loss: 0.029575

run [1200]:
Style Loss : 0.290699 Content Loss: 0.029774

run [1250]:
Style Loss : 0.288378 Content Loss: 0.029967

run [1300]:
Style Loss : 0.286206 Content Loss: 0.030192

run [1350]:
Style Loss : 0.284099 Content Loss: 0.030369

run [1400]:
Style Loss : 0.282007 Content Loss: 0.030529

run [1450]:
Style Loss : 0.280246 Content Loss: 0.030677

run [1500]:
Style Loss : 0.278676 Content Loss: 0.030783

run [1550]:
Style Loss : 0.277228 Content Loss: 0.030916

run [1600]:
Style Loss : 0.275840 Content Loss: 0.031054

run [1650]:
Style Loss : 0.274264 Content Loss: 0.031152

run [1700]:
Style Loss : 0.273461 Content Loss: 0.031319

run [1750]:
Style Loss : 0.276763 Content Loss: 0.031744

run [1800]:
Style Loss : 0.270625 Content Loss: 0.031563

run [1850]:
Style Loss : 0.268867 Content Loss: 0.031615

run [1900]:
Style Loss : 0.267529 Content Loss: 0.031709

run [1950]:
Style Loss : 0.266452 Content Loss: 0.031812

run [2000]:
Style Loss : 0.265452 Content Loss: 0.031900

run [2050]:
Style Loss : 0.264546 Content Loss: 0.032012

run [2100]:
Style Loss : 0.263403 Content Loss: 0.032097

run [2150]:
Style Loss : 0.262578 Content Loss: 0.032217

run [2200]:
Style Loss : 0.261309 Content Loss: 0.032210

run [2250]:
Style Loss : 0.270298 Content Loss: 0.032531

run [2300]:
Style Loss : 0.259770 Content Loss: 0.032408

run [2350]:
Style Loss : 0.258475 Content Loss: 0.032400

run [2400]:
Style Loss : 0.257655 Content Loss: 0.032430

run [2450]:
Style Loss : 0.256996 Content Loss: 0.032520

run [2500]:
Style Loss : 0.256209 Content Loss: 0.032539

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.687308 Content Loss: 0.002315

run [100]:
Style Loss : 1.569553 Content Loss: 0.002607

run [150]:
Style Loss : 1.195833 Content Loss: 0.003062

run [200]:
Style Loss : 0.983118 Content Loss: 0.003637

run [250]:
Style Loss : 0.852057 Content Loss: 0.004271

run [300]:
Style Loss : 0.758725 Content Loss: 0.004921

run [350]:
Style Loss : 0.689465 Content Loss: 0.005698

run [400]:
Style Loss : 0.635379 Content Loss: 0.006511

run [450]:
Style Loss : 0.591978 Content Loss: 0.007284

run [500]:
Style Loss : 0.557202 Content Loss: 0.008065

run [550]:
Style Loss : 0.528490 Content Loss: 0.008856

run [600]:
Style Loss : 0.504166 Content Loss: 0.009650

run [650]:
Style Loss : 0.483776 Content Loss: 0.010423

run [700]:
Style Loss : 0.465359 Content Loss: 0.011242

run [750]:
Style Loss : 0.449202 Content Loss: 0.011955

run [800]:
Style Loss : 0.435204 Content Loss: 0.012680

run [850]:
Style Loss : 0.422543 Content Loss: 0.013294

run [900]:
Style Loss : 0.410791 Content Loss: 0.013885

run [950]:
Style Loss : 0.400172 Content Loss: 0.014451

run [1000]:
Style Loss : 0.390084 Content Loss: 0.014954

run [1050]:
Style Loss : 0.381391 Content Loss: 0.015380

run [1100]:
Style Loss : 0.373322 Content Loss: 0.015759

run [1150]:
Style Loss : 0.366134 Content Loss: 0.016063

run [1200]:
Style Loss : 0.360151 Content Loss: 0.016403

run [1250]:
Style Loss : 0.355069 Content Loss: 0.016655

run [1300]:
Style Loss : 0.349878 Content Loss: 0.016897

run [1350]:
Style Loss : 0.345502 Content Loss: 0.017071

run [1400]:
Style Loss : 0.341832 Content Loss: 0.017240

run [1450]:
Style Loss : 0.338165 Content Loss: 0.017404

run [1500]:
Style Loss : 0.334553 Content Loss: 0.017565

run [1550]:
Style Loss : 0.330870 Content Loss: 0.017697

run [1600]:
Style Loss : 0.327470 Content Loss: 0.017826

run [1650]:
Style Loss : 0.324644 Content Loss: 0.017916

run [1700]:
Style Loss : 0.322134 Content Loss: 0.018004

run [1750]:
Style Loss : 0.320053 Content Loss: 0.018078

run [1800]:
Style Loss : 0.318166 Content Loss: 0.018151

run [1850]:
Style Loss : 0.316462 Content Loss: 0.018216

run [1900]:
Style Loss : 0.314826 Content Loss: 0.018285

run [1950]:
Style Loss : 0.313393 Content Loss: 0.018335

run [2000]:
Style Loss : 0.312001 Content Loss: 0.018384

run [2050]:
Style Loss : 0.310702 Content Loss: 0.018433

run [2100]:
Style Loss : 0.309513 Content Loss: 0.018474

run [2150]:
Style Loss : 0.308425 Content Loss: 0.018513

run [2200]:
Style Loss : 0.307333 Content Loss: 0.018549

run [2250]:
Style Loss : 0.306261 Content Loss: 0.018581

run [2300]:
Style Loss : 0.305268 Content Loss: 0.018614

run [2350]:
Style Loss : 0.304342 Content Loss: 0.018647

run [2400]:
Style Loss : 0.303391 Content Loss: 0.018676

run [2450]:
Style Loss : 0.302492 Content Loss: 0.018707

run [2500]:
Style Loss : 0.301674 Content Loss: 0.018733

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.671316 Content Loss: 0.004095

run [100]:
Style Loss : 1.962271 Content Loss: 0.004147

run [150]:
Style Loss : 1.419040 Content Loss: 0.004644

run [200]:
Style Loss : 1.167665 Content Loss: 0.005457

run [250]:
Style Loss : 0.999389 Content Loss: 0.006531

run [300]:
Style Loss : 0.876621 Content Loss: 0.007631

run [350]:
Style Loss : 0.790828 Content Loss: 0.008825

run [400]:
Style Loss : 0.723723 Content Loss: 0.009945

run [450]:
Style Loss : 0.670341 Content Loss: 0.011202

run [500]:
Style Loss : 0.626945 Content Loss: 0.012227

run [550]:
Style Loss : 0.591931 Content Loss: 0.013293

run [600]:
Style Loss : 0.561028 Content Loss: 0.014269

run [650]:
Style Loss : 0.535608 Content Loss: 0.015127

run [700]:
Style Loss : 0.514765 Content Loss: 0.015923

run [750]:
Style Loss : 0.497684 Content Loss: 0.016712

run [800]:
Style Loss : 0.482931 Content Loss: 0.017323

run [850]:
Style Loss : 0.469210 Content Loss: 0.017897

run [900]:
Style Loss : 0.456869 Content Loss: 0.018313

run [950]:
Style Loss : 0.446064 Content Loss: 0.018729

run [1000]:
Style Loss : 0.436058 Content Loss: 0.019100

run [1050]:
Style Loss : 0.427562 Content Loss: 0.019441

run [1100]:
Style Loss : 0.419344 Content Loss: 0.019756

run [1150]:
Style Loss : 0.411814 Content Loss: 0.020034

run [1200]:
Style Loss : 0.403862 Content Loss: 0.020327

run [1250]:
Style Loss : 0.396099 Content Loss: 0.020582

run [1300]:
Style Loss : 0.387573 Content Loss: 0.020853

run [1350]:
Style Loss : 0.378834 Content Loss: 0.021081

run [1400]:
Style Loss : 0.371254 Content Loss: 0.021242

run [1450]:
Style Loss : 0.364711 Content Loss: 0.021410

run [1500]:
Style Loss : 0.358795 Content Loss: 0.021558

run [1550]:
Style Loss : 0.352760 Content Loss: 0.021689

run [1600]:
Style Loss : 0.347222 Content Loss: 0.021796

run [1650]:
Style Loss : 0.342361 Content Loss: 0.021902

run [1700]:
Style Loss : 0.337900 Content Loss: 0.022034

run [1750]:
Style Loss : 0.333628 Content Loss: 0.022129

run [1800]:
Style Loss : 0.329682 Content Loss: 0.022214

run [1850]:
Style Loss : 0.326336 Content Loss: 0.022289

run [1900]:
Style Loss : 0.322916 Content Loss: 0.022388

run [1950]:
Style Loss : 0.319848 Content Loss: 0.022473

run [2000]:
Style Loss : 0.316666 Content Loss: 0.022568

run [2050]:
Style Loss : 0.313878 Content Loss: 0.022644

run [2100]:
Style Loss : 0.311253 Content Loss: 0.022716

run [2150]:
Style Loss : 0.308882 Content Loss: 0.022790

run [2200]:
Style Loss : 0.306801 Content Loss: 0.022859

run [2250]:
Style Loss : 0.304998 Content Loss: 0.022912

run [2300]:
Style Loss : 0.303249 Content Loss: 0.022976

run [2350]:
Style Loss : 0.301610 Content Loss: 0.023026

run [2400]:
Style Loss : 0.300305 Content Loss: 0.023069

run [2450]:
Style Loss : 0.299022 Content Loss: 0.023119

run [2500]:
Style Loss : 0.297791 Content Loss: 0.023168

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.895044 Content Loss: 0.005166

run [100]:
Style Loss : 2.488518 Content Loss: 0.005907

run [150]:
Style Loss : 1.947610 Content Loss: 0.006929

run [200]:
Style Loss : 1.614888 Content Loss: 0.008016

run [250]:
Style Loss : 1.374588 Content Loss: 0.009410

run [300]:
Style Loss : 1.202822 Content Loss: 0.010562

run [350]:
Style Loss : 1.083170 Content Loss: 0.011786

run [400]:
Style Loss : 0.989153 Content Loss: 0.013052

run [450]:
Style Loss : 0.911807 Content Loss: 0.014127

run [500]:
Style Loss : 0.849476 Content Loss: 0.015196

run [550]:
Style Loss : 0.797252 Content Loss: 0.016214

run [600]:
Style Loss : 0.754259 Content Loss: 0.017077

run [650]:
Style Loss : 0.720636 Content Loss: 0.017990

run [700]:
Style Loss : 0.693406 Content Loss: 0.018838

run [750]:
Style Loss : 0.669398 Content Loss: 0.019644

run [800]:
Style Loss : 0.650097 Content Loss: 0.020196

run [850]:
Style Loss : 0.633956 Content Loss: 0.020791

run [900]:
Style Loss : 0.619927 Content Loss: 0.021310

run [950]:
Style Loss : 0.607778 Content Loss: 0.021816

run [1000]:
Style Loss : 0.597967 Content Loss: 0.022217

run [1050]:
Style Loss : 0.589569 Content Loss: 0.022515

run [1100]:
Style Loss : 0.581088 Content Loss: 0.022821

run [1150]:
Style Loss : 0.574225 Content Loss: 0.023067

run [1200]:
Style Loss : 0.567148 Content Loss: 0.023304

run [1250]:
Style Loss : 0.561251 Content Loss: 0.023490

run [1300]:
Style Loss : 0.555372 Content Loss: 0.023688

run [1350]:
Style Loss : 0.549803 Content Loss: 0.023855

run [1400]:
Style Loss : 0.544158 Content Loss: 0.024032

run [1450]:
Style Loss : 0.539420 Content Loss: 0.024166

run [1500]:
Style Loss : 0.535105 Content Loss: 0.024287

run [1550]:
Style Loss : 0.530932 Content Loss: 0.024424

run [1600]:
Style Loss : 0.527116 Content Loss: 0.024509

run [1650]:
Style Loss : 0.523772 Content Loss: 0.024615

run [1700]:
Style Loss : 0.520728 Content Loss: 0.024704

run [1750]:
Style Loss : 0.517903 Content Loss: 0.024791

run [1800]:
Style Loss : 0.515375 Content Loss: 0.024869

run [1850]:
Style Loss : 0.512996 Content Loss: 0.024949

run [1900]:
Style Loss : 0.510860 Content Loss: 0.025018

run [1950]:
Style Loss : 0.508784 Content Loss: 0.025084

run [2000]:
Style Loss : 0.506797 Content Loss: 0.025162

run [2050]:
Style Loss : 0.504951 Content Loss: 0.025231

run [2100]:
Style Loss : 0.503261 Content Loss: 0.025293

run [2150]:
Style Loss : 0.501638 Content Loss: 0.025358

run [2200]:
Style Loss : 0.500111 Content Loss: 0.025408

run [2250]:
Style Loss : 0.498661 Content Loss: 0.025458

run [2300]:
Style Loss : 0.497256 Content Loss: 0.025516

run [2350]:
Style Loss : 0.495868 Content Loss: 0.025561

run [2400]:
Style Loss : 0.494454 Content Loss: 0.025614

run [2450]:
Style Loss : 0.493071 Content Loss: 0.025669

run [2500]:
Style Loss : 0.491718 Content Loss: 0.025709

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.040195 Content Loss: 0.004270

run [100]:
Style Loss : 1.265598 Content Loss: 0.004783

run [150]:
Style Loss : 0.947933 Content Loss: 0.006008

run [200]:
Style Loss : 0.746896 Content Loss: 0.007676

run [250]:
Style Loss : 0.595207 Content Loss: 0.009337

run [300]:
Style Loss : 0.477150 Content Loss: 0.011178

run [350]:
Style Loss : 0.382392 Content Loss: 0.012990

run [400]:
Style Loss : 0.310547 Content Loss: 0.014856

run [450]:
Style Loss : 0.258353 Content Loss: 0.016654

run [500]:
Style Loss : 0.221392 Content Loss: 0.018305

run [550]:
Style Loss : 0.195032 Content Loss: 0.019862

run [600]:
Style Loss : 0.175866 Content Loss: 0.020889

run [650]:
Style Loss : 0.161665 Content Loss: 0.021758

run [700]:
Style Loss : 0.151145 Content Loss: 0.022201

run [750]:
Style Loss : 0.142803 Content Loss: 0.022547

run [800]:
Style Loss : 0.135977 Content Loss: 0.022849

run [850]:
Style Loss : 0.130145 Content Loss: 0.023119

run [900]:
Style Loss : 0.125077 Content Loss: 0.023388

run [950]:
Style Loss : 0.120729 Content Loss: 0.023618

run [1000]:
Style Loss : 0.116785 Content Loss: 0.023851

run [1050]:
Style Loss : 0.113233 Content Loss: 0.024061

run [1100]:
Style Loss : 0.110076 Content Loss: 0.024236

run [1150]:
Style Loss : 0.107139 Content Loss: 0.024418

run [1200]:
Style Loss : 0.104634 Content Loss: 0.024577

run [1250]:
Style Loss : 0.102206 Content Loss: 0.024725

run [1300]:
Style Loss : 0.099952 Content Loss: 0.024893

run [1350]:
Style Loss : 0.097918 Content Loss: 0.025036

run [1400]:
Style Loss : 0.095935 Content Loss: 0.025183

run [1450]:
Style Loss : 0.094180 Content Loss: 0.025321

run [1500]:
Style Loss : 0.092497 Content Loss: 0.025444

run [1550]:
Style Loss : 0.090952 Content Loss: 0.025570

run [1600]:
Style Loss : 0.089584 Content Loss: 0.025660

run [1650]:
Style Loss : 0.088200 Content Loss: 0.025770

run [1700]:
Style Loss : 0.087093 Content Loss: 0.025854

run [1750]:
Style Loss : 0.085942 Content Loss: 0.025932

run [1800]:
Style Loss : 0.084766 Content Loss: 0.026018

run [1850]:
Style Loss : 0.083680 Content Loss: 0.026096

run [1900]:
Style Loss : 0.082593 Content Loss: 0.026169

run [1950]:
Style Loss : 0.081542 Content Loss: 0.026239

run [2000]:
Style Loss : 0.080408 Content Loss: 0.026308

run [2050]:
Style Loss : 0.079307 Content Loss: 0.026362

run [2100]:
Style Loss : 0.078258 Content Loss: 0.026419

run [2150]:
Style Loss : 0.077291 Content Loss: 0.026466

run [2200]:
Style Loss : 0.076423 Content Loss: 0.026511

run [2250]:
Style Loss : 0.075589 Content Loss: 0.026545

run [2300]:
Style Loss : 0.074772 Content Loss: 0.026562

run [2350]:
Style Loss : 0.073994 Content Loss: 0.026586

run [2400]:
Style Loss : 0.073287 Content Loss: 0.026601

run [2450]:
Style Loss : 0.072603 Content Loss: 0.026626

run [2500]:
Style Loss : 0.071976 Content Loss: 0.026646

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.780035 Content Loss: 0.002501

run [100]:
Style Loss : 1.123366 Content Loss: 0.003603

run [150]:
Style Loss : 0.885379 Content Loss: 0.005576

run [200]:
Style Loss : 0.745733 Content Loss: 0.007874

run [250]:
Style Loss : 0.652503 Content Loss: 0.009970

run [300]:
Style Loss : 0.590809 Content Loss: 0.011792

run [350]:
Style Loss : 0.547560 Content Loss: 0.013390

run [400]:
Style Loss : 0.514463 Content Loss: 0.014754

run [450]:
Style Loss : 0.488006 Content Loss: 0.015920

run [500]:
Style Loss : 0.467430 Content Loss: 0.016818

run [550]:
Style Loss : 0.451670 Content Loss: 0.017702

run [600]:
Style Loss : 0.437573 Content Loss: 0.018584

run [650]:
Style Loss : 0.425361 Content Loss: 0.019217

run [700]:
Style Loss : 0.414500 Content Loss: 0.019770

run [750]:
Style Loss : 0.405744 Content Loss: 0.020216

run [800]:
Style Loss : 0.398722 Content Loss: 0.020592

run [850]:
Style Loss : 0.392583 Content Loss: 0.020971

run [900]:
Style Loss : 0.387201 Content Loss: 0.021326

run [950]:
Style Loss : 0.382479 Content Loss: 0.021622

run [1000]:
Style Loss : 0.378222 Content Loss: 0.021896

run [1050]:
Style Loss : 0.374325 Content Loss: 0.022101

run [1100]:
Style Loss : 0.370828 Content Loss: 0.022309

run [1150]:
Style Loss : 0.367624 Content Loss: 0.022510

run [1200]:
Style Loss : 0.364645 Content Loss: 0.022682

run [1250]:
Style Loss : 0.361789 Content Loss: 0.022861

run [1300]:
Style Loss : 0.359098 Content Loss: 0.023023

run [1350]:
Style Loss : 0.356736 Content Loss: 0.023180

run [1400]:
Style Loss : 0.354429 Content Loss: 0.023331

run [1450]:
Style Loss : 0.352378 Content Loss: 0.023465

run [1500]:
Style Loss : 0.350494 Content Loss: 0.023574

run [1550]:
Style Loss : 0.348850 Content Loss: 0.023663

run [1600]:
Style Loss : 0.347274 Content Loss: 0.023756

run [1650]:
Style Loss : 0.344940 Content Loss: 0.023849

run [1700]:
Style Loss : 0.342791 Content Loss: 0.023950

run [1750]:
Style Loss : 0.340737 Content Loss: 0.024062

run [1800]:
Style Loss : 0.339127 Content Loss: 0.024108

run [1850]:
Style Loss : 0.337627 Content Loss: 0.024195

run [1900]:
Style Loss : 0.336264 Content Loss: 0.024276

run [1950]:
Style Loss : 0.334987 Content Loss: 0.024347

run [2000]:
Style Loss : 0.333670 Content Loss: 0.024419

run [2050]:
Style Loss : 0.332394 Content Loss: 0.024477

run [2100]:
Style Loss : 0.331207 Content Loss: 0.024556

run [2150]:
Style Loss : 0.330054 Content Loss: 0.024627

run [2200]:
Style Loss : 0.328348 Content Loss: 0.024688

run [2250]:
Style Loss : 0.327139 Content Loss: 0.024739

run [2300]:
Style Loss : 0.326193 Content Loss: 0.024780

run [2350]:
Style Loss : 0.325274 Content Loss: 0.024833

run [2400]:
Style Loss : 0.324402 Content Loss: 0.024894

run [2450]:
Style Loss : 0.323364 Content Loss: 0.024944

run [2500]:
Style Loss : 0.322461 Content Loss: 0.025003

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.210550 Content Loss: 0.001745

run [100]:
Style Loss : 0.782329 Content Loss: 0.002509

run [150]:
Style Loss : 0.618531 Content Loss: 0.003663

run [200]:
Style Loss : 0.522818 Content Loss: 0.004961

run [250]:
Style Loss : 0.459669 Content Loss: 0.006470

run [300]:
Style Loss : 0.415835 Content Loss: 0.007703

run [350]:
Style Loss : 0.379989 Content Loss: 0.008739

run [400]:
Style Loss : 0.349013 Content Loss: 0.009451

run [450]:
Style Loss : 0.323128 Content Loss: 0.010092

run [500]:
Style Loss : 0.302042 Content Loss: 0.010637

run [550]:
Style Loss : 0.285687 Content Loss: 0.011105

run [600]:
Style Loss : 0.271385 Content Loss: 0.011620

run [650]:
Style Loss : 0.259798 Content Loss: 0.012043

run [700]:
Style Loss : 0.250240 Content Loss: 0.012425

run [750]:
Style Loss : 0.242727 Content Loss: 0.012723

run [800]:
Style Loss : 0.235982 Content Loss: 0.013068

run [850]:
Style Loss : 0.230314 Content Loss: 0.013344

run [900]:
Style Loss : 0.225639 Content Loss: 0.013600

run [950]:
Style Loss : 0.220987 Content Loss: 0.013840

run [1000]:
Style Loss : 0.217053 Content Loss: 0.014036

run [1050]:
Style Loss : 0.213628 Content Loss: 0.014234

run [1100]:
Style Loss : 0.210618 Content Loss: 0.014403

run [1150]:
Style Loss : 0.208173 Content Loss: 0.014545

run [1200]:
Style Loss : 0.205960 Content Loss: 0.014683

run [1250]:
Style Loss : 0.204019 Content Loss: 0.014823

run [1300]:
Style Loss : 0.202193 Content Loss: 0.014944

run [1350]:
Style Loss : 0.200563 Content Loss: 0.015056

run [1400]:
Style Loss : 0.199066 Content Loss: 0.015184

run [1450]:
Style Loss : 0.197563 Content Loss: 0.015269

run [1500]:
Style Loss : 0.196148 Content Loss: 0.015389

run [1550]:
Style Loss : 0.193786 Content Loss: 0.015518

run [1600]:
Style Loss : 0.191626 Content Loss: 0.015628

run [1650]:
Style Loss : 0.190126 Content Loss: 0.015714

run [1700]:
Style Loss : 0.188569 Content Loss: 0.015832

run [1750]:
Style Loss : 0.187052 Content Loss: 0.015927

run [1800]:
Style Loss : 0.185235 Content Loss: 0.016032

run [1850]:
Style Loss : 0.183217 Content Loss: 0.016139

run [1900]:
Style Loss : 0.181617 Content Loss: 0.016223

run [1950]:
Style Loss : 0.180186 Content Loss: 0.016294

run [2000]:
Style Loss : 0.178800 Content Loss: 0.016373

run [2050]:
Style Loss : 0.177289 Content Loss: 0.016455

run [2100]:
Style Loss : 0.173246 Content Loss: 0.016535

run [2150]:
Style Loss : 0.169741 Content Loss: 0.016630

run [2200]:
Style Loss : 0.167229 Content Loss: 0.016704

run [2250]:
Style Loss : 0.165413 Content Loss: 0.016754

run [2300]:
Style Loss : 0.163734 Content Loss: 0.016829

run [2350]:
Style Loss : 0.162147 Content Loss: 0.016886

run [2400]:
Style Loss : 0.160685 Content Loss: 0.016938

run [2450]:
Style Loss : 0.159161 Content Loss: 0.016983

run [2500]:
Style Loss : 0.157789 Content Loss: 0.017020

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.103111 Content Loss: 0.002705

run [100]:
Style Loss : 0.691306 Content Loss: 0.006411

run [150]:
Style Loss : 0.489467 Content Loss: 0.010257

run [200]:
Style Loss : 0.380804 Content Loss: 0.013330

run [250]:
Style Loss : 0.316659 Content Loss: 0.015417

run [300]:
Style Loss : 0.276513 Content Loss: 0.017308

run [350]:
Style Loss : 0.248757 Content Loss: 0.018622

run [400]:
Style Loss : 0.229361 Content Loss: 0.019878

run [450]:
Style Loss : 0.215260 Content Loss: 0.020893

run [500]:
Style Loss : 0.203038 Content Loss: 0.021792

run [550]:
Style Loss : 0.191648 Content Loss: 0.022438

run [600]:
Style Loss : 0.182345 Content Loss: 0.022989

run [650]:
Style Loss : 0.174862 Content Loss: 0.023505

run [700]:
Style Loss : 0.168485 Content Loss: 0.023889

run [750]:
Style Loss : 0.163040 Content Loss: 0.024281

run [800]:
Style Loss : 0.158301 Content Loss: 0.024687

run [850]:
Style Loss : 0.153392 Content Loss: 0.025062

run [900]:
Style Loss : 0.149440 Content Loss: 0.025373

run [950]:
Style Loss : 0.146133 Content Loss: 0.025647

run [1000]:
Style Loss : 0.143096 Content Loss: 0.025949

run [1050]:
Style Loss : 0.140214 Content Loss: 0.026263

run [1100]:
Style Loss : 0.137609 Content Loss: 0.026560

run [1150]:
Style Loss : 0.135108 Content Loss: 0.026837

run [1200]:
Style Loss : 0.132855 Content Loss: 0.027127

run [1250]:
Style Loss : 0.130342 Content Loss: 0.027441

run [1300]:
Style Loss : 0.128094 Content Loss: 0.027724

run [1350]:
Style Loss : 0.126407 Content Loss: 0.028082

run [1400]:
Style Loss : 0.124417 Content Loss: 0.028358

run [1450]:
Style Loss : 0.122701 Content Loss: 0.028659

run [1500]:
Style Loss : 0.129443 Content Loss: 0.029679

run [1550]:
Style Loss : 0.120164 Content Loss: 0.029550

run [1600]:
Style Loss : 0.117398 Content Loss: 0.029656

run [1650]:
Style Loss : 0.117520 Content Loss: 0.029910

run [1700]:
Style Loss : 0.115021 Content Loss: 0.030122

run [1750]:
Style Loss : 0.116681 Content Loss: 0.030741

run [1800]:
Style Loss : 0.113285 Content Loss: 0.030798

run [1850]:
Style Loss : 0.113316 Content Loss: 0.031163

run [1900]:
Style Loss : 0.112526 Content Loss: 0.031494

run [1950]:
Style Loss : 0.124686 Content Loss: 0.032480

run [2000]:
Style Loss : 0.112253 Content Loss: 0.032283

run [2050]:
Style Loss : 0.110689 Content Loss: 0.032552

run [2100]:
Style Loss : 0.114827 Content Loss: 0.033199

run [2150]:
Style Loss : 0.109569 Content Loss: 0.033215

run [2200]:
Style Loss : 0.118040 Content Loss: 0.034325

run [2250]:
Style Loss : 0.109660 Content Loss: 0.034222

run [2300]:
Style Loss : 0.107554 Content Loss: 0.034326

run [2350]:
Style Loss : 0.106638 Content Loss: 0.034518

run [2400]:
Style Loss : 0.106384 Content Loss: 0.034625

run [2450]:
Style Loss : 0.129986 Content Loss: 0.034911

run [2500]:
Style Loss : 0.104621 Content Loss: 0.034729

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.860911 Content Loss: 0.001495

run [100]:
Style Loss : 0.542470 Content Loss: 0.002733

run [150]:
Style Loss : 0.407873 Content Loss: 0.004813

run [200]:
Style Loss : 0.325714 Content Loss: 0.007049

run [250]:
Style Loss : 0.275621 Content Loss: 0.008729

run [300]:
Style Loss : 0.240560 Content Loss: 0.010214

run [350]:
Style Loss : 0.214847 Content Loss: 0.011428

run [400]:
Style Loss : 0.194182 Content Loss: 0.012231

run [450]:
Style Loss : 0.178796 Content Loss: 0.013055

run [500]:
Style Loss : 0.167580 Content Loss: 0.013822

run [550]:
Style Loss : 0.158971 Content Loss: 0.014444

run [600]:
Style Loss : 0.151665 Content Loss: 0.015004

run [650]:
Style Loss : 0.146076 Content Loss: 0.015496

run [700]:
Style Loss : 0.141305 Content Loss: 0.015898

run [750]:
Style Loss : 0.137084 Content Loss: 0.016316

run [800]:
Style Loss : 0.133337 Content Loss: 0.016636

run [850]:
Style Loss : 0.129842 Content Loss: 0.016920

run [900]:
Style Loss : 0.126934 Content Loss: 0.017170

run [950]:
Style Loss : 0.124488 Content Loss: 0.017390

run [1000]:
Style Loss : 0.122160 Content Loss: 0.017607

run [1050]:
Style Loss : 0.120070 Content Loss: 0.017800

run [1100]:
Style Loss : 0.118274 Content Loss: 0.017954

run [1150]:
Style Loss : 0.116512 Content Loss: 0.018121

run [1200]:
Style Loss : 0.114790 Content Loss: 0.018280

run [1250]:
Style Loss : 0.113198 Content Loss: 0.018433

run [1300]:
Style Loss : 0.111684 Content Loss: 0.018578

run [1350]:
Style Loss : 0.110264 Content Loss: 0.018691

run [1400]:
Style Loss : 0.108991 Content Loss: 0.018802

run [1450]:
Style Loss : 0.107864 Content Loss: 0.018892

run [1500]:
Style Loss : 0.106862 Content Loss: 0.018981

run [1550]:
Style Loss : 0.105881 Content Loss: 0.019067

run [1600]:
Style Loss : 0.104972 Content Loss: 0.019142

run [1650]:
Style Loss : 0.104137 Content Loss: 0.019205

run [1700]:
Style Loss : 0.103352 Content Loss: 0.019275

run [1750]:
Style Loss : 0.102605 Content Loss: 0.019348

run [1800]:
Style Loss : 0.101914 Content Loss: 0.019412

run [1850]:
Style Loss : 0.101234 Content Loss: 0.019466

run [1900]:
Style Loss : 0.100519 Content Loss: 0.019515

run [1950]:
Style Loss : 0.099920 Content Loss: 0.019561

run [2000]:
Style Loss : 0.099388 Content Loss: 0.019589

run [2050]:
Style Loss : 0.098904 Content Loss: 0.019624

run [2100]:
Style Loss : 0.098451 Content Loss: 0.019656

run [2150]:
Style Loss : 0.097994 Content Loss: 0.019686

run [2200]:
Style Loss : 0.097561 Content Loss: 0.019718

run [2250]:
Style Loss : 0.097125 Content Loss: 0.019746

run [2300]:
Style Loss : 0.096745 Content Loss: 0.019771

run [2350]:
Style Loss : 0.096392 Content Loss: 0.019792

run [2400]:
Style Loss : 0.096034 Content Loss: 0.019819

run [2450]:
Style Loss : 0.095679 Content Loss: 0.019836

run [2500]:
Style Loss : 0.095368 Content Loss: 0.019856

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.044409 Content Loss: 0.002637

run [100]:
Style Loss : 2.197532 Content Loss: 0.002943

run [150]:
Style Loss : 1.557883 Content Loss: 0.003402

run [200]:
Style Loss : 1.247130 Content Loss: 0.003867

run [250]:
Style Loss : 1.069553 Content Loss: 0.004789

run [300]:
Style Loss : 0.948950 Content Loss: 0.005800

run [350]:
Style Loss : 0.858009 Content Loss: 0.006843

run [400]:
Style Loss : 0.783638 Content Loss: 0.007880

run [450]:
Style Loss : 0.725785 Content Loss: 0.008912

run [500]:
Style Loss : 0.678589 Content Loss: 0.009840

run [550]:
Style Loss : 0.642819 Content Loss: 0.010816

run [600]:
Style Loss : 0.612590 Content Loss: 0.011774

run [650]:
Style Loss : 0.587838 Content Loss: 0.012635

run [700]:
Style Loss : 0.566451 Content Loss: 0.013451

run [750]:
Style Loss : 0.547563 Content Loss: 0.014165

run [800]:
Style Loss : 0.530841 Content Loss: 0.014859

run [850]:
Style Loss : 0.516240 Content Loss: 0.015499

run [900]:
Style Loss : 0.503882 Content Loss: 0.016045

run [950]:
Style Loss : 0.493181 Content Loss: 0.016572

run [1000]:
Style Loss : 0.483715 Content Loss: 0.017033

run [1050]:
Style Loss : 0.475459 Content Loss: 0.017424

run [1100]:
Style Loss : 0.468445 Content Loss: 0.017737

run [1150]:
Style Loss : 0.462083 Content Loss: 0.018019

run [1200]:
Style Loss : 0.456669 Content Loss: 0.018246

run [1250]:
Style Loss : 0.451896 Content Loss: 0.018427

run [1300]:
Style Loss : 0.447597 Content Loss: 0.018618

run [1350]:
Style Loss : 0.443711 Content Loss: 0.018782

run [1400]:
Style Loss : 0.440207 Content Loss: 0.018921

run [1450]:
Style Loss : 0.436953 Content Loss: 0.019043

run [1500]:
Style Loss : 0.434105 Content Loss: 0.019172

run [1550]:
Style Loss : 0.431448 Content Loss: 0.019296

run [1600]:
Style Loss : 0.429093 Content Loss: 0.019387

run [1650]:
Style Loss : 0.426855 Content Loss: 0.019480

run [1700]:
Style Loss : 0.424943 Content Loss: 0.019560

run [1750]:
Style Loss : 0.423168 Content Loss: 0.019639

run [1800]:
Style Loss : 0.421594 Content Loss: 0.019704

run [1850]:
Style Loss : 0.420033 Content Loss: 0.019773

run [1900]:
Style Loss : 0.418490 Content Loss: 0.019847

run [1950]:
Style Loss : 0.416933 Content Loss: 0.019907

run [2000]:
Style Loss : 0.415468 Content Loss: 0.019979

run [2050]:
Style Loss : 0.413964 Content Loss: 0.020042

run [2100]:
Style Loss : 0.412440 Content Loss: 0.020112

run [2150]:
Style Loss : 0.410956 Content Loss: 0.020173

run [2200]:
Style Loss : 0.409490 Content Loss: 0.020238

run [2250]:
Style Loss : 0.407926 Content Loss: 0.020307

run [2300]:
Style Loss : 0.406414 Content Loss: 0.020368

run [2350]:
Style Loss : 0.404950 Content Loss: 0.020429

run [2400]:
Style Loss : 0.403580 Content Loss: 0.020480

run [2450]:
Style Loss : 0.402291 Content Loss: 0.020536

run [2500]:
Style Loss : 0.401104 Content Loss: 0.020591

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.977883 Content Loss: 0.001770

run [100]:
Style Loss : 0.609484 Content Loss: 0.004805

run [150]:
Style Loss : 0.424071 Content Loss: 0.008095

run [200]:
Style Loss : 0.324992 Content Loss: 0.010858

run [250]:
Style Loss : 0.268252 Content Loss: 0.012891

run [300]:
Style Loss : 0.231822 Content Loss: 0.014679

run [350]:
Style Loss : 0.205918 Content Loss: 0.016080

run [400]:
Style Loss : 0.187614 Content Loss: 0.017248

run [450]:
Style Loss : 0.174611 Content Loss: 0.018183

run [500]:
Style Loss : 0.164550 Content Loss: 0.018879

run [550]:
Style Loss : 0.156475 Content Loss: 0.019426

run [600]:
Style Loss : 0.150211 Content Loss: 0.019819

run [650]:
Style Loss : 0.144665 Content Loss: 0.020200

run [700]:
Style Loss : 0.140168 Content Loss: 0.020529

run [750]:
Style Loss : 0.136149 Content Loss: 0.020824

run [800]:
Style Loss : 0.132607 Content Loss: 0.021109

run [850]:
Style Loss : 0.129276 Content Loss: 0.021375

run [900]:
Style Loss : 0.126198 Content Loss: 0.021604

run [950]:
Style Loss : 0.123602 Content Loss: 0.021801

run [1000]:
Style Loss : 0.121349 Content Loss: 0.021985

run [1050]:
Style Loss : 0.119262 Content Loss: 0.022154

run [1100]:
Style Loss : 0.117509 Content Loss: 0.022309

run [1150]:
Style Loss : 0.115969 Content Loss: 0.022442

run [1200]:
Style Loss : 0.114583 Content Loss: 0.022584

run [1250]:
Style Loss : 0.113252 Content Loss: 0.022705

run [1300]:
Style Loss : 0.112060 Content Loss: 0.022812

run [1350]:
Style Loss : 0.111006 Content Loss: 0.022897

run [1400]:
Style Loss : 0.109911 Content Loss: 0.022978

run [1450]:
Style Loss : 0.108966 Content Loss: 0.023042

run [1500]:
Style Loss : 0.108096 Content Loss: 0.023100

run [1550]:
Style Loss : 0.107274 Content Loss: 0.023150

run [1600]:
Style Loss : 0.106554 Content Loss: 0.023179

run [1650]:
Style Loss : 0.105797 Content Loss: 0.023210

run [1700]:
Style Loss : 0.104324 Content Loss: 0.023247

run [1750]:
Style Loss : 0.103123 Content Loss: 0.023262

run [1800]:
Style Loss : 0.102252 Content Loss: 0.023278

run [1850]:
Style Loss : 0.101545 Content Loss: 0.023293

run [1900]:
Style Loss : 0.100906 Content Loss: 0.023310

run [1950]:
Style Loss : 0.100251 Content Loss: 0.023322

run [2000]:
Style Loss : 0.099680 Content Loss: 0.023332

run [2050]:
Style Loss : 0.099138 Content Loss: 0.023347

run [2100]:
Style Loss : 0.098578 Content Loss: 0.023359

run [2150]:
Style Loss : 0.098019 Content Loss: 0.023370

run [2200]:
Style Loss : 0.097477 Content Loss: 0.023383

run [2250]:
Style Loss : 0.097023 Content Loss: 0.023392

run [2300]:
Style Loss : 0.096577 Content Loss: 0.023399

run [2350]:
Style Loss : 0.096149 Content Loss: 0.023413

run [2400]:
Style Loss : 0.095697 Content Loss: 0.023428

run [2450]:
Style Loss : 0.095270 Content Loss: 0.023435

run [2500]:
Style Loss : 0.094874 Content Loss: 0.023445

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.164994 Content Loss: 0.002388

run [100]:
Style Loss : 1.431978 Content Loss: 0.003678

run [150]:
Style Loss : 1.098015 Content Loss: 0.005487

run [200]:
Style Loss : 0.912059 Content Loss: 0.007686

run [250]:
Style Loss : 0.786707 Content Loss: 0.010005

run [300]:
Style Loss : 0.697696 Content Loss: 0.012486

run [350]:
Style Loss : 0.629428 Content Loss: 0.014596

run [400]:
Style Loss : 0.576771 Content Loss: 0.016446

run [450]:
Style Loss : 0.533557 Content Loss: 0.018049

run [500]:
Style Loss : 0.500869 Content Loss: 0.019574

run [550]:
Style Loss : 0.474038 Content Loss: 0.020867

run [600]:
Style Loss : 0.453658 Content Loss: 0.021793

run [650]:
Style Loss : 0.437428 Content Loss: 0.022544

run [700]:
Style Loss : 0.424208 Content Loss: 0.023213

run [750]:
Style Loss : 0.413380 Content Loss: 0.023704

run [800]:
Style Loss : 0.403576 Content Loss: 0.024224

run [850]:
Style Loss : 0.396025 Content Loss: 0.024559

run [900]:
Style Loss : 0.389780 Content Loss: 0.024860

run [950]:
Style Loss : 0.383823 Content Loss: 0.025146

run [1000]:
Style Loss : 0.377928 Content Loss: 0.025418

run [1050]:
Style Loss : 0.371928 Content Loss: 0.025647

run [1100]:
Style Loss : 0.366838 Content Loss: 0.025827

run [1150]:
Style Loss : 0.362414 Content Loss: 0.026012

run [1200]:
Style Loss : 0.358091 Content Loss: 0.026192

run [1250]:
Style Loss : 0.354325 Content Loss: 0.026344

run [1300]:
Style Loss : 0.351171 Content Loss: 0.026481

run [1350]:
Style Loss : 0.348137 Content Loss: 0.026638

run [1400]:
Style Loss : 0.344756 Content Loss: 0.026810

run [1450]:
Style Loss : 0.341632 Content Loss: 0.026927

run [1500]:
Style Loss : 0.338683 Content Loss: 0.027051

run [1550]:
Style Loss : 0.336010 Content Loss: 0.027156

run [1600]:
Style Loss : 0.332710 Content Loss: 0.027265

run [1650]:
Style Loss : 0.329404 Content Loss: 0.027388

run [1700]:
Style Loss : 0.326778 Content Loss: 0.027467

run [1750]:
Style Loss : 0.323599 Content Loss: 0.027572

run [1800]:
Style Loss : 0.320188 Content Loss: 0.027652

run [1850]:
Style Loss : 0.317217 Content Loss: 0.027744

run [1900]:
Style Loss : 0.314714 Content Loss: 0.027823

run [1950]:
Style Loss : 0.312419 Content Loss: 0.027910

run [2000]:
Style Loss : 0.310194 Content Loss: 0.027993

run [2050]:
Style Loss : 0.308046 Content Loss: 0.028077

run [2100]:
Style Loss : 0.305846 Content Loss: 0.028160

run [2150]:
Style Loss : 0.303926 Content Loss: 0.028239

run [2200]:
Style Loss : 0.301986 Content Loss: 0.028319

run [2250]:
Style Loss : 0.300143 Content Loss: 0.028395

run [2300]:
Style Loss : 0.298506 Content Loss: 0.028467

run [2350]:
Style Loss : 0.297060 Content Loss: 0.028524

run [2400]:
Style Loss : 0.295674 Content Loss: 0.028589

run [2450]:
Style Loss : 0.294353 Content Loss: 0.028663

run [2500]:
Style Loss : 0.293031 Content Loss: 0.028731

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.435040 Content Loss: 0.002079

run [100]:
Style Loss : 0.889376 Content Loss: 0.003942

run [150]:
Style Loss : 0.681155 Content Loss: 0.005845

run [200]:
Style Loss : 0.559638 Content Loss: 0.007457

run [250]:
Style Loss : 0.483285 Content Loss: 0.008542

run [300]:
Style Loss : 0.433829 Content Loss: 0.009322

run [350]:
Style Loss : 0.403034 Content Loss: 0.009825

run [400]:
Style Loss : 0.381968 Content Loss: 0.010279

run [450]:
Style Loss : 0.366093 Content Loss: 0.010630

run [500]:
Style Loss : 0.353784 Content Loss: 0.010992

run [550]:
Style Loss : 0.344121 Content Loss: 0.011237

run [600]:
Style Loss : 0.336392 Content Loss: 0.011412

run [650]:
Style Loss : 0.329992 Content Loss: 0.011588

run [700]:
Style Loss : 0.324642 Content Loss: 0.011765

run [750]:
Style Loss : 0.320180 Content Loss: 0.011917

run [800]:
Style Loss : 0.316509 Content Loss: 0.012083

run [850]:
Style Loss : 0.313119 Content Loss: 0.012238

run [900]:
Style Loss : 0.309869 Content Loss: 0.012386

run [950]:
Style Loss : 0.306977 Content Loss: 0.012516

run [1000]:
Style Loss : 0.304466 Content Loss: 0.012635

run [1050]:
Style Loss : 0.302087 Content Loss: 0.012743

run [1100]:
Style Loss : 0.299912 Content Loss: 0.012846

run [1150]:
Style Loss : 0.297779 Content Loss: 0.012946

run [1200]:
Style Loss : 0.295595 Content Loss: 0.013058

run [1250]:
Style Loss : 0.293073 Content Loss: 0.013174

run [1300]:
Style Loss : 0.291041 Content Loss: 0.013272

run [1350]:
Style Loss : 0.289275 Content Loss: 0.013354

run [1400]:
Style Loss : 0.287623 Content Loss: 0.013438

run [1450]:
Style Loss : 0.286079 Content Loss: 0.013518

run [1500]:
Style Loss : 0.284585 Content Loss: 0.013607

run [1550]:
Style Loss : 0.283247 Content Loss: 0.013684

run [1600]:
Style Loss : 0.281971 Content Loss: 0.013753

run [1650]:
Style Loss : 0.280776 Content Loss: 0.013819

run [1700]:
Style Loss : 0.279691 Content Loss: 0.013885

run [1750]:
Style Loss : 0.278592 Content Loss: 0.013953

run [1800]:
Style Loss : 0.277339 Content Loss: 0.014022

run [1850]:
Style Loss : 0.276205 Content Loss: 0.014069

run [1900]:
Style Loss : 0.275226 Content Loss: 0.014127

run [1950]:
Style Loss : 0.274233 Content Loss: 0.014175

run [2000]:
Style Loss : 0.273281 Content Loss: 0.014219

run [2050]:
Style Loss : 0.272392 Content Loss: 0.014267

run [2100]:
Style Loss : 0.271518 Content Loss: 0.014312

run [2150]:
Style Loss : 0.270754 Content Loss: 0.014359

run [2200]:
Style Loss : 0.270015 Content Loss: 0.014401

run [2250]:
Style Loss : 0.269303 Content Loss: 0.014455

run [2300]:
Style Loss : 0.268636 Content Loss: 0.014508

run [2350]:
Style Loss : 0.267985 Content Loss: 0.014546

run [2400]:
Style Loss : 0.267370 Content Loss: 0.014594

run [2450]:
Style Loss : 0.266837 Content Loss: 0.014635

run [2500]:
Style Loss : 0.266311 Content Loss: 0.014673

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.380919 Content Loss: 0.004458

run [100]:
Style Loss : 0.717574 Content Loss: 0.005486

run [150]:
Style Loss : 0.495482 Content Loss: 0.006726

run [200]:
Style Loss : 0.375906 Content Loss: 0.007795

run [250]:
Style Loss : 0.313240 Content Loss: 0.008734

run [300]:
Style Loss : 0.272342 Content Loss: 0.009680

run [350]:
Style Loss : 0.246946 Content Loss: 0.010352

run [400]:
Style Loss : 0.228949 Content Loss: 0.010878

run [450]:
Style Loss : 0.214808 Content Loss: 0.011268

run [500]:
Style Loss : 0.203744 Content Loss: 0.011597

run [550]:
Style Loss : 0.193803 Content Loss: 0.011865

run [600]:
Style Loss : 0.185710 Content Loss: 0.012029

run [650]:
Style Loss : 0.176397 Content Loss: 0.012208

run [700]:
Style Loss : 0.169534 Content Loss: 0.012335

run [750]:
Style Loss : 0.163752 Content Loss: 0.012496

run [800]:
Style Loss : 0.158641 Content Loss: 0.012613

run [850]:
Style Loss : 0.154391 Content Loss: 0.012710

run [900]:
Style Loss : 0.150568 Content Loss: 0.012810

run [950]:
Style Loss : 0.147039 Content Loss: 0.012902

run [1000]:
Style Loss : 0.144121 Content Loss: 0.012983

run [1050]:
Style Loss : 0.141596 Content Loss: 0.013051

run [1100]:
Style Loss : 0.139288 Content Loss: 0.013123

run [1150]:
Style Loss : 0.137128 Content Loss: 0.013198

run [1200]:
Style Loss : 0.135159 Content Loss: 0.013267

run [1250]:
Style Loss : 0.133481 Content Loss: 0.013323

run [1300]:
Style Loss : 0.131811 Content Loss: 0.013386

run [1350]:
Style Loss : 0.130232 Content Loss: 0.013442

run [1400]:
Style Loss : 0.128586 Content Loss: 0.013488

run [1450]:
Style Loss : 0.127095 Content Loss: 0.013535

run [1500]:
Style Loss : 0.125789 Content Loss: 0.013586

run [1550]:
Style Loss : 0.124498 Content Loss: 0.013627

run [1600]:
Style Loss : 0.123219 Content Loss: 0.013688

run [1650]:
Style Loss : 0.121921 Content Loss: 0.013754

run [1700]:
Style Loss : 0.120720 Content Loss: 0.013819

run [1750]:
Style Loss : 0.119577 Content Loss: 0.013885

run [1800]:
Style Loss : 0.118590 Content Loss: 0.013941

run [1850]:
Style Loss : 0.117622 Content Loss: 0.014005

run [1900]:
Style Loss : 0.116622 Content Loss: 0.014065

run [1950]:
Style Loss : 0.115624 Content Loss: 0.014138

run [2000]:
Style Loss : 0.114643 Content Loss: 0.014231

run [2050]:
Style Loss : 0.113679 Content Loss: 0.014299

run [2100]:
Style Loss : 0.112758 Content Loss: 0.014362

run [2150]:
Style Loss : 0.111915 Content Loss: 0.014415

run [2200]:
Style Loss : 0.111196 Content Loss: 0.014464

run [2250]:
Style Loss : 0.110518 Content Loss: 0.014527

run [2300]:
Style Loss : 0.109849 Content Loss: 0.014555

run [2350]:
Style Loss : 0.109248 Content Loss: 0.014599

run [2400]:
Style Loss : 0.108668 Content Loss: 0.014633

run [2450]:
Style Loss : 0.108129 Content Loss: 0.014683

run [2500]:
Style Loss : 0.107485 Content Loss: 0.014715

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.956077 Content Loss: 0.001875

run [100]:
Style Loss : 1.146625 Content Loss: 0.003647

run [150]:
Style Loss : 0.842456 Content Loss: 0.005398

run [200]:
Style Loss : 0.671061 Content Loss: 0.006586

run [250]:
Style Loss : 0.561015 Content Loss: 0.007414

run [300]:
Style Loss : 0.498925 Content Loss: 0.008069

run [350]:
Style Loss : 0.460454 Content Loss: 0.008627

run [400]:
Style Loss : 0.434099 Content Loss: 0.009107

run [450]:
Style Loss : 0.413726 Content Loss: 0.009486

run [500]:
Style Loss : 0.397722 Content Loss: 0.009785

run [550]:
Style Loss : 0.384403 Content Loss: 0.010060

run [600]:
Style Loss : 0.372537 Content Loss: 0.010297

run [650]:
Style Loss : 0.361983 Content Loss: 0.010503

run [700]:
Style Loss : 0.353152 Content Loss: 0.010666

run [750]:
Style Loss : 0.343965 Content Loss: 0.010814

run [800]:
Style Loss : 0.336353 Content Loss: 0.010916

run [850]:
Style Loss : 0.330173 Content Loss: 0.011004

run [900]:
Style Loss : 0.324855 Content Loss: 0.011096

run [950]:
Style Loss : 0.320095 Content Loss: 0.011171

run [1000]:
Style Loss : 0.315790 Content Loss: 0.011253

run [1050]:
Style Loss : 0.311615 Content Loss: 0.011326

run [1100]:
Style Loss : 0.307359 Content Loss: 0.011408

run [1150]:
Style Loss : 0.303510 Content Loss: 0.011475

run [1200]:
Style Loss : 0.299895 Content Loss: 0.011535

run [1250]:
Style Loss : 0.296408 Content Loss: 0.011603

run [1300]:
Style Loss : 0.292995 Content Loss: 0.011668

run [1350]:
Style Loss : 0.289496 Content Loss: 0.011736

run [1400]:
Style Loss : 0.286473 Content Loss: 0.011781

run [1450]:
Style Loss : 0.283673 Content Loss: 0.011850

run [1500]:
Style Loss : 0.280969 Content Loss: 0.011906

run [1550]:
Style Loss : 0.278428 Content Loss: 0.011965

run [1600]:
Style Loss : 0.275955 Content Loss: 0.012029

run [1650]:
Style Loss : 0.273365 Content Loss: 0.012090

run [1700]:
Style Loss : 0.270964 Content Loss: 0.012156

run [1750]:
Style Loss : 0.268615 Content Loss: 0.012210

run [1800]:
Style Loss : 0.266489 Content Loss: 0.012263

run [1850]:
Style Loss : 0.264361 Content Loss: 0.012312

run [1900]:
Style Loss : 0.262436 Content Loss: 0.012363

run [1950]:
Style Loss : 0.260671 Content Loss: 0.012408

run [2000]:
Style Loss : 0.259090 Content Loss: 0.012459

run [2050]:
Style Loss : 0.257455 Content Loss: 0.012500

run [2100]:
Style Loss : 0.255973 Content Loss: 0.012545

run [2150]:
Style Loss : 0.254599 Content Loss: 0.012587

run [2200]:
Style Loss : 0.253300 Content Loss: 0.012632

run [2250]:
Style Loss : 0.251966 Content Loss: 0.012682

run [2300]:
Style Loss : 0.250615 Content Loss: 0.012722

run [2350]:
Style Loss : 0.249434 Content Loss: 0.012763

run [2400]:
Style Loss : 0.248259 Content Loss: 0.012806

run [2450]:
Style Loss : 0.247056 Content Loss: 0.012853

run [2500]:
Style Loss : 0.245891 Content Loss: 0.012892

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.880423 Content Loss: 0.003514

run [100]:
Style Loss : 0.469841 Content Loss: 0.006144

run [150]:
Style Loss : 0.334134 Content Loss: 0.007790

run [200]:
Style Loss : 0.275687 Content Loss: 0.008989

run [250]:
Style Loss : 0.241427 Content Loss: 0.009805

run [300]:
Style Loss : 0.221389 Content Loss: 0.010414

run [350]:
Style Loss : 0.207739 Content Loss: 0.010912

run [400]:
Style Loss : 0.197727 Content Loss: 0.011317

run [450]:
Style Loss : 0.190891 Content Loss: 0.011621

run [500]:
Style Loss : 0.185283 Content Loss: 0.011925

run [550]:
Style Loss : 0.180483 Content Loss: 0.012136

run [600]:
Style Loss : 0.176459 Content Loss: 0.012318

run [650]:
Style Loss : 0.173539 Content Loss: 0.012470

run [700]:
Style Loss : 0.170888 Content Loss: 0.012620

run [750]:
Style Loss : 0.168798 Content Loss: 0.012714

run [800]:
Style Loss : 0.167055 Content Loss: 0.012817

run [850]:
Style Loss : 0.165693 Content Loss: 0.012900

run [900]:
Style Loss : 0.164266 Content Loss: 0.012963

run [950]:
Style Loss : 0.163065 Content Loss: 0.013011

run [1000]:
Style Loss : 0.161978 Content Loss: 0.013071

run [1050]:
Style Loss : 0.160725 Content Loss: 0.013103

run [1100]:
Style Loss : 0.159861 Content Loss: 0.013144

run [1150]:
Style Loss : 0.159005 Content Loss: 0.013174

run [1200]:
Style Loss : 0.158426 Content Loss: 0.013232

run [1250]:
Style Loss : 0.157479 Content Loss: 0.013270

run [1300]:
Style Loss : 0.156687 Content Loss: 0.013330

run [1350]:
Style Loss : 0.156020 Content Loss: 0.013390

run [1400]:
Style Loss : 0.155352 Content Loss: 0.013444

run [1450]:
Style Loss : 0.154594 Content Loss: 0.013488

run [1500]:
Style Loss : 0.154078 Content Loss: 0.013532

run [1550]:
Style Loss : 0.153459 Content Loss: 0.013602

run [1600]:
Style Loss : 0.152880 Content Loss: 0.013630

run [1650]:
Style Loss : 0.153289 Content Loss: 0.013741

run [1700]:
Style Loss : 0.151705 Content Loss: 0.013723

run [1750]:
Style Loss : 0.151258 Content Loss: 0.013816

run [1800]:
Style Loss : 0.153995 Content Loss: 0.014043

run [1850]:
Style Loss : 0.150027 Content Loss: 0.013960

run [1900]:
Style Loss : 0.149357 Content Loss: 0.013947

run [1950]:
Style Loss : 0.148958 Content Loss: 0.013940

run [2000]:
Style Loss : 0.148512 Content Loss: 0.013951

run [2050]:
Style Loss : 0.148219 Content Loss: 0.013976

run [2100]:
Style Loss : 0.147790 Content Loss: 0.013984

run [2150]:
Style Loss : 0.147484 Content Loss: 0.014012

run [2200]:
Style Loss : 0.155467 Content Loss: 0.014032

run [2250]:
Style Loss : 0.147331 Content Loss: 0.014092

run [2300]:
Style Loss : 0.146352 Content Loss: 0.014061

run [2350]:
Style Loss : 0.146680 Content Loss: 0.014151

run [2400]:
Style Loss : 0.145730 Content Loss: 0.014110

run [2450]:
Style Loss : 0.145484 Content Loss: 0.014141

run [2500]:
Style Loss : 0.145172 Content Loss: 0.014134

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.773093 Content Loss: 0.003389

run [100]:
Style Loss : 0.434615 Content Loss: 0.006483

run [150]:
Style Loss : 0.336247 Content Loss: 0.008932

run [200]:
Style Loss : 0.286207 Content Loss: 0.011361

run [250]:
Style Loss : 0.252902 Content Loss: 0.013581

run [300]:
Style Loss : 0.232250 Content Loss: 0.015428

run [350]:
Style Loss : 0.217741 Content Loss: 0.016737

run [400]:
Style Loss : 0.206713 Content Loss: 0.017533

run [450]:
Style Loss : 0.197323 Content Loss: 0.018068

run [500]:
Style Loss : 0.189467 Content Loss: 0.018388

run [550]:
Style Loss : 0.182972 Content Loss: 0.018601

run [600]:
Style Loss : 0.177417 Content Loss: 0.018787

run [650]:
Style Loss : 0.172412 Content Loss: 0.019021

run [700]:
Style Loss : 0.167672 Content Loss: 0.019227

run [750]:
Style Loss : 0.163169 Content Loss: 0.019510

run [800]:
Style Loss : 0.159408 Content Loss: 0.019809

run [850]:
Style Loss : 0.155503 Content Loss: 0.020072

run [900]:
Style Loss : 0.152632 Content Loss: 0.020328

run [950]:
Style Loss : 0.150023 Content Loss: 0.020598

run [1000]:
Style Loss : 0.146569 Content Loss: 0.020850

run [1050]:
Style Loss : 0.144231 Content Loss: 0.021014

run [1100]:
Style Loss : 0.131326 Content Loss: 0.021203

run [1150]:
Style Loss : 0.128257 Content Loss: 0.021249

run [1200]:
Style Loss : 0.126004 Content Loss: 0.021405

run [1250]:
Style Loss : 0.124135 Content Loss: 0.021538

run [1300]:
Style Loss : 0.122572 Content Loss: 0.021671

run [1350]:
Style Loss : 0.121135 Content Loss: 0.021781

run [1400]:
Style Loss : 0.119843 Content Loss: 0.021874

run [1450]:
Style Loss : 0.118706 Content Loss: 0.021955

run [1500]:
Style Loss : 0.117618 Content Loss: 0.022012

run [1550]:
Style Loss : 0.116582 Content Loss: 0.022047

run [1600]:
Style Loss : 0.115647 Content Loss: 0.022097

run [1650]:
Style Loss : 0.114754 Content Loss: 0.022131

run [1700]:
Style Loss : 0.114013 Content Loss: 0.022170

run [1750]:
Style Loss : 0.113343 Content Loss: 0.022223

run [1800]:
Style Loss : 0.112212 Content Loss: 0.022276

run [1850]:
Style Loss : 0.111497 Content Loss: 0.022324

run [1900]:
Style Loss : 0.110890 Content Loss: 0.022371

run [1950]:
Style Loss : 0.110326 Content Loss: 0.022417

run [2000]:
Style Loss : 0.109838 Content Loss: 0.022462

run [2050]:
Style Loss : 0.109289 Content Loss: 0.022482

run [2100]:
Style Loss : 0.109054 Content Loss: 0.022489

run [2150]:
Style Loss : 0.108457 Content Loss: 0.022521

run [2200]:
Style Loss : 0.108072 Content Loss: 0.022540

run [2250]:
Style Loss : 0.107657 Content Loss: 0.022571

run [2300]:
Style Loss : 0.107232 Content Loss: 0.022627

run [2350]:
Style Loss : 0.106645 Content Loss: 0.022666

run [2400]:
Style Loss : 0.106237 Content Loss: 0.022725

run [2450]:
Style Loss : 0.105827 Content Loss: 0.022758

run [2500]:
Style Loss : 0.105538 Content Loss: 0.022817

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.756336 Content Loss: 0.011751

run [100]:
Style Loss : 1.098261 Content Loss: 0.014493

run [150]:
Style Loss : 0.829717 Content Loss: 0.016220

run [200]:
Style Loss : 0.703693 Content Loss: 0.017723

run [250]:
Style Loss : 0.627648 Content Loss: 0.018827

run [300]:
Style Loss : 0.578064 Content Loss: 0.019772

run [350]:
Style Loss : 0.542270 Content Loss: 0.020482

run [400]:
Style Loss : 0.517238 Content Loss: 0.021043

run [450]:
Style Loss : 0.496262 Content Loss: 0.021595

run [500]:
Style Loss : 0.479693 Content Loss: 0.022072

run [550]:
Style Loss : 0.466061 Content Loss: 0.022537

run [600]:
Style Loss : 0.453783 Content Loss: 0.022879

run [650]:
Style Loss : 0.443500 Content Loss: 0.023166

run [700]:
Style Loss : 0.434537 Content Loss: 0.023455

run [750]:
Style Loss : 0.426486 Content Loss: 0.023704

run [800]:
Style Loss : 0.419818 Content Loss: 0.023939

run [850]:
Style Loss : 0.414046 Content Loss: 0.024100

run [900]:
Style Loss : 0.408766 Content Loss: 0.024279

run [950]:
Style Loss : 0.404485 Content Loss: 0.024447

run [1000]:
Style Loss : 0.400561 Content Loss: 0.024586

run [1050]:
Style Loss : 0.397164 Content Loss: 0.024710

run [1100]:
Style Loss : 0.394222 Content Loss: 0.024803

run [1150]:
Style Loss : 0.391378 Content Loss: 0.024911

run [1200]:
Style Loss : 0.388830 Content Loss: 0.025018

run [1250]:
Style Loss : 0.386347 Content Loss: 0.025138

run [1300]:
Style Loss : 0.384652 Content Loss: 0.025259

run [1350]:
Style Loss : 0.382448 Content Loss: 0.025316

run [1400]:
Style Loss : 0.379994 Content Loss: 0.025380

run [1450]:
Style Loss : 0.377715 Content Loss: 0.025395

run [1500]:
Style Loss : 0.375872 Content Loss: 0.025481

run [1550]:
Style Loss : 0.373314 Content Loss: 0.025510

run [1600]:
Style Loss : 0.371448 Content Loss: 0.025609

run [1650]:
Style Loss : 0.369405 Content Loss: 0.025661

run [1700]:
Style Loss : 0.367458 Content Loss: 0.025715

run [1750]:
Style Loss : 0.365634 Content Loss: 0.025770

run [1800]:
Style Loss : 0.363857 Content Loss: 0.025826

run [1850]:
Style Loss : 0.362026 Content Loss: 0.025913

run [1900]:
Style Loss : 0.360425 Content Loss: 0.025939

run [1950]:
Style Loss : 0.358969 Content Loss: 0.025986

run [2000]:
Style Loss : 0.357597 Content Loss: 0.026073

run [2050]:
Style Loss : 0.355860 Content Loss: 0.026111

run [2100]:
Style Loss : 0.354067 Content Loss: 0.026149

run [2150]:
Style Loss : 0.352457 Content Loss: 0.026213

run [2200]:
Style Loss : 0.350907 Content Loss: 0.026254

run [2250]:
Style Loss : 0.349549 Content Loss: 0.026298

run [2300]:
Style Loss : 0.348213 Content Loss: 0.026329

run [2350]:
Style Loss : 0.346988 Content Loss: 0.026359

run [2400]:
Style Loss : 0.345828 Content Loss: 0.026392

run [2450]:
Style Loss : 0.344558 Content Loss: 0.026433

run [2500]:
Style Loss : 0.344480 Content Loss: 0.026541

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.431440 Content Loss: 0.002006

run [100]:
Style Loss : 0.810630 Content Loss: 0.004468

run [150]:
Style Loss : 0.592604 Content Loss: 0.006441

run [200]:
Style Loss : 0.488224 Content Loss: 0.008189

run [250]:
Style Loss : 0.426197 Content Loss: 0.009451

run [300]:
Style Loss : 0.383836 Content Loss: 0.010602

run [350]:
Style Loss : 0.351693 Content Loss: 0.011343

run [400]:
Style Loss : 0.329008 Content Loss: 0.011926

run [450]:
Style Loss : 0.310603 Content Loss: 0.012371

run [500]:
Style Loss : 0.296007 Content Loss: 0.012725

run [550]:
Style Loss : 0.284361 Content Loss: 0.012981

run [600]:
Style Loss : 0.275427 Content Loss: 0.013179

run [650]:
Style Loss : 0.267563 Content Loss: 0.013346

run [700]:
Style Loss : 0.260480 Content Loss: 0.013499

run [750]:
Style Loss : 0.254530 Content Loss: 0.013644

run [800]:
Style Loss : 0.249356 Content Loss: 0.013798

run [850]:
Style Loss : 0.244150 Content Loss: 0.013937

run [900]:
Style Loss : 0.239762 Content Loss: 0.014083

run [950]:
Style Loss : 0.235530 Content Loss: 0.014196

run [1000]:
Style Loss : 0.231747 Content Loss: 0.014310

run [1050]:
Style Loss : 0.228207 Content Loss: 0.014414

run [1100]:
Style Loss : 0.224748 Content Loss: 0.014521

run [1150]:
Style Loss : 0.221731 Content Loss: 0.014606

run [1200]:
Style Loss : 0.218927 Content Loss: 0.014688

run [1250]:
Style Loss : 0.216484 Content Loss: 0.014777

run [1300]:
Style Loss : 0.214010 Content Loss: 0.014871

run [1350]:
Style Loss : 0.211654 Content Loss: 0.014955

run [1400]:
Style Loss : 0.209587 Content Loss: 0.015017

run [1450]:
Style Loss : 0.207562 Content Loss: 0.015107

run [1500]:
Style Loss : 0.205860 Content Loss: 0.015191

run [1550]:
Style Loss : 0.203728 Content Loss: 0.015253

run [1600]:
Style Loss : 0.201796 Content Loss: 0.015327

run [1650]:
Style Loss : 0.200039 Content Loss: 0.015419

run [1700]:
Style Loss : 0.198273 Content Loss: 0.015479

run [1750]:
Style Loss : 0.197097 Content Loss: 0.015571

run [1800]:
Style Loss : 0.195514 Content Loss: 0.015635

run [1850]:
Style Loss : 0.194160 Content Loss: 0.015702

run [1900]:
Style Loss : 0.193881 Content Loss: 0.015815

run [1950]:
Style Loss : 0.192335 Content Loss: 0.015910

run [2000]:
Style Loss : 0.190810 Content Loss: 0.015941

run [2050]:
Style Loss : 0.189768 Content Loss: 0.016034

run [2100]:
Style Loss : 0.188654 Content Loss: 0.016093

run [2150]:
Style Loss : 0.187758 Content Loss: 0.016174

run [2200]:
Style Loss : 0.232162 Content Loss: 0.016765

run [2250]:
Style Loss : 0.187311 Content Loss: 0.016541

run [2300]:
Style Loss : 0.184797 Content Loss: 0.016496

run [2350]:
Style Loss : 0.183621 Content Loss: 0.016494

run [2400]:
Style Loss : 0.183009 Content Loss: 0.016548

run [2450]:
Style Loss : 0.182049 Content Loss: 0.016602

run [2500]:
Style Loss : 0.181294 Content Loss: 0.016674

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.065382 Content Loss: 0.002641

run [100]:
Style Loss : 0.617935 Content Loss: 0.006501

run [150]:
Style Loss : 0.454282 Content Loss: 0.009775

run [200]:
Style Loss : 0.379192 Content Loss: 0.012391

run [250]:
Style Loss : 0.337426 Content Loss: 0.013723

run [300]:
Style Loss : 0.310028 Content Loss: 0.014338

run [350]:
Style Loss : 0.289518 Content Loss: 0.014578

run [400]:
Style Loss : 0.273505 Content Loss: 0.014867

run [450]:
Style Loss : 0.261427 Content Loss: 0.015055

run [500]:
Style Loss : 0.252497 Content Loss: 0.015216

run [550]:
Style Loss : 0.245491 Content Loss: 0.015370

run [600]:
Style Loss : 0.239407 Content Loss: 0.015508

run [650]:
Style Loss : 0.234010 Content Loss: 0.015609

run [700]:
Style Loss : 0.230060 Content Loss: 0.015684

run [750]:
Style Loss : 0.226670 Content Loss: 0.015761

run [800]:
Style Loss : 0.223565 Content Loss: 0.015839

run [850]:
Style Loss : 0.220827 Content Loss: 0.015907

run [900]:
Style Loss : 0.217738 Content Loss: 0.016011

run [950]:
Style Loss : 0.214631 Content Loss: 0.016126

run [1000]:
Style Loss : 0.211121 Content Loss: 0.016228

run [1050]:
Style Loss : 0.207885 Content Loss: 0.016304

run [1100]:
Style Loss : 0.205254 Content Loss: 0.016350

run [1150]:
Style Loss : 0.202938 Content Loss: 0.016403

run [1200]:
Style Loss : 0.200556 Content Loss: 0.016465

run [1250]:
Style Loss : 0.198288 Content Loss: 0.016516

run [1300]:
Style Loss : 0.196226 Content Loss: 0.016572

run [1350]:
Style Loss : 0.194362 Content Loss: 0.016615

run [1400]:
Style Loss : 0.192731 Content Loss: 0.016660

run [1450]:
Style Loss : 0.191269 Content Loss: 0.016703

run [1500]:
Style Loss : 0.189959 Content Loss: 0.016745

run [1550]:
Style Loss : 0.188771 Content Loss: 0.016789

run [1600]:
Style Loss : 0.187622 Content Loss: 0.016827

run [1650]:
Style Loss : 0.186497 Content Loss: 0.016859

run [1700]:
Style Loss : 0.185387 Content Loss: 0.016895

run [1750]:
Style Loss : 0.184361 Content Loss: 0.016919

run [1800]:
Style Loss : 0.183474 Content Loss: 0.016948

run [1850]:
Style Loss : 0.182407 Content Loss: 0.016976

run [1900]:
Style Loss : 0.181554 Content Loss: 0.016998

run [1950]:
Style Loss : 0.180710 Content Loss: 0.017027

run [2000]:
Style Loss : 0.179981 Content Loss: 0.017059

run [2050]:
Style Loss : 0.179234 Content Loss: 0.017098

run [2100]:
Style Loss : 0.178589 Content Loss: 0.017131

run [2150]:
Style Loss : 0.177950 Content Loss: 0.017159

run [2200]:
Style Loss : 0.177333 Content Loss: 0.017192

run [2250]:
Style Loss : 0.176700 Content Loss: 0.017221

run [2300]:
Style Loss : 0.176078 Content Loss: 0.017254

run [2350]:
Style Loss : 0.175490 Content Loss: 0.017285

run [2400]:
Style Loss : 0.174899 Content Loss: 0.017323

run [2450]:
Style Loss : 0.174362 Content Loss: 0.017357

run [2500]:
Style Loss : 0.173861 Content Loss: 0.017389

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.089937 Content Loss: 0.002011

run [100]:
Style Loss : 0.525699 Content Loss: 0.004220

run [150]:
Style Loss : 0.367943 Content Loss: 0.006091

run [200]:
Style Loss : 0.295981 Content Loss: 0.007511

run [250]:
Style Loss : 0.253380 Content Loss: 0.008587

run [300]:
Style Loss : 0.223481 Content Loss: 0.009334

run [350]:
Style Loss : 0.201722 Content Loss: 0.009866

run [400]:
Style Loss : 0.185399 Content Loss: 0.010284

run [450]:
Style Loss : 0.172057 Content Loss: 0.010617

run [500]:
Style Loss : 0.156012 Content Loss: 0.010798

run [550]:
Style Loss : 0.145655 Content Loss: 0.011023

run [600]:
Style Loss : 0.138212 Content Loss: 0.011196

run [650]:
Style Loss : 0.131942 Content Loss: 0.011341

run [700]:
Style Loss : 0.127046 Content Loss: 0.011489

run [750]:
Style Loss : 0.122954 Content Loss: 0.011584

run [800]:
Style Loss : 0.119516 Content Loss: 0.011656

run [850]:
Style Loss : 0.116374 Content Loss: 0.011707

run [900]:
Style Loss : 0.113621 Content Loss: 0.011747

run [950]:
Style Loss : 0.111503 Content Loss: 0.011771

run [1000]:
Style Loss : 0.109729 Content Loss: 0.011798

run [1050]:
Style Loss : 0.108200 Content Loss: 0.011837

run [1100]:
Style Loss : 0.106595 Content Loss: 0.011885

run [1150]:
Style Loss : 0.105105 Content Loss: 0.011932

run [1200]:
Style Loss : 0.103677 Content Loss: 0.011978

run [1250]:
Style Loss : 0.102382 Content Loss: 0.012024

run [1300]:
Style Loss : 0.101072 Content Loss: 0.012058

run [1350]:
Style Loss : 0.099823 Content Loss: 0.012095

run [1400]:
Style Loss : 0.098738 Content Loss: 0.012129

run [1450]:
Style Loss : 0.097714 Content Loss: 0.012170

run [1500]:
Style Loss : 0.096800 Content Loss: 0.012203

run [1550]:
Style Loss : 0.095767 Content Loss: 0.012249

run [1600]:
Style Loss : 0.094905 Content Loss: 0.012292

run [1650]:
Style Loss : 0.094064 Content Loss: 0.012335

run [1700]:
Style Loss : 0.093298 Content Loss: 0.012382

run [1750]:
Style Loss : 0.092527 Content Loss: 0.012420

run [1800]:
Style Loss : 0.091804 Content Loss: 0.012468

run [1850]:
Style Loss : 0.091157 Content Loss: 0.012513

run [1900]:
Style Loss : 0.090544 Content Loss: 0.012567

run [1950]:
Style Loss : 0.090091 Content Loss: 0.012631

run [2000]:
Style Loss : 0.089028 Content Loss: 0.012684

run [2050]:
Style Loss : 0.088171 Content Loss: 0.012736

run [2100]:
Style Loss : 0.087291 Content Loss: 0.012780

run [2150]:
Style Loss : 0.086442 Content Loss: 0.012824

run [2200]:
Style Loss : 0.085665 Content Loss: 0.012878

run [2250]:
Style Loss : 0.084942 Content Loss: 0.012911

run [2300]:
Style Loss : 0.084247 Content Loss: 0.012960

run [2350]:
Style Loss : 0.083553 Content Loss: 0.012989

run [2400]:
Style Loss : 0.082796 Content Loss: 0.013015

run [2450]:
Style Loss : 0.082219 Content Loss: 0.013075

run [2500]:
Style Loss : 0.081542 Content Loss: 0.013107

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.481693 Content Loss: 0.003865

run [100]:
Style Loss : 0.874370 Content Loss: 0.008076

run [150]:
Style Loss : 0.632338 Content Loss: 0.013723

run [200]:
Style Loss : 0.501349 Content Loss: 0.017541

run [250]:
Style Loss : 0.432434 Content Loss: 0.019794

run [300]:
Style Loss : 0.396714 Content Loss: 0.020902

run [350]:
Style Loss : 0.375670 Content Loss: 0.021285

run [400]:
Style Loss : 0.360889 Content Loss: 0.021689

run [450]:
Style Loss : 0.348605 Content Loss: 0.021990

run [500]:
Style Loss : 0.338954 Content Loss: 0.022373

run [550]:
Style Loss : 0.330428 Content Loss: 0.022727

run [600]:
Style Loss : 0.322867 Content Loss: 0.023109

run [650]:
Style Loss : 0.316659 Content Loss: 0.023429

run [700]:
Style Loss : 0.311082 Content Loss: 0.023741

run [750]:
Style Loss : 0.305890 Content Loss: 0.023952

run [800]:
Style Loss : 0.301239 Content Loss: 0.024179

run [850]:
Style Loss : 0.296546 Content Loss: 0.024400

run [900]:
Style Loss : 0.292619 Content Loss: 0.024643

run [950]:
Style Loss : 0.289072 Content Loss: 0.024772

run [1000]:
Style Loss : 0.286510 Content Loss: 0.024971

run [1050]:
Style Loss : 0.283639 Content Loss: 0.025114

run [1100]:
Style Loss : 0.281884 Content Loss: 0.025361

run [1150]:
Style Loss : 0.279313 Content Loss: 0.025511

run [1200]:
Style Loss : 0.277620 Content Loss: 0.025698

run [1250]:
Style Loss : 0.276127 Content Loss: 0.025826

run [1300]:
Style Loss : 0.274167 Content Loss: 0.025913

run [1350]:
Style Loss : 0.272792 Content Loss: 0.026070

run [1400]:
Style Loss : 0.271278 Content Loss: 0.026183

run [1450]:
Style Loss : 0.270059 Content Loss: 0.026282

run [1500]:
Style Loss : 0.269103 Content Loss: 0.026382

run [1550]:
Style Loss : 0.267483 Content Loss: 0.026470

run [1600]:
Style Loss : 0.266253 Content Loss: 0.026549

run [1650]:
Style Loss : 0.265492 Content Loss: 0.026695

run [1700]:
Style Loss : 0.264033 Content Loss: 0.026793

run [1750]:
Style Loss : 0.264095 Content Loss: 0.026961

run [1800]:
Style Loss : 0.261616 Content Loss: 0.026979

run [1850]:
Style Loss : 0.260507 Content Loss: 0.027072

run [1900]:
Style Loss : 0.259547 Content Loss: 0.027157

run [1950]:
Style Loss : 0.258685 Content Loss: 0.027284

run [2000]:
Style Loss : 0.257728 Content Loss: 0.027362

run [2050]:
Style Loss : 0.259434 Content Loss: 0.027605

run [2100]:
Style Loss : 0.256370 Content Loss: 0.027540

run [2150]:
Style Loss : 0.255404 Content Loss: 0.027640

run [2200]:
Style Loss : 0.255288 Content Loss: 0.027746

run [2250]:
Style Loss : 0.253987 Content Loss: 0.027783

run [2300]:
Style Loss : 0.253894 Content Loss: 0.027870

run [2350]:
Style Loss : 0.252975 Content Loss: 0.027896

run [2400]:
Style Loss : 0.254316 Content Loss: 0.028021

run [2450]:
Style Loss : 0.252170 Content Loss: 0.028006

run [2500]:
Style Loss : 0.251437 Content Loss: 0.028048

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.957717 Content Loss: 0.006348

run [100]:
Style Loss : 0.472102 Content Loss: 0.010117

run [150]:
Style Loss : 0.332862 Content Loss: 0.012741

run [200]:
Style Loss : 0.261417 Content Loss: 0.014337

run [250]:
Style Loss : 0.220201 Content Loss: 0.015592

run [300]:
Style Loss : 0.196650 Content Loss: 0.016185

run [350]:
Style Loss : 0.180227 Content Loss: 0.016545

run [400]:
Style Loss : 0.167301 Content Loss: 0.016909

run [450]:
Style Loss : 0.158371 Content Loss: 0.017202

run [500]:
Style Loss : 0.151726 Content Loss: 0.017413

run [550]:
Style Loss : 0.146789 Content Loss: 0.017560

run [600]:
Style Loss : 0.141856 Content Loss: 0.017717

run [650]:
Style Loss : 0.138087 Content Loss: 0.017843

run [700]:
Style Loss : 0.135035 Content Loss: 0.017921

run [750]:
Style Loss : 0.132311 Content Loss: 0.017988

run [800]:
Style Loss : 0.129843 Content Loss: 0.018070

run [850]:
Style Loss : 0.126901 Content Loss: 0.018134

run [900]:
Style Loss : 0.123651 Content Loss: 0.018175

run [950]:
Style Loss : 0.120749 Content Loss: 0.018204

run [1000]:
Style Loss : 0.117845 Content Loss: 0.018243

run [1050]:
Style Loss : 0.114980 Content Loss: 0.018289

run [1100]:
Style Loss : 0.112257 Content Loss: 0.018315

run [1150]:
Style Loss : 0.109876 Content Loss: 0.018339

run [1200]:
Style Loss : 0.107997 Content Loss: 0.018348

run [1250]:
Style Loss : 0.106460 Content Loss: 0.018349

run [1300]:
Style Loss : 0.105051 Content Loss: 0.018357

run [1350]:
Style Loss : 0.103775 Content Loss: 0.018382

run [1400]:
Style Loss : 0.102720 Content Loss: 0.018393

run [1450]:
Style Loss : 0.101797 Content Loss: 0.018377

run [1500]:
Style Loss : 0.101045 Content Loss: 0.018350

run [1550]:
Style Loss : 0.100303 Content Loss: 0.018337

run [1600]:
Style Loss : 0.099643 Content Loss: 0.018329

run [1650]:
Style Loss : 0.098996 Content Loss: 0.018325

run [1700]:
Style Loss : 0.098333 Content Loss: 0.018317

run [1750]:
Style Loss : 0.097716 Content Loss: 0.018311

run [1800]:
Style Loss : 0.097136 Content Loss: 0.018300

run [1850]:
Style Loss : 0.096571 Content Loss: 0.018295

run [1900]:
Style Loss : 0.096036 Content Loss: 0.018294

run [1950]:
Style Loss : 0.095553 Content Loss: 0.018297

run [2000]:
Style Loss : 0.095097 Content Loss: 0.018297

run [2050]:
Style Loss : 0.094702 Content Loss: 0.018298

run [2100]:
Style Loss : 0.094329 Content Loss: 0.018298

run [2150]:
Style Loss : 0.093971 Content Loss: 0.018303

run [2200]:
Style Loss : 0.093566 Content Loss: 0.018300

run [2250]:
Style Loss : 0.093212 Content Loss: 0.018295

run [2300]:
Style Loss : 0.092843 Content Loss: 0.018294

run [2350]:
Style Loss : 0.092519 Content Loss: 0.018291

run [2400]:
Style Loss : 0.092221 Content Loss: 0.018286

run [2450]:
Style Loss : 0.091937 Content Loss: 0.018276

run [2500]:
Style Loss : 0.091694 Content Loss: 0.018267

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.051039 Content Loss: 0.003234

run [100]:
Style Loss : 1.343607 Content Loss: 0.004707

run [150]:
Style Loss : 1.038935 Content Loss: 0.006076

run [200]:
Style Loss : 0.871500 Content Loss: 0.007403

run [250]:
Style Loss : 0.768510 Content Loss: 0.008499

run [300]:
Style Loss : 0.700163 Content Loss: 0.009413

run [350]:
Style Loss : 0.646884 Content Loss: 0.010247

run [400]:
Style Loss : 0.605320 Content Loss: 0.010983

run [450]:
Style Loss : 0.570961 Content Loss: 0.011693

run [500]:
Style Loss : 0.543887 Content Loss: 0.012271

run [550]:
Style Loss : 0.521379 Content Loss: 0.012748

run [600]:
Style Loss : 0.503677 Content Loss: 0.013237

run [650]:
Style Loss : 0.488434 Content Loss: 0.013603

run [700]:
Style Loss : 0.476552 Content Loss: 0.013939

run [750]:
Style Loss : 0.466222 Content Loss: 0.014200

run [800]:
Style Loss : 0.457022 Content Loss: 0.014434

run [850]:
Style Loss : 0.448621 Content Loss: 0.014598

run [900]:
Style Loss : 0.441499 Content Loss: 0.014752

run [950]:
Style Loss : 0.435223 Content Loss: 0.014895

run [1000]:
Style Loss : 0.429693 Content Loss: 0.015008

run [1050]:
Style Loss : 0.423981 Content Loss: 0.015106

run [1100]:
Style Loss : 0.418039 Content Loss: 0.015213

run [1150]:
Style Loss : 0.412768 Content Loss: 0.015309

run [1200]:
Style Loss : 0.407167 Content Loss: 0.015390

run [1250]:
Style Loss : 0.402493 Content Loss: 0.015463

run [1300]:
Style Loss : 0.398431 Content Loss: 0.015540

run [1350]:
Style Loss : 0.394759 Content Loss: 0.015598

run [1400]:
Style Loss : 0.391195 Content Loss: 0.015655

run [1450]:
Style Loss : 0.387995 Content Loss: 0.015729

run [1500]:
Style Loss : 0.385148 Content Loss: 0.015783

run [1550]:
Style Loss : 0.382522 Content Loss: 0.015842

run [1600]:
Style Loss : 0.380049 Content Loss: 0.015913

run [1650]:
Style Loss : 0.377664 Content Loss: 0.015980

run [1700]:
Style Loss : 0.375433 Content Loss: 0.016050

run [1750]:
Style Loss : 0.373433 Content Loss: 0.016119

run [1800]:
Style Loss : 0.371576 Content Loss: 0.016184

run [1850]:
Style Loss : 0.369803 Content Loss: 0.016250

run [1900]:
Style Loss : 0.368171 Content Loss: 0.016314

run [1950]:
Style Loss : 0.366669 Content Loss: 0.016377

run [2000]:
Style Loss : 0.365129 Content Loss: 0.016438

run [2050]:
Style Loss : 0.363604 Content Loss: 0.016490

run [2100]:
Style Loss : 0.362156 Content Loss: 0.016553

run [2150]:
Style Loss : 0.360835 Content Loss: 0.016609

run [2200]:
Style Loss : 0.359588 Content Loss: 0.016659

run [2250]:
Style Loss : 0.358437 Content Loss: 0.016693

run [2300]:
Style Loss : 0.357333 Content Loss: 0.016744

run [2350]:
Style Loss : 0.356103 Content Loss: 0.016806

run [2400]:
Style Loss : 0.354954 Content Loss: 0.016856

run [2450]:
Style Loss : 0.353863 Content Loss: 0.016888

run [2500]:
Style Loss : 0.352873 Content Loss: 0.016932

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.991133 Content Loss: 0.002195

run [100]:
Style Loss : 1.174798 Content Loss: 0.003072

run [150]:
Style Loss : 0.827777 Content Loss: 0.004482

run [200]:
Style Loss : 0.657489 Content Loss: 0.005441

run [250]:
Style Loss : 0.560088 Content Loss: 0.006537

run [300]:
Style Loss : 0.499167 Content Loss: 0.007381

run [350]:
Style Loss : 0.457127 Content Loss: 0.008119

run [400]:
Style Loss : 0.424437 Content Loss: 0.008744

run [450]:
Style Loss : 0.397994 Content Loss: 0.009262

run [500]:
Style Loss : 0.376181 Content Loss: 0.009685

run [550]:
Style Loss : 0.356357 Content Loss: 0.010067

run [600]:
Style Loss : 0.340653 Content Loss: 0.010440

run [650]:
Style Loss : 0.326772 Content Loss: 0.010761

run [700]:
Style Loss : 0.313146 Content Loss: 0.010980

run [750]:
Style Loss : 0.303081 Content Loss: 0.011176

run [800]:
Style Loss : 0.295327 Content Loss: 0.011367

run [850]:
Style Loss : 0.286952 Content Loss: 0.011536

run [900]:
Style Loss : 0.279523 Content Loss: 0.011692

run [950]:
Style Loss : 0.272770 Content Loss: 0.011810

run [1000]:
Style Loss : 0.267102 Content Loss: 0.011924

run [1050]:
Style Loss : 0.262071 Content Loss: 0.012001

run [1100]:
Style Loss : 0.257233 Content Loss: 0.012099

run [1150]:
Style Loss : 0.252804 Content Loss: 0.012189

run [1200]:
Style Loss : 0.249170 Content Loss: 0.012267

run [1250]:
Style Loss : 0.245622 Content Loss: 0.012315

run [1300]:
Style Loss : 0.242687 Content Loss: 0.012372

run [1350]:
Style Loss : 0.239136 Content Loss: 0.012407

run [1400]:
Style Loss : 0.236324 Content Loss: 0.012471

run [1450]:
Style Loss : 0.233662 Content Loss: 0.012508

run [1500]:
Style Loss : 0.230586 Content Loss: 0.012541

run [1550]:
Style Loss : 0.227947 Content Loss: 0.012575

run [1600]:
Style Loss : 0.225392 Content Loss: 0.012596

run [1650]:
Style Loss : 0.223268 Content Loss: 0.012632

run [1700]:
Style Loss : 0.221113 Content Loss: 0.012660

run [1750]:
Style Loss : 2.097475 Content Loss: 0.019649

run [1800]:
Style Loss : 0.854810 Content Loss: 0.016663

run [1850]:
Style Loss : 0.591469 Content Loss: 0.015725

run [1900]:
Style Loss : 0.480386 Content Loss: 0.015482

run [1950]:
Style Loss : 0.416572 Content Loss: 0.015404

run [2000]:
Style Loss : 0.376010 Content Loss: 0.015389

run [2050]:
Style Loss : 0.347095 Content Loss: 0.015403

run [2100]:
Style Loss : 0.323181 Content Loss: 0.015443

run [2150]:
Style Loss : 0.304267 Content Loss: 0.015454

run [2200]:
Style Loss : 0.287816 Content Loss: 0.015482

run [2250]:
Style Loss : 0.272938 Content Loss: 0.015519

run [2300]:
Style Loss : 0.260538 Content Loss: 0.015524

run [2350]:
Style Loss : 0.250777 Content Loss: 0.015561

run [2400]:
Style Loss : 0.242736 Content Loss: 0.015577

run [2450]:
Style Loss : 0.235798 Content Loss: 0.015577

run [2500]:
Style Loss : 0.229735 Content Loss: 0.015595

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.804823 Content Loss: 0.003246

run [100]:
Style Loss : 1.045861 Content Loss: 0.005207

run [150]:
Style Loss : 0.765044 Content Loss: 0.007486

run [200]:
Style Loss : 0.619546 Content Loss: 0.009429

run [250]:
Style Loss : 0.539352 Content Loss: 0.010902

run [300]:
Style Loss : 0.491982 Content Loss: 0.011976

run [350]:
Style Loss : 0.460198 Content Loss: 0.012802

run [400]:
Style Loss : 0.437229 Content Loss: 0.013284

run [450]:
Style Loss : 0.420244 Content Loss: 0.013694

run [500]:
Style Loss : 0.406323 Content Loss: 0.014043

run [550]:
Style Loss : 0.395277 Content Loss: 0.014307

run [600]:
Style Loss : 0.386249 Content Loss: 0.014556

run [650]:
Style Loss : 0.378979 Content Loss: 0.014759

run [700]:
Style Loss : 0.372633 Content Loss: 0.014966

run [750]:
Style Loss : 0.367341 Content Loss: 0.015151

run [800]:
Style Loss : 0.362803 Content Loss: 0.015323

run [850]:
Style Loss : 0.358683 Content Loss: 0.015464

run [900]:
Style Loss : 0.355287 Content Loss: 0.015584

run [950]:
Style Loss : 0.352102 Content Loss: 0.015699

run [1000]:
Style Loss : 0.349018 Content Loss: 0.015812

run [1050]:
Style Loss : 0.346117 Content Loss: 0.015917

run [1100]:
Style Loss : 0.343384 Content Loss: 0.016014

run [1150]:
Style Loss : 0.340635 Content Loss: 0.016112

run [1200]:
Style Loss : 0.337800 Content Loss: 0.016196

run [1250]:
Style Loss : 0.334998 Content Loss: 0.016269

run [1300]:
Style Loss : 0.332189 Content Loss: 0.016343

run [1350]:
Style Loss : 0.329881 Content Loss: 0.016407

run [1400]:
Style Loss : 0.327732 Content Loss: 0.016470

run [1450]:
Style Loss : 0.325998 Content Loss: 0.016517

run [1500]:
Style Loss : 0.324174 Content Loss: 0.016585

run [1550]:
Style Loss : 0.322448 Content Loss: 0.016644

run [1600]:
Style Loss : 0.320947 Content Loss: 0.016699

run [1650]:
Style Loss : 0.319424 Content Loss: 0.016752

run [1700]:
Style Loss : 0.317977 Content Loss: 0.016809

run [1750]:
Style Loss : 0.316617 Content Loss: 0.016870

run [1800]:
Style Loss : 0.315260 Content Loss: 0.016916

run [1850]:
Style Loss : 0.313892 Content Loss: 0.016970

run [1900]:
Style Loss : 0.312722 Content Loss: 0.017012

run [1950]:
Style Loss : 0.311553 Content Loss: 0.017048

run [2000]:
Style Loss : 0.310444 Content Loss: 0.017087

run [2050]:
Style Loss : 0.309414 Content Loss: 0.017126

run [2100]:
Style Loss : 0.308487 Content Loss: 0.017175

run [2150]:
Style Loss : 0.307611 Content Loss: 0.017198

run [2200]:
Style Loss : 0.306720 Content Loss: 0.017237

run [2250]:
Style Loss : 0.305773 Content Loss: 0.017278

run [2300]:
Style Loss : 0.304915 Content Loss: 0.017313

run [2350]:
Style Loss : 0.303997 Content Loss: 0.017356

run [2400]:
Style Loss : 0.303136 Content Loss: 0.017388

run [2450]:
Style Loss : 0.302334 Content Loss: 0.017433

run [2500]:
Style Loss : 0.301618 Content Loss: 0.017462

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.723968 Content Loss: 0.002636

run [100]:
Style Loss : 1.536313 Content Loss: 0.003118

run [150]:
Style Loss : 1.124693 Content Loss: 0.004080

run [200]:
Style Loss : 0.923104 Content Loss: 0.005062

run [250]:
Style Loss : 0.806323 Content Loss: 0.005818

run [300]:
Style Loss : 0.722699 Content Loss: 0.006429

run [350]:
Style Loss : 0.659798 Content Loss: 0.006937

run [400]:
Style Loss : 0.615214 Content Loss: 0.007333

run [450]:
Style Loss : 0.580029 Content Loss: 0.007708

run [500]:
Style Loss : 0.551692 Content Loss: 0.007983

run [550]:
Style Loss : 0.529431 Content Loss: 0.008239

run [600]:
Style Loss : 0.509870 Content Loss: 0.008399

run [650]:
Style Loss : 0.492363 Content Loss: 0.008591

run [700]:
Style Loss : 0.476471 Content Loss: 0.008768

run [750]:
Style Loss : 0.462396 Content Loss: 0.008887

run [800]:
Style Loss : 0.450679 Content Loss: 0.009021

run [850]:
Style Loss : 0.440918 Content Loss: 0.009137

run [900]:
Style Loss : 0.433150 Content Loss: 0.009239

run [950]:
Style Loss : 0.426347 Content Loss: 0.009341

run [1000]:
Style Loss : 0.420386 Content Loss: 0.009428

run [1050]:
Style Loss : 0.414533 Content Loss: 0.009512

run [1100]:
Style Loss : 0.409294 Content Loss: 0.009598

run [1150]:
Style Loss : 0.404367 Content Loss: 0.009684

run [1200]:
Style Loss : 0.399905 Content Loss: 0.009760

run [1250]:
Style Loss : 0.395885 Content Loss: 0.009839

run [1300]:
Style Loss : 0.392120 Content Loss: 0.009917

run [1350]:
Style Loss : 0.388205 Content Loss: 0.009993

run [1400]:
Style Loss : 0.384739 Content Loss: 0.010061

run [1450]:
Style Loss : 0.381546 Content Loss: 0.010120

run [1500]:
Style Loss : 0.378915 Content Loss: 0.010161

run [1550]:
Style Loss : 0.376591 Content Loss: 0.010208

run [1600]:
Style Loss : 0.374578 Content Loss: 0.010249

run [1650]:
Style Loss : 0.372555 Content Loss: 0.010290

run [1700]:
Style Loss : 0.370741 Content Loss: 0.010329

run [1750]:
Style Loss : 0.369082 Content Loss: 0.010372

run [1800]:
Style Loss : 0.366903 Content Loss: 0.010423

run [1850]:
Style Loss : 0.364947 Content Loss: 0.010473

run [1900]:
Style Loss : 0.362993 Content Loss: 0.010513

run [1950]:
Style Loss : 0.361298 Content Loss: 0.010553

run [2000]:
Style Loss : 0.359771 Content Loss: 0.010590

run [2050]:
Style Loss : 0.358255 Content Loss: 0.010633

run [2100]:
Style Loss : 0.356798 Content Loss: 0.010667

run [2150]:
Style Loss : 0.355488 Content Loss: 0.010696

run [2200]:
Style Loss : 0.354345 Content Loss: 0.010722

run [2250]:
Style Loss : 0.353225 Content Loss: 0.010749

run [2300]:
Style Loss : 0.352116 Content Loss: 0.010772

run [2350]:
Style Loss : 0.351057 Content Loss: 0.010796

run [2400]:
Style Loss : 0.349976 Content Loss: 0.010821

run [2450]:
Style Loss : 0.348997 Content Loss: 0.010843

run [2500]:
Style Loss : 0.348064 Content Loss: 0.010870

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.874814 Content Loss: 0.004246

run [100]:
Style Loss : 1.881427 Content Loss: 0.004423

run [150]:
Style Loss : 1.359288 Content Loss: 0.005373

run [200]:
Style Loss : 1.126433 Content Loss: 0.006212

run [250]:
Style Loss : 0.979040 Content Loss: 0.006997

run [300]:
Style Loss : 0.887140 Content Loss: 0.007655

run [350]:
Style Loss : 0.815760 Content Loss: 0.008272

run [400]:
Style Loss : 0.763184 Content Loss: 0.008690

run [450]:
Style Loss : 0.721269 Content Loss: 0.009063

run [500]:
Style Loss : 0.688670 Content Loss: 0.009339

run [550]:
Style Loss : 0.663169 Content Loss: 0.009636

run [600]:
Style Loss : 0.643589 Content Loss: 0.009861

run [650]:
Style Loss : 0.625680 Content Loss: 0.010107

run [700]:
Style Loss : 0.609526 Content Loss: 0.010333

run [750]:
Style Loss : 0.597880 Content Loss: 0.010453

run [800]:
Style Loss : 0.587898 Content Loss: 0.010614

run [850]:
Style Loss : 0.579310 Content Loss: 0.010772

run [900]:
Style Loss : 0.571253 Content Loss: 0.010926

run [950]:
Style Loss : 0.562920 Content Loss: 0.011068

run [1000]:
Style Loss : 0.555252 Content Loss: 0.011178

run [1050]:
Style Loss : 0.548116 Content Loss: 0.011282

run [1100]:
Style Loss : 0.542004 Content Loss: 0.011368

run [1150]:
Style Loss : 0.536874 Content Loss: 0.011475

run [1200]:
Style Loss : 0.532185 Content Loss: 0.011546

run [1250]:
Style Loss : 0.527716 Content Loss: 0.011623

run [1300]:
Style Loss : 0.523547 Content Loss: 0.011703

run [1350]:
Style Loss : 0.519687 Content Loss: 0.011765

run [1400]:
Style Loss : 0.516431 Content Loss: 0.011836

run [1450]:
Style Loss : 0.513583 Content Loss: 0.011894

run [1500]:
Style Loss : 0.510947 Content Loss: 0.011965

run [1550]:
Style Loss : 0.508433 Content Loss: 0.012022

run [1600]:
Style Loss : 0.505929 Content Loss: 0.012082

run [1650]:
Style Loss : 0.503677 Content Loss: 0.012137

run [1700]:
Style Loss : 0.501337 Content Loss: 0.012205

run [1750]:
Style Loss : 0.499013 Content Loss: 0.012262

run [1800]:
Style Loss : 0.496720 Content Loss: 0.012309

run [1850]:
Style Loss : 0.494607 Content Loss: 0.012369

run [1900]:
Style Loss : 0.492546 Content Loss: 0.012409

run [1950]:
Style Loss : 0.490597 Content Loss: 0.012444

run [2000]:
Style Loss : 0.488888 Content Loss: 0.012486

run [2050]:
Style Loss : 0.487316 Content Loss: 0.012519

run [2100]:
Style Loss : 0.485695 Content Loss: 0.012564

run [2150]:
Style Loss : 0.484073 Content Loss: 0.012612

run [2200]:
Style Loss : 0.482498 Content Loss: 0.012647

run [2250]:
Style Loss : 0.480992 Content Loss: 0.012682

run [2300]:
Style Loss : 0.479523 Content Loss: 0.012713

run [2350]:
Style Loss : 0.478128 Content Loss: 0.012746

run [2400]:
Style Loss : 0.476854 Content Loss: 0.012781

run [2450]:
Style Loss : 0.475602 Content Loss: 0.012813

run [2500]:
Style Loss : 0.474325 Content Loss: 0.012850

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.619762 Content Loss: 0.004107

run [100]:
Style Loss : 2.285078 Content Loss: 0.004777

run [150]:
Style Loss : 1.792047 Content Loss: 0.006023

run [200]:
Style Loss : 1.525558 Content Loss: 0.007059

run [250]:
Style Loss : 1.346378 Content Loss: 0.007893

run [300]:
Style Loss : 1.211943 Content Loss: 0.008575

run [350]:
Style Loss : 1.112869 Content Loss: 0.009234

run [400]:
Style Loss : 1.041124 Content Loss: 0.009773

run [450]:
Style Loss : 0.982296 Content Loss: 0.010204

run [500]:
Style Loss : 0.940079 Content Loss: 0.010628

run [550]:
Style Loss : 0.908077 Content Loss: 0.010946

run [600]:
Style Loss : 0.878521 Content Loss: 0.011250

run [650]:
Style Loss : 0.854168 Content Loss: 0.011508

run [700]:
Style Loss : 0.834810 Content Loss: 0.011739

run [750]:
Style Loss : 0.818759 Content Loss: 0.011984

run [800]:
Style Loss : 0.801139 Content Loss: 0.012168

run [850]:
Style Loss : 0.784995 Content Loss: 0.012377

run [900]:
Style Loss : 0.770015 Content Loss: 0.012544

run [950]:
Style Loss : 0.757293 Content Loss: 0.012697

run [1000]:
Style Loss : 0.745835 Content Loss: 0.012836

run [1050]:
Style Loss : 0.735164 Content Loss: 0.012995

run [1100]:
Style Loss : 0.725462 Content Loss: 0.013145

run [1150]:
Style Loss : 0.717034 Content Loss: 0.013248

run [1200]:
Style Loss : 0.708847 Content Loss: 0.013403

run [1250]:
Style Loss : 0.700720 Content Loss: 0.013520

run [1300]:
Style Loss : 0.693648 Content Loss: 0.013595

run [1350]:
Style Loss : 0.687508 Content Loss: 0.013725

run [1400]:
Style Loss : 0.682216 Content Loss: 0.013786

run [1450]:
Style Loss : 0.677362 Content Loss: 0.013874

run [1500]:
Style Loss : 0.672574 Content Loss: 0.013976

run [1550]:
Style Loss : 0.668026 Content Loss: 0.014070

run [1600]:
Style Loss : 0.663233 Content Loss: 0.014133

run [1650]:
Style Loss : 0.659085 Content Loss: 0.014191

run [1700]:
Style Loss : 0.655167 Content Loss: 0.014245

run [1750]:
Style Loss : 0.651516 Content Loss: 0.014298

run [1800]:
Style Loss : 0.647975 Content Loss: 0.014372

run [1850]:
Style Loss : 0.644690 Content Loss: 0.014410

run [1900]:
Style Loss : 0.641673 Content Loss: 0.014475

run [1950]:
Style Loss : 0.638782 Content Loss: 0.014532

run [2000]:
Style Loss : 0.635906 Content Loss: 0.014581

run [2050]:
Style Loss : 0.632988 Content Loss: 0.014622

run [2100]:
Style Loss : 0.630106 Content Loss: 0.014671

run [2150]:
Style Loss : 0.627520 Content Loss: 0.014705

run [2200]:
Style Loss : 0.625161 Content Loss: 0.014737

run [2250]:
Style Loss : 0.622965 Content Loss: 0.014780

run [2300]:
Style Loss : 0.620923 Content Loss: 0.014812

run [2350]:
Style Loss : 0.619047 Content Loss: 0.014848

run [2400]:
Style Loss : 0.617226 Content Loss: 0.014885

run [2450]:
Style Loss : 0.615655 Content Loss: 0.014922

run [2500]:
Style Loss : 0.614185 Content Loss: 0.014950

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.900779 Content Loss: 0.003888

run [100]:
Style Loss : 0.963671 Content Loss: 0.004368

run [150]:
Style Loss : 0.633238 Content Loss: 0.005277

run [200]:
Style Loss : 0.477063 Content Loss: 0.006159

run [250]:
Style Loss : 0.385960 Content Loss: 0.007082

run [300]:
Style Loss : 0.332144 Content Loss: 0.007850

run [350]:
Style Loss : 0.293111 Content Loss: 0.008382

run [400]:
Style Loss : 0.263629 Content Loss: 0.008954

run [450]:
Style Loss : 0.241182 Content Loss: 0.009423

run [500]:
Style Loss : 0.226438 Content Loss: 0.009794

run [550]:
Style Loss : 0.213845 Content Loss: 0.010190

run [600]:
Style Loss : 0.204354 Content Loss: 0.010402

run [650]:
Style Loss : 0.196991 Content Loss: 0.010582

run [700]:
Style Loss : 0.191978 Content Loss: 0.010764

run [750]:
Style Loss : 0.185716 Content Loss: 0.010841

run [800]:
Style Loss : 0.180964 Content Loss: 0.010954

run [850]:
Style Loss : 0.176913 Content Loss: 0.011030

run [900]:
Style Loss : 0.173326 Content Loss: 0.011107

run [950]:
Style Loss : 0.171194 Content Loss: 0.011163

run [1000]:
Style Loss : 0.168102 Content Loss: 0.011193

run [1050]:
Style Loss : 0.165680 Content Loss: 0.011232

run [1100]:
Style Loss : 0.163596 Content Loss: 0.011258

run [1150]:
Style Loss : 0.161542 Content Loss: 0.011298

run [1200]:
Style Loss : 0.159641 Content Loss: 0.011317

run [1250]:
Style Loss : 0.158045 Content Loss: 0.011339

run [1300]:
Style Loss : 0.156381 Content Loss: 0.011360

run [1350]:
Style Loss : 0.155088 Content Loss: 0.011397

run [1400]:
Style Loss : 0.153471 Content Loss: 0.011395

run [1450]:
Style Loss : 0.151704 Content Loss: 0.011409

run [1500]:
Style Loss : 0.150168 Content Loss: 0.011416

run [1550]:
Style Loss : 0.148626 Content Loss: 0.011421

run [1600]:
Style Loss : 0.147305 Content Loss: 0.011438

run [1650]:
Style Loss : 0.146666 Content Loss: 0.011456

run [1700]:
Style Loss : 0.144599 Content Loss: 0.011476

run [1750]:
Style Loss : 0.143315 Content Loss: 0.011497

run [1800]:
Style Loss : 0.142054 Content Loss: 0.011538

run [1850]:
Style Loss : 0.140701 Content Loss: 0.011557

run [1900]:
Style Loss : 0.139635 Content Loss: 0.011581

run [1950]:
Style Loss : 0.138710 Content Loss: 0.011624

run [2000]:
Style Loss : 0.137508 Content Loss: 0.011633

run [2050]:
Style Loss : 27.697735 Content Loss: 0.018826

run [2100]:
Style Loss : 1007.011292 Content Loss: 0.526661

run [2150]:
Style Loss : 1021.321960 Content Loss: 0.520671

run [2200]:
Style Loss : 705.474915 Content Loss: 0.469973

run [2250]:
Style Loss : 3.534559 Content Loss: 0.034347

run [2300]:
Style Loss : 1.170806 Content Loss: 0.028062

run [2350]:
Style Loss : 0.694531 Content Loss: 0.026505

run [2400]:
Style Loss : 0.507833 Content Loss: 0.026252

run [2450]:
Style Loss : 0.405113 Content Loss: 0.026142

run [2500]:
Style Loss : 0.328451 Content Loss: 0.026123

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.795253 Content Loss: 0.002154

run [100]:
Style Loss : 1.102845 Content Loss: 0.003836

run [150]:
Style Loss : 0.876054 Content Loss: 0.005017

run [200]:
Style Loss : 0.762723 Content Loss: 0.006060

run [250]:
Style Loss : 0.686485 Content Loss: 0.006918

run [300]:
Style Loss : 0.634770 Content Loss: 0.007534

run [350]:
Style Loss : 0.595344 Content Loss: 0.008134

run [400]:
Style Loss : 0.561243 Content Loss: 0.008711

run [450]:
Style Loss : 0.528632 Content Loss: 0.009052

run [500]:
Style Loss : 0.508061 Content Loss: 0.009396

run [550]:
Style Loss : 0.491904 Content Loss: 0.009687

run [600]:
Style Loss : 0.476637 Content Loss: 0.010008

run [650]:
Style Loss : 0.462694 Content Loss: 0.010231

run [700]:
Style Loss : 0.449805 Content Loss: 0.010479

run [750]:
Style Loss : 0.438421 Content Loss: 0.010687

run [800]:
Style Loss : 0.429355 Content Loss: 0.010893

run [850]:
Style Loss : 0.420577 Content Loss: 0.011127

run [900]:
Style Loss : 0.413457 Content Loss: 0.011289

run [950]:
Style Loss : 0.407346 Content Loss: 0.011451

run [1000]:
Style Loss : 0.402183 Content Loss: 0.011631

run [1050]:
Style Loss : 0.397515 Content Loss: 0.011747

run [1100]:
Style Loss : 0.393327 Content Loss: 0.011866

run [1150]:
Style Loss : 0.389285 Content Loss: 0.011982

run [1200]:
Style Loss : 0.385787 Content Loss: 0.012089

run [1250]:
Style Loss : 0.381802 Content Loss: 0.012208

run [1300]:
Style Loss : 0.378327 Content Loss: 0.012309

run [1350]:
Style Loss : 0.375326 Content Loss: 0.012395

run [1400]:
Style Loss : 0.372571 Content Loss: 0.012476

run [1450]:
Style Loss : 0.370092 Content Loss: 0.012547

run [1500]:
Style Loss : 0.367840 Content Loss: 0.012622

run [1550]:
Style Loss : 0.365734 Content Loss: 0.012696

run [1600]:
Style Loss : 0.363812 Content Loss: 0.012766

run [1650]:
Style Loss : 0.362037 Content Loss: 0.012837

run [1700]:
Style Loss : 0.359812 Content Loss: 0.012908

run [1750]:
Style Loss : 0.357935 Content Loss: 0.012959

run [1800]:
Style Loss : 0.356128 Content Loss: 0.013037

run [1850]:
Style Loss : 0.354417 Content Loss: 0.013106

run [1900]:
Style Loss : 0.352826 Content Loss: 0.013155

run [1950]:
Style Loss : 0.351396 Content Loss: 0.013226

run [2000]:
Style Loss : 0.350008 Content Loss: 0.013266

run [2050]:
Style Loss : 0.348784 Content Loss: 0.013320

run [2100]:
Style Loss : 0.347465 Content Loss: 0.013374

run [2150]:
Style Loss : 0.346105 Content Loss: 0.013423

run [2200]:
Style Loss : 0.344760 Content Loss: 0.013471

run [2250]:
Style Loss : 0.343502 Content Loss: 0.013524

run [2300]:
Style Loss : 0.342148 Content Loss: 0.013572

run [2350]:
Style Loss : 0.341032 Content Loss: 0.013617

run [2400]:
Style Loss : 0.339924 Content Loss: 0.013654

run [2450]:
Style Loss : 0.338835 Content Loss: 0.013695

run [2500]:
Style Loss : 0.337804 Content Loss: 0.013735

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.008016 Content Loss: 0.001945

run [100]:
Style Loss : 0.584149 Content Loss: 0.003455

run [150]:
Style Loss : 0.459957 Content Loss: 0.004699

run [200]:
Style Loss : 0.399049 Content Loss: 0.005492

run [250]:
Style Loss : 0.361021 Content Loss: 0.006065

run [300]:
Style Loss : 0.332559 Content Loss: 0.006556

run [350]:
Style Loss : 0.310480 Content Loss: 0.006963

run [400]:
Style Loss : 0.293826 Content Loss: 0.007300

run [450]:
Style Loss : 0.280543 Content Loss: 0.007603

run [500]:
Style Loss : 0.270180 Content Loss: 0.007868

run [550]:
Style Loss : 0.261675 Content Loss: 0.008083

run [600]:
Style Loss : 0.254504 Content Loss: 0.008304

run [650]:
Style Loss : 0.248670 Content Loss: 0.008500

run [700]:
Style Loss : 0.243694 Content Loss: 0.008658

run [750]:
Style Loss : 0.239292 Content Loss: 0.008819

run [800]:
Style Loss : 0.235557 Content Loss: 0.008959

run [850]:
Style Loss : 0.232199 Content Loss: 0.009091

run [900]:
Style Loss : 0.229294 Content Loss: 0.009217

run [950]:
Style Loss : 0.226455 Content Loss: 0.009344

run [1000]:
Style Loss : 0.223585 Content Loss: 0.009453

run [1050]:
Style Loss : 0.221109 Content Loss: 0.009550

run [1100]:
Style Loss : 0.218813 Content Loss: 0.009639

run [1150]:
Style Loss : 0.216911 Content Loss: 0.009734

run [1200]:
Style Loss : 0.215053 Content Loss: 0.009832

run [1250]:
Style Loss : 0.213405 Content Loss: 0.009913

run [1300]:
Style Loss : 0.211845 Content Loss: 0.010011

run [1350]:
Style Loss : 0.210446 Content Loss: 0.010110

run [1400]:
Style Loss : 0.209009 Content Loss: 0.010192

run [1450]:
Style Loss : 0.207588 Content Loss: 0.010267

run [1500]:
Style Loss : 0.206290 Content Loss: 0.010359

run [1550]:
Style Loss : 0.204991 Content Loss: 0.010446

run [1600]:
Style Loss : 0.203735 Content Loss: 0.010539

run [1650]:
Style Loss : 0.202720 Content Loss: 0.010676

run [1700]:
Style Loss : 0.201335 Content Loss: 0.010734

run [1750]:
Style Loss : 0.200065 Content Loss: 0.010817

run [1800]:
Style Loss : 0.198965 Content Loss: 0.010935

run [1850]:
Style Loss : 0.197729 Content Loss: 0.011019

run [1900]:
Style Loss : 0.196547 Content Loss: 0.011098

run [1950]:
Style Loss : 0.195516 Content Loss: 0.011207

run [2000]:
Style Loss : 0.194543 Content Loss: 0.011299

run [2050]:
Style Loss : 0.193309 Content Loss: 0.011366

run [2100]:
Style Loss : 0.191454 Content Loss: 0.011467

run [2150]:
Style Loss : 0.190292 Content Loss: 0.011557

run [2200]:
Style Loss : 0.188982 Content Loss: 0.011653

run [2250]:
Style Loss : 0.188990 Content Loss: 0.011909

run [2300]:
Style Loss : 0.186592 Content Loss: 0.011855

run [2350]:
Style Loss : 0.185532 Content Loss: 0.011951

run [2400]:
Style Loss : 0.186526 Content Loss: 0.012042

run [2450]:
Style Loss : 0.184630 Content Loss: 0.012120

run [2500]:
Style Loss : 0.183645 Content Loss: 0.012218

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.634594 Content Loss: 0.002860

run [100]:
Style Loss : 0.350731 Content Loss: 0.005217

run [150]:
Style Loss : 0.276922 Content Loss: 0.006994

run [200]:
Style Loss : 0.243697 Content Loss: 0.008091

run [250]:
Style Loss : 0.222610 Content Loss: 0.008875

run [300]:
Style Loss : 0.207893 Content Loss: 0.009537

run [350]:
Style Loss : 0.197636 Content Loss: 0.010116

run [400]:
Style Loss : 0.189589 Content Loss: 0.010587

run [450]:
Style Loss : 0.182538 Content Loss: 0.011033

run [500]:
Style Loss : 0.175884 Content Loss: 0.011389

run [550]:
Style Loss : 0.170395 Content Loss: 0.011821

run [600]:
Style Loss : 0.165683 Content Loss: 0.012116

run [650]:
Style Loss : 0.161474 Content Loss: 0.012419

run [700]:
Style Loss : 0.158002 Content Loss: 0.012706

run [750]:
Style Loss : 0.154897 Content Loss: 0.012934

run [800]:
Style Loss : 0.152769 Content Loss: 0.013282

run [850]:
Style Loss : 0.149413 Content Loss: 0.013500

run [900]:
Style Loss : 0.146872 Content Loss: 0.013710

run [950]:
Style Loss : 0.147614 Content Loss: 0.013996

run [1000]:
Style Loss : 0.142849 Content Loss: 0.014212

run [1050]:
Style Loss : 0.140759 Content Loss: 0.014448

run [1100]:
Style Loss : 0.138994 Content Loss: 0.014712

run [1150]:
Style Loss : 0.137970 Content Loss: 0.014923

run [1200]:
Style Loss : 0.136861 Content Loss: 0.015171

run [1250]:
Style Loss : 698.930725 Content Loss: 0.419219

run [1300]:
Style Loss : 0.904161 Content Loss: 0.024447

run [1350]:
Style Loss : 0.544083 Content Loss: 0.024656

run [1400]:
Style Loss : 0.414171 Content Loss: 0.025211

run [1450]:
Style Loss : 0.349813 Content Loss: 0.025627

run [1500]:
Style Loss : 0.309824 Content Loss: 0.026004

run [1550]:
Style Loss : 0.283382 Content Loss: 0.026294

run [1600]:
Style Loss : 0.263710 Content Loss: 0.026478

run [1650]:
Style Loss : 0.248356 Content Loss: 0.026673

run [1700]:
Style Loss : 0.235329 Content Loss: 0.026805

run [1750]:
Style Loss : 0.224606 Content Loss: 0.026837

run [1800]:
Style Loss : 0.216306 Content Loss: 0.026861

run [1850]:
Style Loss : 0.209664 Content Loss: 0.026881

run [1900]:
Style Loss : 0.203644 Content Loss: 0.026905

run [1950]:
Style Loss : 0.197615 Content Loss: 0.026915

run [2000]:
Style Loss : 0.192241 Content Loss: 0.026904

run [2050]:
Style Loss : 0.187919 Content Loss: 0.026874

run [2100]:
Style Loss : 0.183889 Content Loss: 0.026858

run [2150]:
Style Loss : 0.180339 Content Loss: 0.026851

run [2200]:
Style Loss : 0.177456 Content Loss: 0.026838

run [2250]:
Style Loss : 0.175000 Content Loss: 0.026808

run [2300]:
Style Loss : 0.172740 Content Loss: 0.026773

run [2350]:
Style Loss : 0.170581 Content Loss: 0.026744

run [2400]:
Style Loss : 0.168196 Content Loss: 0.026724

run [2450]:
Style Loss : 0.165712 Content Loss: 0.026686

run [2500]:
Style Loss : 0.163542 Content Loss: 0.026639

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.811457 Content Loss: 0.001748

run [100]:
Style Loss : 0.471021 Content Loss: 0.003239

run [150]:
Style Loss : 0.362978 Content Loss: 0.004254

run [200]:
Style Loss : 0.308949 Content Loss: 0.005042

run [250]:
Style Loss : 0.265547 Content Loss: 0.005683

run [300]:
Style Loss : 0.237845 Content Loss: 0.006111

run [350]:
Style Loss : 0.218738 Content Loss: 0.006444

run [400]:
Style Loss : 0.204020 Content Loss: 0.006750

run [450]:
Style Loss : 0.193154 Content Loss: 0.007015

run [500]:
Style Loss : 0.184573 Content Loss: 0.007267

run [550]:
Style Loss : 0.178234 Content Loss: 0.007464

run [600]:
Style Loss : 0.173105 Content Loss: 0.007641

run [650]:
Style Loss : 0.169223 Content Loss: 0.007805

run [700]:
Style Loss : 0.165802 Content Loss: 0.007953

run [750]:
Style Loss : 0.162867 Content Loss: 0.008083

run [800]:
Style Loss : 0.160273 Content Loss: 0.008216

run [850]:
Style Loss : 0.157897 Content Loss: 0.008340

run [900]:
Style Loss : 0.155923 Content Loss: 0.008460

run [950]:
Style Loss : 0.153926 Content Loss: 0.008574

run [1000]:
Style Loss : 0.152187 Content Loss: 0.008665

run [1050]:
Style Loss : 0.150580 Content Loss: 0.008758

run [1100]:
Style Loss : 0.148846 Content Loss: 0.008871

run [1150]:
Style Loss : 0.147000 Content Loss: 0.008960

run [1200]:
Style Loss : 0.144910 Content Loss: 0.009042

run [1250]:
Style Loss : 0.143200 Content Loss: 0.009116

run [1300]:
Style Loss : 0.141578 Content Loss: 0.009217

run [1350]:
Style Loss : 0.140001 Content Loss: 0.009291

run [1400]:
Style Loss : 0.138603 Content Loss: 0.009374

run [1450]:
Style Loss : 0.137177 Content Loss: 0.009458

run [1500]:
Style Loss : 0.135890 Content Loss: 0.009539

run [1550]:
Style Loss : 0.134695 Content Loss: 0.009600

run [1600]:
Style Loss : 0.133661 Content Loss: 0.009641

run [1650]:
Style Loss : 0.132701 Content Loss: 0.009691

run [1700]:
Style Loss : 0.131843 Content Loss: 0.009753

run [1750]:
Style Loss : 0.130967 Content Loss: 0.009800

run [1800]:
Style Loss : 0.130132 Content Loss: 0.009852

run [1850]:
Style Loss : 0.129355 Content Loss: 0.009911

run [1900]:
Style Loss : 0.128608 Content Loss: 0.009970

run [1950]:
Style Loss : 0.127885 Content Loss: 0.010008

run [2000]:
Style Loss : 0.127215 Content Loss: 0.010063

run [2050]:
Style Loss : 0.126584 Content Loss: 0.010123

run [2100]:
Style Loss : 0.125973 Content Loss: 0.010155

run [2150]:
Style Loss : 0.125406 Content Loss: 0.010208

run [2200]:
Style Loss : 0.124803 Content Loss: 0.010255

run [2250]:
Style Loss : 0.124264 Content Loss: 0.010308

run [2300]:
Style Loss : 0.123789 Content Loss: 0.010361

run [2350]:
Style Loss : 0.123327 Content Loss: 0.010390

run [2400]:
Style Loss : 0.122856 Content Loss: 0.010430

run [2450]:
Style Loss : 0.122499 Content Loss: 0.010477

run [2500]:
Style Loss : 0.122109 Content Loss: 0.010519

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.257175 Content Loss: 0.002840

run [100]:
Style Loss : 1.277946 Content Loss: 0.003279

run [150]:
Style Loss : 0.964296 Content Loss: 0.004346

run [200]:
Style Loss : 0.807409 Content Loss: 0.005458

run [250]:
Style Loss : 0.711470 Content Loss: 0.006217

run [300]:
Style Loss : 0.643123 Content Loss: 0.006912

run [350]:
Style Loss : 0.592821 Content Loss: 0.007464

run [400]:
Style Loss : 0.551906 Content Loss: 0.007928

run [450]:
Style Loss : 0.520615 Content Loss: 0.008219

run [500]:
Style Loss : 0.495353 Content Loss: 0.008491

run [550]:
Style Loss : 0.474930 Content Loss: 0.008741

run [600]:
Style Loss : 0.458210 Content Loss: 0.008977

run [650]:
Style Loss : 0.444836 Content Loss: 0.009167

run [700]:
Style Loss : 0.433185 Content Loss: 0.009366

run [750]:
Style Loss : 0.423389 Content Loss: 0.009494

run [800]:
Style Loss : 0.414713 Content Loss: 0.009645

run [850]:
Style Loss : 0.407288 Content Loss: 0.009756

run [900]:
Style Loss : 0.400736 Content Loss: 0.009882

run [950]:
Style Loss : 0.394867 Content Loss: 0.009983

run [1000]:
Style Loss : 0.389543 Content Loss: 0.010084

run [1050]:
Style Loss : 0.384787 Content Loss: 0.010178

run [1100]:
Style Loss : 0.380210 Content Loss: 0.010262

run [1150]:
Style Loss : 0.376031 Content Loss: 0.010335

run [1200]:
Style Loss : 0.372087 Content Loss: 0.010395

run [1250]:
Style Loss : 0.368548 Content Loss: 0.010458

run [1300]:
Style Loss : 0.365289 Content Loss: 0.010510

run [1350]:
Style Loss : 0.362259 Content Loss: 0.010560

run [1400]:
Style Loss : 0.359180 Content Loss: 0.010632

run [1450]:
Style Loss : 0.356024 Content Loss: 0.010696

run [1500]:
Style Loss : 0.352827 Content Loss: 0.010767

run [1550]:
Style Loss : 0.349961 Content Loss: 0.010828

run [1600]:
Style Loss : 0.347235 Content Loss: 0.010894

run [1650]:
Style Loss : 0.344444 Content Loss: 0.010963

run [1700]:
Style Loss : 0.342017 Content Loss: 0.011018

run [1750]:
Style Loss : 0.339604 Content Loss: 0.011068

run [1800]:
Style Loss : 0.337139 Content Loss: 0.011121

run [1850]:
Style Loss : 0.334689 Content Loss: 0.011166

run [1900]:
Style Loss : 0.332463 Content Loss: 0.011222

run [1950]:
Style Loss : 0.330134 Content Loss: 0.011258

run [2000]:
Style Loss : 0.328086 Content Loss: 0.011304

run [2050]:
Style Loss : 0.326165 Content Loss: 0.011346

run [2100]:
Style Loss : 0.324628 Content Loss: 0.011389

run [2150]:
Style Loss : 0.322926 Content Loss: 0.011442

run [2200]:
Style Loss : 0.321264 Content Loss: 0.011482

run [2250]:
Style Loss : 0.319504 Content Loss: 0.011521

run [2300]:
Style Loss : 0.317459 Content Loss: 0.011569

run [2350]:
Style Loss : 0.315772 Content Loss: 0.011617

run [2400]:
Style Loss : 0.313659 Content Loss: 0.011641

run [2450]:
Style Loss : 0.312043 Content Loss: 0.011683

run [2500]:
Style Loss : 0.310443 Content Loss: 0.011730

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.692173 Content Loss: 0.002704

run [100]:
Style Loss : 0.375529 Content Loss: 0.005514

run [150]:
Style Loss : 0.267861 Content Loss: 0.007278

run [200]:
Style Loss : 0.216725 Content Loss: 0.008338

run [250]:
Style Loss : 0.188346 Content Loss: 0.009070

run [300]:
Style Loss : 0.168905 Content Loss: 0.009639

run [350]:
Style Loss : 0.153294 Content Loss: 0.010107

run [400]:
Style Loss : 0.141834 Content Loss: 0.010513

run [450]:
Style Loss : 0.133276 Content Loss: 0.010866

run [500]:
Style Loss : 0.126820 Content Loss: 0.011091

run [550]:
Style Loss : 0.121712 Content Loss: 0.011248

run [600]:
Style Loss : 0.117059 Content Loss: 0.011399

run [650]:
Style Loss : 0.111935 Content Loss: 0.011520

run [700]:
Style Loss : 0.107898 Content Loss: 0.011653

run [750]:
Style Loss : 0.104386 Content Loss: 0.011782

run [800]:
Style Loss : 0.101428 Content Loss: 0.011884

run [850]:
Style Loss : 0.098708 Content Loss: 0.011989

run [900]:
Style Loss : 0.096168 Content Loss: 0.012092

run [950]:
Style Loss : 0.093799 Content Loss: 0.012157

run [1000]:
Style Loss : 0.091782 Content Loss: 0.012221

run [1050]:
Style Loss : 0.090046 Content Loss: 0.012264

run [1100]:
Style Loss : 0.088656 Content Loss: 0.012305

run [1150]:
Style Loss : 0.087424 Content Loss: 0.012361

run [1200]:
Style Loss : 0.086220 Content Loss: 0.012410

run [1250]:
Style Loss : 0.085160 Content Loss: 0.012446

run [1300]:
Style Loss : 0.084331 Content Loss: 0.012484

run [1350]:
Style Loss : 0.083574 Content Loss: 0.012513

run [1400]:
Style Loss : 0.082815 Content Loss: 0.012540

run [1450]:
Style Loss : 0.082154 Content Loss: 0.012564

run [1500]:
Style Loss : 0.081582 Content Loss: 0.012587

run [1550]:
Style Loss : 0.080988 Content Loss: 0.012613

run [1600]:
Style Loss : 0.080412 Content Loss: 0.012636

run [1650]:
Style Loss : 0.079839 Content Loss: 0.012648

run [1700]:
Style Loss : 0.079322 Content Loss: 0.012667

run [1750]:
Style Loss : 0.078814 Content Loss: 0.012673

run [1800]:
Style Loss : 0.078348 Content Loss: 0.012693

run [1850]:
Style Loss : 0.077940 Content Loss: 0.012693

run [1900]:
Style Loss : 0.077544 Content Loss: 0.012706

run [1950]:
Style Loss : 0.077194 Content Loss: 0.012715

run [2000]:
Style Loss : 0.076885 Content Loss: 0.012729

run [2050]:
Style Loss : 0.076568 Content Loss: 0.012738

run [2100]:
Style Loss : 0.076299 Content Loss: 0.012748

run [2150]:
Style Loss : 0.076023 Content Loss: 0.012750

run [2200]:
Style Loss : 0.075802 Content Loss: 0.012759

run [2250]:
Style Loss : 0.075541 Content Loss: 0.012767

run [2300]:
Style Loss : 0.075317 Content Loss: 0.012775

run [2350]:
Style Loss : 0.075103 Content Loss: 0.012780

run [2400]:
Style Loss : 0.074880 Content Loss: 0.012789

run [2450]:
Style Loss : 0.074687 Content Loss: 0.012801

run [2500]:
Style Loss : 0.074467 Content Loss: 0.012811

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.910335 Content Loss: 0.001848

run [100]:
Style Loss : 1.126847 Content Loss: 0.003356

run [150]:
Style Loss : 0.863494 Content Loss: 0.004957

run [200]:
Style Loss : 0.708836 Content Loss: 0.006177

run [250]:
Style Loss : 0.610456 Content Loss: 0.007232

run [300]:
Style Loss : 0.546818 Content Loss: 0.008032

run [350]:
Style Loss : 0.500244 Content Loss: 0.008688

run [400]:
Style Loss : 0.460534 Content Loss: 0.009209

run [450]:
Style Loss : 0.431930 Content Loss: 0.009675

run [500]:
Style Loss : 0.409949 Content Loss: 0.010087

run [550]:
Style Loss : 0.392141 Content Loss: 0.010398

run [600]:
Style Loss : 0.368965 Content Loss: 0.010736

run [650]:
Style Loss : 0.350905 Content Loss: 0.010998

run [700]:
Style Loss : 0.338332 Content Loss: 0.011222

run [750]:
Style Loss : 0.327960 Content Loss: 0.011443

run [800]:
Style Loss : 0.319693 Content Loss: 0.011655

run [850]:
Style Loss : 0.312115 Content Loss: 0.011840

run [900]:
Style Loss : 0.304911 Content Loss: 0.011998

run [950]:
Style Loss : 0.298797 Content Loss: 0.012154

run [1000]:
Style Loss : 0.294018 Content Loss: 0.012270

run [1050]:
Style Loss : 0.289784 Content Loss: 0.012375

run [1100]:
Style Loss : 0.285465 Content Loss: 0.012484

run [1150]:
Style Loss : 0.281813 Content Loss: 0.012565

run [1200]:
Style Loss : 0.278408 Content Loss: 0.012640

run [1250]:
Style Loss : 0.274600 Content Loss: 0.012710

run [1300]:
Style Loss : 0.271483 Content Loss: 0.012773

run [1350]:
Style Loss : 0.268940 Content Loss: 0.012829

run [1400]:
Style Loss : 0.266596 Content Loss: 0.012889

run [1450]:
Style Loss : 0.264422 Content Loss: 0.012949

run [1500]:
Style Loss : 0.262524 Content Loss: 0.012997

run [1550]:
Style Loss : 0.260770 Content Loss: 0.013048

run [1600]:
Style Loss : 0.258782 Content Loss: 0.013112

run [1650]:
Style Loss : 0.256977 Content Loss: 0.013157

run [1700]:
Style Loss : 0.255452 Content Loss: 0.013204

run [1750]:
Style Loss : 0.253996 Content Loss: 0.013251

run [1800]:
Style Loss : 0.252642 Content Loss: 0.013303

run [1850]:
Style Loss : 0.251443 Content Loss: 0.013339

run [1900]:
Style Loss : 0.250299 Content Loss: 0.013381

run [1950]:
Style Loss : 0.249192 Content Loss: 0.013422

run [2000]:
Style Loss : 0.248162 Content Loss: 0.013459

run [2050]:
Style Loss : 0.247055 Content Loss: 0.013507

run [2100]:
Style Loss : 0.245804 Content Loss: 0.013556

run [2150]:
Style Loss : 0.244557 Content Loss: 0.013602

run [2200]:
Style Loss : 0.243324 Content Loss: 0.013644

run [2250]:
Style Loss : 0.242187 Content Loss: 0.013691

run [2300]:
Style Loss : 0.241201 Content Loss: 0.013724

run [2350]:
Style Loss : 0.240219 Content Loss: 0.013758

run [2400]:
Style Loss : 0.239361 Content Loss: 0.013787

run [2450]:
Style Loss : 0.238594 Content Loss: 0.013818

run [2500]:
Style Loss : 0.237887 Content Loss: 0.013848

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.337587 Content Loss: 0.001914

run [100]:
Style Loss : 0.858907 Content Loss: 0.002981

run [150]:
Style Loss : 0.667877 Content Loss: 0.004719

run [200]:
Style Loss : 0.557628 Content Loss: 0.006279

run [250]:
Style Loss : 0.486621 Content Loss: 0.007572

run [300]:
Style Loss : 0.435066 Content Loss: 0.008728

run [350]:
Style Loss : 0.397243 Content Loss: 0.009637

run [400]:
Style Loss : 0.368846 Content Loss: 0.010455

run [450]:
Style Loss : 0.347031 Content Loss: 0.011233

run [500]:
Style Loss : 0.329748 Content Loss: 0.011961

run [550]:
Style Loss : 0.316553 Content Loss: 0.012579

run [600]:
Style Loss : 0.306647 Content Loss: 0.013115

run [650]:
Style Loss : 0.298635 Content Loss: 0.013505

run [700]:
Style Loss : 0.292006 Content Loss: 0.013899

run [750]:
Style Loss : 0.286053 Content Loss: 0.014170

run [800]:
Style Loss : 0.280811 Content Loss: 0.014451

run [850]:
Style Loss : 0.276164 Content Loss: 0.014645

run [900]:
Style Loss : 0.271981 Content Loss: 0.014833

run [950]:
Style Loss : 0.268254 Content Loss: 0.015015

run [1000]:
Style Loss : 0.265023 Content Loss: 0.015166

run [1050]:
Style Loss : 0.262162 Content Loss: 0.015314

run [1100]:
Style Loss : 0.259687 Content Loss: 0.015451

run [1150]:
Style Loss : 0.257366 Content Loss: 0.015580

run [1200]:
Style Loss : 0.255304 Content Loss: 0.015703

run [1250]:
Style Loss : 0.253493 Content Loss: 0.015807

run [1300]:
Style Loss : 0.251733 Content Loss: 0.015905

run [1350]:
Style Loss : 0.250153 Content Loss: 0.015999

run [1400]:
Style Loss : 0.248596 Content Loss: 0.016096

run [1450]:
Style Loss : 0.247235 Content Loss: 0.016169

run [1500]:
Style Loss : 0.245918 Content Loss: 0.016244

run [1550]:
Style Loss : 0.244633 Content Loss: 0.016313

run [1600]:
Style Loss : 0.243553 Content Loss: 0.016370

run [1650]:
Style Loss : 0.242568 Content Loss: 0.016423

run [1700]:
Style Loss : 0.241665 Content Loss: 0.016474

run [1750]:
Style Loss : 0.240802 Content Loss: 0.016525

run [1800]:
Style Loss : 0.239982 Content Loss: 0.016572

run [1850]:
Style Loss : 0.239193 Content Loss: 0.016625

run [1900]:
Style Loss : 0.238415 Content Loss: 0.016679

run [1950]:
Style Loss : 0.237661 Content Loss: 0.016727

run [2000]:
Style Loss : 0.236979 Content Loss: 0.016769

run [2050]:
Style Loss : 0.236310 Content Loss: 0.016808

run [2100]:
Style Loss : 0.235752 Content Loss: 0.016846

run [2150]:
Style Loss : 0.235202 Content Loss: 0.016880

run [2200]:
Style Loss : 0.234676 Content Loss: 0.016907

run [2250]:
Style Loss : 0.234188 Content Loss: 0.016934

run [2300]:
Style Loss : 0.233701 Content Loss: 0.016966

run [2350]:
Style Loss : 0.233267 Content Loss: 0.016993

run [2400]:
Style Loss : 0.232845 Content Loss: 0.017018

run [2450]:
Style Loss : 0.232408 Content Loss: 0.017046

run [2500]:
Style Loss : 0.231991 Content Loss: 0.017074

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.445466 Content Loss: 0.001237

run [100]:
Style Loss : 0.879247 Content Loss: 0.002014

run [150]:
Style Loss : 0.649599 Content Loss: 0.003134

run [200]:
Style Loss : 0.528643 Content Loss: 0.004550

run [250]:
Style Loss : 0.456774 Content Loss: 0.005796

run [300]:
Style Loss : 0.403621 Content Loss: 0.007116

run [350]:
Style Loss : 0.366090 Content Loss: 0.008274

run [400]:
Style Loss : 0.333600 Content Loss: 0.009444

run [450]:
Style Loss : 0.307683 Content Loss: 0.010375

run [500]:
Style Loss : 0.284438 Content Loss: 0.011205

run [550]:
Style Loss : 0.266235 Content Loss: 0.011928

run [600]:
Style Loss : 0.251228 Content Loss: 0.012505

run [650]:
Style Loss : 0.239531 Content Loss: 0.012991

run [700]:
Style Loss : 0.229641 Content Loss: 0.013386

run [750]:
Style Loss : 0.221801 Content Loss: 0.013650

run [800]:
Style Loss : 0.215011 Content Loss: 0.013951

run [850]:
Style Loss : 0.209141 Content Loss: 0.014125

run [900]:
Style Loss : 0.204131 Content Loss: 0.014322

run [950]:
Style Loss : 0.199431 Content Loss: 0.014515

run [1000]:
Style Loss : 0.194899 Content Loss: 0.014692

run [1050]:
Style Loss : 0.190610 Content Loss: 0.014872

run [1100]:
Style Loss : 0.186936 Content Loss: 0.015050

run [1150]:
Style Loss : 0.183438 Content Loss: 0.015187

run [1200]:
Style Loss : 0.180228 Content Loss: 0.015347

run [1250]:
Style Loss : 0.177219 Content Loss: 0.015540

run [1300]:
Style Loss : 0.174545 Content Loss: 0.015719

run [1350]:
Style Loss : 0.171567 Content Loss: 0.015839

run [1400]:
Style Loss : 0.168846 Content Loss: 0.016004

run [1450]:
Style Loss : 0.166330 Content Loss: 0.016171

run [1500]:
Style Loss : 0.163963 Content Loss: 0.016336

run [1550]:
Style Loss : 0.161651 Content Loss: 0.016486

run [1600]:
Style Loss : 0.159647 Content Loss: 0.016644

run [1650]:
Style Loss : 0.157692 Content Loss: 0.016825

run [1700]:
Style Loss : 0.155703 Content Loss: 0.016981

run [1750]:
Style Loss : 0.153907 Content Loss: 0.017164

run [1800]:
Style Loss : 0.152217 Content Loss: 0.017365

run [1850]:
Style Loss : 0.150300 Content Loss: 0.017515

run [1900]:
Style Loss : 0.148730 Content Loss: 0.017695

run [1950]:
Style Loss : 0.147044 Content Loss: 0.017857

run [2000]:
Style Loss : 0.145493 Content Loss: 0.017999

run [2050]:
Style Loss : 0.144064 Content Loss: 0.018170

run [2100]:
Style Loss : 0.142924 Content Loss: 0.018390

run [2150]:
Style Loss : 0.141337 Content Loss: 0.018510

run [2200]:
Style Loss : 0.140001 Content Loss: 0.018704

run [2250]:
Style Loss : 0.138789 Content Loss: 0.018868

run [2300]:
Style Loss : 0.139497 Content Loss: 0.019241

run [2350]:
Style Loss : 0.136443 Content Loss: 0.019195

run [2400]:
Style Loss : 0.135298 Content Loss: 0.019351

run [2450]:
Style Loss : 0.134472 Content Loss: 0.019543

run [2500]:
Style Loss : 0.133509 Content Loss: 0.019640

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.033839 Content Loss: 0.001577

run [100]:
Style Loss : 1.243055 Content Loss: 0.002930

run [150]:
Style Loss : 0.924268 Content Loss: 0.004117

run [200]:
Style Loss : 0.770867 Content Loss: 0.005087

run [250]:
Style Loss : 0.684669 Content Loss: 0.006010

run [300]:
Style Loss : 0.621099 Content Loss: 0.006735

run [350]:
Style Loss : 0.575517 Content Loss: 0.007351

run [400]:
Style Loss : 0.540664 Content Loss: 0.007873

run [450]:
Style Loss : 0.516511 Content Loss: 0.008359

run [500]:
Style Loss : 0.497728 Content Loss: 0.008759

run [550]:
Style Loss : 0.482318 Content Loss: 0.009133

run [600]:
Style Loss : 0.466273 Content Loss: 0.009492

run [650]:
Style Loss : 0.453475 Content Loss: 0.009818

run [700]:
Style Loss : 0.443619 Content Loss: 0.010085

run [750]:
Style Loss : 0.435342 Content Loss: 0.010348

run [800]:
Style Loss : 0.428373 Content Loss: 0.010567

run [850]:
Style Loss : 0.421848 Content Loss: 0.010811

run [900]:
Style Loss : 0.416216 Content Loss: 0.011016

run [950]:
Style Loss : 0.411300 Content Loss: 0.011210

run [1000]:
Style Loss : 0.406778 Content Loss: 0.011395

run [1050]:
Style Loss : 0.402264 Content Loss: 0.011581

run [1100]:
Style Loss : 0.397515 Content Loss: 0.011741

run [1150]:
Style Loss : 0.393441 Content Loss: 0.011872

run [1200]:
Style Loss : 0.389086 Content Loss: 0.012025

run [1250]:
Style Loss : 0.384748 Content Loss: 0.012165

run [1300]:
Style Loss : 0.381323 Content Loss: 0.012288

run [1350]:
Style Loss : 0.378132 Content Loss: 0.012408

run [1400]:
Style Loss : 0.375208 Content Loss: 0.012530

run [1450]:
Style Loss : 0.372527 Content Loss: 0.012638

run [1500]:
Style Loss : 0.369604 Content Loss: 0.012762

run [1550]:
Style Loss : 0.366868 Content Loss: 0.012872

run [1600]:
Style Loss : 0.364255 Content Loss: 0.012986

run [1650]:
Style Loss : 0.361539 Content Loss: 0.013084

run [1700]:
Style Loss : 0.358975 Content Loss: 0.013190

run [1750]:
Style Loss : 0.356481 Content Loss: 0.013294

run [1800]:
Style Loss : 0.354122 Content Loss: 0.013410

run [1850]:
Style Loss : 0.351849 Content Loss: 0.013516

run [1900]:
Style Loss : 0.349622 Content Loss: 0.013620

run [1950]:
Style Loss : 0.347341 Content Loss: 0.013731

run [2000]:
Style Loss : 0.345022 Content Loss: 0.013824

run [2050]:
Style Loss : 0.342831 Content Loss: 0.013940

run [2100]:
Style Loss : 0.340587 Content Loss: 0.014054

run [2150]:
Style Loss : 0.338348 Content Loss: 0.014169

run [2200]:
Style Loss : 0.335936 Content Loss: 0.014307

run [2250]:
Style Loss : 0.333468 Content Loss: 0.014451

run [2300]:
Style Loss : 0.331170 Content Loss: 0.014579

run [2350]:
Style Loss : 0.328981 Content Loss: 0.014704

run [2400]:
Style Loss : 0.326763 Content Loss: 0.014841

run [2450]:
Style Loss : 0.324595 Content Loss: 0.014992

run [2500]:
Style Loss : 0.322432 Content Loss: 0.015150

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.745651 Content Loss: 0.003244

run [100]:
Style Loss : 0.425101 Content Loss: 0.005454

run [150]:
Style Loss : 0.307250 Content Loss: 0.007089

run [200]:
Style Loss : 0.255151 Content Loss: 0.008605

run [250]:
Style Loss : 0.223600 Content Loss: 0.009819

run [300]:
Style Loss : 0.204173 Content Loss: 0.010615

run [350]:
Style Loss : 0.190174 Content Loss: 0.011159

run [400]:
Style Loss : 0.180967 Content Loss: 0.011516

run [450]:
Style Loss : 0.173192 Content Loss: 0.011835

run [500]:
Style Loss : 0.167758 Content Loss: 0.012043

run [550]:
Style Loss : 0.163362 Content Loss: 0.012220

run [600]:
Style Loss : 0.159677 Content Loss: 0.012411

run [650]:
Style Loss : 0.156488 Content Loss: 0.012535

run [700]:
Style Loss : 0.153656 Content Loss: 0.012650

run [750]:
Style Loss : 0.151181 Content Loss: 0.012758

run [800]:
Style Loss : 0.149259 Content Loss: 0.012860

run [850]:
Style Loss : 0.147453 Content Loss: 0.012956

run [900]:
Style Loss : 0.145747 Content Loss: 0.013038

run [950]:
Style Loss : 0.144304 Content Loss: 0.013101

run [1000]:
Style Loss : 0.143074 Content Loss: 0.013168

run [1050]:
Style Loss : 0.141954 Content Loss: 0.013231

run [1100]:
Style Loss : 0.140937 Content Loss: 0.013279

run [1150]:
Style Loss : 0.139913 Content Loss: 0.013342

run [1200]:
Style Loss : 0.138996 Content Loss: 0.013390

run [1250]:
Style Loss : 0.138176 Content Loss: 0.013430

run [1300]:
Style Loss : 0.137450 Content Loss: 0.013465

run [1350]:
Style Loss : 0.136829 Content Loss: 0.013498

run [1400]:
Style Loss : 0.136234 Content Loss: 0.013536

run [1450]:
Style Loss : 0.135732 Content Loss: 0.013561

run [1500]:
Style Loss : 0.135243 Content Loss: 0.013591

run [1550]:
Style Loss : 0.134752 Content Loss: 0.013613

run [1600]:
Style Loss : 0.134293 Content Loss: 0.013647

run [1650]:
Style Loss : 0.133850 Content Loss: 0.013671

run [1700]:
Style Loss : 0.133414 Content Loss: 0.013698

run [1750]:
Style Loss : 0.133009 Content Loss: 0.013725

run [1800]:
Style Loss : 0.132582 Content Loss: 0.013757

run [1850]:
Style Loss : 0.132158 Content Loss: 0.013799

run [1900]:
Style Loss : 0.131727 Content Loss: 0.013826

run [1950]:
Style Loss : 0.131316 Content Loss: 0.013861

run [2000]:
Style Loss : 0.130932 Content Loss: 0.013897

run [2050]:
Style Loss : 0.130555 Content Loss: 0.013929

run [2100]:
Style Loss : 0.130151 Content Loss: 0.013957

run [2150]:
Style Loss : 0.129784 Content Loss: 0.013982

run [2200]:
Style Loss : 0.129433 Content Loss: 0.014009

run [2250]:
Style Loss : 0.129071 Content Loss: 0.014043

run [2300]:
Style Loss : 0.128708 Content Loss: 0.014074

run [2350]:
Style Loss : 0.128356 Content Loss: 0.014101

run [2400]:
Style Loss : 0.128015 Content Loss: 0.014126

run [2450]:
Style Loss : 0.127674 Content Loss: 0.014147

run [2500]:
Style Loss : 0.127384 Content Loss: 0.014163

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.707288 Content Loss: 0.003115

run [100]:
Style Loss : 0.420559 Content Loss: 0.006730

run [150]:
Style Loss : 0.307195 Content Loss: 0.010536

run [200]:
Style Loss : 0.250053 Content Loss: 0.013036

run [250]:
Style Loss : 0.216853 Content Loss: 0.014889

run [300]:
Style Loss : 0.197430 Content Loss: 0.016022

run [350]:
Style Loss : 0.183487 Content Loss: 0.016977

run [400]:
Style Loss : 0.173328 Content Loss: 0.017543

run [450]:
Style Loss : 0.164210 Content Loss: 0.018009

run [500]:
Style Loss : 0.156673 Content Loss: 0.018302

run [550]:
Style Loss : 0.150078 Content Loss: 0.018653

run [600]:
Style Loss : 0.144435 Content Loss: 0.018947

run [650]:
Style Loss : 0.140074 Content Loss: 0.019190

run [700]:
Style Loss : 0.135983 Content Loss: 0.019404

run [750]:
Style Loss : 0.132143 Content Loss: 0.019620

run [800]:
Style Loss : 0.128788 Content Loss: 0.019837

run [850]:
Style Loss : 0.125543 Content Loss: 0.020073

run [900]:
Style Loss : 0.122525 Content Loss: 0.020284

run [950]:
Style Loss : 0.119847 Content Loss: 0.020454

run [1000]:
Style Loss : 0.117350 Content Loss: 0.020619

run [1050]:
Style Loss : 0.115208 Content Loss: 0.020731

run [1100]:
Style Loss : 0.113623 Content Loss: 0.020838

run [1150]:
Style Loss : 0.112215 Content Loss: 0.020955

run [1200]:
Style Loss : 0.110953 Content Loss: 0.021059

run [1250]:
Style Loss : 0.109712 Content Loss: 0.021150

run [1300]:
Style Loss : 0.108628 Content Loss: 0.021220

run [1350]:
Style Loss : 0.107693 Content Loss: 0.021301

run [1400]:
Style Loss : 0.106893 Content Loss: 0.021361

run [1450]:
Style Loss : 0.106216 Content Loss: 0.021422

run [1500]:
Style Loss : 0.105567 Content Loss: 0.021481

run [1550]:
Style Loss : 0.104954 Content Loss: 0.021541

run [1600]:
Style Loss : 0.104323 Content Loss: 0.021595

run [1650]:
Style Loss : 0.103689 Content Loss: 0.021656

run [1700]:
Style Loss : 0.103066 Content Loss: 0.021700

run [1750]:
Style Loss : 0.102362 Content Loss: 0.021753

run [1800]:
Style Loss : 0.101707 Content Loss: 0.021793

run [1850]:
Style Loss : 0.101022 Content Loss: 0.021835

run [1900]:
Style Loss : 0.100443 Content Loss: 0.021870

run [1950]:
Style Loss : 0.099959 Content Loss: 0.021917

run [2000]:
Style Loss : 0.099528 Content Loss: 0.021949

run [2050]:
Style Loss : 0.099193 Content Loss: 0.021974

run [2100]:
Style Loss : 0.098854 Content Loss: 0.022019

run [2150]:
Style Loss : 0.098540 Content Loss: 0.022039

run [2200]:
Style Loss : 0.098281 Content Loss: 0.022076

run [2250]:
Style Loss : 0.098026 Content Loss: 0.022096

run [2300]:
Style Loss : 0.097755 Content Loss: 0.022125

run [2350]:
Style Loss : 0.097479 Content Loss: 0.022154

run [2400]:
Style Loss : 0.097208 Content Loss: 0.022173

run [2450]:
Style Loss : 0.096970 Content Loss: 0.022205

run [2500]:
Style Loss : 0.096719 Content Loss: 0.022217

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.499880 Content Loss: 0.011769

run [100]:
Style Loss : 1.445203 Content Loss: 0.014590

run [150]:
Style Loss : 1.056463 Content Loss: 0.016995

run [200]:
Style Loss : 0.866550 Content Loss: 0.019596

run [250]:
Style Loss : 0.762166 Content Loss: 0.021436

run [300]:
Style Loss : 0.693833 Content Loss: 0.022767

run [350]:
Style Loss : 0.650100 Content Loss: 0.023777

run [400]:
Style Loss : 0.619973 Content Loss: 0.024678

run [450]:
Style Loss : 0.596529 Content Loss: 0.025384

run [500]:
Style Loss : 0.578573 Content Loss: 0.025922

run [550]:
Style Loss : 0.562578 Content Loss: 0.026367

run [600]:
Style Loss : 0.550884 Content Loss: 0.026715

run [650]:
Style Loss : 0.541244 Content Loss: 0.027069

run [700]:
Style Loss : 0.533162 Content Loss: 0.027370

run [750]:
Style Loss : 0.525705 Content Loss: 0.027618

run [800]:
Style Loss : 0.519131 Content Loss: 0.027870

run [850]:
Style Loss : 0.513400 Content Loss: 0.028110

run [900]:
Style Loss : 0.508106 Content Loss: 0.028290

run [950]:
Style Loss : 0.502701 Content Loss: 0.028462

run [1000]:
Style Loss : 0.497851 Content Loss: 0.028623

run [1050]:
Style Loss : 0.493716 Content Loss: 0.028749

run [1100]:
Style Loss : 0.489577 Content Loss: 0.028882

run [1150]:
Style Loss : 0.486096 Content Loss: 0.029012

run [1200]:
Style Loss : 0.482913 Content Loss: 0.029142

run [1250]:
Style Loss : 0.480167 Content Loss: 0.029243

run [1300]:
Style Loss : 0.477516 Content Loss: 0.029359

run [1350]:
Style Loss : 0.475124 Content Loss: 0.029441

run [1400]:
Style Loss : 0.472902 Content Loss: 0.029547

run [1450]:
Style Loss : 0.470842 Content Loss: 0.029646

run [1500]:
Style Loss : 0.469129 Content Loss: 0.029696

run [1550]:
Style Loss : 0.467513 Content Loss: 0.029763

run [1600]:
Style Loss : 0.465906 Content Loss: 0.029839

run [1650]:
Style Loss : 0.464486 Content Loss: 0.029893

run [1700]:
Style Loss : 0.463078 Content Loss: 0.029945

run [1750]:
Style Loss : 0.461758 Content Loss: 0.029986

run [1800]:
Style Loss : 0.460536 Content Loss: 0.030041

run [1850]:
Style Loss : 0.459434 Content Loss: 0.030080

run [1900]:
Style Loss : 0.458354 Content Loss: 0.030127

run [1950]:
Style Loss : 0.457318 Content Loss: 0.030163

run [2000]:
Style Loss : 0.456189 Content Loss: 0.030218

run [2050]:
Style Loss : 0.455178 Content Loss: 0.030275

run [2100]:
Style Loss : 0.454186 Content Loss: 0.030318

run [2150]:
Style Loss : 0.453217 Content Loss: 0.030352

run [2200]:
Style Loss : 0.452329 Content Loss: 0.030394

run [2250]:
Style Loss : 0.451508 Content Loss: 0.030433

run [2300]:
Style Loss : 0.450682 Content Loss: 0.030464

run [2350]:
Style Loss : 0.449847 Content Loss: 0.030510

run [2400]:
Style Loss : 0.449056 Content Loss: 0.030547

run [2450]:
Style Loss : 0.448204 Content Loss: 0.030592

run [2500]:
Style Loss : 0.447401 Content Loss: 0.030621

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.245366 Content Loss: 0.001779

run [100]:
Style Loss : 0.754612 Content Loss: 0.003230

run [150]:
Style Loss : 0.577500 Content Loss: 0.005147

run [200]:
Style Loss : 0.476355 Content Loss: 0.006925

run [250]:
Style Loss : 0.409431 Content Loss: 0.008549

run [300]:
Style Loss : 0.358067 Content Loss: 0.010080

run [350]:
Style Loss : 0.319894 Content Loss: 0.011357

run [400]:
Style Loss : 0.291072 Content Loss: 0.012555

run [450]:
Style Loss : 0.269919 Content Loss: 0.013472

run [500]:
Style Loss : 0.254128 Content Loss: 0.014120

run [550]:
Style Loss : 0.242553 Content Loss: 0.014557

run [600]:
Style Loss : 0.233550 Content Loss: 0.014893

run [650]:
Style Loss : 0.225811 Content Loss: 0.015222

run [700]:
Style Loss : 0.219283 Content Loss: 0.015437

run [750]:
Style Loss : 0.214184 Content Loss: 0.015619

run [800]:
Style Loss : 0.209826 Content Loss: 0.015822

run [850]:
Style Loss : 0.205915 Content Loss: 0.015960

run [900]:
Style Loss : 0.202644 Content Loss: 0.016129

run [950]:
Style Loss : 0.199499 Content Loss: 0.016269

run [1000]:
Style Loss : 0.196603 Content Loss: 0.016408

run [1050]:
Style Loss : 0.193893 Content Loss: 0.016529

run [1100]:
Style Loss : 0.191424 Content Loss: 0.016644

run [1150]:
Style Loss : 0.188790 Content Loss: 0.016768

run [1200]:
Style Loss : 0.186211 Content Loss: 0.016882

run [1250]:
Style Loss : 0.184268 Content Loss: 0.016989

run [1300]:
Style Loss : 0.182451 Content Loss: 0.017072

run [1350]:
Style Loss : 0.180762 Content Loss: 0.017190

run [1400]:
Style Loss : 0.179292 Content Loss: 0.017312

run [1450]:
Style Loss : 0.177834 Content Loss: 0.017418

run [1500]:
Style Loss : 0.176472 Content Loss: 0.017529

run [1550]:
Style Loss : 0.175159 Content Loss: 0.017653

run [1600]:
Style Loss : 0.173870 Content Loss: 0.017766

run [1650]:
Style Loss : 0.172774 Content Loss: 0.017882

run [1700]:
Style Loss : 0.171482 Content Loss: 0.017948

run [1750]:
Style Loss : 0.170213 Content Loss: 0.018063

run [1800]:
Style Loss : 0.169022 Content Loss: 0.018126

run [1850]:
Style Loss : 0.167853 Content Loss: 0.018240

run [1900]:
Style Loss : 0.166482 Content Loss: 0.018285

run [1950]:
Style Loss : 0.165470 Content Loss: 0.018365

run [2000]:
Style Loss : 0.164445 Content Loss: 0.018427

run [2050]:
Style Loss : 0.163464 Content Loss: 0.018512

run [2100]:
Style Loss : 0.162411 Content Loss: 0.018579

run [2150]:
Style Loss : 0.161402 Content Loss: 0.018645

run [2200]:
Style Loss : 0.161109 Content Loss: 0.018791

run [2250]:
Style Loss : 0.159377 Content Loss: 0.018801

run [2300]:
Style Loss : 0.158634 Content Loss: 0.018923

run [2350]:
Style Loss : 0.157495 Content Loss: 0.018980

run [2400]:
Style Loss : 0.156540 Content Loss: 0.019048

run [2450]:
Style Loss : 0.155736 Content Loss: 0.019144

run [2500]:
Style Loss : 0.156228 Content Loss: 0.019269

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.311613 Content Loss: 0.002006

run [100]:
Style Loss : 0.758234 Content Loss: 0.004287

run [150]:
Style Loss : 0.561871 Content Loss: 0.007269

run [200]:
Style Loss : 0.449572 Content Loss: 0.010235

run [250]:
Style Loss : 0.377508 Content Loss: 0.012806

run [300]:
Style Loss : 0.333240 Content Loss: 0.014760

run [350]:
Style Loss : 0.302760 Content Loss: 0.016005

run [400]:
Style Loss : 0.280865 Content Loss: 0.016694

run [450]:
Style Loss : 0.266647 Content Loss: 0.017187

run [500]:
Style Loss : 0.255699 Content Loss: 0.017560

run [550]:
Style Loss : 0.246174 Content Loss: 0.017851

run [600]:
Style Loss : 0.237285 Content Loss: 0.018118

run [650]:
Style Loss : 0.229409 Content Loss: 0.018365

run [700]:
Style Loss : 0.222399 Content Loss: 0.018622

run [750]:
Style Loss : 0.216167 Content Loss: 0.018909

run [800]:
Style Loss : 0.209886 Content Loss: 0.019166

run [850]:
Style Loss : 0.204067 Content Loss: 0.019412

run [900]:
Style Loss : 0.198417 Content Loss: 0.019642

run [950]:
Style Loss : 0.192971 Content Loss: 0.019876

run [1000]:
Style Loss : 0.187845 Content Loss: 0.020153

run [1050]:
Style Loss : 0.182848 Content Loss: 0.020390

run [1100]:
Style Loss : 0.178020 Content Loss: 0.020657

run [1150]:
Style Loss : 0.173290 Content Loss: 0.020912

run [1200]:
Style Loss : 0.168547 Content Loss: 0.021189

run [1250]:
Style Loss : 0.164285 Content Loss: 0.021430

run [1300]:
Style Loss : 0.160146 Content Loss: 0.021660

run [1350]:
Style Loss : 0.155954 Content Loss: 0.021861

run [1400]:
Style Loss : 0.151705 Content Loss: 0.022065

run [1450]:
Style Loss : 0.148458 Content Loss: 0.022251

run [1500]:
Style Loss : 0.145705 Content Loss: 0.022425

run [1550]:
Style Loss : 0.143113 Content Loss: 0.022605

run [1600]:
Style Loss : 0.140579 Content Loss: 0.022812

run [1650]:
Style Loss : 0.138361 Content Loss: 0.022969

run [1700]:
Style Loss : 0.136392 Content Loss: 0.023114

run [1750]:
Style Loss : 0.134561 Content Loss: 0.023236

run [1800]:
Style Loss : 0.132855 Content Loss: 0.023359

run [1850]:
Style Loss : 0.131317 Content Loss: 0.023465

run [1900]:
Style Loss : 0.129926 Content Loss: 0.023570

run [1950]:
Style Loss : 0.128771 Content Loss: 0.023635

run [2000]:
Style Loss : 0.127773 Content Loss: 0.023693

run [2050]:
Style Loss : 0.126916 Content Loss: 0.023751

run [2100]:
Style Loss : 0.126230 Content Loss: 0.023794

run [2150]:
Style Loss : 0.125613 Content Loss: 0.023840

run [2200]:
Style Loss : 0.125024 Content Loss: 0.023866

run [2250]:
Style Loss : 0.124527 Content Loss: 0.023902

run [2300]:
Style Loss : 0.124017 Content Loss: 0.023933

run [2350]:
Style Loss : 0.123547 Content Loss: 0.023949

run [2400]:
Style Loss : 0.123156 Content Loss: 0.023968

run [2450]:
Style Loss : 0.122694 Content Loss: 0.023985

run [2500]:
Style Loss : 0.122284 Content Loss: 0.023995

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.251959 Content Loss: 0.001490

run [100]:
Style Loss : 0.689116 Content Loss: 0.002764

run [150]:
Style Loss : 0.473389 Content Loss: 0.004246

run [200]:
Style Loss : 0.377440 Content Loss: 0.005584

run [250]:
Style Loss : 0.315472 Content Loss: 0.006844

run [300]:
Style Loss : 0.268521 Content Loss: 0.008103

run [350]:
Style Loss : 0.231151 Content Loss: 0.009331

run [400]:
Style Loss : 0.203512 Content Loss: 0.010327

run [450]:
Style Loss : 0.181728 Content Loss: 0.011213

run [500]:
Style Loss : 0.167104 Content Loss: 0.011855

run [550]:
Style Loss : 0.155677 Content Loss: 0.012312

run [600]:
Style Loss : 0.147216 Content Loss: 0.012664

run [650]:
Style Loss : 0.140655 Content Loss: 0.012891

run [700]:
Style Loss : 0.134724 Content Loss: 0.013114

run [750]:
Style Loss : 0.129564 Content Loss: 0.013240

run [800]:
Style Loss : 0.123567 Content Loss: 0.013366

run [850]:
Style Loss : 0.118880 Content Loss: 0.013479

run [900]:
Style Loss : 0.115245 Content Loss: 0.013581

run [950]:
Style Loss : 0.111976 Content Loss: 0.013701

run [1000]:
Style Loss : 0.109069 Content Loss: 0.013790

run [1050]:
Style Loss : 0.106590 Content Loss: 0.013867

run [1100]:
Style Loss : 0.104331 Content Loss: 0.013954

run [1150]:
Style Loss : 0.102192 Content Loss: 0.014024

run [1200]:
Style Loss : 0.100524 Content Loss: 0.014083

run [1250]:
Style Loss : 0.098833 Content Loss: 0.014154

run [1300]:
Style Loss : 0.097323 Content Loss: 0.014202

run [1350]:
Style Loss : 0.095994 Content Loss: 0.014265

run [1400]:
Style Loss : 0.094285 Content Loss: 0.014338

run [1450]:
Style Loss : 0.092738 Content Loss: 0.014394

run [1500]:
Style Loss : 0.091321 Content Loss: 0.014464

run [1550]:
Style Loss : 0.090112 Content Loss: 0.014517

run [1600]:
Style Loss : 0.089095 Content Loss: 0.014572

run [1650]:
Style Loss : 0.088198 Content Loss: 0.014617

run [1700]:
Style Loss : 0.087397 Content Loss: 0.014655

run [1750]:
Style Loss : 0.086587 Content Loss: 0.014702

run [1800]:
Style Loss : 0.085857 Content Loss: 0.014740

run [1850]:
Style Loss : 0.085214 Content Loss: 0.014774

run [1900]:
Style Loss : 0.084613 Content Loss: 0.014808

run [1950]:
Style Loss : 0.084102 Content Loss: 0.014838

run [2000]:
Style Loss : 0.083637 Content Loss: 0.014864

run [2050]:
Style Loss : 0.083185 Content Loss: 0.014893

run [2100]:
Style Loss : 0.082792 Content Loss: 0.014918

run [2150]:
Style Loss : 0.082421 Content Loss: 0.014941

run [2200]:
Style Loss : 0.082051 Content Loss: 0.014968

run [2250]:
Style Loss : 0.081696 Content Loss: 0.014992

run [2300]:
Style Loss : 0.081391 Content Loss: 0.015015

run [2350]:
Style Loss : 0.081062 Content Loss: 0.015039

run [2400]:
Style Loss : 0.080674 Content Loss: 0.015062

run [2450]:
Style Loss : 0.080317 Content Loss: 0.015086

run [2500]:
Style Loss : 0.080013 Content Loss: 0.015106

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.621845 Content Loss: 0.003690

run [100]:
Style Loss : 1.033485 Content Loss: 0.007898

run [150]:
Style Loss : 0.734172 Content Loss: 0.014430

run [200]:
Style Loss : 0.541834 Content Loss: 0.021609

run [250]:
Style Loss : 0.450787 Content Loss: 0.025784

run [300]:
Style Loss : 0.397503 Content Loss: 0.027293

run [350]:
Style Loss : 0.364888 Content Loss: 0.027993

run [400]:
Style Loss : 0.342898 Content Loss: 0.028474

run [450]:
Style Loss : 0.322662 Content Loss: 0.029033

run [500]:
Style Loss : 0.307540 Content Loss: 0.029570

run [550]:
Style Loss : 0.295628 Content Loss: 0.030042

run [600]:
Style Loss : 0.285616 Content Loss: 0.030531

run [650]:
Style Loss : 0.276940 Content Loss: 0.031012

run [700]:
Style Loss : 0.269247 Content Loss: 0.031454

run [750]:
Style Loss : 0.262283 Content Loss: 0.031918

run [800]:
Style Loss : 0.256072 Content Loss: 0.032294

run [850]:
Style Loss : 0.250451 Content Loss: 0.032687

run [900]:
Style Loss : 0.245473 Content Loss: 0.033002

run [950]:
Style Loss : 0.241130 Content Loss: 0.033321

run [1000]:
Style Loss : 0.237051 Content Loss: 0.033643

run [1050]:
Style Loss : 0.233227 Content Loss: 0.033932

run [1100]:
Style Loss : 0.229992 Content Loss: 0.034212

run [1150]:
Style Loss : 0.226917 Content Loss: 0.034477

run [1200]:
Style Loss : 0.224104 Content Loss: 0.034742

run [1250]:
Style Loss : 0.221777 Content Loss: 0.034957

run [1300]:
Style Loss : 0.219677 Content Loss: 0.035203

run [1350]:
Style Loss : 0.217837 Content Loss: 0.035423

run [1400]:
Style Loss : 0.216062 Content Loss: 0.035659

run [1450]:
Style Loss : 0.214483 Content Loss: 0.035840

run [1500]:
Style Loss : 0.213038 Content Loss: 0.035969

run [1550]:
Style Loss : 0.211750 Content Loss: 0.036123

run [1600]:
Style Loss : 0.210360 Content Loss: 0.036249

run [1650]:
Style Loss : 0.209267 Content Loss: 0.036369

run [1700]:
Style Loss : 0.208314 Content Loss: 0.036460

run [1750]:
Style Loss : 0.207621 Content Loss: 0.036567

run [1800]:
Style Loss : 0.206909 Content Loss: 0.036671

run [1850]:
Style Loss : 0.206037 Content Loss: 0.036759

run [1900]:
Style Loss : 0.205410 Content Loss: 0.036854

run [1950]:
Style Loss : 0.204727 Content Loss: 0.036912

run [2000]:
Style Loss : 0.203867 Content Loss: 0.036957

run [2050]:
Style Loss : 0.203491 Content Loss: 0.037029

run [2100]:
Style Loss : 0.219497 Content Loss: 0.037172

run [2150]:
Style Loss : 0.202851 Content Loss: 0.037081

run [2200]:
Style Loss : 0.202799 Content Loss: 0.037206

run [2250]:
Style Loss : 0.201364 Content Loss: 0.037204

run [2300]:
Style Loss : 0.201453 Content Loss: 0.037282

run [2350]:
Style Loss : 0.200144 Content Loss: 0.037284

run [2400]:
Style Loss : 0.200046 Content Loss: 0.037335

run [2450]:
Style Loss : 0.199342 Content Loss: 0.037364

run [2500]:
Style Loss : 0.201133 Content Loss: 0.037440

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.116563 Content Loss: 0.005831

run [100]:
Style Loss : 0.598541 Content Loss: 0.010554

run [150]:
Style Loss : 0.395377 Content Loss: 0.014920

run [200]:
Style Loss : 0.303190 Content Loss: 0.017880

run [250]:
Style Loss : 0.253337 Content Loss: 0.019789

run [300]:
Style Loss : 0.225619 Content Loss: 0.020712

run [350]:
Style Loss : 0.207129 Content Loss: 0.021189

run [400]:
Style Loss : 0.193705 Content Loss: 0.021638

run [450]:
Style Loss : 0.182517 Content Loss: 0.022054

run [500]:
Style Loss : 0.173704 Content Loss: 0.022497

run [550]:
Style Loss : 0.166602 Content Loss: 0.022950

run [600]:
Style Loss : 0.160635 Content Loss: 0.023349

run [650]:
Style Loss : 0.155848 Content Loss: 0.023594

run [700]:
Style Loss : 0.151884 Content Loss: 0.023823

run [750]:
Style Loss : 0.148339 Content Loss: 0.024017

run [800]:
Style Loss : 0.145163 Content Loss: 0.024193

run [850]:
Style Loss : 0.142119 Content Loss: 0.024362

run [900]:
Style Loss : 0.139119 Content Loss: 0.024512

run [950]:
Style Loss : 0.136337 Content Loss: 0.024642

run [1000]:
Style Loss : 0.133908 Content Loss: 0.024754

run [1050]:
Style Loss : 0.131896 Content Loss: 0.024847

run [1100]:
Style Loss : 0.130223 Content Loss: 0.024901

run [1150]:
Style Loss : 0.128635 Content Loss: 0.024956

run [1200]:
Style Loss : 0.127059 Content Loss: 0.025002

run [1250]:
Style Loss : 0.125603 Content Loss: 0.025043

run [1300]:
Style Loss : 0.124339 Content Loss: 0.025098

run [1350]:
Style Loss : 0.123202 Content Loss: 0.025138

run [1400]:
Style Loss : 0.122035 Content Loss: 0.025178

run [1450]:
Style Loss : 0.120902 Content Loss: 0.025214

run [1500]:
Style Loss : 0.119786 Content Loss: 0.025253

run [1550]:
Style Loss : 0.118788 Content Loss: 0.025292

run [1600]:
Style Loss : 0.117865 Content Loss: 0.025331

run [1650]:
Style Loss : 0.116990 Content Loss: 0.025370

run [1700]:
Style Loss : 0.116213 Content Loss: 0.025405

run [1750]:
Style Loss : 0.115548 Content Loss: 0.025427

run [1800]:
Style Loss : 0.114922 Content Loss: 0.025454

run [1850]:
Style Loss : 0.114354 Content Loss: 0.025483

run [1900]:
Style Loss : 0.113789 Content Loss: 0.025505

run [1950]:
Style Loss : 0.113295 Content Loss: 0.025515

run [2000]:
Style Loss : 0.112845 Content Loss: 0.025526

run [2050]:
Style Loss : 0.112435 Content Loss: 0.025538

run [2100]:
Style Loss : 0.112043 Content Loss: 0.025544

run [2150]:
Style Loss : 0.111660 Content Loss: 0.025556

run [2200]:
Style Loss : 0.111322 Content Loss: 0.025562

run [2250]:
Style Loss : 0.110998 Content Loss: 0.025562

run [2300]:
Style Loss : 0.110713 Content Loss: 0.025558

run [2350]:
Style Loss : 0.110404 Content Loss: 0.025559

run [2400]:
Style Loss : 0.110102 Content Loss: 0.025555

run [2450]:
Style Loss : 0.109800 Content Loss: 0.025544

run [2500]:
Style Loss : 0.109527 Content Loss: 0.025538

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.992146 Content Loss: 0.002152

run [100]:
Style Loss : 1.366905 Content Loss: 0.003275

run [150]:
Style Loss : 1.049660 Content Loss: 0.004425

run [200]:
Style Loss : 0.881405 Content Loss: 0.005809

run [250]:
Style Loss : 0.763838 Content Loss: 0.007335

run [300]:
Style Loss : 0.678731 Content Loss: 0.008809

run [350]:
Style Loss : 0.611236 Content Loss: 0.010488

run [400]:
Style Loss : 0.561055 Content Loss: 0.012152

run [450]:
Style Loss : 0.523363 Content Loss: 0.013619

run [500]:
Style Loss : 0.495855 Content Loss: 0.014827

run [550]:
Style Loss : 0.476058 Content Loss: 0.015799

run [600]:
Style Loss : 0.461548 Content Loss: 0.016473

run [650]:
Style Loss : 0.450726 Content Loss: 0.017016

run [700]:
Style Loss : 0.441272 Content Loss: 0.017484

run [750]:
Style Loss : 0.433538 Content Loss: 0.017823

run [800]:
Style Loss : 0.427008 Content Loss: 0.018121

run [850]:
Style Loss : 0.420970 Content Loss: 0.018370

run [900]:
Style Loss : 0.415633 Content Loss: 0.018584

run [950]:
Style Loss : 0.410833 Content Loss: 0.018745

run [1000]:
Style Loss : 0.406513 Content Loss: 0.018943

run [1050]:
Style Loss : 0.402596 Content Loss: 0.019117

run [1100]:
Style Loss : 0.399166 Content Loss: 0.019308

run [1150]:
Style Loss : 0.395910 Content Loss: 0.019442

run [1200]:
Style Loss : 0.392817 Content Loss: 0.019612

run [1250]:
Style Loss : 0.390089 Content Loss: 0.019724

run [1300]:
Style Loss : 0.387754 Content Loss: 0.019865

run [1350]:
Style Loss : 0.385454 Content Loss: 0.019988

run [1400]:
Style Loss : 0.383431 Content Loss: 0.020098

run [1450]:
Style Loss : 0.381625 Content Loss: 0.020212

run [1500]:
Style Loss : 0.379903 Content Loss: 0.020312

run [1550]:
Style Loss : 0.378225 Content Loss: 0.020421

run [1600]:
Style Loss : 0.376731 Content Loss: 0.020508

run [1650]:
Style Loss : 0.375265 Content Loss: 0.020591

run [1700]:
Style Loss : 0.373817 Content Loss: 0.020682

run [1750]:
Style Loss : 0.372490 Content Loss: 0.020760

run [1800]:
Style Loss : 0.371135 Content Loss: 0.020830

run [1850]:
Style Loss : 0.369931 Content Loss: 0.020894

run [1900]:
Style Loss : 0.368743 Content Loss: 0.020954

run [1950]:
Style Loss : 0.367642 Content Loss: 0.021020

run [2000]:
Style Loss : 0.366583 Content Loss: 0.021076

run [2050]:
Style Loss : 0.365562 Content Loss: 0.021142

run [2100]:
Style Loss : 0.364574 Content Loss: 0.021197

run [2150]:
Style Loss : 0.363641 Content Loss: 0.021259

run [2200]:
Style Loss : 0.362705 Content Loss: 0.021314

run [2250]:
Style Loss : 0.361847 Content Loss: 0.021352

run [2300]:
Style Loss : 0.361084 Content Loss: 0.021399

run [2350]:
Style Loss : 0.360385 Content Loss: 0.021444

run [2400]:
Style Loss : 0.359660 Content Loss: 0.021488

run [2450]:
Style Loss : 0.358996 Content Loss: 0.021532

run [2500]:
Style Loss : 0.358277 Content Loss: 0.021572

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.779141 Content Loss: 0.003481

run [100]:
Style Loss : 1.544786 Content Loss: 0.003055

run [150]:
Style Loss : 1.135604 Content Loss: 0.003664

run [200]:
Style Loss : 0.926267 Content Loss: 0.004513

run [250]:
Style Loss : 0.793872 Content Loss: 0.005266

run [300]:
Style Loss : 0.704162 Content Loss: 0.006164

run [350]:
Style Loss : 0.636293 Content Loss: 0.007198

run [400]:
Style Loss : 0.581822 Content Loss: 0.008243

run [450]:
Style Loss : 0.535576 Content Loss: 0.009334

run [500]:
Style Loss : 0.496166 Content Loss: 0.010259

run [550]:
Style Loss : 0.462109 Content Loss: 0.011283

run [600]:
Style Loss : 0.433941 Content Loss: 0.012240

run [650]:
Style Loss : 0.410513 Content Loss: 0.013073

run [700]:
Style Loss : 0.392507 Content Loss: 0.013772

run [750]:
Style Loss : 0.379129 Content Loss: 0.014334

run [800]:
Style Loss : 0.368180 Content Loss: 0.014837

run [850]:
Style Loss : 0.359269 Content Loss: 0.015207

run [900]:
Style Loss : 0.351599 Content Loss: 0.015581

run [950]:
Style Loss : 0.344899 Content Loss: 0.015862

run [1000]:
Style Loss : 0.338738 Content Loss: 0.016088

run [1050]:
Style Loss : 0.332692 Content Loss: 0.016301

run [1100]:
Style Loss : 0.327312 Content Loss: 0.016480

run [1150]:
Style Loss : 0.321994 Content Loss: 0.016641

run [1200]:
Style Loss : 0.316982 Content Loss: 0.016801

run [1250]:
Style Loss : 0.312102 Content Loss: 0.016942

run [1300]:
Style Loss : 0.307434 Content Loss: 0.017080

run [1350]:
Style Loss : 0.302928 Content Loss: 0.017228

run [1400]:
Style Loss : 0.298306 Content Loss: 0.017359

run [1450]:
Style Loss : 0.294011 Content Loss: 0.017477

run [1500]:
Style Loss : 0.289910 Content Loss: 0.017615

run [1550]:
Style Loss : 0.285836 Content Loss: 0.017771

run [1600]:
Style Loss : 0.281712 Content Loss: 0.017967

run [1650]:
Style Loss : 0.277466 Content Loss: 0.018211

run [1700]:
Style Loss : 0.273441 Content Loss: 0.018406

run [1750]:
Style Loss : 0.269108 Content Loss: 0.018632

run [1800]:
Style Loss : 0.264955 Content Loss: 0.018845

run [1850]:
Style Loss : 0.260563 Content Loss: 0.019103

run [1900]:
Style Loss : 0.256119 Content Loss: 0.019393

run [1950]:
Style Loss : 0.251934 Content Loss: 0.019686

run [2000]:
Style Loss : 0.247628 Content Loss: 0.019976

run [2050]:
Style Loss : 0.243852 Content Loss: 0.020264

run [2100]:
Style Loss : 0.240116 Content Loss: 0.020536

run [2150]:
Style Loss : 0.236451 Content Loss: 0.020860

run [2200]:
Style Loss : 0.233057 Content Loss: 0.021209

run [2250]:
Style Loss : 0.230111 Content Loss: 0.021549

run [2300]:
Style Loss : 0.226332 Content Loss: 0.021842

run [2350]:
Style Loss : 0.223293 Content Loss: 0.022149

run [2400]:
Style Loss : 0.220574 Content Loss: 0.022479

run [2450]:
Style Loss : 0.217620 Content Loss: 0.022760

run [2500]:
Style Loss : 0.214882 Content Loss: 0.022985

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.722439 Content Loss: 0.003458

run [100]:
Style Loss : 0.949775 Content Loss: 0.004607

run [150]:
Style Loss : 0.706828 Content Loss: 0.006411

run [200]:
Style Loss : 0.566884 Content Loss: 0.008197

run [250]:
Style Loss : 0.475215 Content Loss: 0.009782

run [300]:
Style Loss : 0.413604 Content Loss: 0.011282

run [350]:
Style Loss : 0.371875 Content Loss: 0.012405

run [400]:
Style Loss : 0.342731 Content Loss: 0.013272

run [450]:
Style Loss : 0.321256 Content Loss: 0.014025

run [500]:
Style Loss : 0.304877 Content Loss: 0.014682

run [550]:
Style Loss : 0.292257 Content Loss: 0.015218

run [600]:
Style Loss : 0.282400 Content Loss: 0.015695

run [650]:
Style Loss : 0.273526 Content Loss: 0.016108

run [700]:
Style Loss : 0.266074 Content Loss: 0.016453

run [750]:
Style Loss : 0.259630 Content Loss: 0.016764

run [800]:
Style Loss : 0.254347 Content Loss: 0.017023

run [850]:
Style Loss : 0.249464 Content Loss: 0.017273

run [900]:
Style Loss : 0.245017 Content Loss: 0.017518

run [950]:
Style Loss : 0.240806 Content Loss: 0.017720

run [1000]:
Style Loss : 0.236857 Content Loss: 0.017904

run [1050]:
Style Loss : 0.233097 Content Loss: 0.018108

run [1100]:
Style Loss : 0.229593 Content Loss: 0.018294

run [1150]:
Style Loss : 0.226060 Content Loss: 0.018493

run [1200]:
Style Loss : 0.222620 Content Loss: 0.018670

run [1250]:
Style Loss : 0.219437 Content Loss: 0.018833

run [1300]:
Style Loss : 0.216613 Content Loss: 0.019014

run [1350]:
Style Loss : 0.213805 Content Loss: 0.019180

run [1400]:
Style Loss : 0.211137 Content Loss: 0.019353

run [1450]:
Style Loss : 0.208723 Content Loss: 0.019512

run [1500]:
Style Loss : 0.206613 Content Loss: 0.019668

run [1550]:
Style Loss : 0.204595 Content Loss: 0.019818

run [1600]:
Style Loss : 0.202691 Content Loss: 0.019982

run [1650]:
Style Loss : 0.200905 Content Loss: 0.020126

run [1700]:
Style Loss : 0.199135 Content Loss: 0.020293

run [1750]:
Style Loss : 0.197595 Content Loss: 0.020420

run [1800]:
Style Loss : 0.195930 Content Loss: 0.020551

run [1850]:
Style Loss : 0.194369 Content Loss: 0.020691

run [1900]:
Style Loss : 0.192764 Content Loss: 0.020802

run [1950]:
Style Loss : 0.191443 Content Loss: 0.020926

run [2000]:
Style Loss : 0.189817 Content Loss: 0.021036

run [2050]:
Style Loss : 0.188597 Content Loss: 0.021151

run [2100]:
Style Loss : 0.235097 Content Loss: 0.021635

run [2150]:
Style Loss : 0.185972 Content Loss: 0.021392

run [2200]:
Style Loss : 0.184539 Content Loss: 0.021493

run [2250]:
Style Loss : 0.183509 Content Loss: 0.021625

run [2300]:
Style Loss : 0.182153 Content Loss: 0.021685

run [2350]:
Style Loss : 1.343156 Content Loss: 0.024451

run [2400]:
Style Loss : 0.202622 Content Loss: 0.022850

run [2450]:
Style Loss : 0.184937 Content Loss: 0.022644

run [2500]:
Style Loss : 0.178254 Content Loss: 0.022680

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.882290 Content Loss: 0.001746

run [100]:
Style Loss : 1.848325 Content Loss: 0.002127

run [150]:
Style Loss : 1.385751 Content Loss: 0.002906

run [200]:
Style Loss : 1.129125 Content Loss: 0.003696

run [250]:
Style Loss : 0.961946 Content Loss: 0.004441

run [300]:
Style Loss : 0.857783 Content Loss: 0.005112

run [350]:
Style Loss : 0.786235 Content Loss: 0.005796

run [400]:
Style Loss : 0.725256 Content Loss: 0.006381

run [450]:
Style Loss : 0.678562 Content Loss: 0.006897

run [500]:
Style Loss : 0.643323 Content Loss: 0.007311

run [550]:
Style Loss : 0.615008 Content Loss: 0.007664

run [600]:
Style Loss : 0.590161 Content Loss: 0.008079

run [650]:
Style Loss : 0.567855 Content Loss: 0.008452

run [700]:
Style Loss : 0.548889 Content Loss: 0.008810

run [750]:
Style Loss : 0.530714 Content Loss: 0.009148

run [800]:
Style Loss : 0.515230 Content Loss: 0.009370

run [850]:
Style Loss : 0.500342 Content Loss: 0.009622

run [900]:
Style Loss : 0.487095 Content Loss: 0.009865

run [950]:
Style Loss : 0.473845 Content Loss: 0.010106

run [1000]:
Style Loss : 0.460826 Content Loss: 0.010337

run [1050]:
Style Loss : 0.448467 Content Loss: 0.010540

run [1100]:
Style Loss : 0.437954 Content Loss: 0.010719

run [1150]:
Style Loss : 0.429065 Content Loss: 0.010861

run [1200]:
Style Loss : 0.421396 Content Loss: 0.011038

run [1250]:
Style Loss : 0.414943 Content Loss: 0.011193

run [1300]:
Style Loss : 0.408845 Content Loss: 0.011345

run [1350]:
Style Loss : 0.403722 Content Loss: 0.011476

run [1400]:
Style Loss : 0.398890 Content Loss: 0.011631

run [1450]:
Style Loss : 0.394167 Content Loss: 0.011769

run [1500]:
Style Loss : 0.389938 Content Loss: 0.011901

run [1550]:
Style Loss : 0.386205 Content Loss: 0.012021

run [1600]:
Style Loss : 0.382998 Content Loss: 0.012132

run [1650]:
Style Loss : 0.380181 Content Loss: 0.012226

run [1700]:
Style Loss : 0.377479 Content Loss: 0.012325

run [1750]:
Style Loss : 0.374928 Content Loss: 0.012412

run [1800]:
Style Loss : 0.372543 Content Loss: 0.012494

run [1850]:
Style Loss : 0.370421 Content Loss: 0.012568

run [1900]:
Style Loss : 0.368428 Content Loss: 0.012641

run [1950]:
Style Loss : 0.366508 Content Loss: 0.012719

run [2000]:
Style Loss : 0.364791 Content Loss: 0.012779

run [2050]:
Style Loss : 0.363065 Content Loss: 0.012845

run [2100]:
Style Loss : 0.361456 Content Loss: 0.012909

run [2150]:
Style Loss : 0.359773 Content Loss: 0.012979

run [2200]:
Style Loss : 0.358152 Content Loss: 0.013037

run [2250]:
Style Loss : 0.356527 Content Loss: 0.013096

run [2300]:
Style Loss : 0.354997 Content Loss: 0.013149

run [2350]:
Style Loss : 0.353573 Content Loss: 0.013202

run [2400]:
Style Loss : 0.352184 Content Loss: 0.013257

run [2450]:
Style Loss : 0.350703 Content Loss: 0.013311

run [2500]:
Style Loss : 0.349154 Content Loss: 0.013364

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.051666 Content Loss: 0.004110

run [100]:
Style Loss : 2.458488 Content Loss: 0.004152

run [150]:
Style Loss : 1.910153 Content Loss: 0.004921

run [200]:
Style Loss : 1.635555 Content Loss: 0.005790

run [250]:
Style Loss : 1.460600 Content Loss: 0.006498

run [300]:
Style Loss : 1.345090 Content Loss: 0.007189

run [350]:
Style Loss : 1.264266 Content Loss: 0.007733

run [400]:
Style Loss : 1.197735 Content Loss: 0.008265

run [450]:
Style Loss : 1.145162 Content Loss: 0.008753

run [500]:
Style Loss : 1.102447 Content Loss: 0.009182

run [550]:
Style Loss : 1.065755 Content Loss: 0.009638

run [600]:
Style Loss : 1.035541 Content Loss: 0.010020

run [650]:
Style Loss : 1.008232 Content Loss: 0.010416

run [700]:
Style Loss : 0.982808 Content Loss: 0.010794

run [750]:
Style Loss : 0.958645 Content Loss: 0.011147

run [800]:
Style Loss : 0.936020 Content Loss: 0.011458

run [850]:
Style Loss : 0.916149 Content Loss: 0.011749

run [900]:
Style Loss : 0.898364 Content Loss: 0.012036

run [950]:
Style Loss : 0.882548 Content Loss: 0.012278

run [1000]:
Style Loss : 0.870163 Content Loss: 0.012466

run [1050]:
Style Loss : 0.859004 Content Loss: 0.012678

run [1100]:
Style Loss : 0.848457 Content Loss: 0.012865

run [1150]:
Style Loss : 0.839433 Content Loss: 0.013024

run [1200]:
Style Loss : 0.831546 Content Loss: 0.013173

run [1250]:
Style Loss : 0.824405 Content Loss: 0.013312

run [1300]:
Style Loss : 0.817965 Content Loss: 0.013447

run [1350]:
Style Loss : 0.812229 Content Loss: 0.013546

run [1400]:
Style Loss : 0.806535 Content Loss: 0.013671

run [1450]:
Style Loss : 0.801341 Content Loss: 0.013783

run [1500]:
Style Loss : 0.796371 Content Loss: 0.013894

run [1550]:
Style Loss : 0.791509 Content Loss: 0.014002

run [1600]:
Style Loss : 0.786407 Content Loss: 0.014118

run [1650]:
Style Loss : 0.781762 Content Loss: 0.014203

run [1700]:
Style Loss : 0.777404 Content Loss: 0.014294

run [1750]:
Style Loss : 0.773324 Content Loss: 0.014395

run [1800]:
Style Loss : 0.769003 Content Loss: 0.014484

run [1850]:
Style Loss : 0.764805 Content Loss: 0.014580

run [1900]:
Style Loss : 0.761185 Content Loss: 0.014650

run [1950]:
Style Loss : 0.757418 Content Loss: 0.014735

run [2000]:
Style Loss : 0.753507 Content Loss: 0.014825

run [2050]:
Style Loss : 0.750162 Content Loss: 0.014885

run [2100]:
Style Loss : 0.747013 Content Loss: 0.014954

run [2150]:
Style Loss : 0.743674 Content Loss: 0.015014

run [2200]:
Style Loss : 0.740717 Content Loss: 0.015070

run [2250]:
Style Loss : 0.737986 Content Loss: 0.015130

run [2300]:
Style Loss : 0.735473 Content Loss: 0.015178

run [2350]:
Style Loss : 0.733068 Content Loss: 0.015227

run [2400]:
Style Loss : 0.730944 Content Loss: 0.015267

run [2450]:
Style Loss : 0.728813 Content Loss: 0.015314

run [2500]:
Style Loss : 0.726651 Content Loss: 0.015362

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.755170 Content Loss: 0.004445

run [100]:
Style Loss : 2.444505 Content Loss: 0.004920

run [150]:
Style Loss : 1.954196 Content Loss: 0.005861

run [200]:
Style Loss : 1.667057 Content Loss: 0.006917

run [250]:
Style Loss : 1.471955 Content Loss: 0.007966

run [300]:
Style Loss : 1.339097 Content Loss: 0.008905

run [350]:
Style Loss : 1.240759 Content Loss: 0.009708

run [400]:
Style Loss : 1.161082 Content Loss: 0.010551

run [450]:
Style Loss : 1.101832 Content Loss: 0.011162

run [500]:
Style Loss : 1.054658 Content Loss: 0.011817

run [550]:
Style Loss : 1.015010 Content Loss: 0.012447

run [600]:
Style Loss : 0.985012 Content Loss: 0.012950

run [650]:
Style Loss : 0.959879 Content Loss: 0.013425

run [700]:
Style Loss : 0.935261 Content Loss: 0.013912

run [750]:
Style Loss : 0.913479 Content Loss: 0.014296

run [800]:
Style Loss : 0.894774 Content Loss: 0.014653

run [850]:
Style Loss : 0.877944 Content Loss: 0.014958

run [900]:
Style Loss : 0.862871 Content Loss: 0.015266

run [950]:
Style Loss : 0.849810 Content Loss: 0.015507

run [1000]:
Style Loss : 0.837661 Content Loss: 0.015793

run [1050]:
Style Loss : 0.827011 Content Loss: 0.016045

run [1100]:
Style Loss : 0.817326 Content Loss: 0.016256

run [1150]:
Style Loss : 0.808963 Content Loss: 0.016446

run [1200]:
Style Loss : 0.800490 Content Loss: 0.016641

run [1250]:
Style Loss : 0.792662 Content Loss: 0.016821

run [1300]:
Style Loss : 0.785760 Content Loss: 0.016957

run [1350]:
Style Loss : 0.779446 Content Loss: 0.017119

run [1400]:
Style Loss : 0.773853 Content Loss: 0.017239

run [1450]:
Style Loss : 0.768539 Content Loss: 0.017366

run [1500]:
Style Loss : 0.763602 Content Loss: 0.017460

run [1550]:
Style Loss : 0.758720 Content Loss: 0.017570

run [1600]:
Style Loss : 0.754149 Content Loss: 0.017656

run [1650]:
Style Loss : 0.750025 Content Loss: 0.017755

run [1700]:
Style Loss : 0.745982 Content Loss: 0.017846

run [1750]:
Style Loss : 0.742024 Content Loss: 0.017919

run [1800]:
Style Loss : 0.738321 Content Loss: 0.017993

run [1850]:
Style Loss : 0.734878 Content Loss: 0.018060

run [1900]:
Style Loss : 0.731724 Content Loss: 0.018131

run [1950]:
Style Loss : 0.728522 Content Loss: 0.018212

run [2000]:
Style Loss : 0.725679 Content Loss: 0.018275

run [2050]:
Style Loss : 0.722850 Content Loss: 0.018346

run [2100]:
Style Loss : 0.719842 Content Loss: 0.018421

run [2150]:
Style Loss : 0.716718 Content Loss: 0.018491

run [2200]:
Style Loss : 0.713529 Content Loss: 0.018576

run [2250]:
Style Loss : 0.710445 Content Loss: 0.018632

run [2300]:
Style Loss : 0.707878 Content Loss: 0.018684

run [2350]:
Style Loss : 0.705703 Content Loss: 0.018737

run [2400]:
Style Loss : 0.703516 Content Loss: 0.018794

run [2450]:
Style Loss : 0.701410 Content Loss: 0.018855

run [2500]:
Style Loss : 0.699405 Content Loss: 0.018909

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.467747 Content Loss: 0.005887

run [100]:
Style Loss : 1.564226 Content Loss: 0.005235

run [150]:
Style Loss : 1.100306 Content Loss: 0.005776

run [200]:
Style Loss : 0.879002 Content Loss: 0.006472

run [250]:
Style Loss : 0.733628 Content Loss: 0.007546

run [300]:
Style Loss : 0.634251 Content Loss: 0.008542

run [350]:
Style Loss : 0.560195 Content Loss: 0.009629

run [400]:
Style Loss : 0.511074 Content Loss: 0.010494

run [450]:
Style Loss : 0.471466 Content Loss: 0.011409

run [500]:
Style Loss : 0.438753 Content Loss: 0.012343

run [550]:
Style Loss : 0.412369 Content Loss: 0.013271

run [600]:
Style Loss : 0.394059 Content Loss: 0.013825

run [650]:
Style Loss : 0.378511 Content Loss: 0.014406

run [700]:
Style Loss : 0.366414 Content Loss: 0.014849

run [750]:
Style Loss : 0.354994 Content Loss: 0.015192

run [800]:
Style Loss : 0.345632 Content Loss: 0.015411

run [850]:
Style Loss : 0.339159 Content Loss: 0.015666

run [900]:
Style Loss : 0.332624 Content Loss: 0.015848

run [950]:
Style Loss : 0.326228 Content Loss: 0.016013

run [1000]:
Style Loss : 0.318512 Content Loss: 0.016206

run [1050]:
Style Loss : 0.311985 Content Loss: 0.016313

run [1100]:
Style Loss : 0.305946 Content Loss: 0.016430

run [1150]:
Style Loss : 0.300525 Content Loss: 0.016553

run [1200]:
Style Loss : 0.295415 Content Loss: 0.016629

run [1250]:
Style Loss : 0.287798 Content Loss: 0.016730

run [1300]:
Style Loss : 0.282563 Content Loss: 0.016843

run [1350]:
Style Loss : 0.278207 Content Loss: 0.016919

run [1400]:
Style Loss : 0.273941 Content Loss: 0.017023

run [1450]:
Style Loss : 0.269811 Content Loss: 0.017107

run [1500]:
Style Loss : 0.266063 Content Loss: 0.017172

run [1550]:
Style Loss : 0.262724 Content Loss: 0.017239

run [1600]:
Style Loss : 0.259782 Content Loss: 0.017334

run [1650]:
Style Loss : 0.256884 Content Loss: 0.017409

run [1700]:
Style Loss : 0.254535 Content Loss: 0.017465

run [1750]:
Style Loss : 0.251854 Content Loss: 0.017533

run [1800]:
Style Loss : 0.249413 Content Loss: 0.017587

run [1850]:
Style Loss : 0.247428 Content Loss: 0.017627

run [1900]:
Style Loss : 0.245485 Content Loss: 0.017679

run [1950]:
Style Loss : 0.243624 Content Loss: 0.017731

run [2000]:
Style Loss : 0.242027 Content Loss: 0.017776

run [2050]:
Style Loss : 0.240438 Content Loss: 0.017815

run [2100]:
Style Loss : 0.238905 Content Loss: 0.017855

run [2150]:
Style Loss : 0.237582 Content Loss: 0.017896

run [2200]:
Style Loss : 0.236293 Content Loss: 0.017932

run [2250]:
Style Loss : 0.234999 Content Loss: 0.017963

run [2300]:
Style Loss : 0.233831 Content Loss: 0.017991

run [2350]:
Style Loss : 0.232746 Content Loss: 0.018029

run [2400]:
Style Loss : 0.231815 Content Loss: 0.018052

run [2450]:
Style Loss : 0.230901 Content Loss: 0.018079

run [2500]:
Style Loss : 0.230021 Content Loss: 0.018110

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.513644 Content Loss: 0.002310

run [100]:
Style Loss : 0.940740 Content Loss: 0.003661

run [150]:
Style Loss : 0.747028 Content Loss: 0.005134

run [200]:
Style Loss : 0.649748 Content Loss: 0.006444

run [250]:
Style Loss : 0.591450 Content Loss: 0.007509

run [300]:
Style Loss : 0.544795 Content Loss: 0.008504

run [350]:
Style Loss : 0.511253 Content Loss: 0.009268

run [400]:
Style Loss : 0.487433 Content Loss: 0.010016

run [450]:
Style Loss : 0.468126 Content Loss: 0.010686

run [500]:
Style Loss : 0.452652 Content Loss: 0.011230

run [550]:
Style Loss : 0.440146 Content Loss: 0.011758

run [600]:
Style Loss : 0.428614 Content Loss: 0.012239

run [650]:
Style Loss : 0.418605 Content Loss: 0.012655

run [700]:
Style Loss : 0.410281 Content Loss: 0.013010

run [750]:
Style Loss : 0.402862 Content Loss: 0.013330

run [800]:
Style Loss : 0.395752 Content Loss: 0.013658

run [850]:
Style Loss : 0.389106 Content Loss: 0.013941

run [900]:
Style Loss : 0.382753 Content Loss: 0.014229

run [950]:
Style Loss : 0.377107 Content Loss: 0.014461

run [1000]:
Style Loss : 0.372251 Content Loss: 0.014708

run [1050]:
Style Loss : 0.367872 Content Loss: 0.014898

run [1100]:
Style Loss : 0.363918 Content Loss: 0.015104

run [1150]:
Style Loss : 0.360389 Content Loss: 0.015268

run [1200]:
Style Loss : 0.357029 Content Loss: 0.015450

run [1250]:
Style Loss : 0.353756 Content Loss: 0.015610

run [1300]:
Style Loss : 0.350667 Content Loss: 0.015776

run [1350]:
Style Loss : 0.347637 Content Loss: 0.015935

run [1400]:
Style Loss : 0.344722 Content Loss: 0.016098

run [1450]:
Style Loss : 0.342005 Content Loss: 0.016260

run [1500]:
Style Loss : 0.339250 Content Loss: 0.016428

run [1550]:
Style Loss : 0.336698 Content Loss: 0.016599

run [1600]:
Style Loss : 0.334281 Content Loss: 0.016762

run [1650]:
Style Loss : 0.331989 Content Loss: 0.016913

run [1700]:
Style Loss : 0.329839 Content Loss: 0.017065

run [1750]:
Style Loss : 0.327685 Content Loss: 0.017225

run [1800]:
Style Loss : 0.325517 Content Loss: 0.017384

run [1850]:
Style Loss : 0.323470 Content Loss: 0.017535

run [1900]:
Style Loss : 0.321584 Content Loss: 0.017688

run [1950]:
Style Loss : 0.319739 Content Loss: 0.017837

run [2000]:
Style Loss : 0.317818 Content Loss: 0.018006

run [2050]:
Style Loss : 0.316004 Content Loss: 0.018144

run [2100]:
Style Loss : 0.314254 Content Loss: 0.018288

run [2150]:
Style Loss : 0.312546 Content Loss: 0.018422

run [2200]:
Style Loss : 0.310945 Content Loss: 0.018563

run [2250]:
Style Loss : 0.309516 Content Loss: 0.018720

run [2300]:
Style Loss : 0.307900 Content Loss: 0.018876

run [2350]:
Style Loss : 0.306379 Content Loss: 0.019007

run [2400]:
Style Loss : 0.305014 Content Loss: 0.019180

run [2450]:
Style Loss : 0.303515 Content Loss: 0.019307

run [2500]:
Style Loss : 0.301973 Content Loss: 0.019446

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.113407 Content Loss: 0.001547

run [100]:
Style Loss : 0.665602 Content Loss: 0.002486

run [150]:
Style Loss : 0.508427 Content Loss: 0.003476

run [200]:
Style Loss : 0.439948 Content Loss: 0.004146

run [250]:
Style Loss : 0.399995 Content Loss: 0.004778

run [300]:
Style Loss : 0.370601 Content Loss: 0.005239

run [350]:
Style Loss : 0.348377 Content Loss: 0.005585

run [400]:
Style Loss : 0.331202 Content Loss: 0.005892

run [450]:
Style Loss : 0.317636 Content Loss: 0.006177

run [500]:
Style Loss : 0.306681 Content Loss: 0.006461

run [550]:
Style Loss : 0.296864 Content Loss: 0.006716

run [600]:
Style Loss : 0.288628 Content Loss: 0.006954

run [650]:
Style Loss : 0.281044 Content Loss: 0.007175

run [700]:
Style Loss : 0.274328 Content Loss: 0.007387

run [750]:
Style Loss : 0.269074 Content Loss: 0.007573

run [800]:
Style Loss : 0.264220 Content Loss: 0.007740

run [850]:
Style Loss : 0.260173 Content Loss: 0.007912

run [900]:
Style Loss : 0.256436 Content Loss: 0.008079

run [950]:
Style Loss : 0.252541 Content Loss: 0.008253

run [1000]:
Style Loss : 0.248411 Content Loss: 0.008412

run [1050]:
Style Loss : 0.244475 Content Loss: 0.008576

run [1100]:
Style Loss : 0.240890 Content Loss: 0.008712

run [1150]:
Style Loss : 0.237728 Content Loss: 0.008829

run [1200]:
Style Loss : 0.234202 Content Loss: 0.008954

run [1250]:
Style Loss : 0.231352 Content Loss: 0.009071

run [1300]:
Style Loss : 0.228827 Content Loss: 0.009193

run [1350]:
Style Loss : 0.226415 Content Loss: 0.009318

run [1400]:
Style Loss : 0.223943 Content Loss: 0.009448

run [1450]:
Style Loss : 0.221269 Content Loss: 0.009603

run [1500]:
Style Loss : 0.218718 Content Loss: 0.009738

run [1550]:
Style Loss : 0.216394 Content Loss: 0.009853

run [1600]:
Style Loss : 0.214328 Content Loss: 0.009966

run [1650]:
Style Loss : 0.212354 Content Loss: 0.010094

run [1700]:
Style Loss : 0.210405 Content Loss: 0.010232

run [1750]:
Style Loss : 0.208666 Content Loss: 0.010358

run [1800]:
Style Loss : 0.206967 Content Loss: 0.010481

run [1850]:
Style Loss : 0.205344 Content Loss: 0.010608

run [1900]:
Style Loss : 0.203735 Content Loss: 0.010738

run [1950]:
Style Loss : 0.202081 Content Loss: 0.010871

run [2000]:
Style Loss : 0.200457 Content Loss: 0.011006

run [2050]:
Style Loss : 0.198896 Content Loss: 0.011140

run [2100]:
Style Loss : 0.197367 Content Loss: 0.011282

run [2150]:
Style Loss : 0.195920 Content Loss: 0.011414

run [2200]:
Style Loss : 0.194484 Content Loss: 0.011560

run [2250]:
Style Loss : 0.193157 Content Loss: 0.011698

run [2300]:
Style Loss : 0.191916 Content Loss: 0.011814

run [2350]:
Style Loss : 0.190788 Content Loss: 0.011940

run [2400]:
Style Loss : 0.189690 Content Loss: 0.012070

run [2450]:
Style Loss : 0.188618 Content Loss: 0.012193

run [2500]:
Style Loss : 0.187655 Content Loss: 0.012325

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.738078 Content Loss: 0.002007

run [100]:
Style Loss : 0.464693 Content Loss: 0.003675

run [150]:
Style Loss : 0.352397 Content Loss: 0.005287

run [200]:
Style Loss : 0.291717 Content Loss: 0.006590

run [250]:
Style Loss : 0.254727 Content Loss: 0.007757

run [300]:
Style Loss : 0.231641 Content Loss: 0.008653

run [350]:
Style Loss : 0.216135 Content Loss: 0.009316

run [400]:
Style Loss : 0.203913 Content Loss: 0.009957

run [450]:
Style Loss : 0.193490 Content Loss: 0.010408

run [500]:
Style Loss : 0.184588 Content Loss: 0.010779

run [550]:
Style Loss : 0.178332 Content Loss: 0.011141

run [600]:
Style Loss : 0.173059 Content Loss: 0.011480

run [650]:
Style Loss : 0.168734 Content Loss: 0.011771

run [700]:
Style Loss : 0.164466 Content Loss: 0.012043

run [750]:
Style Loss : 0.161253 Content Loss: 0.012295

run [800]:
Style Loss : 0.158367 Content Loss: 0.012539

run [850]:
Style Loss : 0.156035 Content Loss: 0.012768

run [900]:
Style Loss : 0.154065 Content Loss: 0.012963

run [950]:
Style Loss : 0.152388 Content Loss: 0.013111

run [1000]:
Style Loss : 0.150958 Content Loss: 0.013291

run [1050]:
Style Loss : 0.149606 Content Loss: 0.013408

run [1100]:
Style Loss : 0.148478 Content Loss: 0.013565

run [1150]:
Style Loss : 0.147268 Content Loss: 0.013706

run [1200]:
Style Loss : 0.146215 Content Loss: 0.013856

run [1250]:
Style Loss : 0.145128 Content Loss: 0.013962

run [1300]:
Style Loss : 0.144189 Content Loss: 0.014110

run [1350]:
Style Loss : 0.143228 Content Loss: 0.014216

run [1400]:
Style Loss : 0.142358 Content Loss: 0.014354

run [1450]:
Style Loss : 0.141199 Content Loss: 0.014456

run [1500]:
Style Loss : 0.140280 Content Loss: 0.014555

run [1550]:
Style Loss : 0.139386 Content Loss: 0.014653

run [1600]:
Style Loss : 0.138907 Content Loss: 0.014762

run [1650]:
Style Loss : 0.137705 Content Loss: 0.014857

run [1700]:
Style Loss : 0.137554 Content Loss: 0.015012

run [1750]:
Style Loss : 0.136402 Content Loss: 0.015073

run [1800]:
Style Loss : 0.135944 Content Loss: 0.015186

run [1850]:
Style Loss : 0.134994 Content Loss: 0.015233

run [1900]:
Style Loss : 0.134373 Content Loss: 0.015329

run [1950]:
Style Loss : 0.134856 Content Loss: 0.015409

run [2000]:
Style Loss : 0.133286 Content Loss: 0.015489

run [2050]:
Style Loss : 0.132966 Content Loss: 0.015571

run [2100]:
Style Loss : 0.132372 Content Loss: 0.015671

run [2150]:
Style Loss : 0.131902 Content Loss: 0.015749

run [2200]:
Style Loss : 0.133257 Content Loss: 0.015783

run [2250]:
Style Loss : 0.130783 Content Loss: 0.015889

run [2300]:
Style Loss : 0.130167 Content Loss: 0.015937

run [2350]:
Style Loss : 0.129787 Content Loss: 0.016010

run [2400]:
Style Loss : 0.129068 Content Loss: 0.016054

run [2450]:
Style Loss : 0.128575 Content Loss: 0.016109

run [2500]:
Style Loss : 0.128176 Content Loss: 0.016184

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.881992 Content Loss: 0.001213

run [100]:
Style Loss : 0.526746 Content Loss: 0.002256

run [150]:
Style Loss : 0.406177 Content Loss: 0.003342

run [200]:
Style Loss : 0.343064 Content Loss: 0.004178

run [250]:
Style Loss : 0.307147 Content Loss: 0.004722

run [300]:
Style Loss : 0.283418 Content Loss: 0.005192

run [350]:
Style Loss : 0.266498 Content Loss: 0.005608

run [400]:
Style Loss : 0.254314 Content Loss: 0.005951

run [450]:
Style Loss : 0.243893 Content Loss: 0.006281

run [500]:
Style Loss : 0.235718 Content Loss: 0.006575

run [550]:
Style Loss : 0.228787 Content Loss: 0.006863

run [600]:
Style Loss : 0.222617 Content Loss: 0.007137

run [650]:
Style Loss : 0.217452 Content Loss: 0.007379

run [700]:
Style Loss : 0.213238 Content Loss: 0.007599

run [750]:
Style Loss : 0.209210 Content Loss: 0.007831

run [800]:
Style Loss : 0.205075 Content Loss: 0.008032

run [850]:
Style Loss : 0.201716 Content Loss: 0.008213

run [900]:
Style Loss : 0.198812 Content Loss: 0.008383

run [950]:
Style Loss : 0.196117 Content Loss: 0.008562

run [1000]:
Style Loss : 0.193704 Content Loss: 0.008735

run [1050]:
Style Loss : 0.191492 Content Loss: 0.008902

run [1100]:
Style Loss : 0.189488 Content Loss: 0.009045

run [1150]:
Style Loss : 0.187546 Content Loss: 0.009189

run [1200]:
Style Loss : 0.185788 Content Loss: 0.009314

run [1250]:
Style Loss : 0.184170 Content Loss: 0.009437

run [1300]:
Style Loss : 0.182546 Content Loss: 0.009557

run [1350]:
Style Loss : 0.181096 Content Loss: 0.009680

run [1400]:
Style Loss : 0.179803 Content Loss: 0.009791

run [1450]:
Style Loss : 0.178488 Content Loss: 0.009898

run [1500]:
Style Loss : 0.177296 Content Loss: 0.010009

run [1550]:
Style Loss : 0.176064 Content Loss: 0.010123

run [1600]:
Style Loss : 0.174938 Content Loss: 0.010227

run [1650]:
Style Loss : 0.173792 Content Loss: 0.010341

run [1700]:
Style Loss : 0.172632 Content Loss: 0.010461

run [1750]:
Style Loss : 0.171497 Content Loss: 0.010591

run [1800]:
Style Loss : 0.170230 Content Loss: 0.010727

run [1850]:
Style Loss : 0.169008 Content Loss: 0.010860

run [1900]:
Style Loss : 0.167845 Content Loss: 0.010990

run [1950]:
Style Loss : 0.166806 Content Loss: 0.011091

run [2000]:
Style Loss : 0.165743 Content Loss: 0.011219

run [2050]:
Style Loss : 0.164698 Content Loss: 0.011331

run [2100]:
Style Loss : 0.163617 Content Loss: 0.011449

run [2150]:
Style Loss : 0.162600 Content Loss: 0.011557

run [2200]:
Style Loss : 0.161605 Content Loss: 0.011674

run [2250]:
Style Loss : 0.160635 Content Loss: 0.011796

run [2300]:
Style Loss : 0.159631 Content Loss: 0.011905

run [2350]:
Style Loss : 0.158702 Content Loss: 0.012006

run [2400]:
Style Loss : 0.157860 Content Loss: 0.012104

run [2450]:
Style Loss : 0.157073 Content Loss: 0.012188

run [2500]:
Style Loss : 0.156300 Content Loss: 0.012279

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.647786 Content Loss: 0.001891

run [100]:
Style Loss : 1.535022 Content Loss: 0.002183

run [150]:
Style Loss : 1.137328 Content Loss: 0.002789

run [200]:
Style Loss : 0.934633 Content Loss: 0.003481

run [250]:
Style Loss : 0.815421 Content Loss: 0.004274

run [300]:
Style Loss : 0.735113 Content Loss: 0.004987

run [350]:
Style Loss : 0.672802 Content Loss: 0.005642

run [400]:
Style Loss : 0.624228 Content Loss: 0.006219

run [450]:
Style Loss : 0.589056 Content Loss: 0.006638

run [500]:
Style Loss : 0.560434 Content Loss: 0.007091

run [550]:
Style Loss : 0.536077 Content Loss: 0.007476

run [600]:
Style Loss : 0.515637 Content Loss: 0.007860

run [650]:
Style Loss : 0.497611 Content Loss: 0.008222

run [700]:
Style Loss : 0.481854 Content Loss: 0.008561

run [750]:
Style Loss : 0.468397 Content Loss: 0.008909

run [800]:
Style Loss : 0.456950 Content Loss: 0.009217

run [850]:
Style Loss : 0.447097 Content Loss: 0.009447

run [900]:
Style Loss : 0.438494 Content Loss: 0.009717

run [950]:
Style Loss : 0.430777 Content Loss: 0.009935

run [1000]:
Style Loss : 0.423967 Content Loss: 0.010102

run [1050]:
Style Loss : 0.417549 Content Loss: 0.010309

run [1100]:
Style Loss : 0.411403 Content Loss: 0.010473

run [1150]:
Style Loss : 0.406156 Content Loss: 0.010615

run [1200]:
Style Loss : 0.401022 Content Loss: 0.010790

run [1250]:
Style Loss : 0.396594 Content Loss: 0.010902

run [1300]:
Style Loss : 0.392705 Content Loss: 0.011021

run [1350]:
Style Loss : 0.389192 Content Loss: 0.011134

run [1400]:
Style Loss : 0.386030 Content Loss: 0.011228

run [1450]:
Style Loss : 0.383258 Content Loss: 0.011330

run [1500]:
Style Loss : 0.380546 Content Loss: 0.011435

run [1550]:
Style Loss : 0.378242 Content Loss: 0.011498

run [1600]:
Style Loss : 0.376297 Content Loss: 0.011567

run [1650]:
Style Loss : 0.374368 Content Loss: 0.011622

run [1700]:
Style Loss : 0.372705 Content Loss: 0.011673

run [1750]:
Style Loss : 0.371241 Content Loss: 0.011726

run [1800]:
Style Loss : 0.369809 Content Loss: 0.011778

run [1850]:
Style Loss : 0.368733 Content Loss: 0.011832

run [1900]:
Style Loss : 0.367051 Content Loss: 0.011870

run [1950]:
Style Loss : 0.365758 Content Loss: 0.011917

run [2000]:
Style Loss : 0.364407 Content Loss: 0.011971

run [2050]:
Style Loss : 0.363127 Content Loss: 0.012010

run [2100]:
Style Loss : 0.361958 Content Loss: 0.012056

run [2150]:
Style Loss : 0.360718 Content Loss: 0.012101

run [2200]:
Style Loss : 0.359540 Content Loss: 0.012145

run [2250]:
Style Loss : 0.358562 Content Loss: 0.012201

run [2300]:
Style Loss : 0.357334 Content Loss: 0.012230

run [2350]:
Style Loss : 0.356241 Content Loss: 0.012262

run [2400]:
Style Loss : 0.355218 Content Loss: 0.012299

run [2450]:
Style Loss : 0.354286 Content Loss: 0.012341

run [2500]:
Style Loss : 0.353410 Content Loss: 0.012387

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.637888 Content Loss: 0.001797

run [100]:
Style Loss : 0.372919 Content Loss: 0.003981

run [150]:
Style Loss : 0.284035 Content Loss: 0.005772

run [200]:
Style Loss : 0.236723 Content Loss: 0.007043

run [250]:
Style Loss : 0.207438 Content Loss: 0.008026

run [300]:
Style Loss : 0.189065 Content Loss: 0.008688

run [350]:
Style Loss : 0.175556 Content Loss: 0.009281

run [400]:
Style Loss : 0.165633 Content Loss: 0.009754

run [450]:
Style Loss : 0.156885 Content Loss: 0.010183

run [500]:
Style Loss : 0.149864 Content Loss: 0.010533

run [550]:
Style Loss : 0.144020 Content Loss: 0.010838

run [600]:
Style Loss : 0.139393 Content Loss: 0.011114

run [650]:
Style Loss : 0.135339 Content Loss: 0.011371

run [700]:
Style Loss : 0.131779 Content Loss: 0.011621

run [750]:
Style Loss : 0.128227 Content Loss: 0.011846

run [800]:
Style Loss : 0.124857 Content Loss: 0.012057

run [850]:
Style Loss : 0.122331 Content Loss: 0.012222

run [900]:
Style Loss : 0.120160 Content Loss: 0.012406

run [950]:
Style Loss : 0.118160 Content Loss: 0.012574

run [1000]:
Style Loss : 0.116394 Content Loss: 0.012739

run [1050]:
Style Loss : 0.114774 Content Loss: 0.012887

run [1100]:
Style Loss : 0.113309 Content Loss: 0.013037

run [1150]:
Style Loss : 0.112018 Content Loss: 0.013150

run [1200]:
Style Loss : 0.110805 Content Loss: 0.013258

run [1250]:
Style Loss : 0.109708 Content Loss: 0.013367

run [1300]:
Style Loss : 0.108684 Content Loss: 0.013454

run [1350]:
Style Loss : 0.107740 Content Loss: 0.013539

run [1400]:
Style Loss : 0.106907 Content Loss: 0.013603

run [1450]:
Style Loss : 0.106185 Content Loss: 0.013676

run [1500]:
Style Loss : 0.105548 Content Loss: 0.013739

run [1550]:
Style Loss : 0.104981 Content Loss: 0.013783

run [1600]:
Style Loss : 0.104436 Content Loss: 0.013842

run [1650]:
Style Loss : 0.103673 Content Loss: 0.013910

run [1700]:
Style Loss : 0.102840 Content Loss: 0.013975

run [1750]:
Style Loss : 0.102168 Content Loss: 0.014043

run [1800]:
Style Loss : 0.101478 Content Loss: 0.014106

run [1850]:
Style Loss : 0.100827 Content Loss: 0.014157

run [1900]:
Style Loss : 0.100273 Content Loss: 0.014204

run [1950]:
Style Loss : 0.099717 Content Loss: 0.014261

run [2000]:
Style Loss : 0.099163 Content Loss: 0.014317

run [2050]:
Style Loss : 0.098644 Content Loss: 0.014355

run [2100]:
Style Loss : 0.098129 Content Loss: 0.014409

run [2150]:
Style Loss : 0.097675 Content Loss: 0.014446

run [2200]:
Style Loss : 0.097269 Content Loss: 0.014479

run [2250]:
Style Loss : 0.096886 Content Loss: 0.014512

run [2300]:
Style Loss : 0.096522 Content Loss: 0.014536

run [2350]:
Style Loss : 0.096155 Content Loss: 0.014555

run [2400]:
Style Loss : 0.095847 Content Loss: 0.014570

run [2450]:
Style Loss : 0.095522 Content Loss: 0.014585

run [2500]:
Style Loss : 0.095188 Content Loss: 0.014595

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.763838 Content Loss: 0.001590

run [100]:
Style Loss : 1.157513 Content Loss: 0.002668

run [150]:
Style Loss : 0.906462 Content Loss: 0.003889

run [200]:
Style Loss : 0.766652 Content Loss: 0.005300

run [250]:
Style Loss : 0.665291 Content Loss: 0.006445

run [300]:
Style Loss : 0.576478 Content Loss: 0.007657

run [350]:
Style Loss : 0.520518 Content Loss: 0.008891

run [400]:
Style Loss : 0.479557 Content Loss: 0.010058

run [450]:
Style Loss : 0.448870 Content Loss: 0.011080

run [500]:
Style Loss : 0.425316 Content Loss: 0.012067

run [550]:
Style Loss : 0.408428 Content Loss: 0.012870

run [600]:
Style Loss : 0.395418 Content Loss: 0.013542

run [650]:
Style Loss : 0.384496 Content Loss: 0.014037

run [700]:
Style Loss : 0.375737 Content Loss: 0.014442

run [750]:
Style Loss : 0.368060 Content Loss: 0.014792

run [800]:
Style Loss : 0.360588 Content Loss: 0.015060

run [850]:
Style Loss : 0.354639 Content Loss: 0.015287

run [900]:
Style Loss : 0.349388 Content Loss: 0.015471

run [950]:
Style Loss : 0.344017 Content Loss: 0.015622

run [1000]:
Style Loss : 0.338345 Content Loss: 0.015762

run [1050]:
Style Loss : 0.333050 Content Loss: 0.015889

run [1100]:
Style Loss : 0.328631 Content Loss: 0.016026

run [1150]:
Style Loss : 0.324580 Content Loss: 0.016161

run [1200]:
Style Loss : 0.321066 Content Loss: 0.016270

run [1250]:
Style Loss : 0.317863 Content Loss: 0.016358

run [1300]:
Style Loss : 0.314349 Content Loss: 0.016479

run [1350]:
Style Loss : 0.310648 Content Loss: 0.016566

run [1400]:
Style Loss : 0.307159 Content Loss: 0.016660

run [1450]:
Style Loss : 0.303861 Content Loss: 0.016732

run [1500]:
Style Loss : 0.301460 Content Loss: 0.016798

run [1550]:
Style Loss : 0.299283 Content Loss: 0.016869

run [1600]:
Style Loss : 0.297131 Content Loss: 0.016939

run [1650]:
Style Loss : 0.295059 Content Loss: 0.016994

run [1700]:
Style Loss : 0.293219 Content Loss: 0.017061

run [1750]:
Style Loss : 0.291490 Content Loss: 0.017120

run [1800]:
Style Loss : 0.290007 Content Loss: 0.017182

run [1850]:
Style Loss : 0.288705 Content Loss: 0.017235

run [1900]:
Style Loss : 0.287430 Content Loss: 0.017293

run [1950]:
Style Loss : 0.286011 Content Loss: 0.017344

run [2000]:
Style Loss : 0.284700 Content Loss: 0.017397

run [2050]:
Style Loss : 0.283636 Content Loss: 0.017447

run [2100]:
Style Loss : 0.282570 Content Loss: 0.017491

run [2150]:
Style Loss : 0.281537 Content Loss: 0.017535

run [2200]:
Style Loss : 0.280634 Content Loss: 0.017569

run [2250]:
Style Loss : 0.279724 Content Loss: 0.017608

run [2300]:
Style Loss : 0.278828 Content Loss: 0.017648

run [2350]:
Style Loss : 0.277954 Content Loss: 0.017684

run [2400]:
Style Loss : 0.277129 Content Loss: 0.017718

run [2450]:
Style Loss : 0.276385 Content Loss: 0.017742

run [2500]:
Style Loss : 0.275675 Content Loss: 0.017773

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.602111 Content Loss: 0.006318

run [100]:
Style Loss : 0.858760 Content Loss: 0.009881

run [150]:
Style Loss : 0.624852 Content Loss: 0.012580

run [200]:
Style Loss : 0.519239 Content Loss: 0.014907

run [250]:
Style Loss : 0.456724 Content Loss: 0.016569

run [300]:
Style Loss : 0.413881 Content Loss: 0.017620

run [350]:
Style Loss : 0.385670 Content Loss: 0.018437

run [400]:
Style Loss : 0.359100 Content Loss: 0.018823

run [450]:
Style Loss : 0.338818 Content Loss: 0.019064

run [500]:
Style Loss : 0.325105 Content Loss: 0.019279

run [550]:
Style Loss : 0.315618 Content Loss: 0.019475

run [600]:
Style Loss : 0.307753 Content Loss: 0.019670

run [650]:
Style Loss : 0.301208 Content Loss: 0.019838

run [700]:
Style Loss : 0.296114 Content Loss: 0.019989

run [750]:
Style Loss : 0.291951 Content Loss: 0.020131

run [800]:
Style Loss : 0.287922 Content Loss: 0.020254

run [850]:
Style Loss : 0.284248 Content Loss: 0.020366

run [900]:
Style Loss : 0.280780 Content Loss: 0.020465

run [950]:
Style Loss : 0.277332 Content Loss: 0.020557

run [1000]:
Style Loss : 0.274437 Content Loss: 0.020640

run [1050]:
Style Loss : 0.272053 Content Loss: 0.020697

run [1100]:
Style Loss : 0.269639 Content Loss: 0.020778

run [1150]:
Style Loss : 0.267485 Content Loss: 0.020848

run [1200]:
Style Loss : 0.265373 Content Loss: 0.020916

run [1250]:
Style Loss : 0.263478 Content Loss: 0.020981

run [1300]:
Style Loss : 0.261878 Content Loss: 0.021058

run [1350]:
Style Loss : 0.260442 Content Loss: 0.021121

run [1400]:
Style Loss : 0.259058 Content Loss: 0.021181

run [1450]:
Style Loss : 0.257569 Content Loss: 0.021245

run [1500]:
Style Loss : 0.255939 Content Loss: 0.021318

run [1550]:
Style Loss : 0.254487 Content Loss: 0.021367

run [1600]:
Style Loss : 0.253191 Content Loss: 0.021419

run [1650]:
Style Loss : 0.251951 Content Loss: 0.021472

run [1700]:
Style Loss : 0.250823 Content Loss: 0.021527

run [1750]:
Style Loss : 0.249830 Content Loss: 0.021576

run [1800]:
Style Loss : 0.248897 Content Loss: 0.021619

run [1850]:
Style Loss : 0.248037 Content Loss: 0.021659

run [1900]:
Style Loss : 0.247236 Content Loss: 0.021699

run [1950]:
Style Loss : 0.246460 Content Loss: 0.021738

run [2000]:
Style Loss : 0.245702 Content Loss: 0.021776

run [2050]:
Style Loss : 0.244788 Content Loss: 0.021823

run [2100]:
Style Loss : 0.243953 Content Loss: 0.021864

run [2150]:
Style Loss : 0.243174 Content Loss: 0.021904

run [2200]:
Style Loss : 0.242481 Content Loss: 0.021938

run [2250]:
Style Loss : 0.241815 Content Loss: 0.021975

run [2300]:
Style Loss : 0.241164 Content Loss: 0.022007

run [2350]:
Style Loss : 0.240507 Content Loss: 0.022041

run [2400]:
Style Loss : 0.239787 Content Loss: 0.022080

run [2450]:
Style Loss : 0.239178 Content Loss: 0.022112

run [2500]:
Style Loss : 0.238647 Content Loss: 0.022136

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.716171 Content Loss: 0.006683

run [100]:
Style Loss : 0.758517 Content Loss: 0.010381

run [150]:
Style Loss : 0.493582 Content Loss: 0.012715

run [200]:
Style Loss : 0.383120 Content Loss: 0.014314

run [250]:
Style Loss : 0.320111 Content Loss: 0.015595

run [300]:
Style Loss : 0.279431 Content Loss: 0.016608

run [350]:
Style Loss : 0.253375 Content Loss: 0.017211

run [400]:
Style Loss : 0.235474 Content Loss: 0.017784

run [450]:
Style Loss : 0.223095 Content Loss: 0.018084

run [500]:
Style Loss : 0.213851 Content Loss: 0.018318

run [550]:
Style Loss : 0.206442 Content Loss: 0.018489

run [600]:
Style Loss : 0.200108 Content Loss: 0.018621

run [650]:
Style Loss : 0.194606 Content Loss: 0.018746

run [700]:
Style Loss : 0.190320 Content Loss: 0.018845

run [750]:
Style Loss : 0.186492 Content Loss: 0.018996

run [800]:
Style Loss : 0.182846 Content Loss: 0.019136

run [850]:
Style Loss : 0.179469 Content Loss: 0.019259

run [900]:
Style Loss : 0.176107 Content Loss: 0.019373

run [950]:
Style Loss : 0.172405 Content Loss: 0.019502

run [1000]:
Style Loss : 0.169181 Content Loss: 0.019613

run [1050]:
Style Loss : 0.165979 Content Loss: 0.019717

run [1100]:
Style Loss : 0.162946 Content Loss: 0.019833

run [1150]:
Style Loss : 0.160127 Content Loss: 0.019939

run [1200]:
Style Loss : 0.157498 Content Loss: 0.020039

run [1250]:
Style Loss : 0.154818 Content Loss: 0.020142

run [1300]:
Style Loss : 0.152012 Content Loss: 0.020242

run [1350]:
Style Loss : 0.149111 Content Loss: 0.020322

run [1400]:
Style Loss : 0.146486 Content Loss: 0.020411

run [1450]:
Style Loss : 0.143949 Content Loss: 0.020505

run [1500]:
Style Loss : 0.141754 Content Loss: 0.020587

run [1550]:
Style Loss : 0.139589 Content Loss: 0.020679

run [1600]:
Style Loss : 0.137623 Content Loss: 0.020765

run [1650]:
Style Loss : 0.135710 Content Loss: 0.020826

run [1700]:
Style Loss : 0.133827 Content Loss: 0.020899

run [1750]:
Style Loss : 0.132170 Content Loss: 0.020964

run [1800]:
Style Loss : 0.130657 Content Loss: 0.021028

run [1850]:
Style Loss : 0.129143 Content Loss: 0.021092

run [1900]:
Style Loss : 0.127633 Content Loss: 0.021160

run [1950]:
Style Loss : 0.126243 Content Loss: 0.021214

run [2000]:
Style Loss : 0.125024 Content Loss: 0.021280

run [2050]:
Style Loss : 0.123909 Content Loss: 0.021340

run [2100]:
Style Loss : 0.122811 Content Loss: 0.021404

run [2150]:
Style Loss : 0.121747 Content Loss: 0.021467

run [2200]:
Style Loss : 0.120735 Content Loss: 0.021537

run [2250]:
Style Loss : 0.119760 Content Loss: 0.021593

run [2300]:
Style Loss : 0.118718 Content Loss: 0.021649

run [2350]:
Style Loss : 0.117720 Content Loss: 0.021718

run [2400]:
Style Loss : 0.116804 Content Loss: 0.021768

run [2450]:
Style Loss : 0.115873 Content Loss: 0.021817

run [2500]:
Style Loss : 0.115043 Content Loss: 0.021866

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.701738 Content Loss: 0.008047

run [100]:
Style Loss : 1.293660 Content Loss: 0.011538

run [150]:
Style Loss : 0.856627 Content Loss: 0.013212

run [200]:
Style Loss : 0.661380 Content Loss: 0.014459

run [250]:
Style Loss : 0.542537 Content Loss: 0.015612

run [300]:
Style Loss : 0.464534 Content Loss: 0.016669

run [350]:
Style Loss : 0.408720 Content Loss: 0.017484

run [400]:
Style Loss : 0.370773 Content Loss: 0.018205

run [450]:
Style Loss : 0.343022 Content Loss: 0.018887

run [500]:
Style Loss : 0.323003 Content Loss: 0.019477

run [550]:
Style Loss : 0.307442 Content Loss: 0.019956

run [600]:
Style Loss : 0.295368 Content Loss: 0.020325

run [650]:
Style Loss : 0.285322 Content Loss: 0.020609

run [700]:
Style Loss : 0.276871 Content Loss: 0.020866

run [750]:
Style Loss : 0.269731 Content Loss: 0.021065

run [800]:
Style Loss : 0.263289 Content Loss: 0.021246

run [850]:
Style Loss : 0.257731 Content Loss: 0.021381

run [900]:
Style Loss : 0.252915 Content Loss: 0.021504

run [950]:
Style Loss : 0.248666 Content Loss: 0.021606

run [1000]:
Style Loss : 0.244955 Content Loss: 0.021692

run [1050]:
Style Loss : 0.241389 Content Loss: 0.021779

run [1100]:
Style Loss : 0.238074 Content Loss: 0.021857

run [1150]:
Style Loss : 0.235016 Content Loss: 0.021940

run [1200]:
Style Loss : 0.231848 Content Loss: 0.022036

run [1250]:
Style Loss : 0.228772 Content Loss: 0.022122

run [1300]:
Style Loss : 0.225736 Content Loss: 0.022201

run [1350]:
Style Loss : 0.222611 Content Loss: 0.022284

run [1400]:
Style Loss : 0.219902 Content Loss: 0.022348

run [1450]:
Style Loss : 0.217041 Content Loss: 0.022435

run [1500]:
Style Loss : 0.214260 Content Loss: 0.022524

run [1550]:
Style Loss : 0.211502 Content Loss: 0.022609

run [1600]:
Style Loss : 0.208678 Content Loss: 0.022702

run [1650]:
Style Loss : 0.206137 Content Loss: 0.022775

run [1700]:
Style Loss : 0.203663 Content Loss: 0.022851

run [1750]:
Style Loss : 0.201307 Content Loss: 0.022923

run [1800]:
Style Loss : 0.199029 Content Loss: 0.023006

run [1850]:
Style Loss : 0.196787 Content Loss: 0.023099

run [1900]:
Style Loss : 0.194653 Content Loss: 0.023190

run [1950]:
Style Loss : 0.192604 Content Loss: 0.023294

run [2000]:
Style Loss : 0.190657 Content Loss: 0.023407

run [2050]:
Style Loss : 0.188754 Content Loss: 0.023518

run [2100]:
Style Loss : 0.187025 Content Loss: 0.023645

run [2150]:
Style Loss : 0.185299 Content Loss: 0.023786

run [2200]:
Style Loss : 0.183412 Content Loss: 0.023928

run [2250]:
Style Loss : 0.181527 Content Loss: 0.024096

run [2300]:
Style Loss : 0.179626 Content Loss: 0.024273

run [2350]:
Style Loss : 0.177960 Content Loss: 0.024457

run [2400]:
Style Loss : 0.176271 Content Loss: 0.024627

run [2450]:
Style Loss : 0.174755 Content Loss: 0.024799

run [2500]:
Style Loss : 0.173060 Content Loss: 0.025002

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.787374 Content Loss: 0.009308

run [100]:
Style Loss : 0.470603 Content Loss: 0.012471

run [150]:
Style Loss : 0.369190 Content Loss: 0.014878

run [200]:
Style Loss : 0.314947 Content Loss: 0.016253

run [250]:
Style Loss : 0.278505 Content Loss: 0.016879

run [300]:
Style Loss : 0.256477 Content Loss: 0.017373

run [350]:
Style Loss : 0.242576 Content Loss: 0.017578

run [400]:
Style Loss : 0.232515 Content Loss: 0.017775

run [450]:
Style Loss : 0.225179 Content Loss: 0.017948

run [500]:
Style Loss : 0.219433 Content Loss: 0.018086

run [550]:
Style Loss : 0.215030 Content Loss: 0.018223

run [600]:
Style Loss : 0.211510 Content Loss: 0.018339

run [650]:
Style Loss : 0.208715 Content Loss: 0.018448

run [700]:
Style Loss : 0.205656 Content Loss: 0.018549

run [750]:
Style Loss : 0.203228 Content Loss: 0.018642

run [800]:
Style Loss : 0.201406 Content Loss: 0.018713

run [850]:
Style Loss : 0.199957 Content Loss: 0.018784

run [900]:
Style Loss : 0.198711 Content Loss: 0.018853

run [950]:
Style Loss : 0.197502 Content Loss: 0.018929

run [1000]:
Style Loss : 0.196287 Content Loss: 0.019002

run [1050]:
Style Loss : 0.197056 Content Loss: 0.019046

run [1100]:
Style Loss : 0.183981 Content Loss: 0.019157

run [1150]:
Style Loss : 0.181906 Content Loss: 0.019231

run [1200]:
Style Loss : 0.180591 Content Loss: 0.019298

run [1250]:
Style Loss : 0.179695 Content Loss: 0.019341

run [1300]:
Style Loss : 0.178840 Content Loss: 0.019382

run [1350]:
Style Loss : 0.178110 Content Loss: 0.019421

run [1400]:
Style Loss : 0.177415 Content Loss: 0.019461

run [1450]:
Style Loss : 0.176785 Content Loss: 0.019503

run [1500]:
Style Loss : 0.176227 Content Loss: 0.019541

run [1550]:
Style Loss : 0.175638 Content Loss: 0.019572

run [1600]:
Style Loss : 0.175087 Content Loss: 0.019599

run [1650]:
Style Loss : 0.174579 Content Loss: 0.019622

run [1700]:
Style Loss : 0.174136 Content Loss: 0.019645

run [1750]:
Style Loss : 0.173741 Content Loss: 0.019659

run [1800]:
Style Loss : 0.173382 Content Loss: 0.019675

run [1850]:
Style Loss : 0.173021 Content Loss: 0.019686

run [1900]:
Style Loss : 0.172688 Content Loss: 0.019699

run [1950]:
Style Loss : 0.172373 Content Loss: 0.019709

run [2000]:
Style Loss : 0.172078 Content Loss: 0.019723

run [2050]:
Style Loss : 0.171837 Content Loss: 0.019728

run [2100]:
Style Loss : 0.171612 Content Loss: 0.019734

run [2150]:
Style Loss : 0.171397 Content Loss: 0.019738

run [2200]:
Style Loss : 0.171186 Content Loss: 0.019744

run [2250]:
Style Loss : 0.170996 Content Loss: 0.019749

run [2300]:
Style Loss : 0.170822 Content Loss: 0.019756

run [2350]:
Style Loss : 0.170660 Content Loss: 0.019762

run [2400]:
Style Loss : 0.170492 Content Loss: 0.019769

run [2450]:
Style Loss : 0.170339 Content Loss: 0.019774

run [2500]:
Style Loss : 0.170197 Content Loss: 0.019781

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.641283 Content Loss: 0.011298

run [100]:
Style Loss : 0.379204 Content Loss: 0.014587

run [150]:
Style Loss : 0.264952 Content Loss: 0.017375

run [200]:
Style Loss : 0.211261 Content Loss: 0.019627

run [250]:
Style Loss : 0.182686 Content Loss: 0.021000

run [300]:
Style Loss : 0.165831 Content Loss: 0.021766

run [350]:
Style Loss : 0.153191 Content Loss: 0.022166

run [400]:
Style Loss : 0.144962 Content Loss: 0.022371

run [450]:
Style Loss : 0.138877 Content Loss: 0.022536

run [500]:
Style Loss : 0.134159 Content Loss: 0.022702

run [550]:
Style Loss : 0.129265 Content Loss: 0.022809

run [600]:
Style Loss : 0.124747 Content Loss: 0.022947

run [650]:
Style Loss : 0.121742 Content Loss: 0.023027

run [700]:
Style Loss : 0.119402 Content Loss: 0.023150

run [750]:
Style Loss : 0.117501 Content Loss: 0.023247

run [800]:
Style Loss : 0.115940 Content Loss: 0.023319

run [850]:
Style Loss : 0.114604 Content Loss: 0.023377

run [900]:
Style Loss : 0.113463 Content Loss: 0.023453

run [950]:
Style Loss : 0.112308 Content Loss: 0.023516

run [1000]:
Style Loss : 0.111449 Content Loss: 0.023547

run [1050]:
Style Loss : 0.110531 Content Loss: 0.023593

run [1100]:
Style Loss : 0.109716 Content Loss: 0.023619

run [1150]:
Style Loss : 0.108993 Content Loss: 0.023658

run [1200]:
Style Loss : 0.108331 Content Loss: 0.023685

run [1250]:
Style Loss : 0.107722 Content Loss: 0.023710

run [1300]:
Style Loss : 0.107110 Content Loss: 0.023757

run [1350]:
Style Loss : 0.106565 Content Loss: 0.023795

run [1400]:
Style Loss : 0.106067 Content Loss: 0.023808

run [1450]:
Style Loss : 0.105606 Content Loss: 0.023826

run [1500]:
Style Loss : 0.105175 Content Loss: 0.023843

run [1550]:
Style Loss : 0.104729 Content Loss: 0.023853

run [1600]:
Style Loss : 0.104371 Content Loss: 0.023869

run [1650]:
Style Loss : 0.103929 Content Loss: 0.023884

run [1700]:
Style Loss : 0.103410 Content Loss: 0.023898

run [1750]:
Style Loss : 0.102771 Content Loss: 0.023924

run [1800]:
Style Loss : 0.102295 Content Loss: 0.023954

run [1850]:
Style Loss : 0.101831 Content Loss: 0.023993

run [1900]:
Style Loss : 0.101307 Content Loss: 0.024036

run [1950]:
Style Loss : 0.100852 Content Loss: 0.024082

run [2000]:
Style Loss : 0.100437 Content Loss: 0.024131

run [2050]:
Style Loss : 0.100057 Content Loss: 0.024146

run [2100]:
Style Loss : 0.099776 Content Loss: 0.024165

run [2150]:
Style Loss : 0.099401 Content Loss: 0.024174

run [2200]:
Style Loss : 0.099110 Content Loss: 0.024188

run [2250]:
Style Loss : 0.098860 Content Loss: 0.024211

run [2300]:
Style Loss : 0.098727 Content Loss: 0.024230

run [2350]:
Style Loss : 0.098331 Content Loss: 0.024244

run [2400]:
Style Loss : 0.098058 Content Loss: 0.024264

run [2450]:
Style Loss : 0.097617 Content Loss: 0.024287

run [2500]:
Style Loss : 0.097244 Content Loss: 0.024315

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.852620 Content Loss: 0.006971

run [100]:
Style Loss : 1.009301 Content Loss: 0.011575

run [150]:
Style Loss : 0.764430 Content Loss: 0.014254

run [200]:
Style Loss : 0.648105 Content Loss: 0.015752

run [250]:
Style Loss : 0.577827 Content Loss: 0.016824

run [300]:
Style Loss : 0.532610 Content Loss: 0.017605

run [350]:
Style Loss : 0.500455 Content Loss: 0.018227

run [400]:
Style Loss : 0.477097 Content Loss: 0.018860

run [450]:
Style Loss : 0.459073 Content Loss: 0.019385

run [500]:
Style Loss : 0.444723 Content Loss: 0.019860

run [550]:
Style Loss : 0.432602 Content Loss: 0.020261

run [600]:
Style Loss : 0.422877 Content Loss: 0.020585

run [650]:
Style Loss : 0.415171 Content Loss: 0.020864

run [700]:
Style Loss : 0.408458 Content Loss: 0.021143

run [750]:
Style Loss : 0.402144 Content Loss: 0.021440

run [800]:
Style Loss : 0.396524 Content Loss: 0.021686

run [850]:
Style Loss : 0.391192 Content Loss: 0.021930

run [900]:
Style Loss : 0.386316 Content Loss: 0.022145

run [950]:
Style Loss : 0.382244 Content Loss: 0.022319

run [1000]:
Style Loss : 0.378767 Content Loss: 0.022488

run [1050]:
Style Loss : 0.375923 Content Loss: 0.022614

run [1100]:
Style Loss : 0.373239 Content Loss: 0.022732

run [1150]:
Style Loss : 0.370772 Content Loss: 0.022828

run [1200]:
Style Loss : 0.368489 Content Loss: 0.022942

run [1250]:
Style Loss : 0.366265 Content Loss: 0.023041

run [1300]:
Style Loss : 0.364271 Content Loss: 0.023113

run [1350]:
Style Loss : 0.362531 Content Loss: 0.023172

run [1400]:
Style Loss : 0.361020 Content Loss: 0.023226

run [1450]:
Style Loss : 0.359538 Content Loss: 0.023262

run [1500]:
Style Loss : 0.358136 Content Loss: 0.023331

run [1550]:
Style Loss : 0.356846 Content Loss: 0.023389

run [1600]:
Style Loss : 0.355505 Content Loss: 0.023435

run [1650]:
Style Loss : 0.354281 Content Loss: 0.023485

run [1700]:
Style Loss : 0.353175 Content Loss: 0.023528

run [1750]:
Style Loss : 0.352139 Content Loss: 0.023560

run [1800]:
Style Loss : 0.351156 Content Loss: 0.023593

run [1850]:
Style Loss : 0.350339 Content Loss: 0.023623

run [1900]:
Style Loss : 0.349563 Content Loss: 0.023650

run [1950]:
Style Loss : 0.348831 Content Loss: 0.023684

run [2000]:
Style Loss : 0.348096 Content Loss: 0.023714

run [2050]:
Style Loss : 0.347322 Content Loss: 0.023731

run [2100]:
Style Loss : 0.346601 Content Loss: 0.023775

run [2150]:
Style Loss : 0.345931 Content Loss: 0.023791

run [2200]:
Style Loss : 0.345310 Content Loss: 0.023829

run [2250]:
Style Loss : 0.344751 Content Loss: 0.023857

run [2300]:
Style Loss : 0.344205 Content Loss: 0.023901

run [2350]:
Style Loss : 0.343722 Content Loss: 0.023943

run [2400]:
Style Loss : 0.343041 Content Loss: 0.023959

run [2450]:
Style Loss : 0.342511 Content Loss: 0.023984

run [2500]:
Style Loss : 0.341854 Content Loss: 0.024023

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.228651 Content Loss: 0.007705

run [100]:
Style Loss : 0.588475 Content Loss: 0.011251

run [150]:
Style Loss : 0.413944 Content Loss: 0.013526

run [200]:
Style Loss : 0.335207 Content Loss: 0.015093

run [250]:
Style Loss : 0.290385 Content Loss: 0.016296

run [300]:
Style Loss : 0.265231 Content Loss: 0.016932

run [350]:
Style Loss : 0.247612 Content Loss: 0.017307

run [400]:
Style Loss : 0.234680 Content Loss: 0.017564

run [450]:
Style Loss : 0.224391 Content Loss: 0.017744

run [500]:
Style Loss : 0.216108 Content Loss: 0.017928

run [550]:
Style Loss : 0.209384 Content Loss: 0.018103

run [600]:
Style Loss : 0.204095 Content Loss: 0.018225

run [650]:
Style Loss : 0.199581 Content Loss: 0.018352

run [700]:
Style Loss : 0.195379 Content Loss: 0.018511

run [750]:
Style Loss : 0.191402 Content Loss: 0.018652

run [800]:
Style Loss : 0.187800 Content Loss: 0.018783

run [850]:
Style Loss : 0.184603 Content Loss: 0.018906

run [900]:
Style Loss : 0.182059 Content Loss: 0.019015

run [950]:
Style Loss : 0.179850 Content Loss: 0.019122

run [1000]:
Style Loss : 0.177858 Content Loss: 0.019234

run [1050]:
Style Loss : 0.176179 Content Loss: 0.019316

run [1100]:
Style Loss : 0.174708 Content Loss: 0.019402

run [1150]:
Style Loss : 0.173303 Content Loss: 0.019495

run [1200]:
Style Loss : 0.171964 Content Loss: 0.019589

run [1250]:
Style Loss : 0.170588 Content Loss: 0.019697

run [1300]:
Style Loss : 0.169199 Content Loss: 0.019803

run [1350]:
Style Loss : 0.167983 Content Loss: 0.019906

run [1400]:
Style Loss : 0.166770 Content Loss: 0.020009

run [1450]:
Style Loss : 0.165668 Content Loss: 0.020101

run [1500]:
Style Loss : 0.164675 Content Loss: 0.020183

run [1550]:
Style Loss : 0.163776 Content Loss: 0.020266

run [1600]:
Style Loss : 0.162924 Content Loss: 0.020353

run [1650]:
Style Loss : 0.162059 Content Loss: 0.020434

run [1700]:
Style Loss : 0.161197 Content Loss: 0.020525

run [1750]:
Style Loss : 0.160435 Content Loss: 0.020597

run [1800]:
Style Loss : 0.159567 Content Loss: 0.020669

run [1850]:
Style Loss : 0.158844 Content Loss: 0.020742

run [1900]:
Style Loss : 0.158124 Content Loss: 0.020815

run [1950]:
Style Loss : 0.157561 Content Loss: 0.020878

run [2000]:
Style Loss : 0.156957 Content Loss: 0.020937

run [2050]:
Style Loss : 0.156395 Content Loss: 0.020991

run [2100]:
Style Loss : 0.155879 Content Loss: 0.021042

run [2150]:
Style Loss : 0.155389 Content Loss: 0.021107

run [2200]:
Style Loss : 0.154829 Content Loss: 0.021160

run [2250]:
Style Loss : 0.154239 Content Loss: 0.021212

run [2300]:
Style Loss : 0.153708 Content Loss: 0.021252

run [2350]:
Style Loss : 0.153243 Content Loss: 0.021303

run [2400]:
Style Loss : 0.152843 Content Loss: 0.021339

run [2450]:
Style Loss : 0.152377 Content Loss: 0.021383

run [2500]:
Style Loss : 0.151905 Content Loss: 0.021416

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.168750 Content Loss: 0.009201

run [100]:
Style Loss : 0.661300 Content Loss: 0.014209

run [150]:
Style Loss : 0.470125 Content Loss: 0.017394

run [200]:
Style Loss : 0.386065 Content Loss: 0.019507

run [250]:
Style Loss : 0.338097 Content Loss: 0.020752

run [300]:
Style Loss : 0.306019 Content Loss: 0.021391

run [350]:
Style Loss : 0.283879 Content Loss: 0.021646

run [400]:
Style Loss : 0.263713 Content Loss: 0.021881

run [450]:
Style Loss : 0.248337 Content Loss: 0.022172

run [500]:
Style Loss : 0.234702 Content Loss: 0.022413

run [550]:
Style Loss : 0.223514 Content Loss: 0.022633

run [600]:
Style Loss : 0.213713 Content Loss: 0.022812

run [650]:
Style Loss : 0.204576 Content Loss: 0.022937

run [700]:
Style Loss : 0.196989 Content Loss: 0.023050

run [750]:
Style Loss : 0.190228 Content Loss: 0.023189

run [800]:
Style Loss : 0.184178 Content Loss: 0.023332

run [850]:
Style Loss : 0.178665 Content Loss: 0.023471

run [900]:
Style Loss : 0.173302 Content Loss: 0.023640

run [950]:
Style Loss : 0.168766 Content Loss: 0.023773

run [1000]:
Style Loss : 0.164755 Content Loss: 0.023935

run [1050]:
Style Loss : 0.161041 Content Loss: 0.024104

run [1100]:
Style Loss : 0.157668 Content Loss: 0.024272

run [1150]:
Style Loss : 0.154635 Content Loss: 0.024425

run [1200]:
Style Loss : 0.151797 Content Loss: 0.024546

run [1250]:
Style Loss : 0.149334 Content Loss: 0.024672

run [1300]:
Style Loss : 0.147072 Content Loss: 0.024809

run [1350]:
Style Loss : 0.145081 Content Loss: 0.024940

run [1400]:
Style Loss : 0.143249 Content Loss: 0.025044

run [1450]:
Style Loss : 0.141484 Content Loss: 0.025173

run [1500]:
Style Loss : 0.139744 Content Loss: 0.025275

run [1550]:
Style Loss : 0.138150 Content Loss: 0.025354

run [1600]:
Style Loss : 0.136606 Content Loss: 0.025430

run [1650]:
Style Loss : 0.135283 Content Loss: 0.025479

run [1700]:
Style Loss : 0.134161 Content Loss: 0.025509

run [1750]:
Style Loss : 0.133233 Content Loss: 0.025535

run [1800]:
Style Loss : 0.132345 Content Loss: 0.025559

run [1850]:
Style Loss : 0.131576 Content Loss: 0.025593

run [1900]:
Style Loss : 0.130899 Content Loss: 0.025598

run [1950]:
Style Loss : 0.130333 Content Loss: 0.025602

run [2000]:
Style Loss : 0.129782 Content Loss: 0.025600

run [2050]:
Style Loss : 0.129330 Content Loss: 0.025594

run [2100]:
Style Loss : 0.128902 Content Loss: 0.025589

run [2150]:
Style Loss : 0.128521 Content Loss: 0.025576

run [2200]:
Style Loss : 0.128190 Content Loss: 0.025563

run [2250]:
Style Loss : 0.127850 Content Loss: 0.025556

run [2300]:
Style Loss : 0.127543 Content Loss: 0.025550

run [2350]:
Style Loss : 0.127243 Content Loss: 0.025548

run [2400]:
Style Loss : 0.126973 Content Loss: 0.025543

run [2450]:
Style Loss : 0.126702 Content Loss: 0.025540

run [2500]:
Style Loss : 0.126449 Content Loss: 0.025534

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.993153 Content Loss: 0.008575

run [100]:
Style Loss : 0.445216 Content Loss: 0.012078

run [150]:
Style Loss : 0.286574 Content Loss: 0.013922

run [200]:
Style Loss : 0.222563 Content Loss: 0.015267

run [250]:
Style Loss : 0.187033 Content Loss: 0.016211

run [300]:
Style Loss : 0.159636 Content Loss: 0.016852

run [350]:
Style Loss : 0.144596 Content Loss: 0.017248

run [400]:
Style Loss : 0.134751 Content Loss: 0.017468

run [450]:
Style Loss : 0.127376 Content Loss: 0.017538

run [500]:
Style Loss : 0.121929 Content Loss: 0.017611

run [550]:
Style Loss : 0.117444 Content Loss: 0.017686

run [600]:
Style Loss : 0.113756 Content Loss: 0.017733

run [650]:
Style Loss : 0.110453 Content Loss: 0.017812

run [700]:
Style Loss : 0.107779 Content Loss: 0.017883

run [750]:
Style Loss : 0.105347 Content Loss: 0.017943

run [800]:
Style Loss : 0.103253 Content Loss: 0.017999

run [850]:
Style Loss : 0.101362 Content Loss: 0.018049

run [900]:
Style Loss : 0.099610 Content Loss: 0.018104

run [950]:
Style Loss : 0.097975 Content Loss: 0.018155

run [1000]:
Style Loss : 0.096484 Content Loss: 0.018194

run [1050]:
Style Loss : 0.095165 Content Loss: 0.018232

run [1100]:
Style Loss : 0.093879 Content Loss: 0.018275

run [1150]:
Style Loss : 0.092705 Content Loss: 0.018317

run [1200]:
Style Loss : 0.091708 Content Loss: 0.018353

run [1250]:
Style Loss : 0.090667 Content Loss: 0.018389

run [1300]:
Style Loss : 0.089703 Content Loss: 0.018427

run [1350]:
Style Loss : 0.088829 Content Loss: 0.018472

run [1400]:
Style Loss : 0.088085 Content Loss: 0.018503

run [1450]:
Style Loss : 0.087446 Content Loss: 0.018531

run [1500]:
Style Loss : 0.086832 Content Loss: 0.018563

run [1550]:
Style Loss : 0.086272 Content Loss: 0.018592

run [1600]:
Style Loss : 0.085712 Content Loss: 0.018620

run [1650]:
Style Loss : 0.085077 Content Loss: 0.018649

run [1700]:
Style Loss : 0.084567 Content Loss: 0.018675

run [1750]:
Style Loss : 0.084019 Content Loss: 0.018700

run [1800]:
Style Loss : 0.083549 Content Loss: 0.018721

run [1850]:
Style Loss : 0.083091 Content Loss: 0.018740

run [1900]:
Style Loss : 0.082660 Content Loss: 0.018762

run [1950]:
Style Loss : 0.082232 Content Loss: 0.018782

run [2000]:
Style Loss : 0.081827 Content Loss: 0.018804

run [2050]:
Style Loss : 0.081474 Content Loss: 0.018821

run [2100]:
Style Loss : 0.081161 Content Loss: 0.018836

run [2150]:
Style Loss : 0.080850 Content Loss: 0.018855

run [2200]:
Style Loss : 0.080563 Content Loss: 0.018875

run [2250]:
Style Loss : 0.080275 Content Loss: 0.018894

run [2300]:
Style Loss : 0.080018 Content Loss: 0.018912

run [2350]:
Style Loss : 0.079781 Content Loss: 0.018927

run [2400]:
Style Loss : 0.079562 Content Loss: 0.018940

run [2450]:
Style Loss : 0.079358 Content Loss: 0.018950

run [2500]:
Style Loss : 0.079163 Content Loss: 0.018961

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.211268 Content Loss: 0.008495

run [100]:
Style Loss : 0.781832 Content Loss: 0.012197

run [150]:
Style Loss : 0.593087 Content Loss: 0.014736

run [200]:
Style Loss : 0.492544 Content Loss: 0.016536

run [250]:
Style Loss : 0.430025 Content Loss: 0.017746

run [300]:
Style Loss : 0.393040 Content Loss: 0.018511

run [350]:
Style Loss : 0.368370 Content Loss: 0.019130

run [400]:
Style Loss : 0.349257 Content Loss: 0.019643

run [450]:
Style Loss : 0.332867 Content Loss: 0.020179

run [500]:
Style Loss : 0.319336 Content Loss: 0.020697

run [550]:
Style Loss : 0.308468 Content Loss: 0.021214

run [600]:
Style Loss : 0.299532 Content Loss: 0.021647

run [650]:
Style Loss : 0.292373 Content Loss: 0.021973

run [700]:
Style Loss : 0.286273 Content Loss: 0.022284

run [750]:
Style Loss : 0.280961 Content Loss: 0.022586

run [800]:
Style Loss : 0.276110 Content Loss: 0.022910

run [850]:
Style Loss : 0.271751 Content Loss: 0.023187

run [900]:
Style Loss : 0.267652 Content Loss: 0.023429

run [950]:
Style Loss : 0.263603 Content Loss: 0.023704

run [1000]:
Style Loss : 0.259862 Content Loss: 0.023960

run [1050]:
Style Loss : 0.256165 Content Loss: 0.024227

run [1100]:
Style Loss : 0.252996 Content Loss: 0.024522

run [1150]:
Style Loss : 0.249956 Content Loss: 0.024831

run [1200]:
Style Loss : 0.247712 Content Loss: 0.025113

run [1250]:
Style Loss : 0.245670 Content Loss: 0.025340

run [1300]:
Style Loss : 0.243756 Content Loss: 0.025649

run [1350]:
Style Loss : 0.241882 Content Loss: 0.025931

run [1400]:
Style Loss : 0.240744 Content Loss: 0.026273

run [1450]:
Style Loss : 0.240176 Content Loss: 0.026613

run [1500]:
Style Loss : 0.237292 Content Loss: 0.026782

run [1550]:
Style Loss : 0.236887 Content Loss: 0.027052

run [1600]:
Style Loss : 0.235449 Content Loss: 0.027361

run [1650]:
Style Loss : 0.233767 Content Loss: 0.027504

run [1700]:
Style Loss : 0.232384 Content Loss: 0.027744

run [1750]:
Style Loss : 0.232020 Content Loss: 0.028051

run [1800]:
Style Loss : 0.230196 Content Loss: 0.028179

run [1850]:
Style Loss : 0.229636 Content Loss: 0.028457

run [1900]:
Style Loss : 0.228325 Content Loss: 0.028531

run [1950]:
Style Loss : 0.226470 Content Loss: 0.028610

run [2000]:
Style Loss : 0.225481 Content Loss: 0.028747

run [2050]:
Style Loss : 0.223949 Content Loss: 0.028792

run [2100]:
Style Loss : 0.222809 Content Loss: 0.028794

run [2150]:
Style Loss : 0.221777 Content Loss: 0.028846

run [2200]:
Style Loss : 0.221686 Content Loss: 0.028915

run [2250]:
Style Loss : 0.220329 Content Loss: 0.028890

run [2300]:
Style Loss : 0.219345 Content Loss: 0.028852

run [2350]:
Style Loss : 0.218221 Content Loss: 0.028837

run [2400]:
Style Loss : 0.217478 Content Loss: 0.028834

run [2450]:
Style Loss : 0.216667 Content Loss: 0.028807

run [2500]:
Style Loss : 0.215996 Content Loss: 0.028766

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.657468 Content Loss: 0.008281

run [100]:
Style Loss : 0.374496 Content Loss: 0.011282

run [150]:
Style Loss : 0.291518 Content Loss: 0.012530

run [200]:
Style Loss : 0.248946 Content Loss: 0.013140

run [250]:
Style Loss : 0.220485 Content Loss: 0.013787

run [300]:
Style Loss : 0.201059 Content Loss: 0.014303

run [350]:
Style Loss : 0.186860 Content Loss: 0.014710

run [400]:
Style Loss : 0.174607 Content Loss: 0.015041

run [450]:
Style Loss : 0.166537 Content Loss: 0.015262

run [500]:
Style Loss : 0.159479 Content Loss: 0.015553

run [550]:
Style Loss : 0.153332 Content Loss: 0.015801

run [600]:
Style Loss : 0.146846 Content Loss: 0.015997

run [650]:
Style Loss : 0.141310 Content Loss: 0.016170

run [700]:
Style Loss : 0.136184 Content Loss: 0.016360

run [750]:
Style Loss : 0.132177 Content Loss: 0.016492

run [800]:
Style Loss : 0.128684 Content Loss: 0.016608

run [850]:
Style Loss : 0.125938 Content Loss: 0.016718

run [900]:
Style Loss : 0.123538 Content Loss: 0.016807

run [950]:
Style Loss : 0.121179 Content Loss: 0.016942

run [1000]:
Style Loss : 0.117253 Content Loss: 0.017041

run [1050]:
Style Loss : 0.115346 Content Loss: 0.017110

run [1100]:
Style Loss : 0.113667 Content Loss: 0.017175

run [1150]:
Style Loss : 0.112327 Content Loss: 0.017210

run [1200]:
Style Loss : 0.111261 Content Loss: 0.017233

run [1250]:
Style Loss : 0.110331 Content Loss: 0.017239

run [1300]:
Style Loss : 0.109445 Content Loss: 0.017257

run [1350]:
Style Loss : 0.108636 Content Loss: 0.017277

run [1400]:
Style Loss : 0.107897 Content Loss: 0.017303

run [1450]:
Style Loss : 0.107219 Content Loss: 0.017305

run [1500]:
Style Loss : 0.106588 Content Loss: 0.017304

run [1550]:
Style Loss : 0.105990 Content Loss: 0.017307

run [1600]:
Style Loss : 0.105455 Content Loss: 0.017325

run [1650]:
Style Loss : 0.104965 Content Loss: 0.017336

run [1700]:
Style Loss : 0.104435 Content Loss: 0.017349

run [1750]:
Style Loss : 0.103997 Content Loss: 0.017346

run [1800]:
Style Loss : 0.103565 Content Loss: 0.017351

run [1850]:
Style Loss : 0.103134 Content Loss: 0.017352

run [1900]:
Style Loss : 0.102721 Content Loss: 0.017362

run [1950]:
Style Loss : 0.102349 Content Loss: 0.017375

run [2000]:
Style Loss : 0.101946 Content Loss: 0.017379

run [2050]:
Style Loss : 0.101620 Content Loss: 0.017386

run [2100]:
Style Loss : 0.101347 Content Loss: 0.017382

run [2150]:
Style Loss : 0.101073 Content Loss: 0.017373

run [2200]:
Style Loss : 0.100854 Content Loss: 0.017375

run [2250]:
Style Loss : 0.100611 Content Loss: 0.017362

run [2300]:
Style Loss : 0.100400 Content Loss: 0.017357

run [2350]:
Style Loss : 0.100194 Content Loss: 0.017351

run [2400]:
Style Loss : 0.099998 Content Loss: 0.017345

run [2450]:
Style Loss : 0.099827 Content Loss: 0.017342

run [2500]:
Style Loss : 0.099634 Content Loss: 0.017338

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.088396 Content Loss: 0.005617

run [100]:
Style Loss : 1.180664 Content Loss: 0.008882

run [150]:
Style Loss : 0.918675 Content Loss: 0.010855

run [200]:
Style Loss : 0.783321 Content Loss: 0.012293

run [250]:
Style Loss : 0.702047 Content Loss: 0.013185

run [300]:
Style Loss : 0.646531 Content Loss: 0.013984

run [350]:
Style Loss : 0.606219 Content Loss: 0.014571

run [400]:
Style Loss : 0.578573 Content Loss: 0.015007

run [450]:
Style Loss : 0.557232 Content Loss: 0.015401

run [500]:
Style Loss : 0.540483 Content Loss: 0.015685

run [550]:
Style Loss : 0.527109 Content Loss: 0.015964

run [600]:
Style Loss : 0.516024 Content Loss: 0.016193

run [650]:
Style Loss : 0.507085 Content Loss: 0.016397

run [700]:
Style Loss : 0.498716 Content Loss: 0.016593

run [750]:
Style Loss : 0.491586 Content Loss: 0.016752

run [800]:
Style Loss : 0.485332 Content Loss: 0.016910

run [850]:
Style Loss : 0.479585 Content Loss: 0.017092

run [900]:
Style Loss : 0.474274 Content Loss: 0.017240

run [950]:
Style Loss : 0.469436 Content Loss: 0.017376

run [1000]:
Style Loss : 0.465002 Content Loss: 0.017492

run [1050]:
Style Loss : 0.460863 Content Loss: 0.017609

run [1100]:
Style Loss : 0.455052 Content Loss: 0.017733

run [1150]:
Style Loss : 0.447600 Content Loss: 0.017879

run [1200]:
Style Loss : 0.440992 Content Loss: 0.018018

run [1250]:
Style Loss : 0.434905 Content Loss: 0.018156

run [1300]:
Style Loss : 0.429706 Content Loss: 0.018244

run [1350]:
Style Loss : 0.425604 Content Loss: 0.018340

run [1400]:
Style Loss : 0.421841 Content Loss: 0.018433

run [1450]:
Style Loss : 0.418490 Content Loss: 0.018523

run [1500]:
Style Loss : 0.415348 Content Loss: 0.018616

run [1550]:
Style Loss : 0.412446 Content Loss: 0.018711

run [1600]:
Style Loss : 0.409570 Content Loss: 0.018789

run [1650]:
Style Loss : 0.406981 Content Loss: 0.018853

run [1700]:
Style Loss : 0.404485 Content Loss: 0.018925

run [1750]:
Style Loss : 0.402321 Content Loss: 0.018986

run [1800]:
Style Loss : 0.400330 Content Loss: 0.019058

run [1850]:
Style Loss : 0.398385 Content Loss: 0.019126

run [1900]:
Style Loss : 0.396666 Content Loss: 0.019183

run [1950]:
Style Loss : 0.394854 Content Loss: 0.019240

run [2000]:
Style Loss : 0.392598 Content Loss: 0.019314

run [2050]:
Style Loss : 0.390516 Content Loss: 0.019376

run [2100]:
Style Loss : 0.388896 Content Loss: 0.019431

run [2150]:
Style Loss : 0.387376 Content Loss: 0.019487

run [2200]:
Style Loss : 0.385456 Content Loss: 0.019555

run [2250]:
Style Loss : 0.383637 Content Loss: 0.019613

run [2300]:
Style Loss : 0.382147 Content Loss: 0.019658

run [2350]:
Style Loss : 0.380867 Content Loss: 0.019696

run [2400]:
Style Loss : 0.379679 Content Loss: 0.019730

run [2450]:
Style Loss : 0.378593 Content Loss: 0.019761

run [2500]:
Style Loss : 0.377575 Content Loss: 0.019789

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.525470 Content Loss: 0.004592

run [100]:
Style Loss : 1.202393 Content Loss: 0.008360

run [150]:
Style Loss : 0.799038 Content Loss: 0.010640

run [200]:
Style Loss : 0.625008 Content Loss: 0.012127

run [250]:
Style Loss : 0.516883 Content Loss: 0.013317

run [300]:
Style Loss : 0.450494 Content Loss: 0.014277

run [350]:
Style Loss : 0.406863 Content Loss: 0.014914

run [400]:
Style Loss : 0.372212 Content Loss: 0.015522

run [450]:
Style Loss : 0.342781 Content Loss: 0.015952

run [500]:
Style Loss : 0.319386 Content Loss: 0.016290

run [550]:
Style Loss : 0.297076 Content Loss: 0.016615

run [600]:
Style Loss : 0.277381 Content Loss: 0.016807

run [650]:
Style Loss : 0.262404 Content Loss: 0.016928

run [700]:
Style Loss : 0.249948 Content Loss: 0.017113

run [750]:
Style Loss : 0.239274 Content Loss: 0.017255

run [800]:
Style Loss : 0.229650 Content Loss: 0.017355

run [850]:
Style Loss : 0.220596 Content Loss: 0.017482

run [900]:
Style Loss : 0.212816 Content Loss: 0.017591

run [950]:
Style Loss : 0.205532 Content Loss: 0.017713

run [1000]:
Style Loss : 0.199123 Content Loss: 0.017834

run [1050]:
Style Loss : 0.193027 Content Loss: 0.017975

run [1100]:
Style Loss : 0.187022 Content Loss: 0.018116

run [1150]:
Style Loss : 0.181211 Content Loss: 0.018262

run [1200]:
Style Loss : 0.175742 Content Loss: 0.018412

run [1250]:
Style Loss : 0.170349 Content Loss: 0.018594

run [1300]:
Style Loss : 0.165320 Content Loss: 0.018791

run [1350]:
Style Loss : 0.160481 Content Loss: 0.018975

run [1400]:
Style Loss : 0.156006 Content Loss: 0.019165

run [1450]:
Style Loss : 0.151522 Content Loss: 0.019366

run [1500]:
Style Loss : 0.147099 Content Loss: 0.019583

run [1550]:
Style Loss : 0.142833 Content Loss: 0.019807

run [1600]:
Style Loss : 0.138590 Content Loss: 0.020050

run [1650]:
Style Loss : 0.134403 Content Loss: 0.020288

run [1700]:
Style Loss : 0.130356 Content Loss: 0.020558

run [1750]:
Style Loss : 0.126490 Content Loss: 0.020820

run [1800]:
Style Loss : 0.122888 Content Loss: 0.021086

run [1850]:
Style Loss : 0.119377 Content Loss: 0.021374

run [1900]:
Style Loss : 0.116058 Content Loss: 0.021629

run [1950]:
Style Loss : 0.112928 Content Loss: 0.021901

run [2000]:
Style Loss : 0.110057 Content Loss: 0.022154

run [2050]:
Style Loss : 0.107266 Content Loss: 0.022401

run [2100]:
Style Loss : 0.104794 Content Loss: 0.022628

run [2150]:
Style Loss : 0.102401 Content Loss: 0.022842

run [2200]:
Style Loss : 0.100360 Content Loss: 0.023022

run [2250]:
Style Loss : 0.098396 Content Loss: 0.023189

run [2300]:
Style Loss : 0.096794 Content Loss: 0.023335

run [2350]:
Style Loss : 0.095268 Content Loss: 0.023481

run [2400]:
Style Loss : 0.093879 Content Loss: 0.023616

run [2450]:
Style Loss : 0.092711 Content Loss: 0.023701

run [2500]:
Style Loss : 0.091487 Content Loss: 0.023740

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.874709 Content Loss: 0.006570

run [100]:
Style Loss : 0.971658 Content Loss: 0.011559

run [150]:
Style Loss : 0.676664 Content Loss: 0.014944

run [200]:
Style Loss : 0.525665 Content Loss: 0.018003

run [250]:
Style Loss : 0.440412 Content Loss: 0.019685

run [300]:
Style Loss : 0.387612 Content Loss: 0.020741

run [350]:
Style Loss : 0.351608 Content Loss: 0.021300

run [400]:
Style Loss : 0.328678 Content Loss: 0.021901

run [450]:
Style Loss : 0.312056 Content Loss: 0.022276

run [500]:
Style Loss : 0.298994 Content Loss: 0.022570

run [550]:
Style Loss : 0.287520 Content Loss: 0.022851

run [600]:
Style Loss : 0.277897 Content Loss: 0.023085

run [650]:
Style Loss : 0.270371 Content Loss: 0.023297

run [700]:
Style Loss : 0.263981 Content Loss: 0.023455

run [750]:
Style Loss : 0.258570 Content Loss: 0.023600

run [800]:
Style Loss : 0.253815 Content Loss: 0.023771

run [850]:
Style Loss : 0.249682 Content Loss: 0.023927

run [900]:
Style Loss : 0.246039 Content Loss: 0.024056

run [950]:
Style Loss : 0.242788 Content Loss: 0.024190

run [1000]:
Style Loss : 0.239759 Content Loss: 0.024298

run [1050]:
Style Loss : 0.236831 Content Loss: 0.024415

run [1100]:
Style Loss : 0.234075 Content Loss: 0.024551

run [1150]:
Style Loss : 0.231518 Content Loss: 0.024684

run [1200]:
Style Loss : 0.229091 Content Loss: 0.024823

run [1250]:
Style Loss : 0.226737 Content Loss: 0.024941

run [1300]:
Style Loss : 0.224534 Content Loss: 0.025077

run [1350]:
Style Loss : 0.222267 Content Loss: 0.025219

run [1400]:
Style Loss : 0.220041 Content Loss: 0.025341

run [1450]:
Style Loss : 0.218064 Content Loss: 0.025470

run [1500]:
Style Loss : 0.216194 Content Loss: 0.025573

run [1550]:
Style Loss : 0.214279 Content Loss: 0.025686

run [1600]:
Style Loss : 0.212690 Content Loss: 0.025814

run [1650]:
Style Loss : 0.211120 Content Loss: 0.025903

run [1700]:
Style Loss : 0.209677 Content Loss: 0.026028

run [1750]:
Style Loss : 0.208205 Content Loss: 0.026141

run [1800]:
Style Loss : 0.207449 Content Loss: 0.026275

run [1850]:
Style Loss : 0.205694 Content Loss: 0.026304

run [1900]:
Style Loss : 0.204538 Content Loss: 0.026404

run [1950]:
Style Loss : 0.203819 Content Loss: 0.026507

run [2000]:
Style Loss : 0.202304 Content Loss: 0.026584

run [2050]:
Style Loss : 0.202621 Content Loss: 0.026891

run [2100]:
Style Loss : 0.200020 Content Loss: 0.026811

run [2150]:
Style Loss : 0.198649 Content Loss: 0.026815

run [2200]:
Style Loss : 0.197821 Content Loss: 0.026852

run [2250]:
Style Loss : 0.365974 Content Loss: 0.027344

run [2300]:
Style Loss : 0.196576 Content Loss: 0.027020

run [2350]:
Style Loss : 0.195538 Content Loss: 0.027079

run [2400]:
Style Loss : 0.217031 Content Loss: 0.027912

run [2450]:
Style Loss : 0.197877 Content Loss: 0.027661

run [2500]:
Style Loss : 0.193378 Content Loss: 0.027628

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.086496 Content Loss: 0.004443

run [100]:
Style Loss : 1.551289 Content Loss: 0.008440

run [150]:
Style Loss : 1.092797 Content Loss: 0.010646

run [200]:
Style Loss : 0.897420 Content Loss: 0.012037

run [250]:
Style Loss : 0.787776 Content Loss: 0.013107

run [300]:
Style Loss : 0.712592 Content Loss: 0.013958

run [350]:
Style Loss : 0.651687 Content Loss: 0.014770

run [400]:
Style Loss : 0.605051 Content Loss: 0.015355

run [450]:
Style Loss : 0.567996 Content Loss: 0.015951

run [500]:
Style Loss : 0.537669 Content Loss: 0.016518

run [550]:
Style Loss : 0.512387 Content Loss: 0.016923

run [600]:
Style Loss : 0.493864 Content Loss: 0.017229

run [650]:
Style Loss : 0.478873 Content Loss: 0.017535

run [700]:
Style Loss : 0.466408 Content Loss: 0.017781

run [750]:
Style Loss : 0.455820 Content Loss: 0.018014

run [800]:
Style Loss : 0.447133 Content Loss: 0.018185

run [850]:
Style Loss : 0.439576 Content Loss: 0.018351

run [900]:
Style Loss : 0.432837 Content Loss: 0.018491

run [950]:
Style Loss : 0.426988 Content Loss: 0.018611

run [1000]:
Style Loss : 0.421032 Content Loss: 0.018748

run [1050]:
Style Loss : 0.415737 Content Loss: 0.018857

run [1100]:
Style Loss : 0.411217 Content Loss: 0.018939

run [1150]:
Style Loss : 0.406888 Content Loss: 0.019008

run [1200]:
Style Loss : 0.401688 Content Loss: 0.019100

run [1250]:
Style Loss : 0.395712 Content Loss: 0.019167

run [1300]:
Style Loss : 0.390728 Content Loss: 0.019233

run [1350]:
Style Loss : 0.386422 Content Loss: 0.019301

run [1400]:
Style Loss : 0.382124 Content Loss: 0.019374

run [1450]:
Style Loss : 0.378148 Content Loss: 0.019438

run [1500]:
Style Loss : 0.374276 Content Loss: 0.019489

run [1550]:
Style Loss : 0.370791 Content Loss: 0.019543

run [1600]:
Style Loss : 0.367501 Content Loss: 0.019598

run [1650]:
Style Loss : 0.363899 Content Loss: 0.019641

run [1700]:
Style Loss : 0.360577 Content Loss: 0.019685

run [1750]:
Style Loss : 0.357779 Content Loss: 0.019715

run [1800]:
Style Loss : 0.355129 Content Loss: 0.019760

run [1850]:
Style Loss : 0.352732 Content Loss: 0.019788

run [1900]:
Style Loss : 0.350448 Content Loss: 0.019822

run [1950]:
Style Loss : 0.348116 Content Loss: 0.019856

run [2000]:
Style Loss : 0.345844 Content Loss: 0.019883

run [2050]:
Style Loss : 0.343608 Content Loss: 0.019914

run [2100]:
Style Loss : 0.341500 Content Loss: 0.019941

run [2150]:
Style Loss : 0.339494 Content Loss: 0.019963

run [2200]:
Style Loss : 0.337660 Content Loss: 0.019980

run [2250]:
Style Loss : 0.336037 Content Loss: 0.020003

run [2300]:
Style Loss : 0.334470 Content Loss: 0.020023

run [2350]:
Style Loss : 0.332849 Content Loss: 0.020042

run [2400]:
Style Loss : 0.331119 Content Loss: 0.020067

run [2450]:
Style Loss : 0.329626 Content Loss: 0.020087

run [2500]:
Style Loss : 0.327985 Content Loss: 0.020110

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.530873 Content Loss: 0.006554

run [100]:
Style Loss : 1.291702 Content Loss: 0.009345

run [150]:
Style Loss : 0.925093 Content Loss: 0.011287

run [200]:
Style Loss : 0.731372 Content Loss: 0.012571

run [250]:
Style Loss : 0.611962 Content Loss: 0.013652

run [300]:
Style Loss : 0.528066 Content Loss: 0.014592

run [350]:
Style Loss : 0.468369 Content Loss: 0.015409

run [400]:
Style Loss : 0.425483 Content Loss: 0.016117

run [450]:
Style Loss : 0.393961 Content Loss: 0.016856

run [500]:
Style Loss : 0.370718 Content Loss: 0.017449

run [550]:
Style Loss : 0.352314 Content Loss: 0.017930

run [600]:
Style Loss : 0.337979 Content Loss: 0.018367

run [650]:
Style Loss : 0.326648 Content Loss: 0.018700

run [700]:
Style Loss : 0.317723 Content Loss: 0.018977

run [750]:
Style Loss : 0.310474 Content Loss: 0.019218

run [800]:
Style Loss : 0.303485 Content Loss: 0.019452

run [850]:
Style Loss : 0.296750 Content Loss: 0.019613

run [900]:
Style Loss : 0.289973 Content Loss: 0.019737

run [950]:
Style Loss : 0.284140 Content Loss: 0.019857

run [1000]:
Style Loss : 0.278653 Content Loss: 0.019971

run [1050]:
Style Loss : 0.272855 Content Loss: 0.020077

run [1100]:
Style Loss : 0.267908 Content Loss: 0.020156

run [1150]:
Style Loss : 0.263719 Content Loss: 0.020238

run [1200]:
Style Loss : 0.259733 Content Loss: 0.020318

run [1250]:
Style Loss : 0.256033 Content Loss: 0.020396

run [1300]:
Style Loss : 0.252244 Content Loss: 0.020480

run [1350]:
Style Loss : 0.248594 Content Loss: 0.020555

run [1400]:
Style Loss : 0.245298 Content Loss: 0.020636

run [1450]:
Style Loss : 0.241812 Content Loss: 0.020722

run [1500]:
Style Loss : 0.237916 Content Loss: 0.020810

run [1550]:
Style Loss : 0.233942 Content Loss: 0.020900

run [1600]:
Style Loss : 0.229545 Content Loss: 0.021001

run [1650]:
Style Loss : 0.224876 Content Loss: 0.021091

run [1700]:
Style Loss : 0.220195 Content Loss: 0.021178

run [1750]:
Style Loss : 0.216086 Content Loss: 0.021248

run [1800]:
Style Loss : 0.211975 Content Loss: 0.021326

run [1850]:
Style Loss : 0.208061 Content Loss: 0.021406

run [1900]:
Style Loss : 0.204060 Content Loss: 0.021485

run [1950]:
Style Loss : 0.199790 Content Loss: 0.021591

run [2000]:
Style Loss : 0.195402 Content Loss: 0.021675

run [2050]:
Style Loss : 0.190927 Content Loss: 0.021746

run [2100]:
Style Loss : 0.186623 Content Loss: 0.021792

run [2150]:
Style Loss : 0.182756 Content Loss: 0.021857

run [2200]:
Style Loss : 0.179143 Content Loss: 0.021918

run [2250]:
Style Loss : 0.175798 Content Loss: 0.021993

run [2300]:
Style Loss : 0.172382 Content Loss: 0.022060

run [2350]:
Style Loss : 0.168607 Content Loss: 0.022139

run [2400]:
Style Loss : 0.164532 Content Loss: 0.022222

run [2450]:
Style Loss : 0.160354 Content Loss: 0.022312

run [2500]:
Style Loss : 0.155921 Content Loss: 0.022381

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.888613 Content Loss: 0.003988

run [100]:
Style Loss : 2.411746 Content Loss: 0.006671

run [150]:
Style Loss : 1.844585 Content Loss: 0.008627

run [200]:
Style Loss : 1.534887 Content Loss: 0.009889

run [250]:
Style Loss : 1.313092 Content Loss: 0.010902

run [300]:
Style Loss : 1.150163 Content Loss: 0.011727

run [350]:
Style Loss : 1.034227 Content Loss: 0.012604

run [400]:
Style Loss : 0.955938 Content Loss: 0.013238

run [450]:
Style Loss : 0.899678 Content Loss: 0.014047

run [500]:
Style Loss : 0.854918 Content Loss: 0.014684

run [550]:
Style Loss : 0.824245 Content Loss: 0.015229

run [600]:
Style Loss : 0.794775 Content Loss: 0.015759

run [650]:
Style Loss : 0.771858 Content Loss: 0.016184

run [700]:
Style Loss : 0.755664 Content Loss: 0.016519

run [750]:
Style Loss : 0.743607 Content Loss: 0.016788

run [800]:
Style Loss : 0.731296 Content Loss: 0.017035

run [850]:
Style Loss : 0.720978 Content Loss: 0.017254

run [900]:
Style Loss : 0.711173 Content Loss: 0.017508

run [950]:
Style Loss : 0.701616 Content Loss: 0.017768

run [1000]:
Style Loss : 0.694280 Content Loss: 0.017971

run [1050]:
Style Loss : 0.687170 Content Loss: 0.018133

run [1100]:
Style Loss : 0.680070 Content Loss: 0.018320

run [1150]:
Style Loss : 0.673663 Content Loss: 0.018466

run [1200]:
Style Loss : 0.666416 Content Loss: 0.018632

run [1250]:
Style Loss : 0.660477 Content Loss: 0.018737

run [1300]:
Style Loss : 0.655197 Content Loss: 0.018844

run [1350]:
Style Loss : 0.649843 Content Loss: 0.018958

run [1400]:
Style Loss : 0.645534 Content Loss: 0.019052

run [1450]:
Style Loss : 0.641645 Content Loss: 0.019138

run [1500]:
Style Loss : 0.637552 Content Loss: 0.019246

run [1550]:
Style Loss : 0.633506 Content Loss: 0.019343

run [1600]:
Style Loss : 0.629431 Content Loss: 0.019435

run [1650]:
Style Loss : 0.625543 Content Loss: 0.019525

run [1700]:
Style Loss : 0.622053 Content Loss: 0.019602

run [1750]:
Style Loss : 0.618354 Content Loss: 0.019662

run [1800]:
Style Loss : 0.614736 Content Loss: 0.019733

run [1850]:
Style Loss : 0.611482 Content Loss: 0.019802

run [1900]:
Style Loss : 0.608939 Content Loss: 0.019860

run [1950]:
Style Loss : 0.606374 Content Loss: 0.019923

run [2000]:
Style Loss : 0.604042 Content Loss: 0.019983

run [2050]:
Style Loss : 0.601633 Content Loss: 0.020038

run [2100]:
Style Loss : 0.600739 Content Loss: 0.020124

run [2150]:
Style Loss : 0.599549 Content Loss: 0.020137

run [2200]:
Style Loss : 0.594873 Content Loss: 0.020177

run [2250]:
Style Loss : 0.593065 Content Loss: 0.020251

run [2300]:
Style Loss : 0.591089 Content Loss: 0.020283

run [2350]:
Style Loss : 0.588993 Content Loss: 0.020320

run [2400]:
Style Loss : 0.587252 Content Loss: 0.020359

run [2450]:
Style Loss : 0.585408 Content Loss: 0.020414

run [2500]:
Style Loss : 0.583788 Content Loss: 0.020459

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.085869 Content Loss: 0.003660

run [100]:
Style Loss : 0.890784 Content Loss: 0.005899

run [150]:
Style Loss : 0.561872 Content Loss: 0.007628

run [200]:
Style Loss : 0.420370 Content Loss: 0.008840

run [250]:
Style Loss : 0.333171 Content Loss: 0.009917

run [300]:
Style Loss : 0.280031 Content Loss: 0.010699

run [350]:
Style Loss : 0.242776 Content Loss: 0.011353

run [400]:
Style Loss : 0.211695 Content Loss: 0.011973

run [450]:
Style Loss : 0.187644 Content Loss: 0.012260

run [500]:
Style Loss : 0.169564 Content Loss: 0.012478

run [550]:
Style Loss : 0.155471 Content Loss: 0.012759

run [600]:
Style Loss : 0.143091 Content Loss: 0.012907

run [650]:
Style Loss : 0.132605 Content Loss: 0.012998

run [700]:
Style Loss : 0.123433 Content Loss: 0.013086

run [750]:
Style Loss : 0.116053 Content Loss: 0.013185

run [800]:
Style Loss : 0.109892 Content Loss: 0.013286

run [850]:
Style Loss : 0.104761 Content Loss: 0.013319

run [900]:
Style Loss : 0.100543 Content Loss: 0.013357

run [950]:
Style Loss : 0.096936 Content Loss: 0.013386

run [1000]:
Style Loss : 0.093815 Content Loss: 0.013428

run [1050]:
Style Loss : 0.091087 Content Loss: 0.013442

run [1100]:
Style Loss : 0.088665 Content Loss: 0.013431

run [1150]:
Style Loss : 0.086572 Content Loss: 0.013436

run [1200]:
Style Loss : 0.084685 Content Loss: 0.013428

run [1250]:
Style Loss : 0.082882 Content Loss: 0.013443

run [1300]:
Style Loss : 0.081226 Content Loss: 0.013443

run [1350]:
Style Loss : 0.079633 Content Loss: 0.013433

run [1400]:
Style Loss : 0.078155 Content Loss: 0.013418

run [1450]:
Style Loss : 0.076781 Content Loss: 0.013404

run [1500]:
Style Loss : 0.075544 Content Loss: 0.013388

run [1550]:
Style Loss : 0.074407 Content Loss: 0.013376

run [1600]:
Style Loss : 0.073237 Content Loss: 0.013367

run [1650]:
Style Loss : 0.072133 Content Loss: 0.013361

run [1700]:
Style Loss : 0.071135 Content Loss: 0.013356

run [1750]:
Style Loss : 0.070214 Content Loss: 0.013349

run [1800]:
Style Loss : 0.069119 Content Loss: 0.013339

run [1850]:
Style Loss : 0.067963 Content Loss: 0.013341

run [1900]:
Style Loss : 0.066824 Content Loss: 0.013350

run [1950]:
Style Loss : 0.065744 Content Loss: 0.013359

run [2000]:
Style Loss : 0.064722 Content Loss: 0.013365

run [2050]:
Style Loss : 0.063713 Content Loss: 0.013372

run [2100]:
Style Loss : 0.062645 Content Loss: 0.013386

run [2150]:
Style Loss : 0.061536 Content Loss: 0.013401

run [2200]:
Style Loss : 0.060468 Content Loss: 0.013410

run [2250]:
Style Loss : 0.059442 Content Loss: 0.013416

run [2300]:
Style Loss : 0.058552 Content Loss: 0.013417

run [2350]:
Style Loss : 0.057715 Content Loss: 0.013422

run [2400]:
Style Loss : 0.056898 Content Loss: 0.013431

run [2450]:
Style Loss : 0.056181 Content Loss: 0.013428

run [2500]:
Style Loss : 0.055519 Content Loss: 0.013418

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.758243 Content Loss: 0.006940

run [100]:
Style Loss : 0.975703 Content Loss: 0.010861

run [150]:
Style Loss : 0.742336 Content Loss: 0.012475

run [200]:
Style Loss : 0.616700 Content Loss: 0.013980

run [250]:
Style Loss : 0.542566 Content Loss: 0.015275

run [300]:
Style Loss : 0.493711 Content Loss: 0.016375

run [350]:
Style Loss : 0.460642 Content Loss: 0.017440

run [400]:
Style Loss : 0.437413 Content Loss: 0.018180

run [450]:
Style Loss : 0.419746 Content Loss: 0.018841

run [500]:
Style Loss : 0.406533 Content Loss: 0.019285

run [550]:
Style Loss : 0.395870 Content Loss: 0.019719

run [600]:
Style Loss : 0.387033 Content Loss: 0.019997

run [650]:
Style Loss : 0.379528 Content Loss: 0.020279

run [700]:
Style Loss : 0.372648 Content Loss: 0.020555

run [750]:
Style Loss : 0.366679 Content Loss: 0.020723

run [800]:
Style Loss : 0.361184 Content Loss: 0.020889

run [850]:
Style Loss : 0.355848 Content Loss: 0.021060

run [900]:
Style Loss : 0.350257 Content Loss: 0.021218

run [950]:
Style Loss : 0.345130 Content Loss: 0.021373

run [1000]:
Style Loss : 0.340599 Content Loss: 0.021504

run [1050]:
Style Loss : 0.336223 Content Loss: 0.021654

run [1100]:
Style Loss : 0.332118 Content Loss: 0.021799

run [1150]:
Style Loss : 0.328001 Content Loss: 0.021944

run [1200]:
Style Loss : 0.323892 Content Loss: 0.022061

run [1250]:
Style Loss : 0.319802 Content Loss: 0.022193

run [1300]:
Style Loss : 0.316125 Content Loss: 0.022304

run [1350]:
Style Loss : 0.312796 Content Loss: 0.022420

run [1400]:
Style Loss : 0.309623 Content Loss: 0.022533

run [1450]:
Style Loss : 0.306715 Content Loss: 0.022654

run [1500]:
Style Loss : 0.303642 Content Loss: 0.022781

run [1550]:
Style Loss : 0.300902 Content Loss: 0.022900

run [1600]:
Style Loss : 0.298558 Content Loss: 0.023019

run [1650]:
Style Loss : 0.296077 Content Loss: 0.023137

run [1700]:
Style Loss : 0.293711 Content Loss: 0.023255

run [1750]:
Style Loss : 0.291475 Content Loss: 0.023370

run [1800]:
Style Loss : 0.289089 Content Loss: 0.023510

run [1850]:
Style Loss : 0.286859 Content Loss: 0.023629

run [1900]:
Style Loss : 0.284739 Content Loss: 0.023747

run [1950]:
Style Loss : 0.282597 Content Loss: 0.023889

run [2000]:
Style Loss : 0.280507 Content Loss: 0.024028

run [2050]:
Style Loss : 0.278518 Content Loss: 0.024153

run [2100]:
Style Loss : 0.276565 Content Loss: 0.024303

run [2150]:
Style Loss : 0.274741 Content Loss: 0.024441

run [2200]:
Style Loss : 0.272900 Content Loss: 0.024576

run [2250]:
Style Loss : 0.271067 Content Loss: 0.024710

run [2300]:
Style Loss : 0.269080 Content Loss: 0.024839

run [2350]:
Style Loss : 0.267337 Content Loss: 0.024961

run [2400]:
Style Loss : 0.265587 Content Loss: 0.025057

run [2450]:
Style Loss : 0.264065 Content Loss: 0.025148

run [2500]:
Style Loss : 0.262776 Content Loss: 0.025259

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.431815 Content Loss: 0.007869

run [100]:
Style Loss : 0.756716 Content Loss: 0.011155

run [150]:
Style Loss : 0.527129 Content Loss: 0.012980

run [200]:
Style Loss : 0.428818 Content Loss: 0.014615

run [250]:
Style Loss : 0.368219 Content Loss: 0.015941

run [300]:
Style Loss : 0.326458 Content Loss: 0.017231

run [350]:
Style Loss : 0.296570 Content Loss: 0.018181

run [400]:
Style Loss : 0.274373 Content Loss: 0.018803

run [450]:
Style Loss : 0.258700 Content Loss: 0.019391

run [500]:
Style Loss : 0.246241 Content Loss: 0.019824

run [550]:
Style Loss : 0.236055 Content Loss: 0.020111

run [600]:
Style Loss : 0.228004 Content Loss: 0.020339

run [650]:
Style Loss : 0.220823 Content Loss: 0.020498

run [700]:
Style Loss : 0.214976 Content Loss: 0.020649

run [750]:
Style Loss : 0.209960 Content Loss: 0.020745

run [800]:
Style Loss : 0.205817 Content Loss: 0.020815

run [850]:
Style Loss : 0.202003 Content Loss: 0.020889

run [900]:
Style Loss : 0.198501 Content Loss: 0.020964

run [950]:
Style Loss : 0.195258 Content Loss: 0.021023

run [1000]:
Style Loss : 0.192277 Content Loss: 0.021078

run [1050]:
Style Loss : 0.189485 Content Loss: 0.021148

run [1100]:
Style Loss : 0.186947 Content Loss: 0.021211

run [1150]:
Style Loss : 0.184416 Content Loss: 0.021282

run [1200]:
Style Loss : 0.182075 Content Loss: 0.021363

run [1250]:
Style Loss : 0.179785 Content Loss: 0.021445

run [1300]:
Style Loss : 0.177683 Content Loss: 0.021509

run [1350]:
Style Loss : 0.175594 Content Loss: 0.021588

run [1400]:
Style Loss : 0.173482 Content Loss: 0.021685

run [1450]:
Style Loss : 0.171381 Content Loss: 0.021790

run [1500]:
Style Loss : 0.169431 Content Loss: 0.021920

run [1550]:
Style Loss : 0.167524 Content Loss: 0.022081

run [1600]:
Style Loss : 0.165671 Content Loss: 0.022239

run [1650]:
Style Loss : 0.163797 Content Loss: 0.022426

run [1700]:
Style Loss : 0.161981 Content Loss: 0.022576

run [1750]:
Style Loss : 0.160310 Content Loss: 0.022713

run [1800]:
Style Loss : 0.158777 Content Loss: 0.022894

run [1850]:
Style Loss : 0.157159 Content Loss: 0.023083

run [1900]:
Style Loss : 0.155719 Content Loss: 0.023301

run [1950]:
Style Loss : 0.153634 Content Loss: 0.023493

run [2000]:
Style Loss : 0.151365 Content Loss: 0.023667

run [2050]:
Style Loss : 0.149688 Content Loss: 0.023879

run [2100]:
Style Loss : 0.147783 Content Loss: 0.024077

run [2150]:
Style Loss : 0.145707 Content Loss: 0.024230

run [2200]:
Style Loss : 0.143928 Content Loss: 0.024402

run [2250]:
Style Loss : 0.142395 Content Loss: 0.024574

run [2300]:
Style Loss : 0.140998 Content Loss: 0.024744

run [2350]:
Style Loss : 0.139578 Content Loss: 0.024833

run [2400]:
Style Loss : 0.138815 Content Loss: 0.024970

run [2450]:
Style Loss : 0.137231 Content Loss: 0.025091

run [2500]:
Style Loss : 0.135886 Content Loss: 0.025195

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.788855 Content Loss: 0.009059

run [100]:
Style Loss : 0.435224 Content Loss: 0.012407

run [150]:
Style Loss : 0.325596 Content Loss: 0.014515

run [200]:
Style Loss : 0.279729 Content Loss: 0.015906

run [250]:
Style Loss : 0.254682 Content Loss: 0.016682

run [300]:
Style Loss : 0.238877 Content Loss: 0.017049

run [350]:
Style Loss : 0.228629 Content Loss: 0.017339

run [400]:
Style Loss : 0.220600 Content Loss: 0.017625

run [450]:
Style Loss : 0.214080 Content Loss: 0.017848

run [500]:
Style Loss : 0.209025 Content Loss: 0.018092

run [550]:
Style Loss : 0.204525 Content Loss: 0.018319

run [600]:
Style Loss : 0.198964 Content Loss: 0.018546

run [650]:
Style Loss : 0.194525 Content Loss: 0.018750

run [700]:
Style Loss : 0.190222 Content Loss: 0.018921

run [750]:
Style Loss : 0.187475 Content Loss: 0.019088

run [800]:
Style Loss : 0.184905 Content Loss: 0.019221

run [850]:
Style Loss : 0.182740 Content Loss: 0.019358

run [900]:
Style Loss : 0.180773 Content Loss: 0.019493

run [950]:
Style Loss : 0.178861 Content Loss: 0.019633

run [1000]:
Style Loss : 0.176986 Content Loss: 0.019774

run [1050]:
Style Loss : 0.175291 Content Loss: 0.019879

run [1100]:
Style Loss : 0.173878 Content Loss: 0.019976

run [1150]:
Style Loss : 0.172507 Content Loss: 0.020089

run [1200]:
Style Loss : 0.171256 Content Loss: 0.020190

run [1250]:
Style Loss : 0.170069 Content Loss: 0.020294

run [1300]:
Style Loss : 0.168920 Content Loss: 0.020390

run [1350]:
Style Loss : 0.167863 Content Loss: 0.020483

run [1400]:
Style Loss : 0.166902 Content Loss: 0.020572

run [1450]:
Style Loss : 0.166030 Content Loss: 0.020659

run [1500]:
Style Loss : 0.165233 Content Loss: 0.020736

run [1550]:
Style Loss : 0.164477 Content Loss: 0.020803

run [1600]:
Style Loss : 0.163728 Content Loss: 0.020864

run [1650]:
Style Loss : 0.163048 Content Loss: 0.020914

run [1700]:
Style Loss : 0.162319 Content Loss: 0.020966

run [1750]:
Style Loss : 0.161703 Content Loss: 0.021015

run [1800]:
Style Loss : 0.161159 Content Loss: 0.021059

run [1850]:
Style Loss : 0.160687 Content Loss: 0.021112

run [1900]:
Style Loss : 0.160171 Content Loss: 0.021166

run [1950]:
Style Loss : 0.159633 Content Loss: 0.021219

run [2000]:
Style Loss : 0.159044 Content Loss: 0.021275

run [2050]:
Style Loss : 0.158496 Content Loss: 0.021322

run [2100]:
Style Loss : 0.158046 Content Loss: 0.021366

run [2150]:
Style Loss : 0.157626 Content Loss: 0.021433

run [2200]:
Style Loss : 0.157280 Content Loss: 0.021494

run [2250]:
Style Loss : 0.156691 Content Loss: 0.021545

run [2300]:
Style Loss : 0.156235 Content Loss: 0.021597

run [2350]:
Style Loss : 0.155738 Content Loss: 0.021660

run [2400]:
Style Loss : 0.155287 Content Loss: 0.021709

run [2450]:
Style Loss : 0.154755 Content Loss: 0.021752

run [2500]:
Style Loss : 0.154310 Content Loss: 0.021811

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.253382 Content Loss: 0.008668

run [100]:
Style Loss : 0.676043 Content Loss: 0.011703

run [150]:
Style Loss : 0.501892 Content Loss: 0.013422

run [200]:
Style Loss : 0.409102 Content Loss: 0.015111

run [250]:
Style Loss : 0.353455 Content Loss: 0.016419

run [300]:
Style Loss : 0.318762 Content Loss: 0.017637

run [350]:
Style Loss : 0.295206 Content Loss: 0.018679

run [400]:
Style Loss : 0.279103 Content Loss: 0.019380

run [450]:
Style Loss : 0.267520 Content Loss: 0.019889

run [500]:
Style Loss : 0.258079 Content Loss: 0.020218

run [550]:
Style Loss : 0.251099 Content Loss: 0.020448

run [600]:
Style Loss : 0.244843 Content Loss: 0.020653

run [650]:
Style Loss : 0.239430 Content Loss: 0.020817

run [700]:
Style Loss : 0.234790 Content Loss: 0.020952

run [750]:
Style Loss : 0.230785 Content Loss: 0.021065

run [800]:
Style Loss : 0.227189 Content Loss: 0.021159

run [850]:
Style Loss : 0.224466 Content Loss: 0.021261

run [900]:
Style Loss : 0.221921 Content Loss: 0.021351

run [950]:
Style Loss : 0.219733 Content Loss: 0.021424

run [1000]:
Style Loss : 0.217795 Content Loss: 0.021489

run [1050]:
Style Loss : 0.215846 Content Loss: 0.021553

run [1100]:
Style Loss : 0.213503 Content Loss: 0.021633

run [1150]:
Style Loss : 0.211072 Content Loss: 0.021709

run [1200]:
Style Loss : 0.208987 Content Loss: 0.021783

run [1250]:
Style Loss : 0.207114 Content Loss: 0.021857

run [1300]:
Style Loss : 0.204835 Content Loss: 0.021942

run [1350]:
Style Loss : 0.202822 Content Loss: 0.022009

run [1400]:
Style Loss : 0.200759 Content Loss: 0.022100

run [1450]:
Style Loss : 0.198094 Content Loss: 0.022166

run [1500]:
Style Loss : 0.195958 Content Loss: 0.022230

run [1550]:
Style Loss : 0.194088 Content Loss: 0.022288

run [1600]:
Style Loss : 0.192418 Content Loss: 0.022343

run [1650]:
Style Loss : 0.190857 Content Loss: 0.022400

run [1700]:
Style Loss : 0.189067 Content Loss: 0.022466

run [1750]:
Style Loss : 0.187525 Content Loss: 0.022517

run [1800]:
Style Loss : 0.186139 Content Loss: 0.022566

run [1850]:
Style Loss : 0.184912 Content Loss: 0.022629

run [1900]:
Style Loss : 0.183787 Content Loss: 0.022687

run [1950]:
Style Loss : 0.182684 Content Loss: 0.022738

run [2000]:
Style Loss : 0.181623 Content Loss: 0.022795

run [2050]:
Style Loss : 0.180651 Content Loss: 0.022848

run [2100]:
Style Loss : 0.179713 Content Loss: 0.022915

run [2150]:
Style Loss : 0.178880 Content Loss: 0.022964

run [2200]:
Style Loss : 0.178068 Content Loss: 0.023004

run [2250]:
Style Loss : 0.177302 Content Loss: 0.023060

run [2300]:
Style Loss : 0.176547 Content Loss: 0.023112

run [2350]:
Style Loss : 0.175837 Content Loss: 0.023158

run [2400]:
Style Loss : 0.175149 Content Loss: 0.023220

run [2450]:
Style Loss : 0.174313 Content Loss: 0.023276

run [2500]:
Style Loss : 0.173582 Content Loss: 0.023336

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.472314 Content Loss: 0.003287

run [100]:
Style Loss : 1.556008 Content Loss: 0.007594

run [150]:
Style Loss : 1.038772 Content Loss: 0.009740

run [200]:
Style Loss : 0.817490 Content Loss: 0.011366

run [250]:
Style Loss : 0.703908 Content Loss: 0.012562

run [300]:
Style Loss : 0.631072 Content Loss: 0.013628

run [350]:
Style Loss : 0.573980 Content Loss: 0.014563

run [400]:
Style Loss : 0.531278 Content Loss: 0.015452

run [450]:
Style Loss : 0.498563 Content Loss: 0.016092

run [500]:
Style Loss : 0.473978 Content Loss: 0.016674

run [550]:
Style Loss : 0.454531 Content Loss: 0.017134

run [600]:
Style Loss : 0.438431 Content Loss: 0.017541

run [650]:
Style Loss : 0.425678 Content Loss: 0.017857

run [700]:
Style Loss : 0.414913 Content Loss: 0.018150

run [750]:
Style Loss : 0.405732 Content Loss: 0.018400

run [800]:
Style Loss : 0.398156 Content Loss: 0.018615

run [850]:
Style Loss : 0.391706 Content Loss: 0.018797

run [900]:
Style Loss : 0.385986 Content Loss: 0.018951

run [950]:
Style Loss : 0.380944 Content Loss: 0.019074

run [1000]:
Style Loss : 0.376544 Content Loss: 0.019184

run [1050]:
Style Loss : 0.372373 Content Loss: 0.019300

run [1100]:
Style Loss : 0.368597 Content Loss: 0.019375

run [1150]:
Style Loss : 0.365406 Content Loss: 0.019454

run [1200]:
Style Loss : 0.362595 Content Loss: 0.019515

run [1250]:
Style Loss : 0.359957 Content Loss: 0.019588

run [1300]:
Style Loss : 0.357515 Content Loss: 0.019641

run [1350]:
Style Loss : 0.355329 Content Loss: 0.019696

run [1400]:
Style Loss : 0.353248 Content Loss: 0.019748

run [1450]:
Style Loss : 0.351340 Content Loss: 0.019798

run [1500]:
Style Loss : 0.349439 Content Loss: 0.019848

run [1550]:
Style Loss : 0.347753 Content Loss: 0.019889

run [1600]:
Style Loss : 0.346271 Content Loss: 0.019927

run [1650]:
Style Loss : 0.344505 Content Loss: 0.019967

run [1700]:
Style Loss : 0.342960 Content Loss: 0.020005

run [1750]:
Style Loss : 0.341412 Content Loss: 0.020044

run [1800]:
Style Loss : 0.339859 Content Loss: 0.020080

run [1850]:
Style Loss : 0.338333 Content Loss: 0.020114

run [1900]:
Style Loss : 0.337013 Content Loss: 0.020153

run [1950]:
Style Loss : 0.335656 Content Loss: 0.020189

run [2000]:
Style Loss : 0.334394 Content Loss: 0.020225

run [2050]:
Style Loss : 0.333282 Content Loss: 0.020258

run [2100]:
Style Loss : 0.332198 Content Loss: 0.020295

run [2150]:
Style Loss : 0.330996 Content Loss: 0.020336

run [2200]:
Style Loss : 0.329895 Content Loss: 0.020375

run [2250]:
Style Loss : 0.328884 Content Loss: 0.020413

run [2300]:
Style Loss : 0.327928 Content Loss: 0.020446

run [2350]:
Style Loss : 0.327001 Content Loss: 0.020477

run [2400]:
Style Loss : 0.326093 Content Loss: 0.020512

run [2450]:
Style Loss : 0.325273 Content Loss: 0.020545

run [2500]:
Style Loss : 0.324492 Content Loss: 0.020577

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.614445 Content Loss: 0.009396

run [100]:
Style Loss : 0.328413 Content Loss: 0.013527

run [150]:
Style Loss : 0.234775 Content Loss: 0.015954

run [200]:
Style Loss : 0.187369 Content Loss: 0.017397

run [250]:
Style Loss : 0.160620 Content Loss: 0.018131

run [300]:
Style Loss : 0.146275 Content Loss: 0.018473

run [350]:
Style Loss : 0.137440 Content Loss: 0.018693

run [400]:
Style Loss : 0.130765 Content Loss: 0.018858

run [450]:
Style Loss : 0.125894 Content Loss: 0.018965

run [500]:
Style Loss : 0.122256 Content Loss: 0.019045

run [550]:
Style Loss : 0.119181 Content Loss: 0.019152

run [600]:
Style Loss : 0.116436 Content Loss: 0.019275

run [650]:
Style Loss : 0.113796 Content Loss: 0.019402

run [700]:
Style Loss : 0.108249 Content Loss: 0.019507

run [750]:
Style Loss : 0.105554 Content Loss: 0.019639

run [800]:
Style Loss : 0.103430 Content Loss: 0.019747

run [850]:
Style Loss : 0.101729 Content Loss: 0.019840

run [900]:
Style Loss : 0.100241 Content Loss: 0.019927

run [950]:
Style Loss : 0.098918 Content Loss: 0.019997

run [1000]:
Style Loss : 0.097710 Content Loss: 0.020056

run [1050]:
Style Loss : 0.096624 Content Loss: 0.020099

run [1100]:
Style Loss : 0.095712 Content Loss: 0.020142

run [1150]:
Style Loss : 0.094930 Content Loss: 0.020184

run [1200]:
Style Loss : 0.094205 Content Loss: 0.020220

run [1250]:
Style Loss : 0.093514 Content Loss: 0.020256

run [1300]:
Style Loss : 0.092905 Content Loss: 0.020286

run [1350]:
Style Loss : 0.092336 Content Loss: 0.020323

run [1400]:
Style Loss : 0.091727 Content Loss: 0.020356

run [1450]:
Style Loss : 0.091191 Content Loss: 0.020381

run [1500]:
Style Loss : 0.090719 Content Loss: 0.020402

run [1550]:
Style Loss : 0.090285 Content Loss: 0.020421

run [1600]:
Style Loss : 0.089891 Content Loss: 0.020437

run [1650]:
Style Loss : 0.089521 Content Loss: 0.020452

run [1700]:
Style Loss : 0.089153 Content Loss: 0.020457

run [1750]:
Style Loss : 0.088795 Content Loss: 0.020472

run [1800]:
Style Loss : 0.088483 Content Loss: 0.020484

run [1850]:
Style Loss : 0.088229 Content Loss: 0.020491

run [1900]:
Style Loss : 0.087966 Content Loss: 0.020496

run [1950]:
Style Loss : 0.086455 Content Loss: 0.020533

run [2000]:
Style Loss : 0.085736 Content Loss: 0.020538

run [2050]:
Style Loss : 0.085190 Content Loss: 0.020548

run [2100]:
Style Loss : 0.084757 Content Loss: 0.020560

run [2150]:
Style Loss : 0.084378 Content Loss: 0.020577

run [2200]:
Style Loss : 0.083798 Content Loss: 0.020597

run [2250]:
Style Loss : 0.083257 Content Loss: 0.020613

run [2300]:
Style Loss : 0.082803 Content Loss: 0.020624

run [2350]:
Style Loss : 0.082388 Content Loss: 0.020640

run [2400]:
Style Loss : 0.081952 Content Loss: 0.020658

run [2450]:
Style Loss : 0.081540 Content Loss: 0.020667

run [2500]:
Style Loss : 0.081195 Content Loss: 0.020672

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.794094 Content Loss: 0.007000

run [100]:
Style Loss : 0.966943 Content Loss: 0.010339

run [150]:
Style Loss : 0.702223 Content Loss: 0.012093

run [200]:
Style Loss : 0.578570 Content Loss: 0.013481

run [250]:
Style Loss : 0.509944 Content Loss: 0.014481

run [300]:
Style Loss : 0.467689 Content Loss: 0.015234

run [350]:
Style Loss : 0.439472 Content Loss: 0.015761

run [400]:
Style Loss : 0.418987 Content Loss: 0.016158

run [450]:
Style Loss : 0.400867 Content Loss: 0.016460

run [500]:
Style Loss : 0.385155 Content Loss: 0.016685

run [550]:
Style Loss : 0.372087 Content Loss: 0.016901

run [600]:
Style Loss : 0.359640 Content Loss: 0.017106

run [650]:
Style Loss : 0.348804 Content Loss: 0.017292

run [700]:
Style Loss : 0.339736 Content Loss: 0.017452

run [750]:
Style Loss : 0.331966 Content Loss: 0.017613

run [800]:
Style Loss : 0.325515 Content Loss: 0.017749

run [850]:
Style Loss : 0.320557 Content Loss: 0.017864

run [900]:
Style Loss : 0.316348 Content Loss: 0.017983

run [950]:
Style Loss : 0.312172 Content Loss: 0.018075

run [1000]:
Style Loss : 0.308349 Content Loss: 0.018162

run [1050]:
Style Loss : 0.305098 Content Loss: 0.018233

run [1100]:
Style Loss : 0.302289 Content Loss: 0.018300

run [1150]:
Style Loss : 0.299899 Content Loss: 0.018359

run [1200]:
Style Loss : 0.297955 Content Loss: 0.018403

run [1250]:
Style Loss : 0.296244 Content Loss: 0.018458

run [1300]:
Style Loss : 0.294667 Content Loss: 0.018510

run [1350]:
Style Loss : 0.293306 Content Loss: 0.018562

run [1400]:
Style Loss : 0.292074 Content Loss: 0.018613

run [1450]:
Style Loss : 0.290874 Content Loss: 0.018666

run [1500]:
Style Loss : 0.289762 Content Loss: 0.018720

run [1550]:
Style Loss : 0.288794 Content Loss: 0.018768

run [1600]:
Style Loss : 0.287829 Content Loss: 0.018815

run [1650]:
Style Loss : 0.286802 Content Loss: 0.018863

run [1700]:
Style Loss : 0.285800 Content Loss: 0.018912

run [1750]:
Style Loss : 0.284859 Content Loss: 0.018956

run [1800]:
Style Loss : 0.283966 Content Loss: 0.019005

run [1850]:
Style Loss : 0.283051 Content Loss: 0.019048

run [1900]:
Style Loss : 0.282272 Content Loss: 0.019080

run [1950]:
Style Loss : 0.281537 Content Loss: 0.019114

run [2000]:
Style Loss : 0.280852 Content Loss: 0.019146

run [2050]:
Style Loss : 0.280174 Content Loss: 0.019178

run [2100]:
Style Loss : 0.279458 Content Loss: 0.019215

run [2150]:
Style Loss : 0.278818 Content Loss: 0.019247

run [2200]:
Style Loss : 0.278240 Content Loss: 0.019275

run [2250]:
Style Loss : 0.277692 Content Loss: 0.019300

run [2300]:
Style Loss : 0.277146 Content Loss: 0.019325

run [2350]:
Style Loss : 0.276636 Content Loss: 0.019351

run [2400]:
Style Loss : 0.276101 Content Loss: 0.019372

run [2450]:
Style Loss : 0.275599 Content Loss: 0.019398

run [2500]:
Style Loss : 0.275122 Content Loss: 0.019418

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.283454 Content Loss: 0.002190

run [100]:
Style Loss : 0.787460 Content Loss: 0.003210

run [150]:
Style Loss : 0.626950 Content Loss: 0.004510

run [200]:
Style Loss : 0.535616 Content Loss: 0.005702

run [250]:
Style Loss : 0.482769 Content Loss: 0.006631

run [300]:
Style Loss : 0.448147 Content Loss: 0.007437

run [350]:
Style Loss : 0.421819 Content Loss: 0.008039

run [400]:
Style Loss : 0.401343 Content Loss: 0.008575

run [450]:
Style Loss : 0.383877 Content Loss: 0.009086

run [500]:
Style Loss : 0.369045 Content Loss: 0.009498

run [550]:
Style Loss : 0.355427 Content Loss: 0.009903

run [600]:
Style Loss : 0.343923 Content Loss: 0.010249

run [650]:
Style Loss : 0.333717 Content Loss: 0.010534

run [700]:
Style Loss : 0.324963 Content Loss: 0.010819

run [750]:
Style Loss : 0.317498 Content Loss: 0.011088

run [800]:
Style Loss : 0.310220 Content Loss: 0.011334

run [850]:
Style Loss : 0.304190 Content Loss: 0.011566

run [900]:
Style Loss : 0.299034 Content Loss: 0.011794

run [950]:
Style Loss : 0.294325 Content Loss: 0.011983

run [1000]:
Style Loss : 0.290089 Content Loss: 0.012159

run [1050]:
Style Loss : 0.286254 Content Loss: 0.012316

run [1100]:
Style Loss : 0.282649 Content Loss: 0.012468

run [1150]:
Style Loss : 0.279582 Content Loss: 0.012604

run [1200]:
Style Loss : 0.276701 Content Loss: 0.012717

run [1250]:
Style Loss : 0.273976 Content Loss: 0.012843

run [1300]:
Style Loss : 0.271436 Content Loss: 0.012953

run [1350]:
Style Loss : 0.268757 Content Loss: 0.013041

run [1400]:
Style Loss : 0.266432 Content Loss: 0.013133

run [1450]:
Style Loss : 0.264287 Content Loss: 0.013216

run [1500]:
Style Loss : 0.262224 Content Loss: 0.013306

run [1550]:
Style Loss : 0.260433 Content Loss: 0.013385

run [1600]:
Style Loss : 0.258790 Content Loss: 0.013461

run [1650]:
Style Loss : 0.257084 Content Loss: 0.013537

run [1700]:
Style Loss : 0.255271 Content Loss: 0.013616

run [1750]:
Style Loss : 0.253476 Content Loss: 0.013678

run [1800]:
Style Loss : 0.251913 Content Loss: 0.013737

run [1850]:
Style Loss : 0.250474 Content Loss: 0.013800

run [1900]:
Style Loss : 0.248989 Content Loss: 0.013853

run [1950]:
Style Loss : 0.247647 Content Loss: 0.013899

run [2000]:
Style Loss : 0.246433 Content Loss: 0.013948

run [2050]:
Style Loss : 0.245392 Content Loss: 0.013988

run [2100]:
Style Loss : 0.244477 Content Loss: 0.014023

run [2150]:
Style Loss : 0.243560 Content Loss: 0.014069

run [2200]:
Style Loss : 0.242710 Content Loss: 0.014106

run [2250]:
Style Loss : 0.241903 Content Loss: 0.014143

run [2300]:
Style Loss : 0.241143 Content Loss: 0.014179

run [2350]:
Style Loss : 0.240386 Content Loss: 0.014223

run [2400]:
Style Loss : 0.239671 Content Loss: 0.014260

run [2450]:
Style Loss : 0.238952 Content Loss: 0.014302

run [2500]:
Style Loss : 0.238203 Content Loss: 0.014341

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.296360 Content Loss: 0.001861

run [100]:
Style Loss : 0.664624 Content Loss: 0.003095

run [150]:
Style Loss : 0.486451 Content Loss: 0.004363

run [200]:
Style Loss : 0.386539 Content Loss: 0.005513

run [250]:
Style Loss : 0.325801 Content Loss: 0.006464

run [300]:
Style Loss : 0.284925 Content Loss: 0.007379

run [350]:
Style Loss : 0.253558 Content Loss: 0.008227

run [400]:
Style Loss : 0.229849 Content Loss: 0.008952

run [450]:
Style Loss : 0.212209 Content Loss: 0.009518

run [500]:
Style Loss : 0.198162 Content Loss: 0.010139

run [550]:
Style Loss : 0.187344 Content Loss: 0.010584

run [600]:
Style Loss : 0.178249 Content Loss: 0.010991

run [650]:
Style Loss : 0.170696 Content Loss: 0.011314

run [700]:
Style Loss : 0.163716 Content Loss: 0.011637

run [750]:
Style Loss : 0.157349 Content Loss: 0.011867

run [800]:
Style Loss : 0.151908 Content Loss: 0.012094

run [850]:
Style Loss : 0.147357 Content Loss: 0.012277

run [900]:
Style Loss : 0.143447 Content Loss: 0.012470

run [950]:
Style Loss : 0.140045 Content Loss: 0.012663

run [1000]:
Style Loss : 0.136994 Content Loss: 0.012822

run [1050]:
Style Loss : 0.134183 Content Loss: 0.013000

run [1100]:
Style Loss : 0.131548 Content Loss: 0.013162

run [1150]:
Style Loss : 0.129269 Content Loss: 0.013317

run [1200]:
Style Loss : 0.127130 Content Loss: 0.013471

run [1250]:
Style Loss : 0.124935 Content Loss: 0.013618

run [1300]:
Style Loss : 0.122809 Content Loss: 0.013784

run [1350]:
Style Loss : 0.120766 Content Loss: 0.013958

run [1400]:
Style Loss : 0.118990 Content Loss: 0.014109

run [1450]:
Style Loss : 0.117365 Content Loss: 0.014274

run [1500]:
Style Loss : 0.115930 Content Loss: 0.014409

run [1550]:
Style Loss : 0.114636 Content Loss: 0.014550

run [1600]:
Style Loss : 0.113374 Content Loss: 0.014664

run [1650]:
Style Loss : 0.112151 Content Loss: 0.014782

run [1700]:
Style Loss : 0.110985 Content Loss: 0.014903

run [1750]:
Style Loss : 0.109827 Content Loss: 0.015017

run [1800]:
Style Loss : 0.108640 Content Loss: 0.015124

run [1850]:
Style Loss : 0.107571 Content Loss: 0.015210

run [1900]:
Style Loss : 0.106584 Content Loss: 0.015306

run [1950]:
Style Loss : 0.105644 Content Loss: 0.015375

run [2000]:
Style Loss : 0.104835 Content Loss: 0.015445

run [2050]:
Style Loss : 0.104044 Content Loss: 0.015508

run [2100]:
Style Loss : 0.103376 Content Loss: 0.015569

run [2150]:
Style Loss : 0.102791 Content Loss: 0.015624

run [2200]:
Style Loss : 0.102194 Content Loss: 0.015687

run [2250]:
Style Loss : 0.101633 Content Loss: 0.015749

run [2300]:
Style Loss : 0.101102 Content Loss: 0.015795

run [2350]:
Style Loss : 0.100647 Content Loss: 0.015848

run [2400]:
Style Loss : 0.100172 Content Loss: 0.015897

run [2450]:
Style Loss : 0.099721 Content Loss: 0.015942

run [2500]:
Style Loss : 0.099299 Content Loss: 0.015988

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.115282 Content Loss: 0.002400

run [100]:
Style Loss : 1.093259 Content Loss: 0.003611

run [150]:
Style Loss : 0.733025 Content Loss: 0.004742

run [200]:
Style Loss : 0.590329 Content Loss: 0.005518

run [250]:
Style Loss : 0.507205 Content Loss: 0.006377

run [300]:
Style Loss : 0.456621 Content Loss: 0.006916

run [350]:
Style Loss : 0.423575 Content Loss: 0.007426

run [400]:
Style Loss : 0.398720 Content Loss: 0.007864

run [450]:
Style Loss : 0.379398 Content Loss: 0.008230

run [500]:
Style Loss : 0.364629 Content Loss: 0.008555

run [550]:
Style Loss : 0.352679 Content Loss: 0.008792

run [600]:
Style Loss : 0.342483 Content Loss: 0.009016

run [650]:
Style Loss : 0.333323 Content Loss: 0.009217

run [700]:
Style Loss : 0.321595 Content Loss: 0.009388

run [750]:
Style Loss : 0.311604 Content Loss: 0.009551

run [800]:
Style Loss : 0.301832 Content Loss: 0.009713

run [850]:
Style Loss : 0.293748 Content Loss: 0.009859

run [900]:
Style Loss : 0.286987 Content Loss: 0.010009

run [950]:
Style Loss : 0.281122 Content Loss: 0.010126

run [1000]:
Style Loss : 0.276111 Content Loss: 0.010238

run [1050]:
Style Loss : 0.271586 Content Loss: 0.010363

run [1100]:
Style Loss : 0.267312 Content Loss: 0.010488

run [1150]:
Style Loss : 0.263296 Content Loss: 0.010606

run [1200]:
Style Loss : 0.259740 Content Loss: 0.010723

run [1250]:
Style Loss : 0.255645 Content Loss: 0.010851

run [1300]:
Style Loss : 0.251583 Content Loss: 0.010957

run [1350]:
Style Loss : 0.247742 Content Loss: 0.011084

run [1400]:
Style Loss : 0.243984 Content Loss: 0.011209

run [1450]:
Style Loss : 0.239650 Content Loss: 0.011309

run [1500]:
Style Loss : 0.236412 Content Loss: 0.011400

run [1550]:
Style Loss : 0.233712 Content Loss: 0.011481

run [1600]:
Style Loss : 0.231342 Content Loss: 0.011562

run [1650]:
Style Loss : 0.229381 Content Loss: 0.011643

run [1700]:
Style Loss : 0.227484 Content Loss: 0.011723

run [1750]:
Style Loss : 0.225604 Content Loss: 0.011801

run [1800]:
Style Loss : 0.223817 Content Loss: 0.011874

run [1850]:
Style Loss : 0.222120 Content Loss: 0.011952

run [1900]:
Style Loss : 0.220353 Content Loss: 0.012027

run [1950]:
Style Loss : 0.218521 Content Loss: 0.012097

run [2000]:
Style Loss : 0.216893 Content Loss: 0.012168

run [2050]:
Style Loss : 0.215346 Content Loss: 0.012239

run [2100]:
Style Loss : 0.213842 Content Loss: 0.012305

run [2150]:
Style Loss : 0.212400 Content Loss: 0.012376

run [2200]:
Style Loss : 0.210915 Content Loss: 0.012444

run [2250]:
Style Loss : 0.209622 Content Loss: 0.012506

run [2300]:
Style Loss : 0.208306 Content Loss: 0.012578

run [2350]:
Style Loss : 0.206965 Content Loss: 0.012650

run [2400]:
Style Loss : 0.205562 Content Loss: 0.012724

run [2450]:
Style Loss : 0.204203 Content Loss: 0.012797

run [2500]:
Style Loss : 0.202837 Content Loss: 0.012866

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.715757 Content Loss: 0.002985

run [100]:
Style Loss : 0.406391 Content Loss: 0.004611

run [150]:
Style Loss : 0.309400 Content Loss: 0.005775

run [200]:
Style Loss : 0.259431 Content Loss: 0.006813

run [250]:
Style Loss : 0.228436 Content Loss: 0.007542

run [300]:
Style Loss : 0.208311 Content Loss: 0.008175

run [350]:
Style Loss : 0.194572 Content Loss: 0.008713

run [400]:
Style Loss : 0.183092 Content Loss: 0.009164

run [450]:
Style Loss : 0.174234 Content Loss: 0.009563

run [500]:
Style Loss : 0.165481 Content Loss: 0.009978

run [550]:
Style Loss : 0.157488 Content Loss: 0.010306

run [600]:
Style Loss : 0.151194 Content Loss: 0.010670

run [650]:
Style Loss : 0.146046 Content Loss: 0.010988

run [700]:
Style Loss : 0.141721 Content Loss: 0.011241

run [750]:
Style Loss : 0.138319 Content Loss: 0.011504

run [800]:
Style Loss : 0.135189 Content Loss: 0.011781

run [850]:
Style Loss : 0.132481 Content Loss: 0.012007

run [900]:
Style Loss : 0.130334 Content Loss: 0.012202

run [950]:
Style Loss : 0.128538 Content Loss: 0.012395

run [1000]:
Style Loss : 0.126744 Content Loss: 0.012553

run [1050]:
Style Loss : 0.125076 Content Loss: 0.012717

run [1100]:
Style Loss : 0.123658 Content Loss: 0.012855

run [1150]:
Style Loss : 0.122322 Content Loss: 0.012980

run [1200]:
Style Loss : 0.120705 Content Loss: 0.013105

run [1250]:
Style Loss : 0.119319 Content Loss: 0.013240

run [1300]:
Style Loss : 0.118133 Content Loss: 0.013343

run [1350]:
Style Loss : 0.117100 Content Loss: 0.013442

run [1400]:
Style Loss : 0.115979 Content Loss: 0.013517

run [1450]:
Style Loss : 0.114992 Content Loss: 0.013594

run [1500]:
Style Loss : 0.114107 Content Loss: 0.013669

run [1550]:
Style Loss : 0.113312 Content Loss: 0.013715

run [1600]:
Style Loss : 0.112680 Content Loss: 0.013798

run [1650]:
Style Loss : 0.111628 Content Loss: 0.013811

run [1700]:
Style Loss : 0.110739 Content Loss: 0.013842

run [1750]:
Style Loss : 0.110068 Content Loss: 0.013892

run [1800]:
Style Loss : 0.109541 Content Loss: 0.013952

run [1850]:
Style Loss : 0.108956 Content Loss: 0.013988

run [1900]:
Style Loss : 0.108412 Content Loss: 0.014020

run [1950]:
Style Loss : 0.107954 Content Loss: 0.014054

run [2000]:
Style Loss : 0.107509 Content Loss: 0.014079

run [2050]:
Style Loss : 0.107038 Content Loss: 0.014103

run [2100]:
Style Loss : 0.107978 Content Loss: 0.014179

run [2150]:
Style Loss : 0.106299 Content Loss: 0.014143

run [2200]:
Style Loss : 0.106278 Content Loss: 0.014231

run [2250]:
Style Loss : 0.105606 Content Loss: 0.014186

run [2300]:
Style Loss : 0.105381 Content Loss: 0.014204

run [2350]:
Style Loss : 0.105156 Content Loss: 0.014212

run [2400]:
Style Loss : 0.104936 Content Loss: 0.014227

run [2450]:
Style Loss : 0.104708 Content Loss: 0.014242

run [2500]:
Style Loss : 0.105928 Content Loss: 0.014270

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.635234 Content Loss: 0.003661

run [100]:
Style Loss : 0.321046 Content Loss: 0.006085

run [150]:
Style Loss : 0.243005 Content Loss: 0.008652

run [200]:
Style Loss : 0.203681 Content Loss: 0.010520

run [250]:
Style Loss : 0.178823 Content Loss: 0.012155

run [300]:
Style Loss : 0.162194 Content Loss: 0.013349

run [350]:
Style Loss : 0.151148 Content Loss: 0.014398

run [400]:
Style Loss : 0.142353 Content Loss: 0.015266

run [450]:
Style Loss : 0.136065 Content Loss: 0.015891

run [500]:
Style Loss : 0.130676 Content Loss: 0.016286

run [550]:
Style Loss : 0.126688 Content Loss: 0.016668

run [600]:
Style Loss : 0.123838 Content Loss: 0.016918

run [650]:
Style Loss : 0.121238 Content Loss: 0.017141

run [700]:
Style Loss : 0.119120 Content Loss: 0.017308

run [750]:
Style Loss : 0.117174 Content Loss: 0.017441

run [800]:
Style Loss : 0.115465 Content Loss: 0.017564

run [850]:
Style Loss : 0.114015 Content Loss: 0.017645

run [900]:
Style Loss : 0.112650 Content Loss: 0.017740

run [950]:
Style Loss : 0.111569 Content Loss: 0.017844

run [1000]:
Style Loss : 0.110413 Content Loss: 0.017910

run [1050]:
Style Loss : 0.109292 Content Loss: 0.017975

run [1100]:
Style Loss : 0.108319 Content Loss: 0.018045

run [1150]:
Style Loss : 0.107495 Content Loss: 0.018090

run [1200]:
Style Loss : 0.106799 Content Loss: 0.018122

run [1250]:
Style Loss : 0.106204 Content Loss: 0.018156

run [1300]:
Style Loss : 0.105612 Content Loss: 0.018207

run [1350]:
Style Loss : 0.105116 Content Loss: 0.018232

run [1400]:
Style Loss : 0.104635 Content Loss: 0.018263

run [1450]:
Style Loss : 0.104191 Content Loss: 0.018304

run [1500]:
Style Loss : 0.103767 Content Loss: 0.018346

run [1550]:
Style Loss : 0.103354 Content Loss: 0.018369

run [1600]:
Style Loss : 0.102980 Content Loss: 0.018418

run [1650]:
Style Loss : 0.102682 Content Loss: 0.018447

run [1700]:
Style Loss : 0.102639 Content Loss: 0.018470

run [1750]:
Style Loss : 0.102265 Content Loss: 0.018499

run [1800]:
Style Loss : 0.101798 Content Loss: 0.018518

run [1850]:
Style Loss : 0.101460 Content Loss: 0.018543

run [1900]:
Style Loss : 0.101145 Content Loss: 0.018583

run [1950]:
Style Loss : 0.100888 Content Loss: 0.018626

run [2000]:
Style Loss : 0.100654 Content Loss: 0.018671

run [2050]:
Style Loss : 0.100408 Content Loss: 0.018732

run [2100]:
Style Loss : 0.100146 Content Loss: 0.018779

run [2150]:
Style Loss : 0.102295 Content Loss: 0.019132

run [2200]:
Style Loss : 0.099222 Content Loss: 0.019129

run [2250]:
Style Loss : 0.098144 Content Loss: 0.019135

run [2300]:
Style Loss : 0.097592 Content Loss: 0.019172

run [2350]:
Style Loss : 0.097170 Content Loss: 0.019204

run [2400]:
Style Loss : 0.096763 Content Loss: 0.019250

run [2450]:
Style Loss : 0.096415 Content Loss: 0.019308

run [2500]:
Style Loss : 0.096142 Content Loss: 0.019351

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.946814 Content Loss: 0.011750

run [100]:
Style Loss : 1.081115 Content Loss: 0.014501

run [150]:
Style Loss : 0.824302 Content Loss: 0.016566

run [200]:
Style Loss : 0.702900 Content Loss: 0.018307

run [250]:
Style Loss : 0.626725 Content Loss: 0.019663

run [300]:
Style Loss : 0.572265 Content Loss: 0.020719

run [350]:
Style Loss : 0.534135 Content Loss: 0.021596

run [400]:
Style Loss : 0.506164 Content Loss: 0.022315

run [450]:
Style Loss : 0.484920 Content Loss: 0.022999

run [500]:
Style Loss : 0.467524 Content Loss: 0.023582

run [550]:
Style Loss : 0.453725 Content Loss: 0.024105

run [600]:
Style Loss : 0.442300 Content Loss: 0.024583

run [650]:
Style Loss : 0.432280 Content Loss: 0.024957

run [700]:
Style Loss : 0.423157 Content Loss: 0.025339

run [750]:
Style Loss : 0.415056 Content Loss: 0.025688

run [800]:
Style Loss : 0.406978 Content Loss: 0.026027

run [850]:
Style Loss : 0.399837 Content Loss: 0.026324

run [900]:
Style Loss : 0.393888 Content Loss: 0.026597

run [950]:
Style Loss : 0.388455 Content Loss: 0.026858

run [1000]:
Style Loss : 0.383694 Content Loss: 0.027116

run [1050]:
Style Loss : 0.379216 Content Loss: 0.027376

run [1100]:
Style Loss : 0.375004 Content Loss: 0.027608

run [1150]:
Style Loss : 0.370989 Content Loss: 0.027835

run [1200]:
Style Loss : 0.367285 Content Loss: 0.028079

run [1250]:
Style Loss : 0.363850 Content Loss: 0.028266

run [1300]:
Style Loss : 0.360719 Content Loss: 0.028447

run [1350]:
Style Loss : 0.357480 Content Loss: 0.028643

run [1400]:
Style Loss : 0.354922 Content Loss: 0.028763

run [1450]:
Style Loss : 0.352516 Content Loss: 0.028896

run [1500]:
Style Loss : 0.350183 Content Loss: 0.028990

run [1550]:
Style Loss : 0.348178 Content Loss: 0.029090

run [1600]:
Style Loss : 0.346294 Content Loss: 0.029178

run [1650]:
Style Loss : 0.344428 Content Loss: 0.029270

run [1700]:
Style Loss : 0.342699 Content Loss: 0.029373

run [1750]:
Style Loss : 0.341128 Content Loss: 0.029463

run [1800]:
Style Loss : 0.339465 Content Loss: 0.029542

run [1850]:
Style Loss : 0.337964 Content Loss: 0.029672

run [1900]:
Style Loss : 0.336295 Content Loss: 0.029752

run [1950]:
Style Loss : 0.334843 Content Loss: 0.029821

run [2000]:
Style Loss : 0.333583 Content Loss: 0.029864

run [2050]:
Style Loss : 0.332369 Content Loss: 0.029929

run [2100]:
Style Loss : 0.331269 Content Loss: 0.030006

run [2150]:
Style Loss : 0.330160 Content Loss: 0.030044

run [2200]:
Style Loss : 0.329093 Content Loss: 0.030065

run [2250]:
Style Loss : 0.328154 Content Loss: 0.030126

run [2300]:
Style Loss : 0.327057 Content Loss: 0.030167

run [2350]:
Style Loss : 0.326015 Content Loss: 0.030185

run [2400]:
Style Loss : 0.325110 Content Loss: 0.030229

run [2450]:
Style Loss : 0.324124 Content Loss: 0.030245

run [2500]:
Style Loss : 0.323380 Content Loss: 0.030243

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.365782 Content Loss: 0.001798

run [100]:
Style Loss : 0.780305 Content Loss: 0.003399

run [150]:
Style Loss : 0.569189 Content Loss: 0.005070

run [200]:
Style Loss : 0.467112 Content Loss: 0.006336

run [250]:
Style Loss : 0.403763 Content Loss: 0.007624

run [300]:
Style Loss : 0.353813 Content Loss: 0.008810

run [350]:
Style Loss : 0.316338 Content Loss: 0.009756

run [400]:
Style Loss : 0.288225 Content Loss: 0.010592

run [450]:
Style Loss : 0.269004 Content Loss: 0.011244

run [500]:
Style Loss : 0.254154 Content Loss: 0.011816

run [550]:
Style Loss : 0.241970 Content Loss: 0.012260

run [600]:
Style Loss : 0.232522 Content Loss: 0.012610

run [650]:
Style Loss : 0.224709 Content Loss: 0.012889

run [700]:
Style Loss : 0.217689 Content Loss: 0.013112

run [750]:
Style Loss : 0.211793 Content Loss: 0.013273

run [800]:
Style Loss : 0.206641 Content Loss: 0.013466

run [850]:
Style Loss : 0.202220 Content Loss: 0.013633

run [900]:
Style Loss : 0.198280 Content Loss: 0.013782

run [950]:
Style Loss : 0.194723 Content Loss: 0.013948

run [1000]:
Style Loss : 0.191628 Content Loss: 0.014103

run [1050]:
Style Loss : 0.188325 Content Loss: 0.014265

run [1100]:
Style Loss : 0.185379 Content Loss: 0.014422

run [1150]:
Style Loss : 0.182456 Content Loss: 0.014578

run [1200]:
Style Loss : 0.179529 Content Loss: 0.014732

run [1250]:
Style Loss : 0.176936 Content Loss: 0.014869

run [1300]:
Style Loss : 0.174782 Content Loss: 0.015016

run [1350]:
Style Loss : 0.172781 Content Loss: 0.015177

run [1400]:
Style Loss : 0.170795 Content Loss: 0.015345

run [1450]:
Style Loss : 0.169071 Content Loss: 0.015499

run [1500]:
Style Loss : 0.167354 Content Loss: 0.015650

run [1550]:
Style Loss : 0.165592 Content Loss: 0.015793

run [1600]:
Style Loss : 0.163995 Content Loss: 0.015925

run [1650]:
Style Loss : 0.162141 Content Loss: 0.016066

run [1700]:
Style Loss : 0.160373 Content Loss: 0.016185

run [1750]:
Style Loss : 0.158875 Content Loss: 0.016275

run [1800]:
Style Loss : 0.157520 Content Loss: 0.016382

run [1850]:
Style Loss : 0.156187 Content Loss: 0.016478

run [1900]:
Style Loss : 0.155041 Content Loss: 0.016594

run [1950]:
Style Loss : 0.153778 Content Loss: 0.016672

run [2000]:
Style Loss : 0.152717 Content Loss: 0.016758

run [2050]:
Style Loss : 0.152823 Content Loss: 0.016865

run [2100]:
Style Loss : 0.150834 Content Loss: 0.016961

run [2150]:
Style Loss : 0.149862 Content Loss: 0.017045

run [2200]:
Style Loss : 0.148992 Content Loss: 0.017132

run [2250]:
Style Loss : 0.148025 Content Loss: 0.017206

run [2300]:
Style Loss : 0.147257 Content Loss: 0.017311

run [2350]:
Style Loss : 0.146612 Content Loss: 0.017421

run [2400]:
Style Loss : 0.145940 Content Loss: 0.017548

run [2450]:
Style Loss : 0.149065 Content Loss: 0.017926

run [2500]:
Style Loss : 0.144132 Content Loss: 0.017815

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.093016 Content Loss: 0.002225

run [100]:
Style Loss : 0.616463 Content Loss: 0.004839

run [150]:
Style Loss : 0.413113 Content Loss: 0.007203

run [200]:
Style Loss : 0.316535 Content Loss: 0.009540

run [250]:
Style Loss : 0.265572 Content Loss: 0.011560

run [300]:
Style Loss : 0.232079 Content Loss: 0.012750

run [350]:
Style Loss : 0.210024 Content Loss: 0.013526

run [400]:
Style Loss : 0.194251 Content Loss: 0.014036

run [450]:
Style Loss : 0.182788 Content Loss: 0.014418

run [500]:
Style Loss : 0.174194 Content Loss: 0.014649

run [550]:
Style Loss : 0.167911 Content Loss: 0.014847

run [600]:
Style Loss : 0.161898 Content Loss: 0.015070

run [650]:
Style Loss : 0.157186 Content Loss: 0.015258

run [700]:
Style Loss : 0.152792 Content Loss: 0.015419

run [750]:
Style Loss : 0.148901 Content Loss: 0.015585

run [800]:
Style Loss : 0.145435 Content Loss: 0.015728

run [850]:
Style Loss : 0.141718 Content Loss: 0.015871

run [900]:
Style Loss : 0.137823 Content Loss: 0.016027

run [950]:
Style Loss : 0.133729 Content Loss: 0.016158

run [1000]:
Style Loss : 0.130224 Content Loss: 0.016280

run [1050]:
Style Loss : 0.127598 Content Loss: 0.016396

run [1100]:
Style Loss : 0.125474 Content Loss: 0.016506

run [1150]:
Style Loss : 0.123445 Content Loss: 0.016609

run [1200]:
Style Loss : 0.121574 Content Loss: 0.016713

run [1250]:
Style Loss : 0.119797 Content Loss: 0.016809

run [1300]:
Style Loss : 0.118199 Content Loss: 0.016900

run [1350]:
Style Loss : 0.116752 Content Loss: 0.016975

run [1400]:
Style Loss : 0.115324 Content Loss: 0.017056

run [1450]:
Style Loss : 0.114059 Content Loss: 0.017116

run [1500]:
Style Loss : 0.112966 Content Loss: 0.017172

run [1550]:
Style Loss : 0.111909 Content Loss: 0.017222

run [1600]:
Style Loss : 0.110856 Content Loss: 0.017272

run [1650]:
Style Loss : 0.109897 Content Loss: 0.017311

run [1700]:
Style Loss : 0.109014 Content Loss: 0.017353

run [1750]:
Style Loss : 0.108205 Content Loss: 0.017400

run [1800]:
Style Loss : 0.107299 Content Loss: 0.017444

run [1850]:
Style Loss : 0.106508 Content Loss: 0.017484

run [1900]:
Style Loss : 0.105808 Content Loss: 0.017527

run [1950]:
Style Loss : 0.105144 Content Loss: 0.017561

run [2000]:
Style Loss : 0.104483 Content Loss: 0.017592

run [2050]:
Style Loss : 0.103816 Content Loss: 0.017614

run [2100]:
Style Loss : 0.103083 Content Loss: 0.017633

run [2150]:
Style Loss : 0.102463 Content Loss: 0.017646

run [2200]:
Style Loss : 0.101808 Content Loss: 0.017665

run [2250]:
Style Loss : 0.100943 Content Loss: 0.017684

run [2300]:
Style Loss : 0.100297 Content Loss: 0.017696

run [2350]:
Style Loss : 0.099688 Content Loss: 0.017715

run [2400]:
Style Loss : 0.099130 Content Loss: 0.017733

run [2450]:
Style Loss : 0.098658 Content Loss: 0.017750

run [2500]:
Style Loss : 0.098249 Content Loss: 0.017758

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.393386 Content Loss: 0.002151

run [100]:
Style Loss : 0.645204 Content Loss: 0.003430

run [150]:
Style Loss : 0.412520 Content Loss: 0.004599

run [200]:
Style Loss : 0.314156 Content Loss: 0.005545

run [250]:
Style Loss : 0.248986 Content Loss: 0.006431

run [300]:
Style Loss : 0.207698 Content Loss: 0.007165

run [350]:
Style Loss : 0.178698 Content Loss: 0.007789

run [400]:
Style Loss : 0.158198 Content Loss: 0.008425

run [450]:
Style Loss : 0.143619 Content Loss: 0.008929

run [500]:
Style Loss : 0.131598 Content Loss: 0.009342

run [550]:
Style Loss : 0.121343 Content Loss: 0.009726

run [600]:
Style Loss : 0.113826 Content Loss: 0.010055

run [650]:
Style Loss : 0.108629 Content Loss: 0.010355

run [700]:
Style Loss : 0.104704 Content Loss: 0.010563

run [750]:
Style Loss : 0.101727 Content Loss: 0.010701

run [800]:
Style Loss : 0.099385 Content Loss: 0.010809

run [850]:
Style Loss : 0.097314 Content Loss: 0.010889

run [900]:
Style Loss : 0.095530 Content Loss: 0.010960

run [950]:
Style Loss : 0.093969 Content Loss: 0.011033

run [1000]:
Style Loss : 0.092529 Content Loss: 0.011109

run [1050]:
Style Loss : 0.091138 Content Loss: 0.011207

run [1100]:
Style Loss : 0.089655 Content Loss: 0.011284

run [1150]:
Style Loss : 0.088403 Content Loss: 0.011362

run [1200]:
Style Loss : 0.086140 Content Loss: 0.011433

run [1250]:
Style Loss : 0.084699 Content Loss: 0.011509

run [1300]:
Style Loss : 0.083601 Content Loss: 0.011588

run [1350]:
Style Loss : 0.082667 Content Loss: 0.011660

run [1400]:
Style Loss : 0.081873 Content Loss: 0.011736

run [1450]:
Style Loss : 0.081147 Content Loss: 0.011815

run [1500]:
Style Loss : 0.080452 Content Loss: 0.011902

run [1550]:
Style Loss : 0.079809 Content Loss: 0.011991

run [1600]:
Style Loss : 0.079224 Content Loss: 0.012071

run [1650]:
Style Loss : 0.078651 Content Loss: 0.012154

run [1700]:
Style Loss : 0.078135 Content Loss: 0.012239

run [1750]:
Style Loss : 0.077616 Content Loss: 0.012320

run [1800]:
Style Loss : 0.077113 Content Loss: 0.012368

run [1850]:
Style Loss : 0.076660 Content Loss: 0.012443

run [1900]:
Style Loss : 0.076256 Content Loss: 0.012494

run [1950]:
Style Loss : 0.075865 Content Loss: 0.012555

run [2000]:
Style Loss : 0.075516 Content Loss: 0.012617

run [2050]:
Style Loss : 0.075131 Content Loss: 0.012669

run [2100]:
Style Loss : 0.074757 Content Loss: 0.012714

run [2150]:
Style Loss : 0.074443 Content Loss: 0.012755

run [2200]:
Style Loss : 0.074100 Content Loss: 0.012806

run [2250]:
Style Loss : 0.073804 Content Loss: 0.012870

run [2300]:
Style Loss : 0.073502 Content Loss: 0.012909

run [2350]:
Style Loss : 0.073264 Content Loss: 0.012952

run [2400]:
Style Loss : 0.072986 Content Loss: 0.012988

run [2450]:
Style Loss : 0.072708 Content Loss: 0.013009

run [2500]:
Style Loss : 0.072461 Content Loss: 0.013058

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.676332 Content Loss: 0.004452

run [100]:
Style Loss : 1.009946 Content Loss: 0.007430

run [150]:
Style Loss : 0.724387 Content Loss: 0.011345

run [200]:
Style Loss : 0.545476 Content Loss: 0.015697

run [250]:
Style Loss : 0.421110 Content Loss: 0.019244

run [300]:
Style Loss : 0.353605 Content Loss: 0.021521

run [350]:
Style Loss : 0.317391 Content Loss: 0.022930

run [400]:
Style Loss : 0.292292 Content Loss: 0.023572

run [450]:
Style Loss : 0.274642 Content Loss: 0.024058

run [500]:
Style Loss : 0.260081 Content Loss: 0.024485

run [550]:
Style Loss : 0.249148 Content Loss: 0.024932

run [600]:
Style Loss : 0.240690 Content Loss: 0.025302

run [650]:
Style Loss : 0.232257 Content Loss: 0.025654

run [700]:
Style Loss : 0.224765 Content Loss: 0.026007

run [750]:
Style Loss : 0.219171 Content Loss: 0.026297

run [800]:
Style Loss : 0.214134 Content Loss: 0.026548

run [850]:
Style Loss : 0.209687 Content Loss: 0.026746

run [900]:
Style Loss : 0.206047 Content Loss: 0.026939

run [950]:
Style Loss : 0.203102 Content Loss: 0.027137

run [1000]:
Style Loss : 0.200411 Content Loss: 0.027294

run [1050]:
Style Loss : 0.198147 Content Loss: 0.027468

run [1100]:
Style Loss : 0.196215 Content Loss: 0.027593

run [1150]:
Style Loss : 0.194249 Content Loss: 0.027758

run [1200]:
Style Loss : 0.192354 Content Loss: 0.027897

run [1250]:
Style Loss : 0.190414 Content Loss: 0.028046

run [1300]:
Style Loss : 0.188391 Content Loss: 0.028120

run [1350]:
Style Loss : 0.186860 Content Loss: 0.028237

run [1400]:
Style Loss : 0.185677 Content Loss: 0.028320

run [1450]:
Style Loss : 0.184579 Content Loss: 0.028435

run [1500]:
Style Loss : 0.183457 Content Loss: 0.028506

run [1550]:
Style Loss : 0.182517 Content Loss: 0.028604

run [1600]:
Style Loss : 0.181603 Content Loss: 0.028670

run [1650]:
Style Loss : 0.181667 Content Loss: 0.028758

run [1700]:
Style Loss : 0.179928 Content Loss: 0.028773

run [1750]:
Style Loss : 0.179207 Content Loss: 0.028837

run [1800]:
Style Loss : 0.178540 Content Loss: 0.028902

run [1850]:
Style Loss : 0.177930 Content Loss: 0.028969

run [1900]:
Style Loss : 0.178946 Content Loss: 0.028952

run [1950]:
Style Loss : 0.177456 Content Loss: 0.029085

run [2000]:
Style Loss : 0.176722 Content Loss: 0.029130

run [2050]:
Style Loss : 0.176248 Content Loss: 0.029172

run [2100]:
Style Loss : 0.175686 Content Loss: 0.029209

run [2150]:
Style Loss : 0.175737 Content Loss: 0.029317

run [2200]:
Style Loss : 0.184247 Content Loss: 0.029599

run [2250]:
Style Loss : 0.174365 Content Loss: 0.029496

run [2300]:
Style Loss : 0.173166 Content Loss: 0.029661

run [2350]:
Style Loss : 0.172055 Content Loss: 0.029727

run [2400]:
Style Loss : 0.171312 Content Loss: 0.029778

run [2450]:
Style Loss : 0.191993 Content Loss: 0.030383

run [2500]:
Style Loss : 0.172710 Content Loss: 0.030246

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.907507 Content Loss: 0.006054

run [100]:
Style Loss : 0.427961 Content Loss: 0.009873

run [150]:
Style Loss : 0.270732 Content Loss: 0.013099

run [200]:
Style Loss : 0.186995 Content Loss: 0.015180

run [250]:
Style Loss : 0.145177 Content Loss: 0.016540

run [300]:
Style Loss : 0.121981 Content Loss: 0.017511

run [350]:
Style Loss : 0.108115 Content Loss: 0.017836

run [400]:
Style Loss : 0.098027 Content Loss: 0.018150

run [450]:
Style Loss : 0.087792 Content Loss: 0.018375

run [500]:
Style Loss : 0.079828 Content Loss: 0.018664

run [550]:
Style Loss : 0.074249 Content Loss: 0.018853

run [600]:
Style Loss : 0.069540 Content Loss: 0.019065

run [650]:
Style Loss : 0.065539 Content Loss: 0.019249

run [700]:
Style Loss : 0.062268 Content Loss: 0.019397

run [750]:
Style Loss : 0.059386 Content Loss: 0.019491

run [800]:
Style Loss : 0.057090 Content Loss: 0.019590

run [850]:
Style Loss : 0.054855 Content Loss: 0.019673

run [900]:
Style Loss : 0.052529 Content Loss: 0.019697

run [950]:
Style Loss : 0.050813 Content Loss: 0.019724

run [1000]:
Style Loss : 0.049329 Content Loss: 0.019726

run [1050]:
Style Loss : 0.048114 Content Loss: 0.019729

run [1100]:
Style Loss : 0.047069 Content Loss: 0.019721

run [1150]:
Style Loss : 0.046179 Content Loss: 0.019690

run [1200]:
Style Loss : 0.045392 Content Loss: 0.019657

run [1250]:
Style Loss : 0.044674 Content Loss: 0.019610

run [1300]:
Style Loss : 0.044040 Content Loss: 0.019567

run [1350]:
Style Loss : 0.043465 Content Loss: 0.019535

run [1400]:
Style Loss : 0.042905 Content Loss: 0.019503

run [1450]:
Style Loss : 0.042367 Content Loss: 0.019464

run [1500]:
Style Loss : 0.041910 Content Loss: 0.019437

run [1550]:
Style Loss : 0.041503 Content Loss: 0.019406

run [1600]:
Style Loss : 0.041124 Content Loss: 0.019367

run [1650]:
Style Loss : 0.040810 Content Loss: 0.019333

run [1700]:
Style Loss : 0.040521 Content Loss: 0.019288

run [1750]:
Style Loss : 0.040245 Content Loss: 0.019250

run [1800]:
Style Loss : 0.039996 Content Loss: 0.019214

run [1850]:
Style Loss : 0.039679 Content Loss: 0.019172

run [1900]:
Style Loss : 0.039415 Content Loss: 0.019145

run [1950]:
Style Loss : 0.039138 Content Loss: 0.019123

run [2000]:
Style Loss : 0.038921 Content Loss: 0.019095

run [2050]:
Style Loss : 0.038684 Content Loss: 0.019070

run [2100]:
Style Loss : 0.038478 Content Loss: 0.019037

run [2150]:
Style Loss : 0.038259 Content Loss: 0.019006

run [2200]:
Style Loss : 0.038050 Content Loss: 0.018980

run [2250]:
Style Loss : 0.037866 Content Loss: 0.018950

run [2300]:
Style Loss : 0.037691 Content Loss: 0.018926

run [2350]:
Style Loss : 0.037564 Content Loss: 0.018906

run [2400]:
Style Loss : 0.037371 Content Loss: 0.018893

run [2450]:
Style Loss : 0.037244 Content Loss: 0.018874

run [2500]:
Style Loss : 0.037093 Content Loss: 0.018852

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.134868 Content Loss: 0.002200

run [100]:
Style Loss : 1.293581 Content Loss: 0.003283

run [150]:
Style Loss : 1.011500 Content Loss: 0.004187

run [200]:
Style Loss : 0.841528 Content Loss: 0.005268

run [250]:
Style Loss : 0.732683 Content Loss: 0.006260

run [300]:
Style Loss : 0.656106 Content Loss: 0.007300

run [350]:
Style Loss : 0.595658 Content Loss: 0.008335

run [400]:
Style Loss : 0.548226 Content Loss: 0.009331

run [450]:
Style Loss : 0.512745 Content Loss: 0.010202

run [500]:
Style Loss : 0.480875 Content Loss: 0.011055

run [550]:
Style Loss : 0.454537 Content Loss: 0.011679

run [600]:
Style Loss : 0.435326 Content Loss: 0.012275

run [650]:
Style Loss : 0.420217 Content Loss: 0.012828

run [700]:
Style Loss : 0.409002 Content Loss: 0.013280

run [750]:
Style Loss : 0.400192 Content Loss: 0.013650

run [800]:
Style Loss : 0.392525 Content Loss: 0.013964

run [850]:
Style Loss : 0.385739 Content Loss: 0.014254

run [900]:
Style Loss : 0.379682 Content Loss: 0.014478

run [950]:
Style Loss : 0.374705 Content Loss: 0.014638

run [1000]:
Style Loss : 0.370196 Content Loss: 0.014792

run [1050]:
Style Loss : 0.366373 Content Loss: 0.014932

run [1100]:
Style Loss : 0.362864 Content Loss: 0.015046

run [1150]:
Style Loss : 0.359681 Content Loss: 0.015170

run [1200]:
Style Loss : 0.356676 Content Loss: 0.015279

run [1250]:
Style Loss : 0.353899 Content Loss: 0.015398

run [1300]:
Style Loss : 0.351314 Content Loss: 0.015515

run [1350]:
Style Loss : 0.349075 Content Loss: 0.015619

run [1400]:
Style Loss : 0.346585 Content Loss: 0.015737

run [1450]:
Style Loss : 0.344368 Content Loss: 0.015840

run [1500]:
Style Loss : 0.342340 Content Loss: 0.015944

run [1550]:
Style Loss : 0.340267 Content Loss: 0.016047

run [1600]:
Style Loss : 0.338389 Content Loss: 0.016143

run [1650]:
Style Loss : 0.336723 Content Loss: 0.016237

run [1700]:
Style Loss : 0.335175 Content Loss: 0.016320

run [1750]:
Style Loss : 0.333605 Content Loss: 0.016427

run [1800]:
Style Loss : 0.332025 Content Loss: 0.016517

run [1850]:
Style Loss : 0.330579 Content Loss: 0.016599

run [1900]:
Style Loss : 0.329307 Content Loss: 0.016673

run [1950]:
Style Loss : 0.328025 Content Loss: 0.016750

run [2000]:
Style Loss : 0.326825 Content Loss: 0.016818

run [2050]:
Style Loss : 0.325650 Content Loss: 0.016898

run [2100]:
Style Loss : 0.324538 Content Loss: 0.016969

run [2150]:
Style Loss : 0.323560 Content Loss: 0.017033

run [2200]:
Style Loss : 0.322612 Content Loss: 0.017096

run [2250]:
Style Loss : 0.321619 Content Loss: 0.017173

run [2300]:
Style Loss : 0.320635 Content Loss: 0.017243

run [2350]:
Style Loss : 0.319725 Content Loss: 0.017305

run [2400]:
Style Loss : 0.318878 Content Loss: 0.017361

run [2450]:
Style Loss : 0.318049 Content Loss: 0.017421

run [2500]:
Style Loss : 0.317221 Content Loss: 0.017480

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.174204 Content Loss: 0.002600

run [100]:
Style Loss : 1.156821 Content Loss: 0.003124

run [150]:
Style Loss : 0.800783 Content Loss: 0.003971

run [200]:
Style Loss : 0.643653 Content Loss: 0.004653

run [250]:
Style Loss : 0.555763 Content Loss: 0.005414

run [300]:
Style Loss : 0.497271 Content Loss: 0.006151

run [350]:
Style Loss : 0.454128 Content Loss: 0.006852

run [400]:
Style Loss : 0.428164 Content Loss: 0.007475

run [450]:
Style Loss : 0.394852 Content Loss: 0.008069

run [500]:
Style Loss : 0.369738 Content Loss: 0.008689

run [550]:
Style Loss : 0.347718 Content Loss: 0.009219

run [600]:
Style Loss : 0.329762 Content Loss: 0.009728

run [650]:
Style Loss : 0.316172 Content Loss: 0.010282

run [700]:
Style Loss : 0.302197 Content Loss: 0.010686

run [750]:
Style Loss : 0.291560 Content Loss: 0.011074

run [800]:
Style Loss : 0.281649 Content Loss: 0.011471

run [850]:
Style Loss : 0.271895 Content Loss: 0.011944

run [900]:
Style Loss : 0.264639 Content Loss: 0.012252

run [950]:
Style Loss : 0.258874 Content Loss: 0.012632

run [1000]:
Style Loss : 0.253003 Content Loss: 0.012834

run [1050]:
Style Loss : 0.248499 Content Loss: 0.013033

run [1100]:
Style Loss : 0.244196 Content Loss: 0.013201

run [1150]:
Style Loss : 0.239973 Content Loss: 0.013349

run [1200]:
Style Loss : 0.235928 Content Loss: 0.013493

run [1250]:
Style Loss : 0.232332 Content Loss: 0.013614

run [1300]:
Style Loss : 0.228960 Content Loss: 0.013730

run [1350]:
Style Loss : 0.225651 Content Loss: 0.013857

run [1400]:
Style Loss : 0.222788 Content Loss: 0.013948

run [1450]:
Style Loss : 0.220288 Content Loss: 0.014072

run [1500]:
Style Loss : 0.217533 Content Loss: 0.014140

run [1550]:
Style Loss : 0.215280 Content Loss: 0.014236

run [1600]:
Style Loss : 0.213015 Content Loss: 0.014306

run [1650]:
Style Loss : 0.211170 Content Loss: 0.014414

run [1700]:
Style Loss : 0.208865 Content Loss: 0.014468

run [1750]:
Style Loss : 0.207505 Content Loss: 0.014547

run [1800]:
Style Loss : 0.204560 Content Loss: 0.014640

run [1850]:
Style Loss : 0.202353 Content Loss: 0.014728

run [1900]:
Style Loss : 0.200325 Content Loss: 0.014826

run [1950]:
Style Loss : 0.198521 Content Loss: 0.014921

run [2000]:
Style Loss : 0.196980 Content Loss: 0.015041

run [2050]:
Style Loss : 0.194847 Content Loss: 0.015099

run [2100]:
Style Loss : 0.196176 Content Loss: 0.015347

run [2150]:
Style Loss : 0.192089 Content Loss: 0.015338

run [2200]:
Style Loss : 0.190548 Content Loss: 0.015395

run [2250]:
Style Loss : 0.188785 Content Loss: 0.015531

run [2300]:
Style Loss : 0.187055 Content Loss: 0.015606

run [2350]:
Style Loss : 0.185745 Content Loss: 0.015725

run [2400]:
Style Loss : 0.184180 Content Loss: 0.015812

run [2450]:
Style Loss : 0.182897 Content Loss: 0.015933

run [2500]:
Style Loss : 0.181602 Content Loss: 0.016053

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.243174 Content Loss: 0.002911

run [100]:
Style Loss : 0.643549 Content Loss: 0.004491

run [150]:
Style Loss : 0.463093 Content Loss: 0.006417

run [200]:
Style Loss : 0.372508 Content Loss: 0.008054

run [250]:
Style Loss : 0.318743 Content Loss: 0.009444

run [300]:
Style Loss : 0.283968 Content Loss: 0.010292

run [350]:
Style Loss : 0.261048 Content Loss: 0.010977

run [400]:
Style Loss : 0.245565 Content Loss: 0.011509

run [450]:
Style Loss : 0.233728 Content Loss: 0.012001

run [500]:
Style Loss : 0.224481 Content Loss: 0.012379

run [550]:
Style Loss : 0.216777 Content Loss: 0.012737

run [600]:
Style Loss : 0.210087 Content Loss: 0.013066

run [650]:
Style Loss : 0.204797 Content Loss: 0.013367

run [700]:
Style Loss : 0.199958 Content Loss: 0.013673

run [750]:
Style Loss : 0.195702 Content Loss: 0.013932

run [800]:
Style Loss : 0.191926 Content Loss: 0.014171

run [850]:
Style Loss : 0.188483 Content Loss: 0.014378

run [900]:
Style Loss : 0.185406 Content Loss: 0.014587

run [950]:
Style Loss : 0.182467 Content Loss: 0.014809

run [1000]:
Style Loss : 0.179691 Content Loss: 0.015017

run [1050]:
Style Loss : 0.177100 Content Loss: 0.015215

run [1100]:
Style Loss : 0.174758 Content Loss: 0.015402

run [1150]:
Style Loss : 0.172605 Content Loss: 0.015580

run [1200]:
Style Loss : 0.170482 Content Loss: 0.015757

run [1250]:
Style Loss : 0.168607 Content Loss: 0.015902

run [1300]:
Style Loss : 0.166919 Content Loss: 0.016055

run [1350]:
Style Loss : 0.165358 Content Loss: 0.016192

run [1400]:
Style Loss : 0.163809 Content Loss: 0.016329

run [1450]:
Style Loss : 0.162319 Content Loss: 0.016473

run [1500]:
Style Loss : 0.160974 Content Loss: 0.016593

run [1550]:
Style Loss : 0.159723 Content Loss: 0.016719

run [1600]:
Style Loss : 0.158517 Content Loss: 0.016827

run [1650]:
Style Loss : 0.157365 Content Loss: 0.016931

run [1700]:
Style Loss : 0.156315 Content Loss: 0.017032

run [1750]:
Style Loss : 0.155395 Content Loss: 0.017125

run [1800]:
Style Loss : 0.154512 Content Loss: 0.017210

run [1850]:
Style Loss : 0.153600 Content Loss: 0.017303

run [1900]:
Style Loss : 0.152603 Content Loss: 0.017376

run [1950]:
Style Loss : 0.151665 Content Loss: 0.017445

run [2000]:
Style Loss : 0.150798 Content Loss: 0.017514

run [2050]:
Style Loss : 0.149987 Content Loss: 0.017562

run [2100]:
Style Loss : 0.149166 Content Loss: 0.017618

run [2150]:
Style Loss : 0.148329 Content Loss: 0.017678

run [2200]:
Style Loss : 0.147518 Content Loss: 0.017735

run [2250]:
Style Loss : 0.146692 Content Loss: 0.017787

run [2300]:
Style Loss : 0.145843 Content Loss: 0.017820

run [2350]:
Style Loss : 0.145080 Content Loss: 0.017858

run [2400]:
Style Loss : 0.144340 Content Loss: 0.017906

run [2450]:
Style Loss : 0.143640 Content Loss: 0.017943

run [2500]:
Style Loss : 0.142931 Content Loss: 0.017989

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.678641 Content Loss: 0.002050

run [100]:
Style Loss : 1.417919 Content Loss: 0.002550

run [150]:
Style Loss : 1.009009 Content Loss: 0.003239

run [200]:
Style Loss : 0.810900 Content Loss: 0.003945

run [250]:
Style Loss : 0.695096 Content Loss: 0.004554

run [300]:
Style Loss : 0.624880 Content Loss: 0.005025

run [350]:
Style Loss : 0.577643 Content Loss: 0.005474

run [400]:
Style Loss : 0.542005 Content Loss: 0.005860

run [450]:
Style Loss : 0.514067 Content Loss: 0.006229

run [500]:
Style Loss : 0.491298 Content Loss: 0.006539

run [550]:
Style Loss : 0.471930 Content Loss: 0.006819

run [600]:
Style Loss : 0.456819 Content Loss: 0.007087

run [650]:
Style Loss : 0.444145 Content Loss: 0.007358

run [700]:
Style Loss : 0.431539 Content Loss: 0.007631

run [750]:
Style Loss : 0.418893 Content Loss: 0.007860

run [800]:
Style Loss : 0.405982 Content Loss: 0.008104

run [850]:
Style Loss : 0.395005 Content Loss: 0.008290

run [900]:
Style Loss : 0.385410 Content Loss: 0.008462

run [950]:
Style Loss : 0.377474 Content Loss: 0.008592

run [1000]:
Style Loss : 0.370188 Content Loss: 0.008773

run [1050]:
Style Loss : 0.363756 Content Loss: 0.008921

run [1100]:
Style Loss : 0.358176 Content Loss: 0.009055

run [1150]:
Style Loss : 0.352849 Content Loss: 0.009168

run [1200]:
Style Loss : 0.348417 Content Loss: 0.009284

run [1250]:
Style Loss : 0.344565 Content Loss: 0.009380

run [1300]:
Style Loss : 0.341160 Content Loss: 0.009487

run [1350]:
Style Loss : 0.337792 Content Loss: 0.009598

run [1400]:
Style Loss : 0.334712 Content Loss: 0.009704

run [1450]:
Style Loss : 0.331977 Content Loss: 0.009805

run [1500]:
Style Loss : 0.329562 Content Loss: 0.009885

run [1550]:
Style Loss : 0.327217 Content Loss: 0.009985

run [1600]:
Style Loss : 0.324914 Content Loss: 0.010070

run [1650]:
Style Loss : 0.322873 Content Loss: 0.010146

run [1700]:
Style Loss : 0.320940 Content Loss: 0.010227

run [1750]:
Style Loss : 0.319175 Content Loss: 0.010299

run [1800]:
Style Loss : 0.317415 Content Loss: 0.010363

run [1850]:
Style Loss : 0.315783 Content Loss: 0.010432

run [1900]:
Style Loss : 0.314343 Content Loss: 0.010487

run [1950]:
Style Loss : 0.312873 Content Loss: 0.010547

run [2000]:
Style Loss : 0.311509 Content Loss: 0.010603

run [2050]:
Style Loss : 0.310206 Content Loss: 0.010650

run [2100]:
Style Loss : 0.309013 Content Loss: 0.010700

run [2150]:
Style Loss : 0.307765 Content Loss: 0.010752

run [2200]:
Style Loss : 0.306634 Content Loss: 0.010787

run [2250]:
Style Loss : 0.305630 Content Loss: 0.010817

run [2300]:
Style Loss : 0.304734 Content Loss: 0.010844

run [2350]:
Style Loss : 0.303836 Content Loss: 0.010875

run [2400]:
Style Loss : 0.303002 Content Loss: 0.010907

run [2450]:
Style Loss : 0.302099 Content Loss: 0.010940

run [2500]:
Style Loss : 0.301276 Content Loss: 0.010968

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.309413 Content Loss: 0.003509

run [100]:
Style Loss : 1.239078 Content Loss: 0.003729

run [150]:
Style Loss : 0.958628 Content Loss: 0.004396

run [200]:
Style Loss : 0.793068 Content Loss: 0.005146

run [250]:
Style Loss : 0.691577 Content Loss: 0.005719

run [300]:
Style Loss : 0.629333 Content Loss: 0.006179

run [350]:
Style Loss : 0.581509 Content Loss: 0.006667

run [400]:
Style Loss : 0.544033 Content Loss: 0.007059

run [450]:
Style Loss : 0.515746 Content Loss: 0.007447

run [500]:
Style Loss : 0.492210 Content Loss: 0.007766

run [550]:
Style Loss : 0.473064 Content Loss: 0.008072

run [600]:
Style Loss : 0.457444 Content Loss: 0.008357

run [650]:
Style Loss : 0.444585 Content Loss: 0.008664

run [700]:
Style Loss : 0.432820 Content Loss: 0.008919

run [750]:
Style Loss : 0.421781 Content Loss: 0.009184

run [800]:
Style Loss : 0.412195 Content Loss: 0.009427

run [850]:
Style Loss : 0.404100 Content Loss: 0.009651

run [900]:
Style Loss : 0.397269 Content Loss: 0.009837

run [950]:
Style Loss : 0.390984 Content Loss: 0.010043

run [1000]:
Style Loss : 0.384991 Content Loss: 0.010233

run [1050]:
Style Loss : 0.379792 Content Loss: 0.010404

run [1100]:
Style Loss : 0.375083 Content Loss: 0.010568

run [1150]:
Style Loss : 0.370981 Content Loss: 0.010722

run [1200]:
Style Loss : 0.367329 Content Loss: 0.010860

run [1250]:
Style Loss : 0.363805 Content Loss: 0.010992

run [1300]:
Style Loss : 0.360761 Content Loss: 0.011105

run [1350]:
Style Loss : 0.357931 Content Loss: 0.011207

run [1400]:
Style Loss : 0.355426 Content Loss: 0.011297

run [1450]:
Style Loss : 0.353081 Content Loss: 0.011413

run [1500]:
Style Loss : 0.350842 Content Loss: 0.011527

run [1550]:
Style Loss : 0.348663 Content Loss: 0.011621

run [1600]:
Style Loss : 0.346404 Content Loss: 0.011729

run [1650]:
Style Loss : 0.344068 Content Loss: 0.011835

run [1700]:
Style Loss : 0.342045 Content Loss: 0.011915

run [1750]:
Style Loss : 0.340347 Content Loss: 0.011992

run [1800]:
Style Loss : 0.338816 Content Loss: 0.012053

run [1850]:
Style Loss : 0.337351 Content Loss: 0.012119

run [1900]:
Style Loss : 0.335774 Content Loss: 0.012205

run [1950]:
Style Loss : 0.334312 Content Loss: 0.012267

run [2000]:
Style Loss : 0.332916 Content Loss: 0.012335

run [2050]:
Style Loss : 0.331257 Content Loss: 0.012413

run [2100]:
Style Loss : 0.329459 Content Loss: 0.012487

run [2150]:
Style Loss : 0.327706 Content Loss: 0.012540

run [2200]:
Style Loss : 0.326033 Content Loss: 0.012613

run [2250]:
Style Loss : 0.324432 Content Loss: 0.012664

run [2300]:
Style Loss : 0.323055 Content Loss: 0.012717

run [2350]:
Style Loss : 0.321778 Content Loss: 0.012760

run [2400]:
Style Loss : 0.320632 Content Loss: 0.012812

run [2450]:
Style Loss : 0.319437 Content Loss: 0.012864

run [2500]:
Style Loss : 0.318357 Content Loss: 0.012913

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.558069 Content Loss: 0.004033

run [100]:
Style Loss : 2.141379 Content Loss: 0.004809

run [150]:
Style Loss : 1.679736 Content Loss: 0.005630

run [200]:
Style Loss : 1.438213 Content Loss: 0.006399

run [250]:
Style Loss : 1.291399 Content Loss: 0.007017

run [300]:
Style Loss : 1.184224 Content Loss: 0.007617

run [350]:
Style Loss : 1.111497 Content Loss: 0.008253

run [400]:
Style Loss : 1.057068 Content Loss: 0.008652

run [450]:
Style Loss : 1.020931 Content Loss: 0.009052

run [500]:
Style Loss : 0.984658 Content Loss: 0.009369

run [550]:
Style Loss : 0.958147 Content Loss: 0.009625

run [600]:
Style Loss : 0.932460 Content Loss: 0.009851

run [650]:
Style Loss : 1.256356 Content Loss: 0.010418

run [700]:
Style Loss : 0.890634 Content Loss: 0.010304

run [750]:
Style Loss : 0.875233 Content Loss: 0.010520

run [800]:
Style Loss : 0.859015 Content Loss: 0.010759

run [850]:
Style Loss : 0.844364 Content Loss: 0.011033

run [900]:
Style Loss : 0.831175 Content Loss: 0.011217

run [950]:
Style Loss : 0.819249 Content Loss: 0.011473

run [1000]:
Style Loss : 0.804589 Content Loss: 0.011686

run [1050]:
Style Loss : 0.794324 Content Loss: 0.011895

run [1100]:
Style Loss : 0.782602 Content Loss: 0.012088

run [1150]:
Style Loss : 0.772551 Content Loss: 0.012295

run [1200]:
Style Loss : 0.763458 Content Loss: 0.012459

run [1250]:
Style Loss : 0.753775 Content Loss: 0.012635

run [1300]:
Style Loss : 0.744543 Content Loss: 0.012789

run [1350]:
Style Loss : 0.734886 Content Loss: 0.012969

run [1400]:
Style Loss : 0.726135 Content Loss: 0.013147

run [1450]:
Style Loss : 0.717391 Content Loss: 0.013340

run [1500]:
Style Loss : 0.709631 Content Loss: 0.013459

run [1550]:
Style Loss : 0.702892 Content Loss: 0.013610

run [1600]:
Style Loss : 0.696521 Content Loss: 0.013728

run [1650]:
Style Loss : 0.691032 Content Loss: 0.013842

run [1700]:
Style Loss : 0.685290 Content Loss: 0.013959

run [1750]:
Style Loss : 0.680447 Content Loss: 0.014054

run [1800]:
Style Loss : 0.676385 Content Loss: 0.014163

run [1850]:
Style Loss : 0.672377 Content Loss: 0.014258

run [1900]:
Style Loss : 0.668724 Content Loss: 0.014336

run [1950]:
Style Loss : 0.665800 Content Loss: 0.014440

run [2000]:
Style Loss : 0.662925 Content Loss: 0.014530

run [2050]:
Style Loss : 0.659928 Content Loss: 0.014594

run [2100]:
Style Loss : 0.656942 Content Loss: 0.014648

run [2150]:
Style Loss : 0.654642 Content Loss: 0.014735

run [2200]:
Style Loss : 0.651756 Content Loss: 0.014766

run [2250]:
Style Loss : 0.649510 Content Loss: 0.014821

run [2300]:
Style Loss : 0.647190 Content Loss: 0.014890

run [2350]:
Style Loss : 0.644816 Content Loss: 0.014948

run [2400]:
Style Loss : 0.642666 Content Loss: 0.014993

run [2450]:
Style Loss : 0.640706 Content Loss: 0.015049

run [2500]:
Style Loss : 0.638666 Content Loss: 0.015100

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.844860 Content Loss: 0.003990

run [100]:
Style Loss : 1.003526 Content Loss: 0.004099

run [150]:
Style Loss : 0.728661 Content Loss: 0.004754

run [200]:
Style Loss : 0.594803 Content Loss: 0.005424

run [250]:
Style Loss : 0.503148 Content Loss: 0.006157

run [300]:
Style Loss : 0.436877 Content Loss: 0.006938

run [350]:
Style Loss : 0.386755 Content Loss: 0.007709

run [400]:
Style Loss : 0.346037 Content Loss: 0.008476

run [450]:
Style Loss : 0.313501 Content Loss: 0.009155

run [500]:
Style Loss : 0.285276 Content Loss: 0.009827

run [550]:
Style Loss : 0.262177 Content Loss: 0.010425

run [600]:
Style Loss : 0.244162 Content Loss: 0.010895

run [650]:
Style Loss : 0.229622 Content Loss: 0.011290

run [700]:
Style Loss : 0.215522 Content Loss: 0.011530

run [750]:
Style Loss : 0.202541 Content Loss: 0.011769

run [800]:
Style Loss : 0.190960 Content Loss: 0.011909

run [850]:
Style Loss : 0.182307 Content Loss: 0.012052

run [900]:
Style Loss : 0.174278 Content Loss: 0.012178

run [950]:
Style Loss : 0.167360 Content Loss: 0.012279

run [1000]:
Style Loss : 0.161262 Content Loss: 0.012372

run [1050]:
Style Loss : 0.156003 Content Loss: 0.012482

run [1100]:
Style Loss : 0.151401 Content Loss: 0.012565

run [1150]:
Style Loss : 0.147301 Content Loss: 0.012648

run [1200]:
Style Loss : 0.143839 Content Loss: 0.012699

run [1250]:
Style Loss : 0.140861 Content Loss: 0.012768

run [1300]:
Style Loss : 0.138347 Content Loss: 0.012835

run [1350]:
Style Loss : 0.135817 Content Loss: 0.012909

run [1400]:
Style Loss : 0.133345 Content Loss: 0.012963

run [1450]:
Style Loss : 0.131155 Content Loss: 0.013042

run [1500]:
Style Loss : 0.129050 Content Loss: 0.013112

run [1550]:
Style Loss : 0.127124 Content Loss: 0.013185

run [1600]:
Style Loss : 0.125439 Content Loss: 0.013240

run [1650]:
Style Loss : 0.123802 Content Loss: 0.013292

run [1700]:
Style Loss : 0.122225 Content Loss: 0.013351

run [1750]:
Style Loss : 0.120726 Content Loss: 0.013394

run [1800]:
Style Loss : 0.119314 Content Loss: 0.013438

run [1850]:
Style Loss : 0.117955 Content Loss: 0.013482

run [1900]:
Style Loss : 0.116631 Content Loss: 0.013517

run [1950]:
Style Loss : 0.115443 Content Loss: 0.013552

run [2000]:
Style Loss : 0.114323 Content Loss: 0.013588

run [2050]:
Style Loss : 0.113267 Content Loss: 0.013609

run [2100]:
Style Loss : 0.112275 Content Loss: 0.013644

run [2150]:
Style Loss : 0.111421 Content Loss: 0.013673

run [2200]:
Style Loss : 0.110549 Content Loss: 0.013701

run [2250]:
Style Loss : 0.109676 Content Loss: 0.013730

run [2300]:
Style Loss : 0.108787 Content Loss: 0.013754

run [2350]:
Style Loss : 0.108032 Content Loss: 0.013778

run [2400]:
Style Loss : 0.107342 Content Loss: 0.013796

run [2450]:
Style Loss : 0.106628 Content Loss: 0.013814

run [2500]:
Style Loss : 0.106011 Content Loss: 0.013829

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.484416 Content Loss: 0.002358

run [100]:
Style Loss : 0.945827 Content Loss: 0.003704

run [150]:
Style Loss : 0.738799 Content Loss: 0.004851

run [200]:
Style Loss : 0.636844 Content Loss: 0.005837

run [250]:
Style Loss : 0.570755 Content Loss: 0.006664

run [300]:
Style Loss : 0.529224 Content Loss: 0.007287

run [350]:
Style Loss : 0.496258 Content Loss: 0.007898

run [400]:
Style Loss : 0.468256 Content Loss: 0.008471

run [450]:
Style Loss : 0.445471 Content Loss: 0.008947

run [500]:
Style Loss : 0.426315 Content Loss: 0.009387

run [550]:
Style Loss : 0.412487 Content Loss: 0.009762

run [600]:
Style Loss : 0.402493 Content Loss: 0.010033

run [650]:
Style Loss : 0.394435 Content Loss: 0.010335

run [700]:
Style Loss : 0.387824 Content Loss: 0.010614

run [750]:
Style Loss : 0.382125 Content Loss: 0.010857

run [800]:
Style Loss : 0.376446 Content Loss: 0.011103

run [850]:
Style Loss : 0.371951 Content Loss: 0.011298

run [900]:
Style Loss : 0.368046 Content Loss: 0.011491

run [950]:
Style Loss : 0.364408 Content Loss: 0.011666

run [1000]:
Style Loss : 0.360929 Content Loss: 0.011832

run [1050]:
Style Loss : 0.357513 Content Loss: 0.012017

run [1100]:
Style Loss : 0.354394 Content Loss: 0.012152

run [1150]:
Style Loss : 0.351489 Content Loss: 0.012310

run [1200]:
Style Loss : 0.348940 Content Loss: 0.012449

run [1250]:
Style Loss : 0.346450 Content Loss: 0.012572

run [1300]:
Style Loss : 0.344071 Content Loss: 0.012726

run [1350]:
Style Loss : 0.341478 Content Loss: 0.012874

run [1400]:
Style Loss : 0.338765 Content Loss: 0.013005

run [1450]:
Style Loss : 0.336524 Content Loss: 0.013110

run [1500]:
Style Loss : 0.334424 Content Loss: 0.013243

run [1550]:
Style Loss : 0.332333 Content Loss: 0.013327

run [1600]:
Style Loss : 0.330484 Content Loss: 0.013427

run [1650]:
Style Loss : 0.328818 Content Loss: 0.013519

run [1700]:
Style Loss : 0.327084 Content Loss: 0.013601

run [1750]:
Style Loss : 0.325548 Content Loss: 0.013685

run [1800]:
Style Loss : 0.324150 Content Loss: 0.013757

run [1850]:
Style Loss : 0.322772 Content Loss: 0.013841

run [1900]:
Style Loss : 0.321488 Content Loss: 0.013908

run [1950]:
Style Loss : 0.320342 Content Loss: 0.013990

run [2000]:
Style Loss : 0.319270 Content Loss: 0.014040

run [2050]:
Style Loss : 0.318328 Content Loss: 0.014096

run [2100]:
Style Loss : 0.317434 Content Loss: 0.014142

run [2150]:
Style Loss : 0.316632 Content Loss: 0.014190

run [2200]:
Style Loss : 0.315817 Content Loss: 0.014247

run [2250]:
Style Loss : 0.314953 Content Loss: 0.014296

run [2300]:
Style Loss : 0.314050 Content Loss: 0.014346

run [2350]:
Style Loss : 0.313171 Content Loss: 0.014392

run [2400]:
Style Loss : 0.312381 Content Loss: 0.014437

run [2450]:
Style Loss : 0.311584 Content Loss: 0.014475

run [2500]:
Style Loss : 0.310784 Content Loss: 0.014525

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.168551 Content Loss: 0.002155

run [100]:
Style Loss : 0.666890 Content Loss: 0.003306

run [150]:
Style Loss : 0.534747 Content Loss: 0.004187

run [200]:
Style Loss : 0.462788 Content Loss: 0.004890

run [250]:
Style Loss : 0.411108 Content Loss: 0.005421

run [300]:
Style Loss : 0.376478 Content Loss: 0.005824

run [350]:
Style Loss : 0.346866 Content Loss: 0.006260

run [400]:
Style Loss : 0.323170 Content Loss: 0.006554

run [450]:
Style Loss : 0.307780 Content Loss: 0.006836

run [500]:
Style Loss : 0.296521 Content Loss: 0.007072

run [550]:
Style Loss : 0.287879 Content Loss: 0.007275

run [600]:
Style Loss : 0.281618 Content Loss: 0.007440

run [650]:
Style Loss : 0.275918 Content Loss: 0.007616

run [700]:
Style Loss : 0.270248 Content Loss: 0.007773

run [750]:
Style Loss : 0.265768 Content Loss: 0.007913

run [800]:
Style Loss : 0.261525 Content Loss: 0.008037

run [850]:
Style Loss : 0.257145 Content Loss: 0.008185

run [900]:
Style Loss : 0.252482 Content Loss: 0.008339

run [950]:
Style Loss : 0.249028 Content Loss: 0.008450

run [1000]:
Style Loss : 0.246166 Content Loss: 0.008568

run [1050]:
Style Loss : 0.243694 Content Loss: 0.008687

run [1100]:
Style Loss : 0.241287 Content Loss: 0.008775

run [1150]:
Style Loss : 0.239133 Content Loss: 0.008869

run [1200]:
Style Loss : 0.237194 Content Loss: 0.008957

run [1250]:
Style Loss : 0.235510 Content Loss: 0.009033

run [1300]:
Style Loss : 0.234091 Content Loss: 0.009105

run [1350]:
Style Loss : 0.232713 Content Loss: 0.009182

run [1400]:
Style Loss : 0.231482 Content Loss: 0.009251

run [1450]:
Style Loss : 0.230233 Content Loss: 0.009312

run [1500]:
Style Loss : 0.229123 Content Loss: 0.009368

run [1550]:
Style Loss : 0.228126 Content Loss: 0.009423

run [1600]:
Style Loss : 0.227092 Content Loss: 0.009481

run [1650]:
Style Loss : 0.225727 Content Loss: 0.009558

run [1700]:
Style Loss : 0.224535 Content Loss: 0.009622

run [1750]:
Style Loss : 0.223351 Content Loss: 0.009678

run [1800]:
Style Loss : 0.222309 Content Loss: 0.009732

run [1850]:
Style Loss : 0.220298 Content Loss: 0.009815

run [1900]:
Style Loss : 0.218605 Content Loss: 0.009885

run [1950]:
Style Loss : 0.217132 Content Loss: 0.009952

run [2000]:
Style Loss : 0.215832 Content Loss: 0.010014

run [2050]:
Style Loss : 0.214608 Content Loss: 0.010079

run [2100]:
Style Loss : 0.213474 Content Loss: 0.010143

run [2150]:
Style Loss : 0.212478 Content Loss: 0.010187

run [2200]:
Style Loss : 0.211509 Content Loss: 0.010240

run [2250]:
Style Loss : 0.210458 Content Loss: 0.010304

run [2300]:
Style Loss : 0.209465 Content Loss: 0.010359

run [2350]:
Style Loss : 0.208590 Content Loss: 0.010404

run [2400]:
Style Loss : 0.207852 Content Loss: 0.010446

run [2450]:
Style Loss : 0.207012 Content Loss: 0.010495

run [2500]:
Style Loss : 0.206180 Content Loss: 0.010543

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.739342 Content Loss: 0.002051

run [100]:
Style Loss : 0.394565 Content Loss: 0.003539

run [150]:
Style Loss : 0.302287 Content Loss: 0.004737

run [200]:
Style Loss : 0.258028 Content Loss: 0.005747

run [250]:
Style Loss : 0.232070 Content Loss: 0.006512

run [300]:
Style Loss : 0.215570 Content Loss: 0.007220

run [350]:
Style Loss : 0.203675 Content Loss: 0.007776

run [400]:
Style Loss : 0.194476 Content Loss: 0.008313

run [450]:
Style Loss : 0.187557 Content Loss: 0.008807

run [500]:
Style Loss : 0.181380 Content Loss: 0.009219

run [550]:
Style Loss : 0.175973 Content Loss: 0.009618

run [600]:
Style Loss : 0.171383 Content Loss: 0.009992

run [650]:
Style Loss : 0.167286 Content Loss: 0.010304

run [700]:
Style Loss : 0.163731 Content Loss: 0.010558

run [750]:
Style Loss : 0.160340 Content Loss: 0.010852

run [800]:
Style Loss : 0.157159 Content Loss: 0.011108

run [850]:
Style Loss : 0.154411 Content Loss: 0.011367

run [900]:
Style Loss : 0.151970 Content Loss: 0.011654

run [950]:
Style Loss : 0.149196 Content Loss: 0.011914

run [1000]:
Style Loss : 0.146859 Content Loss: 0.012201

run [1050]:
Style Loss : 0.144875 Content Loss: 0.012444

run [1100]:
Style Loss : 0.143130 Content Loss: 0.012733

run [1150]:
Style Loss : 0.141490 Content Loss: 0.012956

run [1200]:
Style Loss : 0.139990 Content Loss: 0.013202

run [1250]:
Style Loss : 0.138716 Content Loss: 0.013491

run [1300]:
Style Loss : 0.137242 Content Loss: 0.013705

run [1350]:
Style Loss : 0.136250 Content Loss: 0.013992

run [1400]:
Style Loss : 0.134844 Content Loss: 0.014274

run [1450]:
Style Loss : 0.133347 Content Loss: 0.014501

run [1500]:
Style Loss : 0.132106 Content Loss: 0.014810

run [1550]:
Style Loss : 0.131037 Content Loss: 0.015197

run [1600]:
Style Loss : 0.131232 Content Loss: 0.015647

run [1650]:
Style Loss : 0.128623 Content Loss: 0.015795

run [1700]:
Style Loss : 0.133616 Content Loss: 0.016243

run [1750]:
Style Loss : 0.126806 Content Loss: 0.016539

run [1800]:
Style Loss : 0.126427 Content Loss: 0.017042

run [1850]:
Style Loss : 0.185157 Content Loss: 0.017839

run [1900]:
Style Loss : 0.124239 Content Loss: 0.018010

run [1950]:
Style Loss : 0.124895 Content Loss: 0.018606

run [2000]:
Style Loss : 0.307987 Content Loss: 0.020122

run [2050]:
Style Loss : 0.126253 Content Loss: 0.020192

run [2100]:
Style Loss : 0.120692 Content Loss: 0.020138

run [2150]:
Style Loss : 0.118989 Content Loss: 0.020368

run [2200]:
Style Loss : 0.123110 Content Loss: 0.021266

run [2250]:
Style Loss : 0.117592 Content Loss: 0.021205

run [2300]:
Style Loss : 0.119211 Content Loss: 0.021575

run [2350]:
Style Loss : 0.122600 Content Loss: 0.022169

run [2400]:
Style Loss : 0.136948 Content Loss: 0.022298

run [2450]:
Style Loss : 0.159445 Content Loss: 0.022149

run [2500]:
Style Loss : 0.123006 Content Loss: 0.022977

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.946255 Content Loss: 0.001717

run [100]:
Style Loss : 0.521791 Content Loss: 0.002859

run [150]:
Style Loss : 0.389726 Content Loss: 0.003624

run [200]:
Style Loss : 0.326165 Content Loss: 0.004231

run [250]:
Style Loss : 0.290900 Content Loss: 0.004628

run [300]:
Style Loss : 0.267914 Content Loss: 0.005026

run [350]:
Style Loss : 0.249627 Content Loss: 0.005357

run [400]:
Style Loss : 0.231218 Content Loss: 0.005664

run [450]:
Style Loss : 0.218955 Content Loss: 0.005905

run [500]:
Style Loss : 0.210021 Content Loss: 0.006141

run [550]:
Style Loss : 0.202948 Content Loss: 0.006365

run [600]:
Style Loss : 0.197251 Content Loss: 0.006597

run [650]:
Style Loss : 0.192421 Content Loss: 0.006801

run [700]:
Style Loss : 0.188165 Content Loss: 0.006986

run [750]:
Style Loss : 0.184483 Content Loss: 0.007188

run [800]:
Style Loss : 0.181145 Content Loss: 0.007354

run [850]:
Style Loss : 0.178132 Content Loss: 0.007522

run [900]:
Style Loss : 0.174892 Content Loss: 0.007667

run [950]:
Style Loss : 0.171749 Content Loss: 0.007811

run [1000]:
Style Loss : 0.169338 Content Loss: 0.007929

run [1050]:
Style Loss : 0.167313 Content Loss: 0.008035

run [1100]:
Style Loss : 0.165538 Content Loss: 0.008146

run [1150]:
Style Loss : 0.163948 Content Loss: 0.008243

run [1200]:
Style Loss : 0.162571 Content Loss: 0.008334

run [1250]:
Style Loss : 0.161113 Content Loss: 0.008429

run [1300]:
Style Loss : 0.159846 Content Loss: 0.008520

run [1350]:
Style Loss : 0.158781 Content Loss: 0.008597

run [1400]:
Style Loss : 0.157743 Content Loss: 0.008674

run [1450]:
Style Loss : 0.156798 Content Loss: 0.008746

run [1500]:
Style Loss : 0.155930 Content Loss: 0.008816

run [1550]:
Style Loss : 0.155098 Content Loss: 0.008881

run [1600]:
Style Loss : 0.154269 Content Loss: 0.008951

run [1650]:
Style Loss : 0.153519 Content Loss: 0.009007

run [1700]:
Style Loss : 0.152825 Content Loss: 0.009071

run [1750]:
Style Loss : 0.152194 Content Loss: 0.009125

run [1800]:
Style Loss : 0.151541 Content Loss: 0.009180

run [1850]:
Style Loss : 0.150832 Content Loss: 0.009245

run [1900]:
Style Loss : 0.150036 Content Loss: 0.009303

run [1950]:
Style Loss : 0.149407 Content Loss: 0.009343

run [2000]:
Style Loss : 0.148793 Content Loss: 0.009393

run [2050]:
Style Loss : 0.148236 Content Loss: 0.009445

run [2100]:
Style Loss : 0.147733 Content Loss: 0.009493

run [2150]:
Style Loss : 0.147259 Content Loss: 0.009538

run [2200]:
Style Loss : 0.146790 Content Loss: 0.009581

run [2250]:
Style Loss : 0.146256 Content Loss: 0.009623

run [2300]:
Style Loss : 0.145767 Content Loss: 0.009662

run [2350]:
Style Loss : 0.145350 Content Loss: 0.009696

run [2400]:
Style Loss : 0.144983 Content Loss: 0.009728

run [2450]:
Style Loss : 0.144612 Content Loss: 0.009761

run [2500]:
Style Loss : 0.144266 Content Loss: 0.009789

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.294077 Content Loss: 0.002293

run [100]:
Style Loss : 1.597044 Content Loss: 0.002658

run [150]:
Style Loss : 1.110539 Content Loss: 0.003067

run [200]:
Style Loss : 0.878469 Content Loss: 0.003778

run [250]:
Style Loss : 0.724785 Content Loss: 0.004368

run [300]:
Style Loss : 0.633370 Content Loss: 0.004809

run [350]:
Style Loss : 0.570601 Content Loss: 0.005316

run [400]:
Style Loss : 0.528515 Content Loss: 0.005693

run [450]:
Style Loss : 0.496249 Content Loss: 0.005993

run [500]:
Style Loss : 0.471244 Content Loss: 0.006326

run [550]:
Style Loss : 0.451784 Content Loss: 0.006614

run [600]:
Style Loss : 0.436432 Content Loss: 0.006880

run [650]:
Style Loss : 0.423069 Content Loss: 0.007162

run [700]:
Style Loss : 0.411659 Content Loss: 0.007391

run [750]:
Style Loss : 0.401870 Content Loss: 0.007602

run [800]:
Style Loss : 0.393279 Content Loss: 0.007767

run [850]:
Style Loss : 0.385898 Content Loss: 0.007930

run [900]:
Style Loss : 0.379933 Content Loss: 0.008062

run [950]:
Style Loss : 0.374238 Content Loss: 0.008196

run [1000]:
Style Loss : 0.369263 Content Loss: 0.008335

run [1050]:
Style Loss : 0.364645 Content Loss: 0.008466

run [1100]:
Style Loss : 0.360325 Content Loss: 0.008599

run [1150]:
Style Loss : 0.356750 Content Loss: 0.008736

run [1200]:
Style Loss : 0.353515 Content Loss: 0.008851

run [1250]:
Style Loss : 0.350309 Content Loss: 0.008945

run [1300]:
Style Loss : 0.347198 Content Loss: 0.009052

run [1350]:
Style Loss : 0.344196 Content Loss: 0.009172

run [1400]:
Style Loss : 0.341359 Content Loss: 0.009281

run [1450]:
Style Loss : 0.338988 Content Loss: 0.009357

run [1500]:
Style Loss : 0.336694 Content Loss: 0.009457

run [1550]:
Style Loss : 0.334327 Content Loss: 0.009565

run [1600]:
Style Loss : 0.332483 Content Loss: 0.009661

run [1650]:
Style Loss : 0.330163 Content Loss: 0.009743

run [1700]:
Style Loss : 0.328363 Content Loss: 0.009833

run [1750]:
Style Loss : 0.326506 Content Loss: 0.009932

run [1800]:
Style Loss : 0.324812 Content Loss: 0.010034

run [1850]:
Style Loss : 0.322632 Content Loss: 0.010098

run [1900]:
Style Loss : 0.320808 Content Loss: 0.010223

run [1950]:
Style Loss : 0.318929 Content Loss: 0.010309

run [2000]:
Style Loss : 0.317085 Content Loss: 0.010374

run [2050]:
Style Loss : 0.315658 Content Loss: 0.010463

run [2100]:
Style Loss : 0.317544 Content Loss: 0.010590

run [2150]:
Style Loss : 0.320575 Content Loss: 0.010933

run [2200]:
Style Loss : 0.311134 Content Loss: 0.010804

run [2250]:
Style Loss : 0.308990 Content Loss: 0.010783

run [2300]:
Style Loss : 0.307739 Content Loss: 0.010883

run [2350]:
Style Loss : 0.306761 Content Loss: 0.011035

run [2400]:
Style Loss : 0.315596 Content Loss: 0.011275

run [2450]:
Style Loss : 0.304914 Content Loss: 0.011263

run [2500]:
Style Loss : 0.302876 Content Loss: 0.011254

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.535191 Content Loss: 0.002198

run [100]:
Style Loss : 0.297746 Content Loss: 0.003971

run [150]:
Style Loss : 0.215295 Content Loss: 0.005181

run [200]:
Style Loss : 0.174579 Content Loss: 0.006045

run [250]:
Style Loss : 0.150942 Content Loss: 0.006687

run [300]:
Style Loss : 0.134879 Content Loss: 0.007191

run [350]:
Style Loss : 0.122469 Content Loss: 0.007615

run [400]:
Style Loss : 0.112548 Content Loss: 0.007903

run [450]:
Style Loss : 0.105052 Content Loss: 0.008233

run [500]:
Style Loss : 0.099237 Content Loss: 0.008498

run [550]:
Style Loss : 0.094458 Content Loss: 0.008706

run [600]:
Style Loss : 0.090213 Content Loss: 0.008912

run [650]:
Style Loss : 0.086556 Content Loss: 0.009114

run [700]:
Style Loss : 0.083115 Content Loss: 0.009320

run [750]:
Style Loss : 0.080539 Content Loss: 0.009511

run [800]:
Style Loss : 0.078396 Content Loss: 0.009690

run [850]:
Style Loss : 0.076476 Content Loss: 0.009861

run [900]:
Style Loss : 0.074836 Content Loss: 0.009989

run [950]:
Style Loss : 0.073484 Content Loss: 0.010110

run [1000]:
Style Loss : 0.072293 Content Loss: 0.010239

run [1050]:
Style Loss : 0.071231 Content Loss: 0.010341

run [1100]:
Style Loss : 0.070294 Content Loss: 0.010429

run [1150]:
Style Loss : 0.069499 Content Loss: 0.010510

run [1200]:
Style Loss : 0.068736 Content Loss: 0.010590

run [1250]:
Style Loss : 0.066082 Content Loss: 0.010755

run [1300]:
Style Loss : 0.063679 Content Loss: 0.010772

run [1350]:
Style Loss : 0.062889 Content Loss: 0.010840

run [1400]:
Style Loss : 0.062247 Content Loss: 0.010901

run [1450]:
Style Loss : 0.061724 Content Loss: 0.010949

run [1500]:
Style Loss : 0.061259 Content Loss: 0.011004

run [1550]:
Style Loss : 0.060847 Content Loss: 0.011039

run [1600]:
Style Loss : 0.060475 Content Loss: 0.011073

run [1650]:
Style Loss : 0.060150 Content Loss: 0.011102

run [1700]:
Style Loss : 0.059852 Content Loss: 0.011146

run [1750]:
Style Loss : 0.059536 Content Loss: 0.011167

run [1800]:
Style Loss : 0.059299 Content Loss: 0.011188

run [1850]:
Style Loss : 0.058984 Content Loss: 0.011222

run [1900]:
Style Loss : 0.058584 Content Loss: 0.011214

run [1950]:
Style Loss : 0.058350 Content Loss: 0.011225

run [2000]:
Style Loss : 0.058114 Content Loss: 0.011231

run [2050]:
Style Loss : 0.057913 Content Loss: 0.011250

run [2100]:
Style Loss : 0.057640 Content Loss: 0.011264

run [2150]:
Style Loss : 0.057451 Content Loss: 0.011289

run [2200]:
Style Loss : 0.057634 Content Loss: 0.011325

run [2250]:
Style Loss : 0.058110 Content Loss: 0.011453

run [2300]:
Style Loss : 0.056569 Content Loss: 0.011383

run [2350]:
Style Loss : 0.056167 Content Loss: 0.011405

run [2400]:
Style Loss : 0.055864 Content Loss: 0.011423

run [2450]:
Style Loss : 0.055582 Content Loss: 0.011461

run [2500]:
Style Loss : 0.055330 Content Loss: 0.011501

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.804674 Content Loss: 0.001904

run [100]:
Style Loss : 1.022514 Content Loss: 0.002711

run [150]:
Style Loss : 0.757465 Content Loss: 0.003761

run [200]:
Style Loss : 0.621896 Content Loss: 0.004657

run [250]:
Style Loss : 0.530803 Content Loss: 0.005452

run [300]:
Style Loss : 0.463608 Content Loss: 0.006102

run [350]:
Style Loss : 0.416839 Content Loss: 0.006761

run [400]:
Style Loss : 0.386237 Content Loss: 0.007400

run [450]:
Style Loss : 0.362099 Content Loss: 0.008045

run [500]:
Style Loss : 0.342134 Content Loss: 0.008607

run [550]:
Style Loss : 0.327219 Content Loss: 0.009113

run [600]:
Style Loss : 0.314758 Content Loss: 0.009601

run [650]:
Style Loss : 0.304512 Content Loss: 0.010006

run [700]:
Style Loss : 0.296086 Content Loss: 0.010358

run [750]:
Style Loss : 0.289355 Content Loss: 0.010636

run [800]:
Style Loss : 0.283791 Content Loss: 0.010866

run [850]:
Style Loss : 0.279344 Content Loss: 0.011079

run [900]:
Style Loss : 0.275284 Content Loss: 0.011276

run [950]:
Style Loss : 0.271745 Content Loss: 0.011437

run [1000]:
Style Loss : 0.268389 Content Loss: 0.011571

run [1050]:
Style Loss : 0.265306 Content Loss: 0.011719

run [1100]:
Style Loss : 0.262446 Content Loss: 0.011852

run [1150]:
Style Loss : 0.259888 Content Loss: 0.011976

run [1200]:
Style Loss : 0.257485 Content Loss: 0.012097

run [1250]:
Style Loss : 0.255332 Content Loss: 0.012218

run [1300]:
Style Loss : 0.253472 Content Loss: 0.012332

run [1350]:
Style Loss : 0.251818 Content Loss: 0.012440

run [1400]:
Style Loss : 0.250268 Content Loss: 0.012539

run [1450]:
Style Loss : 0.248942 Content Loss: 0.012617

run [1500]:
Style Loss : 0.247725 Content Loss: 0.012698

run [1550]:
Style Loss : 0.246554 Content Loss: 0.012777

run [1600]:
Style Loss : 0.245462 Content Loss: 0.012855

run [1650]:
Style Loss : 0.244328 Content Loss: 0.012937

run [1700]:
Style Loss : 0.243212 Content Loss: 0.013017

run [1750]:
Style Loss : 0.242142 Content Loss: 0.013075

run [1800]:
Style Loss : 0.241129 Content Loss: 0.013148

run [1850]:
Style Loss : 0.240175 Content Loss: 0.013214

run [1900]:
Style Loss : 0.239275 Content Loss: 0.013286

run [1950]:
Style Loss : 0.238404 Content Loss: 0.013343

run [2000]:
Style Loss : 0.237648 Content Loss: 0.013393

run [2050]:
Style Loss : 0.236923 Content Loss: 0.013442

run [2100]:
Style Loss : 0.236205 Content Loss: 0.013489

run [2150]:
Style Loss : 0.235526 Content Loss: 0.013534

run [2200]:
Style Loss : 0.234865 Content Loss: 0.013576

run [2250]:
Style Loss : 0.234261 Content Loss: 0.013616

run [2300]:
Style Loss : 0.233709 Content Loss: 0.013656

run [2350]:
Style Loss : 0.233118 Content Loss: 0.013683

run [2400]:
Style Loss : 0.232536 Content Loss: 0.013722

run [2450]:
Style Loss : 0.231969 Content Loss: 0.013757

run [2500]:
Style Loss : 0.231351 Content Loss: 0.013801

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.661997 Content Loss: 0.004005

run [100]:
Style Loss : 0.879616 Content Loss: 0.007435

run [150]:
Style Loss : 0.628019 Content Loss: 0.009634

run [200]:
Style Loss : 0.505164 Content Loss: 0.011213

run [250]:
Style Loss : 0.439593 Content Loss: 0.012381

run [300]:
Style Loss : 0.398171 Content Loss: 0.013286

run [350]:
Style Loss : 0.362860 Content Loss: 0.013906

run [400]:
Style Loss : 0.336497 Content Loss: 0.014458

run [450]:
Style Loss : 0.315719 Content Loss: 0.014843

run [500]:
Style Loss : 0.299116 Content Loss: 0.015211

run [550]:
Style Loss : 0.286425 Content Loss: 0.015514

run [600]:
Style Loss : 0.276204 Content Loss: 0.015792

run [650]:
Style Loss : 0.267586 Content Loss: 0.016107

run [700]:
Style Loss : 0.260241 Content Loss: 0.016404

run [750]:
Style Loss : 0.253825 Content Loss: 0.016683

run [800]:
Style Loss : 0.247989 Content Loss: 0.016961

run [850]:
Style Loss : 0.242846 Content Loss: 0.017235

run [900]:
Style Loss : 0.238399 Content Loss: 0.017473

run [950]:
Style Loss : 0.234330 Content Loss: 0.017674

run [1000]:
Style Loss : 0.230755 Content Loss: 0.017855

run [1050]:
Style Loss : 0.227739 Content Loss: 0.018021

run [1100]:
Style Loss : 0.225020 Content Loss: 0.018191

run [1150]:
Style Loss : 0.222417 Content Loss: 0.018319

run [1200]:
Style Loss : 0.219933 Content Loss: 0.018442

run [1250]:
Style Loss : 0.217585 Content Loss: 0.018564

run [1300]:
Style Loss : 0.215531 Content Loss: 0.018669

run [1350]:
Style Loss : 0.213628 Content Loss: 0.018771

run [1400]:
Style Loss : 0.211945 Content Loss: 0.018863

run [1450]:
Style Loss : 0.210472 Content Loss: 0.018945

run [1500]:
Style Loss : 0.209233 Content Loss: 0.019008

run [1550]:
Style Loss : 0.208039 Content Loss: 0.019079

run [1600]:
Style Loss : 0.206919 Content Loss: 0.019150

run [1650]:
Style Loss : 0.205891 Content Loss: 0.019216

run [1700]:
Style Loss : 0.204923 Content Loss: 0.019277

run [1750]:
Style Loss : 0.203969 Content Loss: 0.019337

run [1800]:
Style Loss : 0.203127 Content Loss: 0.019389

run [1850]:
Style Loss : 0.202383 Content Loss: 0.019435

run [1900]:
Style Loss : 0.201652 Content Loss: 0.019485

run [1950]:
Style Loss : 0.200637 Content Loss: 0.019547

run [2000]:
Style Loss : 0.199379 Content Loss: 0.019606

run [2050]:
Style Loss : 0.198487 Content Loss: 0.019655

run [2100]:
Style Loss : 0.197654 Content Loss: 0.019694

run [2150]:
Style Loss : 0.196873 Content Loss: 0.019742

run [2200]:
Style Loss : 0.196135 Content Loss: 0.019784

run [2250]:
Style Loss : 0.195425 Content Loss: 0.019828

run [2300]:
Style Loss : 0.194786 Content Loss: 0.019858

run [2350]:
Style Loss : 0.194224 Content Loss: 0.019891

run [2400]:
Style Loss : 0.193713 Content Loss: 0.019921

run [2450]:
Style Loss : 0.193225 Content Loss: 0.019950

run [2500]:
Style Loss : 0.192752 Content Loss: 0.019976

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.371314 Content Loss: 0.009639

run [100]:
Style Loss : 0.725444 Content Loss: 0.011170

run [150]:
Style Loss : 0.539072 Content Loss: 0.012367

run [200]:
Style Loss : 0.435169 Content Loss: 0.013458

run [250]:
Style Loss : 0.369213 Content Loss: 0.014457

run [300]:
Style Loss : 0.317656 Content Loss: 0.015177

run [350]:
Style Loss : 0.282134 Content Loss: 0.015856

run [400]:
Style Loss : 0.257974 Content Loss: 0.016505

run [450]:
Style Loss : 0.237918 Content Loss: 0.017075

run [500]:
Style Loss : 0.222527 Content Loss: 0.017582

run [550]:
Style Loss : 0.210089 Content Loss: 0.018007

run [600]:
Style Loss : 0.200013 Content Loss: 0.018364

run [650]:
Style Loss : 0.192213 Content Loss: 0.018661

run [700]:
Style Loss : 0.185924 Content Loss: 0.018928

run [750]:
Style Loss : 0.180560 Content Loss: 0.019150

run [800]:
Style Loss : 0.175710 Content Loss: 0.019362

run [850]:
Style Loss : 0.171103 Content Loss: 0.019535

run [900]:
Style Loss : 0.166664 Content Loss: 0.019713

run [950]:
Style Loss : 0.162689 Content Loss: 0.019874

run [1000]:
Style Loss : 0.159267 Content Loss: 0.019980

run [1050]:
Style Loss : 0.156149 Content Loss: 0.020103

run [1100]:
Style Loss : 0.153083 Content Loss: 0.020240

run [1150]:
Style Loss : 0.150305 Content Loss: 0.020364

run [1200]:
Style Loss : 0.147681 Content Loss: 0.020484

run [1250]:
Style Loss : 0.145126 Content Loss: 0.020590

run [1300]:
Style Loss : 0.142760 Content Loss: 0.020698

run [1350]:
Style Loss : 0.140485 Content Loss: 0.020798

run [1400]:
Style Loss : 0.138419 Content Loss: 0.020894

run [1450]:
Style Loss : 0.136473 Content Loss: 0.021009

run [1500]:
Style Loss : 0.134574 Content Loss: 0.021113

run [1550]:
Style Loss : 0.132684 Content Loss: 0.021216

run [1600]:
Style Loss : 0.130999 Content Loss: 0.021302

run [1650]:
Style Loss : 0.129407 Content Loss: 0.021395

run [1700]:
Style Loss : 0.127919 Content Loss: 0.021484

run [1750]:
Style Loss : 0.126477 Content Loss: 0.021579

run [1800]:
Style Loss : 0.125054 Content Loss: 0.021671

run [1850]:
Style Loss : 0.123581 Content Loss: 0.021755

run [1900]:
Style Loss : 0.122133 Content Loss: 0.021850

run [1950]:
Style Loss : 0.120778 Content Loss: 0.021943

run [2000]:
Style Loss : 0.119467 Content Loss: 0.022038

run [2050]:
Style Loss : 0.118284 Content Loss: 0.022120

run [2100]:
Style Loss : 0.117156 Content Loss: 0.022213

run [2150]:
Style Loss : 0.116078 Content Loss: 0.022305

run [2200]:
Style Loss : 0.115113 Content Loss: 0.022387

run [2250]:
Style Loss : 0.114187 Content Loss: 0.022464

run [2300]:
Style Loss : 0.113222 Content Loss: 0.022528

run [2350]:
Style Loss : 0.112293 Content Loss: 0.022595

run [2400]:
Style Loss : 0.111425 Content Loss: 0.022657

run [2450]:
Style Loss : 0.110593 Content Loss: 0.022713

run [2500]:
Style Loss : 0.109750 Content Loss: 0.022774

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.679291 Content Loss: 0.005144

run [100]:
Style Loss : 1.396265 Content Loss: 0.009374

run [150]:
Style Loss : 0.992723 Content Loss: 0.011937

run [200]:
Style Loss : 0.796799 Content Loss: 0.013502

run [250]:
Style Loss : 0.672846 Content Loss: 0.014756

run [300]:
Style Loss : 0.591227 Content Loss: 0.015519

run [350]:
Style Loss : 0.533235 Content Loss: 0.016159

run [400]:
Style Loss : 0.493798 Content Loss: 0.016729

run [450]:
Style Loss : 0.464604 Content Loss: 0.017153

run [500]:
Style Loss : 0.440893 Content Loss: 0.017566

run [550]:
Style Loss : 0.421761 Content Loss: 0.017865

run [600]:
Style Loss : 0.404405 Content Loss: 0.018144

run [650]:
Style Loss : 0.389674 Content Loss: 0.018412

run [700]:
Style Loss : 0.377420 Content Loss: 0.018635

run [750]:
Style Loss : 0.368272 Content Loss: 0.018797

run [800]:
Style Loss : 0.360187 Content Loss: 0.018931

run [850]:
Style Loss : 0.352362 Content Loss: 0.019106

run [900]:
Style Loss : 0.344952 Content Loss: 0.019272

run [950]:
Style Loss : 0.338043 Content Loss: 0.019416

run [1000]:
Style Loss : 0.332188 Content Loss: 0.019561

run [1050]:
Style Loss : 0.326626 Content Loss: 0.019691

run [1100]:
Style Loss : 0.321785 Content Loss: 0.019824

run [1150]:
Style Loss : 0.317550 Content Loss: 0.019947

run [1200]:
Style Loss : 0.313802 Content Loss: 0.020059

run [1250]:
Style Loss : 0.310542 Content Loss: 0.020177

run [1300]:
Style Loss : 0.307451 Content Loss: 0.020300

run [1350]:
Style Loss : 0.304704 Content Loss: 0.020421

run [1400]:
Style Loss : 0.302105 Content Loss: 0.020535

run [1450]:
Style Loss : 0.299808 Content Loss: 0.020638

run [1500]:
Style Loss : 0.297759 Content Loss: 0.020727

run [1550]:
Style Loss : 0.295749 Content Loss: 0.020816

run [1600]:
Style Loss : 0.293864 Content Loss: 0.020910

run [1650]:
Style Loss : 0.291728 Content Loss: 0.020999

run [1700]:
Style Loss : 0.289437 Content Loss: 0.021097

run [1750]:
Style Loss : 0.287226 Content Loss: 0.021191

run [1800]:
Style Loss : 0.285061 Content Loss: 0.021287

run [1850]:
Style Loss : 0.282807 Content Loss: 0.021396

run [1900]:
Style Loss : 0.280647 Content Loss: 0.021500

run [1950]:
Style Loss : 0.278545 Content Loss: 0.021607

run [2000]:
Style Loss : 0.276351 Content Loss: 0.021724

run [2050]:
Style Loss : 0.274146 Content Loss: 0.021839

run [2100]:
Style Loss : 0.271937 Content Loss: 0.021945

run [2150]:
Style Loss : 0.269785 Content Loss: 0.022051

run [2200]:
Style Loss : 0.267690 Content Loss: 0.022150

run [2250]:
Style Loss : 0.265499 Content Loss: 0.022261

run [2300]:
Style Loss : 0.262834 Content Loss: 0.022384

run [2350]:
Style Loss : 0.260430 Content Loss: 0.022482

run [2400]:
Style Loss : 0.258272 Content Loss: 0.022569

run [2450]:
Style Loss : 0.256104 Content Loss: 0.022657

run [2500]:
Style Loss : 0.254123 Content Loss: 0.022739

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.724299 Content Loss: 0.016211

run [100]:
Style Loss : 0.400672 Content Loss: 0.016135

run [150]:
Style Loss : 0.304290 Content Loss: 0.016466

run [200]:
Style Loss : 0.241866 Content Loss: 0.016764

run [250]:
Style Loss : 0.211077 Content Loss: 0.016991

run [300]:
Style Loss : 0.191232 Content Loss: 0.017166

run [350]:
Style Loss : 0.177899 Content Loss: 0.017370

run [400]:
Style Loss : 0.168175 Content Loss: 0.017550

run [450]:
Style Loss : 0.160656 Content Loss: 0.017695

run [500]:
Style Loss : 0.154620 Content Loss: 0.017851

run [550]:
Style Loss : 0.149345 Content Loss: 0.018005

run [600]:
Style Loss : 0.145152 Content Loss: 0.018146

run [650]:
Style Loss : 0.141354 Content Loss: 0.018266

run [700]:
Style Loss : 0.138312 Content Loss: 0.018363

run [750]:
Style Loss : 0.135637 Content Loss: 0.018454

run [800]:
Style Loss : 0.133492 Content Loss: 0.018512

run [850]:
Style Loss : 0.131738 Content Loss: 0.018561

run [900]:
Style Loss : 0.129930 Content Loss: 0.018639

run [950]:
Style Loss : 0.128447 Content Loss: 0.018691

run [1000]:
Style Loss : 0.127143 Content Loss: 0.018741

run [1050]:
Style Loss : 0.126068 Content Loss: 0.018772

run [1100]:
Style Loss : 0.125123 Content Loss: 0.018809

run [1150]:
Style Loss : 0.124292 Content Loss: 0.018841

run [1200]:
Style Loss : 0.123532 Content Loss: 0.018872

run [1250]:
Style Loss : 0.122841 Content Loss: 0.018897

run [1300]:
Style Loss : 0.122192 Content Loss: 0.018922

run [1350]:
Style Loss : 0.121530 Content Loss: 0.018939

run [1400]:
Style Loss : 0.120786 Content Loss: 0.018966

run [1450]:
Style Loss : 0.119809 Content Loss: 0.018998

run [1500]:
Style Loss : 0.119000 Content Loss: 0.019023

run [1550]:
Style Loss : 0.118317 Content Loss: 0.019041

run [1600]:
Style Loss : 0.117712 Content Loss: 0.019052

run [1650]:
Style Loss : 0.117205 Content Loss: 0.019059

run [1700]:
Style Loss : 0.116755 Content Loss: 0.019064

run [1750]:
Style Loss : 0.116352 Content Loss: 0.019068

run [1800]:
Style Loss : 0.116018 Content Loss: 0.019071

run [1850]:
Style Loss : 0.115713 Content Loss: 0.019066

run [1900]:
Style Loss : 0.115432 Content Loss: 0.019059

run [1950]:
Style Loss : 0.115153 Content Loss: 0.019051

run [2000]:
Style Loss : 0.114868 Content Loss: 0.019049

run [2050]:
Style Loss : 0.114592 Content Loss: 0.019044

run [2100]:
Style Loss : 0.114329 Content Loss: 0.019046

run [2150]:
Style Loss : 0.114081 Content Loss: 0.019047

run [2200]:
Style Loss : 0.113671 Content Loss: 0.019056

run [2250]:
Style Loss : 0.113316 Content Loss: 0.019061

run [2300]:
Style Loss : 0.112984 Content Loss: 0.019060

run [2350]:
Style Loss : 0.112622 Content Loss: 0.019067

run [2400]:
Style Loss : 0.112321 Content Loss: 0.019068

run [2450]:
Style Loss : 0.112045 Content Loss: 0.019070

run [2500]:
Style Loss : 0.111744 Content Loss: 0.019075

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.504320 Content Loss: 0.018623

run [100]:
Style Loss : 0.301294 Content Loss: 0.019374

run [150]:
Style Loss : 0.240056 Content Loss: 0.020364

run [200]:
Style Loss : 0.209206 Content Loss: 0.021355

run [250]:
Style Loss : 0.189428 Content Loss: 0.022093

run [300]:
Style Loss : 0.177042 Content Loss: 0.022682

run [350]:
Style Loss : 0.166839 Content Loss: 0.023174

run [400]:
Style Loss : 0.160335 Content Loss: 0.023556

run [450]:
Style Loss : 0.155531 Content Loss: 0.023845

run [500]:
Style Loss : 0.151677 Content Loss: 0.024029

run [550]:
Style Loss : 0.148951 Content Loss: 0.024168

run [600]:
Style Loss : 0.145408 Content Loss: 0.024314

run [650]:
Style Loss : 0.142996 Content Loss: 0.024407

run [700]:
Style Loss : 0.141174 Content Loss: 0.024487

run [750]:
Style Loss : 0.139532 Content Loss: 0.024540

run [800]:
Style Loss : 0.138149 Content Loss: 0.024582

run [850]:
Style Loss : 0.136940 Content Loss: 0.024619

run [900]:
Style Loss : 0.135772 Content Loss: 0.024662

run [950]:
Style Loss : 0.134709 Content Loss: 0.024707

run [1000]:
Style Loss : 0.133870 Content Loss: 0.024730

run [1050]:
Style Loss : 0.133133 Content Loss: 0.024745

run [1100]:
Style Loss : 0.132425 Content Loss: 0.024773

run [1150]:
Style Loss : 0.131751 Content Loss: 0.024802

run [1200]:
Style Loss : 0.131128 Content Loss: 0.024841

run [1250]:
Style Loss : 0.130529 Content Loss: 0.024880

run [1300]:
Style Loss : 0.129987 Content Loss: 0.024913

run [1350]:
Style Loss : 0.129183 Content Loss: 0.024944

run [1400]:
Style Loss : 0.128497 Content Loss: 0.024969

run [1450]:
Style Loss : 0.127914 Content Loss: 0.024982

run [1500]:
Style Loss : 0.127420 Content Loss: 0.024998

run [1550]:
Style Loss : 0.126968 Content Loss: 0.025015

run [1600]:
Style Loss : 0.126526 Content Loss: 0.025029

run [1650]:
Style Loss : 0.126143 Content Loss: 0.025041

run [1700]:
Style Loss : 0.125795 Content Loss: 0.025051

run [1750]:
Style Loss : 0.125463 Content Loss: 0.025065

run [1800]:
Style Loss : 0.125134 Content Loss: 0.025080

run [1850]:
Style Loss : 0.124857 Content Loss: 0.025081

run [1900]:
Style Loss : 0.124591 Content Loss: 0.025087

run [1950]:
Style Loss : 0.124323 Content Loss: 0.025095

run [2000]:
Style Loss : 0.124086 Content Loss: 0.025101

run [2050]:
Style Loss : 0.123856 Content Loss: 0.025099

run [2100]:
Style Loss : 0.123640 Content Loss: 0.025103

run [2150]:
Style Loss : 0.123434 Content Loss: 0.025110

run [2200]:
Style Loss : 0.123226 Content Loss: 0.025112

run [2250]:
Style Loss : 0.123025 Content Loss: 0.025118

run [2300]:
Style Loss : 0.122808 Content Loss: 0.025123

run [2350]:
Style Loss : 0.122601 Content Loss: 0.025129

run [2400]:
Style Loss : 0.122385 Content Loss: 0.025135

run [2450]:
Style Loss : 0.122178 Content Loss: 0.025140

run [2500]:
Style Loss : 0.121953 Content Loss: 0.025147

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.863213 Content Loss: 0.007659

run [100]:
Style Loss : 1.070299 Content Loss: 0.010111

run [150]:
Style Loss : 0.832853 Content Loss: 0.012018

run [200]:
Style Loss : 0.695914 Content Loss: 0.013631

run [250]:
Style Loss : 0.616947 Content Loss: 0.014998

run [300]:
Style Loss : 0.568720 Content Loss: 0.016279

run [350]:
Style Loss : 0.531593 Content Loss: 0.017245

run [400]:
Style Loss : 0.502783 Content Loss: 0.018036

run [450]:
Style Loss : 0.479848 Content Loss: 0.018773

run [500]:
Style Loss : 0.461172 Content Loss: 0.019302

run [550]:
Style Loss : 0.445653 Content Loss: 0.019800

run [600]:
Style Loss : 0.432964 Content Loss: 0.020263

run [650]:
Style Loss : 0.422251 Content Loss: 0.020702

run [700]:
Style Loss : 0.412794 Content Loss: 0.021122

run [750]:
Style Loss : 0.404309 Content Loss: 0.021505

run [800]:
Style Loss : 0.397132 Content Loss: 0.021857

run [850]:
Style Loss : 0.391139 Content Loss: 0.022149

run [900]:
Style Loss : 0.385249 Content Loss: 0.022401

run [950]:
Style Loss : 0.379997 Content Loss: 0.022661

run [1000]:
Style Loss : 0.373932 Content Loss: 0.022900

run [1050]:
Style Loss : 0.368689 Content Loss: 0.023105

run [1100]:
Style Loss : 0.363007 Content Loss: 0.023258

run [1150]:
Style Loss : 0.358760 Content Loss: 0.023405

run [1200]:
Style Loss : 0.354850 Content Loss: 0.023534

run [1250]:
Style Loss : 0.350964 Content Loss: 0.023662

run [1300]:
Style Loss : 0.347767 Content Loss: 0.023787

run [1350]:
Style Loss : 0.344817 Content Loss: 0.023890

run [1400]:
Style Loss : 0.342099 Content Loss: 0.024004

run [1450]:
Style Loss : 0.339434 Content Loss: 0.024114

run [1500]:
Style Loss : 0.336923 Content Loss: 0.024217

run [1550]:
Style Loss : 0.334750 Content Loss: 0.024310

run [1600]:
Style Loss : 0.332752 Content Loss: 0.024408

run [1650]:
Style Loss : 0.330818 Content Loss: 0.024486

run [1700]:
Style Loss : 0.329006 Content Loss: 0.024541

run [1750]:
Style Loss : 0.327292 Content Loss: 0.024605

run [1800]:
Style Loss : 0.325784 Content Loss: 0.024665

run [1850]:
Style Loss : 0.324364 Content Loss: 0.024721

run [1900]:
Style Loss : 0.323015 Content Loss: 0.024763

run [1950]:
Style Loss : 0.321762 Content Loss: 0.024811

run [2000]:
Style Loss : 0.320499 Content Loss: 0.024839

run [2050]:
Style Loss : 0.319231 Content Loss: 0.024878

run [2100]:
Style Loss : 0.318083 Content Loss: 0.024898

run [2150]:
Style Loss : 0.317022 Content Loss: 0.024917

run [2200]:
Style Loss : 0.316047 Content Loss: 0.024943

run [2250]:
Style Loss : 0.315159 Content Loss: 0.024979

run [2300]:
Style Loss : 0.314281 Content Loss: 0.025011

run [2350]:
Style Loss : 0.313162 Content Loss: 0.025032

run [2400]:
Style Loss : 0.312112 Content Loss: 0.025057

run [2450]:
Style Loss : 0.311100 Content Loss: 0.025083

run [2500]:
Style Loss : 0.310233 Content Loss: 0.025107

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.461767 Content Loss: 0.010534

run [100]:
Style Loss : 0.723457 Content Loss: 0.011968

run [150]:
Style Loss : 0.515910 Content Loss: 0.013377

run [200]:
Style Loss : 0.421766 Content Loss: 0.014441

run [250]:
Style Loss : 0.365207 Content Loss: 0.015382

run [300]:
Style Loss : 0.327447 Content Loss: 0.016214

run [350]:
Style Loss : 0.299258 Content Loss: 0.016982

run [400]:
Style Loss : 0.276480 Content Loss: 0.017688

run [450]:
Style Loss : 0.258168 Content Loss: 0.018251

run [500]:
Style Loss : 0.243120 Content Loss: 0.018750

run [550]:
Style Loss : 0.232178 Content Loss: 0.019171

run [600]:
Style Loss : 0.223399 Content Loss: 0.019481

run [650]:
Style Loss : 0.216905 Content Loss: 0.019739

run [700]:
Style Loss : 0.211372 Content Loss: 0.019990

run [750]:
Style Loss : 0.206803 Content Loss: 0.020176

run [800]:
Style Loss : 0.202359 Content Loss: 0.020395

run [850]:
Style Loss : 0.198451 Content Loss: 0.020592

run [900]:
Style Loss : 0.194960 Content Loss: 0.020765

run [950]:
Style Loss : 0.191911 Content Loss: 0.020908

run [1000]:
Style Loss : 0.189312 Content Loss: 0.021043

run [1050]:
Style Loss : 0.186895 Content Loss: 0.021185

run [1100]:
Style Loss : 0.184606 Content Loss: 0.021330

run [1150]:
Style Loss : 0.182532 Content Loss: 0.021461

run [1200]:
Style Loss : 0.180522 Content Loss: 0.021599

run [1250]:
Style Loss : 0.178802 Content Loss: 0.021714

run [1300]:
Style Loss : 0.177141 Content Loss: 0.021838

run [1350]:
Style Loss : 0.175661 Content Loss: 0.021932

run [1400]:
Style Loss : 0.174114 Content Loss: 0.022033

run [1450]:
Style Loss : 0.172702 Content Loss: 0.022133

run [1500]:
Style Loss : 0.171401 Content Loss: 0.022220

run [1550]:
Style Loss : 0.170221 Content Loss: 0.022300

run [1600]:
Style Loss : 0.169305 Content Loss: 0.022371

run [1650]:
Style Loss : 0.168392 Content Loss: 0.022453

run [1700]:
Style Loss : 0.167495 Content Loss: 0.022528

run [1750]:
Style Loss : 0.166618 Content Loss: 0.022612

run [1800]:
Style Loss : 0.165814 Content Loss: 0.022685

run [1850]:
Style Loss : 0.164980 Content Loss: 0.022751

run [1900]:
Style Loss : 0.164173 Content Loss: 0.022815

run [1950]:
Style Loss : 0.163421 Content Loss: 0.022872

run [2000]:
Style Loss : 0.162729 Content Loss: 0.022926

run [2050]:
Style Loss : 0.162040 Content Loss: 0.022983

run [2100]:
Style Loss : 0.161378 Content Loss: 0.023030

run [2150]:
Style Loss : 0.160730 Content Loss: 0.023077

run [2200]:
Style Loss : 0.160047 Content Loss: 0.023124

run [2250]:
Style Loss : 0.159380 Content Loss: 0.023170

run [2300]:
Style Loss : 0.158740 Content Loss: 0.023222

run [2350]:
Style Loss : 0.158196 Content Loss: 0.023257

run [2400]:
Style Loss : 0.157661 Content Loss: 0.023293

run [2450]:
Style Loss : 0.157108 Content Loss: 0.023335

run [2500]:
Style Loss : 0.156555 Content Loss: 0.023379

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.001956 Content Loss: 0.014578

run [100]:
Style Loss : 0.601621 Content Loss: 0.015655

run [150]:
Style Loss : 0.463677 Content Loss: 0.017360

run [200]:
Style Loss : 0.389967 Content Loss: 0.018940

run [250]:
Style Loss : 0.345883 Content Loss: 0.020243

run [300]:
Style Loss : 0.317569 Content Loss: 0.021067

run [350]:
Style Loss : 0.297782 Content Loss: 0.021613

run [400]:
Style Loss : 0.282278 Content Loss: 0.021920

run [450]:
Style Loss : 0.270695 Content Loss: 0.022145

run [500]:
Style Loss : 0.261700 Content Loss: 0.022378

run [550]:
Style Loss : 0.255258 Content Loss: 0.022570

run [600]:
Style Loss : 0.249869 Content Loss: 0.022762

run [650]:
Style Loss : 0.245301 Content Loss: 0.022918

run [700]:
Style Loss : 0.241143 Content Loss: 0.023057

run [750]:
Style Loss : 0.237454 Content Loss: 0.023223

run [800]:
Style Loss : 0.234187 Content Loss: 0.023353

run [850]:
Style Loss : 0.231051 Content Loss: 0.023497

run [900]:
Style Loss : 0.227921 Content Loss: 0.023636

run [950]:
Style Loss : 0.224905 Content Loss: 0.023785

run [1000]:
Style Loss : 0.221913 Content Loss: 0.023934

run [1050]:
Style Loss : 0.219238 Content Loss: 0.024079

run [1100]:
Style Loss : 0.216706 Content Loss: 0.024226

run [1150]:
Style Loss : 0.214266 Content Loss: 0.024363

run [1200]:
Style Loss : 0.211982 Content Loss: 0.024502

run [1250]:
Style Loss : 0.209715 Content Loss: 0.024657

run [1300]:
Style Loss : 0.207390 Content Loss: 0.024819

run [1350]:
Style Loss : 0.205288 Content Loss: 0.024957

run [1400]:
Style Loss : 0.203384 Content Loss: 0.025083

run [1450]:
Style Loss : 0.201684 Content Loss: 0.025194

run [1500]:
Style Loss : 0.200031 Content Loss: 0.025306

run [1550]:
Style Loss : 0.198504 Content Loss: 0.025422

run [1600]:
Style Loss : 0.196970 Content Loss: 0.025517

run [1650]:
Style Loss : 0.195533 Content Loss: 0.025607

run [1700]:
Style Loss : 0.194160 Content Loss: 0.025691

run [1750]:
Style Loss : 0.192657 Content Loss: 0.025805

run [1800]:
Style Loss : 0.190726 Content Loss: 0.025915

run [1850]:
Style Loss : 0.188945 Content Loss: 0.025994

run [1900]:
Style Loss : 0.187405 Content Loss: 0.026089

run [1950]:
Style Loss : 0.185949 Content Loss: 0.026155

run [2000]:
Style Loss : 0.184765 Content Loss: 0.026204

run [2050]:
Style Loss : 0.183725 Content Loss: 0.026262

run [2100]:
Style Loss : 0.182834 Content Loss: 0.026322

run [2150]:
Style Loss : 0.181938 Content Loss: 0.026383

run [2200]:
Style Loss : 0.181039 Content Loss: 0.026444

run [2250]:
Style Loss : 0.180220 Content Loss: 0.026491

run [2300]:
Style Loss : 0.179484 Content Loss: 0.026534

run [2350]:
Style Loss : 0.178798 Content Loss: 0.026578

run [2400]:
Style Loss : 0.178165 Content Loss: 0.026623

run [2450]:
Style Loss : 0.177479 Content Loss: 0.026644

run [2500]:
Style Loss : 0.176915 Content Loss: 0.026664

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.042982 Content Loss: 0.012492

run [100]:
Style Loss : 0.492842 Content Loss: 0.013382

run [150]:
Style Loss : 0.347637 Content Loss: 0.014379

run [200]:
Style Loss : 0.277116 Content Loss: 0.015371

run [250]:
Style Loss : 0.235200 Content Loss: 0.016081

run [300]:
Style Loss : 0.206262 Content Loss: 0.016749

run [350]:
Style Loss : 0.184797 Content Loss: 0.017221

run [400]:
Style Loss : 0.169105 Content Loss: 0.017604

run [450]:
Style Loss : 0.157320 Content Loss: 0.017951

run [500]:
Style Loss : 0.147519 Content Loss: 0.018241

run [550]:
Style Loss : 0.139566 Content Loss: 0.018499

run [600]:
Style Loss : 0.133528 Content Loss: 0.018713

run [650]:
Style Loss : 0.127304 Content Loss: 0.018908

run [700]:
Style Loss : 0.120176 Content Loss: 0.019028

run [750]:
Style Loss : 0.114689 Content Loss: 0.019145

run [800]:
Style Loss : 0.110519 Content Loss: 0.019270

run [850]:
Style Loss : 0.107250 Content Loss: 0.019382

run [900]:
Style Loss : 0.103802 Content Loss: 0.019467

run [950]:
Style Loss : 0.101204 Content Loss: 0.019550

run [1000]:
Style Loss : 0.099167 Content Loss: 0.019625

run [1050]:
Style Loss : 0.097483 Content Loss: 0.019687

run [1100]:
Style Loss : 0.095929 Content Loss: 0.019737

run [1150]:
Style Loss : 0.094532 Content Loss: 0.019784

run [1200]:
Style Loss : 0.093379 Content Loss: 0.019816

run [1250]:
Style Loss : 0.092251 Content Loss: 0.019853

run [1300]:
Style Loss : 0.091227 Content Loss: 0.019893

run [1350]:
Style Loss : 0.090158 Content Loss: 0.019926

run [1400]:
Style Loss : 0.089108 Content Loss: 0.019963

run [1450]:
Style Loss : 0.088139 Content Loss: 0.020003

run [1500]:
Style Loss : 0.087185 Content Loss: 0.020051

run [1550]:
Style Loss : 0.086202 Content Loss: 0.020097

run [1600]:
Style Loss : 0.085375 Content Loss: 0.020137

run [1650]:
Style Loss : 0.084622 Content Loss: 0.020172

run [1700]:
Style Loss : 0.083951 Content Loss: 0.020199

run [1750]:
Style Loss : 0.083284 Content Loss: 0.020224

run [1800]:
Style Loss : 0.082696 Content Loss: 0.020245

run [1850]:
Style Loss : 0.082187 Content Loss: 0.020265

run [1900]:
Style Loss : 0.081686 Content Loss: 0.020283

run [1950]:
Style Loss : 0.081240 Content Loss: 0.020300

run [2000]:
Style Loss : 0.080818 Content Loss: 0.020316

run [2050]:
Style Loss : 0.080446 Content Loss: 0.020332

run [2100]:
Style Loss : 0.080074 Content Loss: 0.020352

run [2150]:
Style Loss : 0.079705 Content Loss: 0.020369

run [2200]:
Style Loss : 0.079368 Content Loss: 0.020384

run [2250]:
Style Loss : 0.079078 Content Loss: 0.020398

run [2300]:
Style Loss : 0.078817 Content Loss: 0.020411

run [2350]:
Style Loss : 0.078568 Content Loss: 0.020424

run [2400]:
Style Loss : 0.078328 Content Loss: 0.020436

run [2450]:
Style Loss : 0.078077 Content Loss: 0.020448

run [2500]:
Style Loss : 0.077781 Content Loss: 0.020463

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.321407 Content Loss: 0.013021

run [100]:
Style Loss : 0.822002 Content Loss: 0.015505

run [150]:
Style Loss : 0.590442 Content Loss: 0.019502

run [200]:
Style Loss : 0.457748 Content Loss: 0.023294

run [250]:
Style Loss : 0.389615 Content Loss: 0.025695

run [300]:
Style Loss : 0.354061 Content Loss: 0.026920

run [350]:
Style Loss : 0.331307 Content Loss: 0.027587

run [400]:
Style Loss : 0.315323 Content Loss: 0.028010

run [450]:
Style Loss : 0.301981 Content Loss: 0.028407

run [500]:
Style Loss : 0.291389 Content Loss: 0.028743

run [550]:
Style Loss : 0.282828 Content Loss: 0.029071

run [600]:
Style Loss : 0.275683 Content Loss: 0.029261

run [650]:
Style Loss : 0.269883 Content Loss: 0.029467

run [700]:
Style Loss : 0.265108 Content Loss: 0.029672

run [750]:
Style Loss : 0.260301 Content Loss: 0.029864

run [800]:
Style Loss : 0.256086 Content Loss: 0.030051

run [850]:
Style Loss : 0.252481 Content Loss: 0.030215

run [900]:
Style Loss : 0.249260 Content Loss: 0.030400

run [950]:
Style Loss : 0.246477 Content Loss: 0.030614

run [1000]:
Style Loss : 0.243761 Content Loss: 0.030846

run [1050]:
Style Loss : 0.241095 Content Loss: 0.031096

run [1100]:
Style Loss : 0.238550 Content Loss: 0.031321

run [1150]:
Style Loss : 0.236002 Content Loss: 0.031553

run [1200]:
Style Loss : 0.233829 Content Loss: 0.031735

run [1250]:
Style Loss : 0.231751 Content Loss: 0.031959

run [1300]:
Style Loss : 0.229690 Content Loss: 0.032166

run [1350]:
Style Loss : 0.227446 Content Loss: 0.032439

run [1400]:
Style Loss : 0.225295 Content Loss: 0.032662

run [1450]:
Style Loss : 0.223549 Content Loss: 0.032882

run [1500]:
Style Loss : 0.221969 Content Loss: 0.033094

run [1550]:
Style Loss : 0.220658 Content Loss: 0.033269

run [1600]:
Style Loss : 0.219485 Content Loss: 0.033425

run [1650]:
Style Loss : 0.217842 Content Loss: 0.033586

run [1700]:
Style Loss : 0.217008 Content Loss: 0.033768

run [1750]:
Style Loss : 0.215680 Content Loss: 0.033877

run [1800]:
Style Loss : 0.214799 Content Loss: 0.034031

run [1850]:
Style Loss : 0.213707 Content Loss: 0.034196

run [1900]:
Style Loss : 0.212994 Content Loss: 0.034352

run [1950]:
Style Loss : 0.211888 Content Loss: 0.034449

run [2000]:
Style Loss : 0.210818 Content Loss: 0.034578

run [2050]:
Style Loss : 0.209911 Content Loss: 0.034663

run [2100]:
Style Loss : 0.208942 Content Loss: 0.034768

run [2150]:
Style Loss : 0.209561 Content Loss: 0.034960

run [2200]:
Style Loss : 0.207946 Content Loss: 0.034984

run [2250]:
Style Loss : 0.206906 Content Loss: 0.035059

run [2300]:
Style Loss : 0.206176 Content Loss: 0.035136

run [2350]:
Style Loss : 0.205791 Content Loss: 0.035215

run [2400]:
Style Loss : 0.205187 Content Loss: 0.035235

run [2450]:
Style Loss : 0.204250 Content Loss: 0.035279

run [2500]:
Style Loss : 0.205843 Content Loss: 0.035353

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.810497 Content Loss: 0.018924

run [100]:
Style Loss : 0.449218 Content Loss: 0.020448

run [150]:
Style Loss : 0.312303 Content Loss: 0.021990

run [200]:
Style Loss : 0.245362 Content Loss: 0.023282

run [250]:
Style Loss : 0.210209 Content Loss: 0.023695

run [300]:
Style Loss : 0.188554 Content Loss: 0.023895

run [350]:
Style Loss : 0.174585 Content Loss: 0.023972

run [400]:
Style Loss : 0.163866 Content Loss: 0.024026

run [450]:
Style Loss : 0.155966 Content Loss: 0.024069

run [500]:
Style Loss : 0.149760 Content Loss: 0.024135

run [550]:
Style Loss : 0.144202 Content Loss: 0.024188

run [600]:
Style Loss : 0.138911 Content Loss: 0.024243

run [650]:
Style Loss : 0.134320 Content Loss: 0.024314

run [700]:
Style Loss : 0.130278 Content Loss: 0.024356

run [750]:
Style Loss : 0.127044 Content Loss: 0.024357

run [800]:
Style Loss : 0.124245 Content Loss: 0.024366

run [850]:
Style Loss : 0.121769 Content Loss: 0.024354

run [900]:
Style Loss : 0.119546 Content Loss: 0.024345

run [950]:
Style Loss : 0.117675 Content Loss: 0.024341

run [1000]:
Style Loss : 0.115926 Content Loss: 0.024335

run [1050]:
Style Loss : 0.114447 Content Loss: 0.024307

run [1100]:
Style Loss : 0.113150 Content Loss: 0.024274

run [1150]:
Style Loss : 0.111264 Content Loss: 0.024265

run [1200]:
Style Loss : 0.109987 Content Loss: 0.024251

run [1250]:
Style Loss : 0.108852 Content Loss: 0.024240

run [1300]:
Style Loss : 0.107957 Content Loss: 0.024222

run [1350]:
Style Loss : 0.107090 Content Loss: 0.024201

run [1400]:
Style Loss : 0.106323 Content Loss: 0.024192

run [1450]:
Style Loss : 0.105665 Content Loss: 0.024174

run [1500]:
Style Loss : 0.105092 Content Loss: 0.024146

run [1550]:
Style Loss : 0.104548 Content Loss: 0.024121

run [1600]:
Style Loss : 0.104124 Content Loss: 0.024094

run [1650]:
Style Loss : 0.103711 Content Loss: 0.024062

run [1700]:
Style Loss : 0.103331 Content Loss: 0.024030

run [1750]:
Style Loss : 0.102974 Content Loss: 0.024010

run [1800]:
Style Loss : 0.102662 Content Loss: 0.023986

run [1850]:
Style Loss : 0.102383 Content Loss: 0.023967

run [1900]:
Style Loss : 0.102100 Content Loss: 0.023953

run [1950]:
Style Loss : 0.101828 Content Loss: 0.023940

run [2000]:
Style Loss : 0.101586 Content Loss: 0.023931

run [2050]:
Style Loss : 0.101348 Content Loss: 0.023920

run [2100]:
Style Loss : 0.101119 Content Loss: 0.023907

run [2150]:
Style Loss : 0.100891 Content Loss: 0.023899

run [2200]:
Style Loss : 0.100680 Content Loss: 0.023894

run [2250]:
Style Loss : 0.100480 Content Loss: 0.023890

run [2300]:
Style Loss : 0.100293 Content Loss: 0.023887

run [2350]:
Style Loss : 0.100116 Content Loss: 0.023879

run [2400]:
Style Loss : 0.099932 Content Loss: 0.023872

run [2450]:
Style Loss : 0.099770 Content Loss: 0.023863

run [2500]:
Style Loss : 0.099623 Content Loss: 0.023856

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.446814 Content Loss: 0.004233

run [100]:
Style Loss : 1.525142 Content Loss: 0.006792

run [150]:
Style Loss : 1.177259 Content Loss: 0.008704

run [200]:
Style Loss : 0.962687 Content Loss: 0.010026

run [250]:
Style Loss : 0.821745 Content Loss: 0.011179

run [300]:
Style Loss : 0.730796 Content Loss: 0.012176

run [350]:
Style Loss : 0.662754 Content Loss: 0.013179

run [400]:
Style Loss : 0.606729 Content Loss: 0.014072

run [450]:
Style Loss : 0.565940 Content Loss: 0.014938

run [500]:
Style Loss : 0.527571 Content Loss: 0.015867

run [550]:
Style Loss : 0.496254 Content Loss: 0.016704

run [600]:
Style Loss : 0.469851 Content Loss: 0.017457

run [650]:
Style Loss : 0.450340 Content Loss: 0.018164

run [700]:
Style Loss : 0.434292 Content Loss: 0.018785

run [750]:
Style Loss : 0.420819 Content Loss: 0.019319

run [800]:
Style Loss : 0.409659 Content Loss: 0.019755

run [850]:
Style Loss : 0.400938 Content Loss: 0.020133

run [900]:
Style Loss : 0.393742 Content Loss: 0.020431

run [950]:
Style Loss : 0.388133 Content Loss: 0.020705

run [1000]:
Style Loss : 0.383354 Content Loss: 0.020935

run [1050]:
Style Loss : 0.379232 Content Loss: 0.021135

run [1100]:
Style Loss : 0.375326 Content Loss: 0.021322

run [1150]:
Style Loss : 0.371200 Content Loss: 0.021484

run [1200]:
Style Loss : 0.367245 Content Loss: 0.021635

run [1250]:
Style Loss : 0.363602 Content Loss: 0.021771

run [1300]:
Style Loss : 0.360127 Content Loss: 0.021915

run [1350]:
Style Loss : 0.356563 Content Loss: 0.022041

run [1400]:
Style Loss : 0.353494 Content Loss: 0.022186

run [1450]:
Style Loss : 0.350792 Content Loss: 0.022317

run [1500]:
Style Loss : 0.348159 Content Loss: 0.022445

run [1550]:
Style Loss : 0.345714 Content Loss: 0.022575

run [1600]:
Style Loss : 0.343372 Content Loss: 0.022693

run [1650]:
Style Loss : 0.341067 Content Loss: 0.022805

run [1700]:
Style Loss : 0.338968 Content Loss: 0.022912

run [1750]:
Style Loss : 0.336795 Content Loss: 0.023033

run [1800]:
Style Loss : 0.334892 Content Loss: 0.023135

run [1850]:
Style Loss : 0.333182 Content Loss: 0.023239

run [1900]:
Style Loss : 0.331533 Content Loss: 0.023336

run [1950]:
Style Loss : 0.329989 Content Loss: 0.023426

run [2000]:
Style Loss : 0.328623 Content Loss: 0.023507

run [2050]:
Style Loss : 0.327334 Content Loss: 0.023585

run [2100]:
Style Loss : 0.326078 Content Loss: 0.023662

run [2150]:
Style Loss : 0.324925 Content Loss: 0.023729

run [2200]:
Style Loss : 0.323919 Content Loss: 0.023786

run [2250]:
Style Loss : 0.322907 Content Loss: 0.023841

run [2300]:
Style Loss : 0.321888 Content Loss: 0.023897

run [2350]:
Style Loss : 0.320889 Content Loss: 0.023960

run [2400]:
Style Loss : 0.319844 Content Loss: 0.024023

run [2450]:
Style Loss : 0.318845 Content Loss: 0.024081

run [2500]:
Style Loss : 0.317875 Content Loss: 0.024131

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.329885 Content Loss: 0.003738

run [100]:
Style Loss : 1.523199 Content Loss: 0.006291

run [150]:
Style Loss : 0.985455 Content Loss: 0.008915

run [200]:
Style Loss : 0.761997 Content Loss: 0.010546

run [250]:
Style Loss : 0.637691 Content Loss: 0.011824

run [300]:
Style Loss : 0.554425 Content Loss: 0.013003

run [350]:
Style Loss : 0.493523 Content Loss: 0.014063

run [400]:
Style Loss : 0.449400 Content Loss: 0.014797

run [450]:
Style Loss : 0.415305 Content Loss: 0.015497

run [500]:
Style Loss : 0.383195 Content Loss: 0.016057

run [550]:
Style Loss : 0.357473 Content Loss: 0.016534

run [600]:
Style Loss : 0.336791 Content Loss: 0.017068

run [650]:
Style Loss : 0.318207 Content Loss: 0.017632

run [700]:
Style Loss : 0.303357 Content Loss: 0.018166

run [750]:
Style Loss : 0.290715 Content Loss: 0.018658

run [800]:
Style Loss : 0.280901 Content Loss: 0.019044

run [850]:
Style Loss : 0.273306 Content Loss: 0.019382

run [900]:
Style Loss : 0.265853 Content Loss: 0.019696

run [950]:
Style Loss : 0.259404 Content Loss: 0.019997

run [1000]:
Style Loss : 0.253592 Content Loss: 0.020240

run [1050]:
Style Loss : 0.248260 Content Loss: 0.020476

run [1100]:
Style Loss : 0.242945 Content Loss: 0.020678

run [1150]:
Style Loss : 0.238156 Content Loss: 0.020842

run [1200]:
Style Loss : 0.233746 Content Loss: 0.020984

run [1250]:
Style Loss : 0.229539 Content Loss: 0.021124

run [1300]:
Style Loss : 0.225419 Content Loss: 0.021278

run [1350]:
Style Loss : 0.221661 Content Loss: 0.021436

run [1400]:
Style Loss : 0.217786 Content Loss: 0.021613

run [1450]:
Style Loss : 0.213996 Content Loss: 0.021767

run [1500]:
Style Loss : 0.210448 Content Loss: 0.021917

run [1550]:
Style Loss : 0.206977 Content Loss: 0.022051

run [1600]:
Style Loss : 0.203781 Content Loss: 0.022183

run [1650]:
Style Loss : 0.200730 Content Loss: 0.022312

run [1700]:
Style Loss : 0.197703 Content Loss: 0.022461

run [1750]:
Style Loss : 0.194812 Content Loss: 0.022608

run [1800]:
Style Loss : 0.191897 Content Loss: 0.022771

run [1850]:
Style Loss : 0.189144 Content Loss: 0.022935

run [1900]:
Style Loss : 0.186153 Content Loss: 0.023103

run [1950]:
Style Loss : 0.183059 Content Loss: 0.023272

run [2000]:
Style Loss : 0.180342 Content Loss: 0.023433

run [2050]:
Style Loss : 0.177453 Content Loss: 0.023634

run [2100]:
Style Loss : 0.174846 Content Loss: 0.023833

run [2150]:
Style Loss : 0.172489 Content Loss: 0.024010

run [2200]:
Style Loss : 0.170217 Content Loss: 0.024207

run [2250]:
Style Loss : 0.168102 Content Loss: 0.024390

run [2300]:
Style Loss : 0.166028 Content Loss: 0.024568

run [2350]:
Style Loss : 0.164197 Content Loss: 0.024732

run [2400]:
Style Loss : 0.162373 Content Loss: 0.024892

run [2450]:
Style Loss : 0.160633 Content Loss: 0.025035

run [2500]:
Style Loss : 0.158796 Content Loss: 0.025210

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.350835 Content Loss: 0.012898

run [100]:
Style Loss : 0.854064 Content Loss: 0.013647

run [150]:
Style Loss : 0.641601 Content Loss: 0.015187

run [200]:
Style Loss : 0.546206 Content Loss: 0.016336

run [250]:
Style Loss : 0.488768 Content Loss: 0.017266

run [300]:
Style Loss : 0.453057 Content Loss: 0.017921

run [350]:
Style Loss : 0.429944 Content Loss: 0.018389

run [400]:
Style Loss : 0.413382 Content Loss: 0.018788

run [450]:
Style Loss : 0.401306 Content Loss: 0.019138

run [500]:
Style Loss : 0.391880 Content Loss: 0.019485

run [550]:
Style Loss : 0.384138 Content Loss: 0.019772

run [600]:
Style Loss : 0.377918 Content Loss: 0.020017

run [650]:
Style Loss : 0.372449 Content Loss: 0.020257

run [700]:
Style Loss : 0.367275 Content Loss: 0.020483

run [750]:
Style Loss : 0.362578 Content Loss: 0.020713

run [800]:
Style Loss : 0.357833 Content Loss: 0.020926

run [850]:
Style Loss : 0.353692 Content Loss: 0.021128

run [900]:
Style Loss : 0.350343 Content Loss: 0.021284

run [950]:
Style Loss : 0.347323 Content Loss: 0.021458

run [1000]:
Style Loss : 0.344465 Content Loss: 0.021607

run [1050]:
Style Loss : 0.342003 Content Loss: 0.021733

run [1100]:
Style Loss : 0.339781 Content Loss: 0.021864

run [1150]:
Style Loss : 0.337692 Content Loss: 0.021999

run [1200]:
Style Loss : 0.335861 Content Loss: 0.022112

run [1250]:
Style Loss : 0.334096 Content Loss: 0.022225

run [1300]:
Style Loss : 0.332270 Content Loss: 0.022351

run [1350]:
Style Loss : 0.330445 Content Loss: 0.022471

run [1400]:
Style Loss : 0.328853 Content Loss: 0.022586

run [1450]:
Style Loss : 0.327390 Content Loss: 0.022692

run [1500]:
Style Loss : 0.325962 Content Loss: 0.022799

run [1550]:
Style Loss : 0.324189 Content Loss: 0.022904

run [1600]:
Style Loss : 0.322727 Content Loss: 0.022990

run [1650]:
Style Loss : 0.321294 Content Loss: 0.023069

run [1700]:
Style Loss : 0.319891 Content Loss: 0.023154

run [1750]:
Style Loss : 0.318715 Content Loss: 0.023220

run [1800]:
Style Loss : 0.317601 Content Loss: 0.023283

run [1850]:
Style Loss : 0.316563 Content Loss: 0.023342

run [1900]:
Style Loss : 0.315575 Content Loss: 0.023395

run [1950]:
Style Loss : 0.314637 Content Loss: 0.023452

run [2000]:
Style Loss : 0.313590 Content Loss: 0.023517

run [2050]:
Style Loss : 0.312671 Content Loss: 0.023572

run [2100]:
Style Loss : 0.311749 Content Loss: 0.023634

run [2150]:
Style Loss : 0.310768 Content Loss: 0.023700

run [2200]:
Style Loss : 0.309782 Content Loss: 0.023759

run [2250]:
Style Loss : 0.308849 Content Loss: 0.023818

run [2300]:
Style Loss : 0.307999 Content Loss: 0.023872

run [2350]:
Style Loss : 0.307161 Content Loss: 0.023932

run [2400]:
Style Loss : 0.306373 Content Loss: 0.023985

run [2450]:
Style Loss : 0.305567 Content Loss: 0.024036

run [2500]:
Style Loss : 0.304779 Content Loss: 0.024078

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.962369 Content Loss: 0.002958

run [100]:
Style Loss : 2.680616 Content Loss: 0.004971

run [150]:
Style Loss : 1.763017 Content Loss: 0.007616

run [200]:
Style Loss : 1.337771 Content Loss: 0.009906

run [250]:
Style Loss : 1.119340 Content Loss: 0.011308

run [300]:
Style Loss : 0.983505 Content Loss: 0.012400

run [350]:
Style Loss : 0.885866 Content Loss: 0.013281

run [400]:
Style Loss : 0.814014 Content Loss: 0.013870

run [450]:
Style Loss : 0.760621 Content Loss: 0.014400

run [500]:
Style Loss : 0.717351 Content Loss: 0.014872

run [550]:
Style Loss : 0.682328 Content Loss: 0.015351

run [600]:
Style Loss : 0.652377 Content Loss: 0.015713

run [650]:
Style Loss : 0.627809 Content Loss: 0.016023

run [700]:
Style Loss : 0.608252 Content Loss: 0.016267

run [750]:
Style Loss : 0.591688 Content Loss: 0.016525

run [800]:
Style Loss : 0.577758 Content Loss: 0.016767

run [850]:
Style Loss : 0.564765 Content Loss: 0.016996

run [900]:
Style Loss : 0.553782 Content Loss: 0.017205

run [950]:
Style Loss : 0.542669 Content Loss: 0.017424

run [1000]:
Style Loss : 0.532691 Content Loss: 0.017626

run [1050]:
Style Loss : 0.523985 Content Loss: 0.017782

run [1100]:
Style Loss : 0.516390 Content Loss: 0.017941

run [1150]:
Style Loss : 0.509623 Content Loss: 0.018094

run [1200]:
Style Loss : 0.503251 Content Loss: 0.018254

run [1250]:
Style Loss : 0.497321 Content Loss: 0.018397

run [1300]:
Style Loss : 0.491737 Content Loss: 0.018538

run [1350]:
Style Loss : 0.485799 Content Loss: 0.018694

run [1400]:
Style Loss : 0.479654 Content Loss: 0.018853

run [1450]:
Style Loss : 0.473321 Content Loss: 0.019007

run [1500]:
Style Loss : 0.467543 Content Loss: 0.019137

run [1550]:
Style Loss : 0.462566 Content Loss: 0.019233

run [1600]:
Style Loss : 0.458148 Content Loss: 0.019339

run [1650]:
Style Loss : 0.453316 Content Loss: 0.019440

run [1700]:
Style Loss : 0.448748 Content Loss: 0.019539

run [1750]:
Style Loss : 0.444669 Content Loss: 0.019630

run [1800]:
Style Loss : 0.440302 Content Loss: 0.019724

run [1850]:
Style Loss : 0.436709 Content Loss: 0.019789

run [1900]:
Style Loss : 0.433637 Content Loss: 0.019862

run [1950]:
Style Loss : 0.430610 Content Loss: 0.019942

run [2000]:
Style Loss : 0.427708 Content Loss: 0.020020

run [2050]:
Style Loss : 0.424765 Content Loss: 0.020096

run [2100]:
Style Loss : 0.422143 Content Loss: 0.020156

run [2150]:
Style Loss : 0.419840 Content Loss: 0.020213

run [2200]:
Style Loss : 0.417758 Content Loss: 0.020267

run [2250]:
Style Loss : 0.415901 Content Loss: 0.020314

run [2300]:
Style Loss : 0.414252 Content Loss: 0.020354

run [2350]:
Style Loss : 0.412640 Content Loss: 0.020401

run [2400]:
Style Loss : 0.411151 Content Loss: 0.020441

run [2450]:
Style Loss : 0.409629 Content Loss: 0.020489

run [2500]:
Style Loss : 0.408226 Content Loss: 0.020524

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.493000 Content Loss: 0.005370

run [100]:
Style Loss : 2.294143 Content Loss: 0.007879

run [150]:
Style Loss : 1.647642 Content Loss: 0.010189

run [200]:
Style Loss : 1.361388 Content Loss: 0.011884

run [250]:
Style Loss : 1.181257 Content Loss: 0.013034

run [300]:
Style Loss : 1.068322 Content Loss: 0.013878

run [350]:
Style Loss : 0.986528 Content Loss: 0.014742

run [400]:
Style Loss : 0.926591 Content Loss: 0.015420

run [450]:
Style Loss : 0.881144 Content Loss: 0.015970

run [500]:
Style Loss : 0.841650 Content Loss: 0.016593

run [550]:
Style Loss : 0.804528 Content Loss: 0.017121

run [600]:
Style Loss : 0.770909 Content Loss: 0.017587

run [650]:
Style Loss : 0.743998 Content Loss: 0.017939

run [700]:
Style Loss : 0.721064 Content Loss: 0.018277

run [750]:
Style Loss : 0.702346 Content Loss: 0.018546

run [800]:
Style Loss : 0.686738 Content Loss: 0.018802

run [850]:
Style Loss : 0.672562 Content Loss: 0.019062

run [900]:
Style Loss : 0.657336 Content Loss: 0.019369

run [950]:
Style Loss : 0.642319 Content Loss: 0.019587

run [1000]:
Style Loss : 0.629701 Content Loss: 0.019775

run [1050]:
Style Loss : 0.619170 Content Loss: 0.019951

run [1100]:
Style Loss : 0.610314 Content Loss: 0.020096

run [1150]:
Style Loss : 0.602733 Content Loss: 0.020222

run [1200]:
Style Loss : 0.595684 Content Loss: 0.020347

run [1250]:
Style Loss : 0.588877 Content Loss: 0.020476

run [1300]:
Style Loss : 0.582548 Content Loss: 0.020602

run [1350]:
Style Loss : 0.576770 Content Loss: 0.020704

run [1400]:
Style Loss : 0.571359 Content Loss: 0.020798

run [1450]:
Style Loss : 0.566807 Content Loss: 0.020894

run [1500]:
Style Loss : 0.562609 Content Loss: 0.020988

run [1550]:
Style Loss : 0.558460 Content Loss: 0.021084

run [1600]:
Style Loss : 0.554439 Content Loss: 0.021181

run [1650]:
Style Loss : 0.550880 Content Loss: 0.021269

run [1700]:
Style Loss : 0.547570 Content Loss: 0.021362

run [1750]:
Style Loss : 0.544241 Content Loss: 0.021449

run [1800]:
Style Loss : 0.540784 Content Loss: 0.021529

run [1850]:
Style Loss : 0.537828 Content Loss: 0.021601

run [1900]:
Style Loss : 0.534723 Content Loss: 0.021699

run [1950]:
Style Loss : 0.531690 Content Loss: 0.021777

run [2000]:
Style Loss : 0.528585 Content Loss: 0.021874

run [2050]:
Style Loss : 0.525294 Content Loss: 0.021967

run [2100]:
Style Loss : 0.522355 Content Loss: 0.022049

run [2150]:
Style Loss : 0.519164 Content Loss: 0.022140

run [2200]:
Style Loss : 0.515770 Content Loss: 0.022228

run [2250]:
Style Loss : 0.512439 Content Loss: 0.022326

run [2300]:
Style Loss : 0.509012 Content Loss: 0.022430

run [2350]:
Style Loss : 0.505655 Content Loss: 0.022522

run [2400]:
Style Loss : 0.502303 Content Loss: 0.022613

run [2450]:
Style Loss : 0.498998 Content Loss: 0.022696

run [2500]:
Style Loss : 0.495777 Content Loss: 0.022782

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.270461 Content Loss: 0.006602

run [100]:
Style Loss : 2.458885 Content Loss: 0.007614

run [150]:
Style Loss : 1.916106 Content Loss: 0.009424

run [200]:
Style Loss : 1.637761 Content Loss: 0.010935

run [250]:
Style Loss : 1.469709 Content Loss: 0.012040

run [300]:
Style Loss : 1.360687 Content Loss: 0.012924

run [350]:
Style Loss : 1.276782 Content Loss: 0.013727

run [400]:
Style Loss : 1.213505 Content Loss: 0.014361

run [450]:
Style Loss : 1.161337 Content Loss: 0.015008

run [500]:
Style Loss : 1.121296 Content Loss: 0.015570

run [550]:
Style Loss : 1.087951 Content Loss: 0.016081

run [600]:
Style Loss : 1.057478 Content Loss: 0.016531

run [650]:
Style Loss : 1.032785 Content Loss: 0.016854

run [700]:
Style Loss : 1.010262 Content Loss: 0.017229

run [750]:
Style Loss : 0.990321 Content Loss: 0.017526

run [800]:
Style Loss : 0.972282 Content Loss: 0.017866

run [850]:
Style Loss : 0.956709 Content Loss: 0.018134

run [900]:
Style Loss : 0.943278 Content Loss: 0.018397

run [950]:
Style Loss : 0.930813 Content Loss: 0.018647

run [1000]:
Style Loss : 0.920105 Content Loss: 0.018855

run [1050]:
Style Loss : 0.909225 Content Loss: 0.019102

run [1100]:
Style Loss : 0.899639 Content Loss: 0.019322

run [1150]:
Style Loss : 0.890661 Content Loss: 0.019552

run [1200]:
Style Loss : 0.882227 Content Loss: 0.019736

run [1250]:
Style Loss : 0.874792 Content Loss: 0.019897

run [1300]:
Style Loss : 0.867857 Content Loss: 0.020053

run [1350]:
Style Loss : 0.862081 Content Loss: 0.020210

run [1400]:
Style Loss : 0.856797 Content Loss: 0.020348

run [1450]:
Style Loss : 0.851832 Content Loss: 0.020467

run [1500]:
Style Loss : 0.847668 Content Loss: 0.020595

run [1550]:
Style Loss : 0.844056 Content Loss: 0.020684

run [1600]:
Style Loss : 0.840684 Content Loss: 0.020786

run [1650]:
Style Loss : 0.837489 Content Loss: 0.020889

run [1700]:
Style Loss : 0.834398 Content Loss: 0.020980

run [1750]:
Style Loss : 0.831549 Content Loss: 0.021074

run [1800]:
Style Loss : 0.828752 Content Loss: 0.021155

run [1850]:
Style Loss : 0.826031 Content Loss: 0.021243

run [1900]:
Style Loss : 0.823476 Content Loss: 0.021334

run [1950]:
Style Loss : 0.821127 Content Loss: 0.021407

run [2000]:
Style Loss : 0.819124 Content Loss: 0.021483

run [2050]:
Style Loss : 0.817194 Content Loss: 0.021556

run [2100]:
Style Loss : 0.815290 Content Loss: 0.021634

run [2150]:
Style Loss : 0.813482 Content Loss: 0.021705

run [2200]:
Style Loss : 0.811669 Content Loss: 0.021780

run [2250]:
Style Loss : 0.809900 Content Loss: 0.021830

run [2300]:
Style Loss : 0.808432 Content Loss: 0.021878

run [2350]:
Style Loss : 0.806936 Content Loss: 0.021947

run [2400]:
Style Loss : 0.805481 Content Loss: 0.021999

run [2450]:
Style Loss : 0.804084 Content Loss: 0.022049

run [2500]:
Style Loss : 0.802791 Content Loss: 0.022092

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.270432 Content Loss: 0.006119

run [100]:
Style Loss : 1.424245 Content Loss: 0.007061

run [150]:
Style Loss : 0.976331 Content Loss: 0.008875

run [200]:
Style Loss : 0.803696 Content Loss: 0.010167

run [250]:
Style Loss : 0.684028 Content Loss: 0.011484

run [300]:
Style Loss : 0.597865 Content Loss: 0.012755

run [350]:
Style Loss : 0.537100 Content Loss: 0.013683

run [400]:
Style Loss : 0.493745 Content Loss: 0.014620

run [450]:
Style Loss : 0.456551 Content Loss: 0.015438

run [500]:
Style Loss : 0.428807 Content Loss: 0.016198

run [550]:
Style Loss : 0.406233 Content Loss: 0.016825

run [600]:
Style Loss : 0.388160 Content Loss: 0.017408

run [650]:
Style Loss : 0.373617 Content Loss: 0.017831

run [700]:
Style Loss : 0.360094 Content Loss: 0.018249

run [750]:
Style Loss : 0.346006 Content Loss: 0.018596

run [800]:
Style Loss : 0.333769 Content Loss: 0.018886

run [850]:
Style Loss : 0.323491 Content Loss: 0.019106

run [900]:
Style Loss : 0.313498 Content Loss: 0.019316

run [950]:
Style Loss : 0.304639 Content Loss: 0.019517

run [1000]:
Style Loss : 0.296599 Content Loss: 0.019687

run [1050]:
Style Loss : 0.288947 Content Loss: 0.019847

run [1100]:
Style Loss : 0.282384 Content Loss: 0.019960

run [1150]:
Style Loss : 0.276918 Content Loss: 0.020069

run [1200]:
Style Loss : 0.272025 Content Loss: 0.020169

run [1250]:
Style Loss : 0.267736 Content Loss: 0.020251

run [1300]:
Style Loss : 0.263737 Content Loss: 0.020327

run [1350]:
Style Loss : 0.260268 Content Loss: 0.020407

run [1400]:
Style Loss : 0.257393 Content Loss: 0.020462

run [1450]:
Style Loss : 0.254829 Content Loss: 0.020515

run [1500]:
Style Loss : 0.252144 Content Loss: 0.020581

run [1550]:
Style Loss : 0.250048 Content Loss: 0.020616

run [1600]:
Style Loss : 0.248170 Content Loss: 0.020654

run [1650]:
Style Loss : 0.246492 Content Loss: 0.020691

run [1700]:
Style Loss : 0.244854 Content Loss: 0.020734

run [1750]:
Style Loss : 0.243298 Content Loss: 0.020774

run [1800]:
Style Loss : 0.241829 Content Loss: 0.020810

run [1850]:
Style Loss : 0.240454 Content Loss: 0.020855

run [1900]:
Style Loss : 0.239126 Content Loss: 0.020890

run [1950]:
Style Loss : 0.237929 Content Loss: 0.020915

run [2000]:
Style Loss : 0.236716 Content Loss: 0.020936

run [2050]:
Style Loss : 0.235552 Content Loss: 0.020957

run [2100]:
Style Loss : 0.234445 Content Loss: 0.020967

run [2150]:
Style Loss : 0.233451 Content Loss: 0.020971

run [2200]:
Style Loss : 0.232507 Content Loss: 0.020984

run [2250]:
Style Loss : 0.231677 Content Loss: 0.020986

run [2300]:
Style Loss : 0.229016 Content Loss: 0.021001

run [2350]:
Style Loss : 0.227790 Content Loss: 0.021008

run [2400]:
Style Loss : 0.226917 Content Loss: 0.021006

run [2450]:
Style Loss : 0.226092 Content Loss: 0.021009

run [2500]:
Style Loss : 0.225261 Content Loss: 0.021018

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.761605 Content Loss: 0.006068

run [100]:
Style Loss : 1.012759 Content Loss: 0.008894

run [150]:
Style Loss : 0.785649 Content Loss: 0.010775

run [200]:
Style Loss : 0.678035 Content Loss: 0.011964

run [250]:
Style Loss : 0.609751 Content Loss: 0.012900

run [300]:
Style Loss : 0.556407 Content Loss: 0.013566

run [350]:
Style Loss : 0.518117 Content Loss: 0.014181

run [400]:
Style Loss : 0.489081 Content Loss: 0.014678

run [450]:
Style Loss : 0.466681 Content Loss: 0.015093

run [500]:
Style Loss : 0.448721 Content Loss: 0.015451

run [550]:
Style Loss : 0.434278 Content Loss: 0.015821

run [600]:
Style Loss : 0.422682 Content Loss: 0.016140

run [650]:
Style Loss : 0.413539 Content Loss: 0.016439

run [700]:
Style Loss : 0.406413 Content Loss: 0.016713

run [750]:
Style Loss : 0.400384 Content Loss: 0.016954

run [800]:
Style Loss : 0.394891 Content Loss: 0.017157

run [850]:
Style Loss : 0.390074 Content Loss: 0.017356

run [900]:
Style Loss : 0.385599 Content Loss: 0.017570

run [950]:
Style Loss : 0.381464 Content Loss: 0.017758

run [1000]:
Style Loss : 0.377650 Content Loss: 0.017929

run [1050]:
Style Loss : 0.374331 Content Loss: 0.018077

run [1100]:
Style Loss : 0.371110 Content Loss: 0.018241

run [1150]:
Style Loss : 0.367844 Content Loss: 0.018406

run [1200]:
Style Loss : 0.365216 Content Loss: 0.018545

run [1250]:
Style Loss : 0.362521 Content Loss: 0.018690

run [1300]:
Style Loss : 0.360053 Content Loss: 0.018822

run [1350]:
Style Loss : 0.355364 Content Loss: 0.018946

run [1400]:
Style Loss : 0.352713 Content Loss: 0.019069

run [1450]:
Style Loss : 0.350684 Content Loss: 0.019159

run [1500]:
Style Loss : 0.348746 Content Loss: 0.019254

run [1550]:
Style Loss : 0.347028 Content Loss: 0.019333

run [1600]:
Style Loss : 0.345389 Content Loss: 0.019431

run [1650]:
Style Loss : 0.343870 Content Loss: 0.019511

run [1700]:
Style Loss : 0.342304 Content Loss: 0.019603

run [1750]:
Style Loss : 0.340656 Content Loss: 0.019693

run [1800]:
Style Loss : 0.339114 Content Loss: 0.019782

run [1850]:
Style Loss : 0.337681 Content Loss: 0.019869

run [1900]:
Style Loss : 0.336267 Content Loss: 0.019954

run [1950]:
Style Loss : 0.335018 Content Loss: 0.020030

run [2000]:
Style Loss : 0.333833 Content Loss: 0.020100

run [2050]:
Style Loss : 0.332750 Content Loss: 0.020167

run [2100]:
Style Loss : 0.331627 Content Loss: 0.020240

run [2150]:
Style Loss : 0.330519 Content Loss: 0.020306

run [2200]:
Style Loss : 0.329479 Content Loss: 0.020373

run [2250]:
Style Loss : 0.328506 Content Loss: 0.020430

run [2300]:
Style Loss : 0.327631 Content Loss: 0.020485

run [2350]:
Style Loss : 0.326683 Content Loss: 0.020547

run [2400]:
Style Loss : 0.325675 Content Loss: 0.020616

run [2450]:
Style Loss : 0.324467 Content Loss: 0.020682

run [2500]:
Style Loss : 0.323308 Content Loss: 0.020746

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.012049 Content Loss: 0.013186

run [100]:
Style Loss : 0.582419 Content Loss: 0.013738

run [150]:
Style Loss : 0.443093 Content Loss: 0.014359

run [200]:
Style Loss : 0.377900 Content Loss: 0.014797

run [250]:
Style Loss : 0.340407 Content Loss: 0.015006

run [300]:
Style Loss : 0.317775 Content Loss: 0.015229

run [350]:
Style Loss : 0.302821 Content Loss: 0.015383

run [400]:
Style Loss : 0.292468 Content Loss: 0.015532

run [450]:
Style Loss : 0.283092 Content Loss: 0.015677

run [500]:
Style Loss : 0.275267 Content Loss: 0.015805

run [550]:
Style Loss : 0.268593 Content Loss: 0.015959

run [600]:
Style Loss : 0.262884 Content Loss: 0.016100

run [650]:
Style Loss : 0.258601 Content Loss: 0.016196

run [700]:
Style Loss : 0.254987 Content Loss: 0.016314

run [750]:
Style Loss : 0.251724 Content Loss: 0.016419

run [800]:
Style Loss : 0.248418 Content Loss: 0.016530

run [850]:
Style Loss : 0.245642 Content Loss: 0.016632

run [900]:
Style Loss : 0.242854 Content Loss: 0.016739

run [950]:
Style Loss : 0.240042 Content Loss: 0.016868

run [1000]:
Style Loss : 0.237404 Content Loss: 0.016983

run [1050]:
Style Loss : 0.235008 Content Loss: 0.017093

run [1100]:
Style Loss : 0.232752 Content Loss: 0.017185

run [1150]:
Style Loss : 0.230680 Content Loss: 0.017278

run [1200]:
Style Loss : 0.228733 Content Loss: 0.017372

run [1250]:
Style Loss : 0.226863 Content Loss: 0.017455

run [1300]:
Style Loss : 0.224812 Content Loss: 0.017549

run [1350]:
Style Loss : 0.222672 Content Loss: 0.017637

run [1400]:
Style Loss : 0.220672 Content Loss: 0.017721

run [1450]:
Style Loss : 0.219037 Content Loss: 0.017798

run [1500]:
Style Loss : 0.217461 Content Loss: 0.017874

run [1550]:
Style Loss : 0.216018 Content Loss: 0.017947

run [1600]:
Style Loss : 0.214588 Content Loss: 0.018013

run [1650]:
Style Loss : 0.213228 Content Loss: 0.018065

run [1700]:
Style Loss : 0.212116 Content Loss: 0.018119

run [1750]:
Style Loss : 0.210983 Content Loss: 0.018169

run [1800]:
Style Loss : 0.209895 Content Loss: 0.018224

run [1850]:
Style Loss : 0.208829 Content Loss: 0.018277

run [1900]:
Style Loss : 0.207831 Content Loss: 0.018334

run [1950]:
Style Loss : 0.206968 Content Loss: 0.018380

run [2000]:
Style Loss : 0.206155 Content Loss: 0.018429

run [2050]:
Style Loss : 0.205275 Content Loss: 0.018482

run [2100]:
Style Loss : 0.204477 Content Loss: 0.018532

run [2150]:
Style Loss : 0.203713 Content Loss: 0.018585

run [2200]:
Style Loss : 0.202939 Content Loss: 0.018639

run [2250]:
Style Loss : 0.202241 Content Loss: 0.018689

run [2300]:
Style Loss : 0.201517 Content Loss: 0.018739

run [2350]:
Style Loss : 0.200841 Content Loss: 0.018791

run [2400]:
Style Loss : 0.200207 Content Loss: 0.018834

run [2450]:
Style Loss : 0.199610 Content Loss: 0.018881

run [2500]:
Style Loss : 0.199018 Content Loss: 0.018926

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.615214 Content Loss: 0.016003

run [100]:
Style Loss : 0.386377 Content Loss: 0.015662

run [150]:
Style Loss : 0.305776 Content Loss: 0.015984

run [200]:
Style Loss : 0.264901 Content Loss: 0.016401

run [250]:
Style Loss : 0.239713 Content Loss: 0.016833

run [300]:
Style Loss : 0.222547 Content Loss: 0.017213

run [350]:
Style Loss : 0.210556 Content Loss: 0.017558

run [400]:
Style Loss : 0.201595 Content Loss: 0.017851

run [450]:
Style Loss : 0.194558 Content Loss: 0.018097

run [500]:
Style Loss : 0.189412 Content Loss: 0.018331

run [550]:
Style Loss : 0.185121 Content Loss: 0.018561

run [600]:
Style Loss : 0.181538 Content Loss: 0.018742

run [650]:
Style Loss : 0.178322 Content Loss: 0.018916

run [700]:
Style Loss : 0.175325 Content Loss: 0.019086

run [750]:
Style Loss : 0.172528 Content Loss: 0.019279

run [800]:
Style Loss : 0.169828 Content Loss: 0.019473

run [850]:
Style Loss : 0.167463 Content Loss: 0.019622

run [900]:
Style Loss : 0.165441 Content Loss: 0.019771

run [950]:
Style Loss : 0.163556 Content Loss: 0.019914

run [1000]:
Style Loss : 0.161881 Content Loss: 0.020043

run [1050]:
Style Loss : 0.160227 Content Loss: 0.020180

run [1100]:
Style Loss : 0.158695 Content Loss: 0.020321

run [1150]:
Style Loss : 0.157239 Content Loss: 0.020433

run [1200]:
Style Loss : 0.155955 Content Loss: 0.020554

run [1250]:
Style Loss : 0.154682 Content Loss: 0.020677

run [1300]:
Style Loss : 0.153505 Content Loss: 0.020796

run [1350]:
Style Loss : 0.152399 Content Loss: 0.020887

run [1400]:
Style Loss : 0.151331 Content Loss: 0.020977

run [1450]:
Style Loss : 0.150310 Content Loss: 0.021053

run [1500]:
Style Loss : 0.149390 Content Loss: 0.021130

run [1550]:
Style Loss : 0.148467 Content Loss: 0.021226

run [1600]:
Style Loss : 0.147558 Content Loss: 0.021301

run [1650]:
Style Loss : 0.146908 Content Loss: 0.021402

run [1700]:
Style Loss : 0.145963 Content Loss: 0.021488

run [1750]:
Style Loss : 0.145026 Content Loss: 0.021534

run [1800]:
Style Loss : 0.144322 Content Loss: 0.021616

run [1850]:
Style Loss : 0.143494 Content Loss: 0.021688

run [1900]:
Style Loss : 0.142793 Content Loss: 0.021764

run [1950]:
Style Loss : 0.142275 Content Loss: 0.021855

run [2000]:
Style Loss : 0.141437 Content Loss: 0.021919

run [2050]:
Style Loss : 0.140805 Content Loss: 0.021987

run [2100]:
Style Loss : 0.140977 Content Loss: 0.022092

run [2150]:
Style Loss : 0.139103 Content Loss: 0.022149

run [2200]:
Style Loss : 0.138484 Content Loss: 0.022226

run [2250]:
Style Loss : 0.137738 Content Loss: 0.022282

run [2300]:
Style Loss : 0.137178 Content Loss: 0.022372

run [2350]:
Style Loss : 0.137218 Content Loss: 0.022560

run [2400]:
Style Loss : 0.136088 Content Loss: 0.022539

run [2450]:
Style Loss : 0.135607 Content Loss: 0.022678

run [2500]:
Style Loss : 0.135463 Content Loss: 0.022816

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.820618 Content Loss: 0.013280

run [100]:
Style Loss : 0.483848 Content Loss: 0.013267

run [150]:
Style Loss : 0.394942 Content Loss: 0.013641

run [200]:
Style Loss : 0.345875 Content Loss: 0.013957

run [250]:
Style Loss : 0.314748 Content Loss: 0.014261

run [300]:
Style Loss : 0.291295 Content Loss: 0.014508

run [350]:
Style Loss : 0.272897 Content Loss: 0.014761

run [400]:
Style Loss : 0.257185 Content Loss: 0.014981

run [450]:
Style Loss : 0.245578 Content Loss: 0.015156

run [500]:
Style Loss : 0.235864 Content Loss: 0.015323

run [550]:
Style Loss : 0.227433 Content Loss: 0.015492

run [600]:
Style Loss : 0.220188 Content Loss: 0.015635

run [650]:
Style Loss : 0.213787 Content Loss: 0.015826

run [700]:
Style Loss : 0.208484 Content Loss: 0.015958

run [750]:
Style Loss : 0.203945 Content Loss: 0.016074

run [800]:
Style Loss : 0.199529 Content Loss: 0.016200

run [850]:
Style Loss : 0.195710 Content Loss: 0.016315

run [900]:
Style Loss : 0.192506 Content Loss: 0.016423

run [950]:
Style Loss : 0.189802 Content Loss: 0.016544

run [1000]:
Style Loss : 0.187630 Content Loss: 0.016634

run [1050]:
Style Loss : 0.185834 Content Loss: 0.016713

run [1100]:
Style Loss : 0.184240 Content Loss: 0.016791

run [1150]:
Style Loss : 0.182749 Content Loss: 0.016870

run [1200]:
Style Loss : 0.181409 Content Loss: 0.016940

run [1250]:
Style Loss : 0.180226 Content Loss: 0.017004

run [1300]:
Style Loss : 0.179034 Content Loss: 0.017077

run [1350]:
Style Loss : 0.177958 Content Loss: 0.017131

run [1400]:
Style Loss : 0.177080 Content Loss: 0.017179

run [1450]:
Style Loss : 0.176199 Content Loss: 0.017228

run [1500]:
Style Loss : 0.175390 Content Loss: 0.017276

run [1550]:
Style Loss : 0.174557 Content Loss: 0.017329

run [1600]:
Style Loss : 0.173799 Content Loss: 0.017373

run [1650]:
Style Loss : 0.173081 Content Loss: 0.017414

run [1700]:
Style Loss : 0.172389 Content Loss: 0.017457

run [1750]:
Style Loss : 0.171636 Content Loss: 0.017505

run [1800]:
Style Loss : 0.170901 Content Loss: 0.017551

run [1850]:
Style Loss : 0.170214 Content Loss: 0.017594

run [1900]:
Style Loss : 0.169583 Content Loss: 0.017631

run [1950]:
Style Loss : 0.168980 Content Loss: 0.017670

run [2000]:
Style Loss : 0.168365 Content Loss: 0.017707

run [2050]:
Style Loss : 0.167739 Content Loss: 0.017747

run [2100]:
Style Loss : 0.167053 Content Loss: 0.017791

run [2150]:
Style Loss : 0.166433 Content Loss: 0.017829

run [2200]:
Style Loss : 0.165847 Content Loss: 0.017862

run [2250]:
Style Loss : 0.165263 Content Loss: 0.017901

run [2300]:
Style Loss : 0.164765 Content Loss: 0.017929

run [2350]:
Style Loss : 0.164278 Content Loss: 0.017959

run [2400]:
Style Loss : 0.163808 Content Loss: 0.017990

run [2450]:
Style Loss : 0.163306 Content Loss: 0.018027

run [2500]:
Style Loss : 0.162837 Content Loss: 0.018063

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.216899 Content Loss: 0.003560

run [100]:
Style Loss : 2.135333 Content Loss: 0.005912

run [150]:
Style Loss : 1.463722 Content Loss: 0.008594

run [200]:
Style Loss : 1.113023 Content Loss: 0.010535

run [250]:
Style Loss : 0.911554 Content Loss: 0.012001

run [300]:
Style Loss : 0.787485 Content Loss: 0.012912

run [350]:
Style Loss : 0.702036 Content Loss: 0.013627

run [400]:
Style Loss : 0.645165 Content Loss: 0.014135

run [450]:
Style Loss : 0.604995 Content Loss: 0.014636

run [500]:
Style Loss : 0.574644 Content Loss: 0.015054

run [550]:
Style Loss : 0.550348 Content Loss: 0.015389

run [600]:
Style Loss : 0.530338 Content Loss: 0.015699

run [650]:
Style Loss : 0.513766 Content Loss: 0.015972

run [700]:
Style Loss : 0.499262 Content Loss: 0.016250

run [750]:
Style Loss : 0.486182 Content Loss: 0.016495

run [800]:
Style Loss : 0.474377 Content Loss: 0.016741

run [850]:
Style Loss : 0.463187 Content Loss: 0.016993

run [900]:
Style Loss : 0.452122 Content Loss: 0.017220

run [950]:
Style Loss : 0.441560 Content Loss: 0.017430

run [1000]:
Style Loss : 0.432032 Content Loss: 0.017626

run [1050]:
Style Loss : 0.423122 Content Loss: 0.017815

run [1100]:
Style Loss : 0.414121 Content Loss: 0.018027

run [1150]:
Style Loss : 0.405400 Content Loss: 0.018239

run [1200]:
Style Loss : 0.397512 Content Loss: 0.018401

run [1250]:
Style Loss : 0.390839 Content Loss: 0.018562

run [1300]:
Style Loss : 0.384351 Content Loss: 0.018742

run [1350]:
Style Loss : 0.378134 Content Loss: 0.018904

run [1400]:
Style Loss : 0.372788 Content Loss: 0.019054

run [1450]:
Style Loss : 0.368062 Content Loss: 0.019177

run [1500]:
Style Loss : 0.363193 Content Loss: 0.019329

run [1550]:
Style Loss : 0.358134 Content Loss: 0.019470

run [1600]:
Style Loss : 0.353371 Content Loss: 0.019597

run [1650]:
Style Loss : 0.349061 Content Loss: 0.019734

run [1700]:
Style Loss : 0.345087 Content Loss: 0.019842

run [1750]:
Style Loss : 0.341539 Content Loss: 0.019941

run [1800]:
Style Loss : 0.338355 Content Loss: 0.020046

run [1850]:
Style Loss : 0.335237 Content Loss: 0.020144

run [1900]:
Style Loss : 0.332345 Content Loss: 0.020238

run [1950]:
Style Loss : 0.329523 Content Loss: 0.020338

run [2000]:
Style Loss : 0.326843 Content Loss: 0.020401

run [2050]:
Style Loss : 0.324105 Content Loss: 0.020489

run [2100]:
Style Loss : 0.321728 Content Loss: 0.020561

run [2150]:
Style Loss : 0.319307 Content Loss: 0.020629

run [2200]:
Style Loss : 0.316867 Content Loss: 0.020703

run [2250]:
Style Loss : 0.314667 Content Loss: 0.020764

run [2300]:
Style Loss : 0.312588 Content Loss: 0.020835

run [2350]:
Style Loss : 0.310421 Content Loss: 0.020879

run [2400]:
Style Loss : 0.308629 Content Loss: 0.020929

run [2450]:
Style Loss : 0.306903 Content Loss: 0.020977

run [2500]:
Style Loss : 0.305500 Content Loss: 0.021044

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.552231 Content Loss: 0.014341

run [100]:
Style Loss : 0.305718 Content Loss: 0.014950

run [150]:
Style Loss : 0.226166 Content Loss: 0.015458

run [200]:
Style Loss : 0.184697 Content Loss: 0.015796

run [250]:
Style Loss : 0.157043 Content Loss: 0.016017

run [300]:
Style Loss : 0.139894 Content Loss: 0.016256

run [350]:
Style Loss : 0.126778 Content Loss: 0.016497

run [400]:
Style Loss : 0.116135 Content Loss: 0.016655

run [450]:
Style Loss : 0.108407 Content Loss: 0.016813

run [500]:
Style Loss : 0.102511 Content Loss: 0.016906

run [550]:
Style Loss : 0.097966 Content Loss: 0.017001

run [600]:
Style Loss : 0.094198 Content Loss: 0.017101

run [650]:
Style Loss : 0.090698 Content Loss: 0.017224

run [700]:
Style Loss : 0.087256 Content Loss: 0.017317

run [750]:
Style Loss : 0.084434 Content Loss: 0.017395

run [800]:
Style Loss : 0.082029 Content Loss: 0.017465

run [850]:
Style Loss : 0.079966 Content Loss: 0.017527

run [900]:
Style Loss : 0.078146 Content Loss: 0.017599

run [950]:
Style Loss : 0.076360 Content Loss: 0.017672

run [1000]:
Style Loss : 0.074638 Content Loss: 0.017744

run [1050]:
Style Loss : 0.073140 Content Loss: 0.017801

run [1100]:
Style Loss : 0.071860 Content Loss: 0.017845

run [1150]:
Style Loss : 0.070809 Content Loss: 0.017882

run [1200]:
Style Loss : 0.069853 Content Loss: 0.017919

run [1250]:
Style Loss : 0.068977 Content Loss: 0.017947

run [1300]:
Style Loss : 0.068131 Content Loss: 0.017951

run [1350]:
Style Loss : 0.067313 Content Loss: 0.017955

run [1400]:
Style Loss : 0.066574 Content Loss: 0.017964

run [1450]:
Style Loss : 0.065910 Content Loss: 0.017975

run [1500]:
Style Loss : 0.065365 Content Loss: 0.017983

run [1550]:
Style Loss : 0.064839 Content Loss: 0.017992

run [1600]:
Style Loss : 0.064392 Content Loss: 0.017993

run [1650]:
Style Loss : 0.063991 Content Loss: 0.017993

run [1700]:
Style Loss : 0.063604 Content Loss: 0.017996

run [1750]:
Style Loss : 0.063225 Content Loss: 0.018000

run [1800]:
Style Loss : 0.062834 Content Loss: 0.018010

run [1850]:
Style Loss : 0.062474 Content Loss: 0.018025

run [1900]:
Style Loss : 0.062128 Content Loss: 0.018040

run [1950]:
Style Loss : 0.061773 Content Loss: 0.018052

run [2000]:
Style Loss : 0.061408 Content Loss: 0.018064

run [2050]:
Style Loss : 0.061057 Content Loss: 0.018082

run [2100]:
Style Loss : 0.060713 Content Loss: 0.018106

run [2150]:
Style Loss : 0.060405 Content Loss: 0.018122

run [2200]:
Style Loss : 0.060110 Content Loss: 0.018141

run [2250]:
Style Loss : 0.059818 Content Loss: 0.018161

run [2300]:
Style Loss : 0.059516 Content Loss: 0.018182

run [2350]:
Style Loss : 0.059181 Content Loss: 0.018211

run [2400]:
Style Loss : 0.058854 Content Loss: 0.018235

run [2450]:
Style Loss : 0.058546 Content Loss: 0.018262

run [2500]:
Style Loss : 0.058291 Content Loss: 0.018286

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.050337 Content Loss: 0.004834

run [100]:
Style Loss : 1.071450 Content Loss: 0.008715

run [150]:
Style Loss : 0.803757 Content Loss: 0.010508

run [200]:
Style Loss : 0.664019 Content Loss: 0.011643

run [250]:
Style Loss : 0.581343 Content Loss: 0.012518

run [300]:
Style Loss : 0.521341 Content Loss: 0.013409

run [350]:
Style Loss : 0.477310 Content Loss: 0.014191

run [400]:
Style Loss : 0.441635 Content Loss: 0.014977

run [450]:
Style Loss : 0.415057 Content Loss: 0.015658

run [500]:
Style Loss : 0.394886 Content Loss: 0.016228

run [550]:
Style Loss : 0.379079 Content Loss: 0.016789

run [600]:
Style Loss : 0.367386 Content Loss: 0.017217

run [650]:
Style Loss : 0.358443 Content Loss: 0.017605

run [700]:
Style Loss : 0.351343 Content Loss: 0.017937

run [750]:
Style Loss : 0.345417 Content Loss: 0.018210

run [800]:
Style Loss : 0.340479 Content Loss: 0.018434

run [850]:
Style Loss : 0.335766 Content Loss: 0.018668

run [900]:
Style Loss : 0.331809 Content Loss: 0.018883

run [950]:
Style Loss : 0.328297 Content Loss: 0.019070

run [1000]:
Style Loss : 0.324840 Content Loss: 0.019251

run [1050]:
Style Loss : 0.321539 Content Loss: 0.019426

run [1100]:
Style Loss : 0.318883 Content Loss: 0.019539

run [1150]:
Style Loss : 0.316454 Content Loss: 0.019663

run [1200]:
Style Loss : 0.314252 Content Loss: 0.019770

run [1250]:
Style Loss : 0.312032 Content Loss: 0.019890

run [1300]:
Style Loss : 0.309911 Content Loss: 0.019990

run [1350]:
Style Loss : 0.307953 Content Loss: 0.020082

run [1400]:
Style Loss : 0.306286 Content Loss: 0.020157

run [1450]:
Style Loss : 0.304901 Content Loss: 0.020220

run [1500]:
Style Loss : 0.303651 Content Loss: 0.020283

run [1550]:
Style Loss : 0.302505 Content Loss: 0.020340

run [1600]:
Style Loss : 0.301454 Content Loss: 0.020395

run [1650]:
Style Loss : 0.300450 Content Loss: 0.020446

run [1700]:
Style Loss : 0.299336 Content Loss: 0.020503

run [1750]:
Style Loss : 0.298307 Content Loss: 0.020550

run [1800]:
Style Loss : 0.297416 Content Loss: 0.020595

run [1850]:
Style Loss : 0.296663 Content Loss: 0.020636

run [1900]:
Style Loss : 0.295923 Content Loss: 0.020677

run [1950]:
Style Loss : 0.295156 Content Loss: 0.020716

run [2000]:
Style Loss : 0.294482 Content Loss: 0.020752

run [2050]:
Style Loss : 0.293654 Content Loss: 0.020784

run [2100]:
Style Loss : 0.292859 Content Loss: 0.020822

run [2150]:
Style Loss : 0.292171 Content Loss: 0.020853

run [2200]:
Style Loss : 0.291410 Content Loss: 0.020888

run [2250]:
Style Loss : 0.290306 Content Loss: 0.020932

run [2300]:
Style Loss : 0.289340 Content Loss: 0.020975

run [2350]:
Style Loss : 0.288500 Content Loss: 0.021014

run [2400]:
Style Loss : 0.287769 Content Loss: 0.021044

run [2450]:
Style Loss : 0.287125 Content Loss: 0.021067

run [2500]:
Style Loss : 0.286523 Content Loss: 0.021092

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.500607 Content Loss: 0.001597

run [100]:
Style Loss : 1.021947 Content Loss: 0.001918

run [150]:
Style Loss : 0.820852 Content Loss: 0.002512

run [200]:
Style Loss : 0.701364 Content Loss: 0.003293

run [250]:
Style Loss : 0.611936 Content Loss: 0.004322

run [300]:
Style Loss : 0.541048 Content Loss: 0.005635

run [350]:
Style Loss : 0.480702 Content Loss: 0.007198

run [400]:
Style Loss : 0.427442 Content Loss: 0.009109

run [450]:
Style Loss : 0.382209 Content Loss: 0.011270

run [500]:
Style Loss : 0.344249 Content Loss: 0.013424

run [550]:
Style Loss : 0.315652 Content Loss: 0.015400

run [600]:
Style Loss : 0.294980 Content Loss: 0.017071

run [650]:
Style Loss : 0.279698 Content Loss: 0.018353

run [700]:
Style Loss : 0.268343 Content Loss: 0.019245

run [750]:
Style Loss : 0.259639 Content Loss: 0.019925

run [800]:
Style Loss : 0.252445 Content Loss: 0.020400

run [850]:
Style Loss : 0.246069 Content Loss: 0.020801

run [900]:
Style Loss : 0.240758 Content Loss: 0.021102

run [950]:
Style Loss : 0.236136 Content Loss: 0.021364

run [1000]:
Style Loss : 0.231980 Content Loss: 0.021609

run [1050]:
Style Loss : 0.228385 Content Loss: 0.021842

run [1100]:
Style Loss : 0.224953 Content Loss: 0.022051

run [1150]:
Style Loss : 0.221887 Content Loss: 0.022230

run [1200]:
Style Loss : 0.219024 Content Loss: 0.022403

run [1250]:
Style Loss : 0.216385 Content Loss: 0.022560

run [1300]:
Style Loss : 0.213918 Content Loss: 0.022732

run [1350]:
Style Loss : 0.211798 Content Loss: 0.022873

run [1400]:
Style Loss : 0.209915 Content Loss: 0.023011

run [1450]:
Style Loss : 0.208139 Content Loss: 0.023142

run [1500]:
Style Loss : 0.206454 Content Loss: 0.023273

run [1550]:
Style Loss : 0.204557 Content Loss: 0.023387

run [1600]:
Style Loss : 0.203047 Content Loss: 0.023480

run [1650]:
Style Loss : 0.201744 Content Loss: 0.023569

run [1700]:
Style Loss : 0.200654 Content Loss: 0.023664

run [1750]:
Style Loss : 0.199551 Content Loss: 0.023760

run [1800]:
Style Loss : 0.198521 Content Loss: 0.023846

run [1850]:
Style Loss : 0.197581 Content Loss: 0.023930

run [1900]:
Style Loss : 0.196622 Content Loss: 0.024014

run [1950]:
Style Loss : 0.195715 Content Loss: 0.024089

run [2000]:
Style Loss : 0.194896 Content Loss: 0.024154

run [2050]:
Style Loss : 0.194116 Content Loss: 0.024214

run [2100]:
Style Loss : 0.193382 Content Loss: 0.024265

run [2150]:
Style Loss : 0.192666 Content Loss: 0.024310

run [2200]:
Style Loss : 0.191948 Content Loss: 0.024360

run [2250]:
Style Loss : 0.191304 Content Loss: 0.024407

run [2300]:
Style Loss : 0.190664 Content Loss: 0.024454

run [2350]:
Style Loss : 0.190030 Content Loss: 0.024504

run [2400]:
Style Loss : 0.189396 Content Loss: 0.024550

run [2450]:
Style Loss : 0.188833 Content Loss: 0.024581

run [2500]:
Style Loss : 0.188333 Content Loss: 0.024614

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.451864 Content Loss: 0.001280

run [100]:
Style Loss : 0.995126 Content Loss: 0.001753

run [150]:
Style Loss : 0.799697 Content Loss: 0.002603

run [200]:
Style Loss : 0.676137 Content Loss: 0.003667

run [250]:
Style Loss : 0.588914 Content Loss: 0.005034

run [300]:
Style Loss : 0.514249 Content Loss: 0.006880

run [350]:
Style Loss : 0.445328 Content Loss: 0.009180

run [400]:
Style Loss : 0.387829 Content Loss: 0.011974

run [450]:
Style Loss : 0.334151 Content Loss: 0.014749

run [500]:
Style Loss : 0.293181 Content Loss: 0.017405

run [550]:
Style Loss : 0.264041 Content Loss: 0.019817

run [600]:
Style Loss : 0.242964 Content Loss: 0.021579

run [650]:
Style Loss : 0.229146 Content Loss: 0.022688

run [700]:
Style Loss : 0.218918 Content Loss: 0.023504

run [750]:
Style Loss : 0.211374 Content Loss: 0.023987

run [800]:
Style Loss : 0.205436 Content Loss: 0.024364

run [850]:
Style Loss : 0.200210 Content Loss: 0.024712

run [900]:
Style Loss : 0.195518 Content Loss: 0.024987

run [950]:
Style Loss : 0.191285 Content Loss: 0.025140

run [1000]:
Style Loss : 0.187131 Content Loss: 0.025351

run [1050]:
Style Loss : 0.183314 Content Loss: 0.025542

run [1100]:
Style Loss : 0.180031 Content Loss: 0.025738

run [1150]:
Style Loss : 0.176785 Content Loss: 0.025933

run [1200]:
Style Loss : 0.173730 Content Loss: 0.026116

run [1250]:
Style Loss : 0.170835 Content Loss: 0.026307

run [1300]:
Style Loss : 0.167855 Content Loss: 0.026518

run [1350]:
Style Loss : 0.164815 Content Loss: 0.026697

run [1400]:
Style Loss : 0.162352 Content Loss: 0.026889

run [1450]:
Style Loss : 0.159801 Content Loss: 0.027103

run [1500]:
Style Loss : 0.157423 Content Loss: 0.027284

run [1550]:
Style Loss : 0.155177 Content Loss: 0.027472

run [1600]:
Style Loss : 0.153049 Content Loss: 0.027648

run [1650]:
Style Loss : 0.151186 Content Loss: 0.027832

run [1700]:
Style Loss : 0.149381 Content Loss: 0.028025

run [1750]:
Style Loss : 0.147544 Content Loss: 0.028230

run [1800]:
Style Loss : 0.145818 Content Loss: 0.028448

run [1850]:
Style Loss : 0.144104 Content Loss: 0.028648

run [1900]:
Style Loss : 0.142354 Content Loss: 0.028830

run [1950]:
Style Loss : 0.140868 Content Loss: 0.029022

run [2000]:
Style Loss : 0.139329 Content Loss: 0.029202

run [2050]:
Style Loss : 0.137898 Content Loss: 0.029395

run [2100]:
Style Loss : 0.136521 Content Loss: 0.029600

run [2150]:
Style Loss : 0.135126 Content Loss: 0.029779

run [2200]:
Style Loss : 0.133889 Content Loss: 0.029959

run [2250]:
Style Loss : 0.132587 Content Loss: 0.030136

run [2300]:
Style Loss : 0.131340 Content Loss: 0.030297

run [2350]:
Style Loss : 0.130245 Content Loss: 0.030454

run [2400]:
Style Loss : 0.129157 Content Loss: 0.030595

run [2450]:
Style Loss : 0.127812 Content Loss: 0.030719

run [2500]:
Style Loss : 0.126774 Content Loss: 0.030864

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.315974 Content Loss: 0.001535

run [100]:
Style Loss : 1.471045 Content Loss: 0.002091

run [150]:
Style Loss : 1.126988 Content Loss: 0.002886

run [200]:
Style Loss : 0.959001 Content Loss: 0.003782

run [250]:
Style Loss : 0.843489 Content Loss: 0.004667

run [300]:
Style Loss : 0.767032 Content Loss: 0.005557

run [350]:
Style Loss : 0.707173 Content Loss: 0.006556

run [400]:
Style Loss : 0.657160 Content Loss: 0.007589

run [450]:
Style Loss : 0.612784 Content Loss: 0.008821

run [500]:
Style Loss : 0.575163 Content Loss: 0.010159

run [550]:
Style Loss : 0.542589 Content Loss: 0.011584

run [600]:
Style Loss : 0.515223 Content Loss: 0.013130

run [650]:
Style Loss : 0.492337 Content Loss: 0.014645

run [700]:
Style Loss : 0.473494 Content Loss: 0.016065

run [750]:
Style Loss : 0.459353 Content Loss: 0.017263

run [800]:
Style Loss : 0.448265 Content Loss: 0.018198

run [850]:
Style Loss : 0.440337 Content Loss: 0.018860

run [900]:
Style Loss : 0.434144 Content Loss: 0.019404

run [950]:
Style Loss : 0.429326 Content Loss: 0.019815

run [1000]:
Style Loss : 0.424954 Content Loss: 0.020166

run [1050]:
Style Loss : 0.421144 Content Loss: 0.020432

run [1100]:
Style Loss : 0.417521 Content Loss: 0.020667

run [1150]:
Style Loss : 0.414183 Content Loss: 0.020861

run [1200]:
Style Loss : 0.411193 Content Loss: 0.021031

run [1250]:
Style Loss : 0.408260 Content Loss: 0.021182

run [1300]:
Style Loss : 0.405783 Content Loss: 0.021280

run [1350]:
Style Loss : 0.403396 Content Loss: 0.021375

run [1400]:
Style Loss : 0.401073 Content Loss: 0.021469

run [1450]:
Style Loss : 0.398819 Content Loss: 0.021549

run [1500]:
Style Loss : 0.396679 Content Loss: 0.021607

run [1550]:
Style Loss : 0.394742 Content Loss: 0.021668

run [1600]:
Style Loss : 0.392817 Content Loss: 0.021728

run [1650]:
Style Loss : 0.390816 Content Loss: 0.021780

run [1700]:
Style Loss : 0.388853 Content Loss: 0.021841

run [1750]:
Style Loss : 0.387019 Content Loss: 0.021893

run [1800]:
Style Loss : 0.385066 Content Loss: 0.021946

run [1850]:
Style Loss : 0.383232 Content Loss: 0.021997

run [1900]:
Style Loss : 0.381276 Content Loss: 0.022050

run [1950]:
Style Loss : 0.379497 Content Loss: 0.022099

run [2000]:
Style Loss : 0.377815 Content Loss: 0.022150

run [2050]:
Style Loss : 0.376279 Content Loss: 0.022201

run [2100]:
Style Loss : 0.374660 Content Loss: 0.022261

run [2150]:
Style Loss : 0.372997 Content Loss: 0.022318

run [2200]:
Style Loss : 0.371316 Content Loss: 0.022383

run [2250]:
Style Loss : 0.369565 Content Loss: 0.022444

run [2300]:
Style Loss : 0.367800 Content Loss: 0.022516

run [2350]:
Style Loss : 0.366059 Content Loss: 0.022583

run [2400]:
Style Loss : 0.364398 Content Loss: 0.022660

run [2450]:
Style Loss : 0.362796 Content Loss: 0.022735

run [2500]:
Style Loss : 0.361382 Content Loss: 0.022811

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.998491 Content Loss: 0.003634

run [100]:
Style Loss : 0.611567 Content Loss: 0.005818

run [150]:
Style Loss : 0.411531 Content Loss: 0.009110

run [200]:
Style Loss : 0.288466 Content Loss: 0.013914

run [250]:
Style Loss : 0.227228 Content Loss: 0.017773

run [300]:
Style Loss : 0.197508 Content Loss: 0.019988

run [350]:
Style Loss : 0.179616 Content Loss: 0.020829

run [400]:
Style Loss : 0.167173 Content Loss: 0.021496

run [450]:
Style Loss : 0.158125 Content Loss: 0.022038

run [500]:
Style Loss : 0.151263 Content Loss: 0.022519

run [550]:
Style Loss : 0.146155 Content Loss: 0.022981

run [600]:
Style Loss : 0.138746 Content Loss: 0.023264

run [650]:
Style Loss : 0.135265 Content Loss: 0.023535

run [700]:
Style Loss : 0.132366 Content Loss: 0.023830

run [750]:
Style Loss : 0.130103 Content Loss: 0.024049

run [800]:
Style Loss : 0.128019 Content Loss: 0.024228

run [850]:
Style Loss : 0.126263 Content Loss: 0.024376

run [900]:
Style Loss : 0.124785 Content Loss: 0.024502

run [950]:
Style Loss : 0.123527 Content Loss: 0.024601

run [1000]:
Style Loss : 0.122263 Content Loss: 0.024682

run [1050]:
Style Loss : 0.121141 Content Loss: 0.024750

run [1100]:
Style Loss : 0.120126 Content Loss: 0.024815

run [1150]:
Style Loss : 0.119265 Content Loss: 0.024863

run [1200]:
Style Loss : 0.118445 Content Loss: 0.024894

run [1250]:
Style Loss : 0.117650 Content Loss: 0.024912

run [1300]:
Style Loss : 0.116914 Content Loss: 0.024930

run [1350]:
Style Loss : 0.116243 Content Loss: 0.024951

run [1400]:
Style Loss : 0.115598 Content Loss: 0.024978

run [1450]:
Style Loss : 0.115071 Content Loss: 0.024996

run [1500]:
Style Loss : 0.114609 Content Loss: 0.025006

run [1550]:
Style Loss : 0.114183 Content Loss: 0.025016

run [1600]:
Style Loss : 0.113772 Content Loss: 0.025033

run [1650]:
Style Loss : 0.113361 Content Loss: 0.025050

run [1700]:
Style Loss : 0.113007 Content Loss: 0.025058

run [1750]:
Style Loss : 0.112678 Content Loss: 0.025065

run [1800]:
Style Loss : 0.112389 Content Loss: 0.025063

run [1850]:
Style Loss : 0.112108 Content Loss: 0.025060

run [1900]:
Style Loss : 0.111830 Content Loss: 0.025058

run [1950]:
Style Loss : 0.111560 Content Loss: 0.025052

run [2000]:
Style Loss : 0.111329 Content Loss: 0.025046

run [2050]:
Style Loss : 0.110943 Content Loss: 0.025037

run [2100]:
Style Loss : 0.110611 Content Loss: 0.025028

run [2150]:
Style Loss : 0.110357 Content Loss: 0.025017

run [2200]:
Style Loss : 0.110150 Content Loss: 0.025003

run [2250]:
Style Loss : 0.109941 Content Loss: 0.024990

run [2300]:
Style Loss : 0.109748 Content Loss: 0.024972

run [2350]:
Style Loss : 0.109550 Content Loss: 0.024956

run [2400]:
Style Loss : 0.109368 Content Loss: 0.024938

run [2450]:
Style Loss : 0.109199 Content Loss: 0.024925

run [2500]:
Style Loss : 0.109048 Content Loss: 0.024911

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.771165 Content Loss: 0.004038

run [100]:
Style Loss : 0.452629 Content Loss: 0.006770

run [150]:
Style Loss : 0.318534 Content Loss: 0.011323

run [200]:
Style Loss : 0.238804 Content Loss: 0.016533

run [250]:
Style Loss : 0.193068 Content Loss: 0.020984

run [300]:
Style Loss : 0.172522 Content Loss: 0.023086

run [350]:
Style Loss : 0.161394 Content Loss: 0.024133

run [400]:
Style Loss : 0.153641 Content Loss: 0.024823

run [450]:
Style Loss : 0.148239 Content Loss: 0.025345

run [500]:
Style Loss : 0.144112 Content Loss: 0.025752

run [550]:
Style Loss : 0.140733 Content Loss: 0.026088

run [600]:
Style Loss : 0.137390 Content Loss: 0.026402

run [650]:
Style Loss : 0.134193 Content Loss: 0.026608

run [700]:
Style Loss : 0.131695 Content Loss: 0.026827

run [750]:
Style Loss : 0.129724 Content Loss: 0.027026

run [800]:
Style Loss : 0.128023 Content Loss: 0.027200

run [850]:
Style Loss : 0.126642 Content Loss: 0.027329

run [900]:
Style Loss : 0.125422 Content Loss: 0.027413

run [950]:
Style Loss : 0.124368 Content Loss: 0.027492

run [1000]:
Style Loss : 0.123367 Content Loss: 0.027558

run [1050]:
Style Loss : 0.122548 Content Loss: 0.027594

run [1100]:
Style Loss : 0.121733 Content Loss: 0.027627

run [1150]:
Style Loss : 0.120954 Content Loss: 0.027657

run [1200]:
Style Loss : 0.120261 Content Loss: 0.027687

run [1250]:
Style Loss : 0.119602 Content Loss: 0.027718

run [1300]:
Style Loss : 0.118984 Content Loss: 0.027738

run [1350]:
Style Loss : 0.118429 Content Loss: 0.027744

run [1400]:
Style Loss : 0.117893 Content Loss: 0.027742

run [1450]:
Style Loss : 0.117409 Content Loss: 0.027742

run [1500]:
Style Loss : 0.116972 Content Loss: 0.027745

run [1550]:
Style Loss : 0.116544 Content Loss: 0.027756

run [1600]:
Style Loss : 0.116133 Content Loss: 0.027772

run [1650]:
Style Loss : 0.115734 Content Loss: 0.027785

run [1700]:
Style Loss : 0.115282 Content Loss: 0.027807

run [1750]:
Style Loss : 0.114866 Content Loss: 0.027834

run [1800]:
Style Loss : 0.114532 Content Loss: 0.027859

run [1850]:
Style Loss : 0.114227 Content Loss: 0.027888

run [1900]:
Style Loss : 0.113920 Content Loss: 0.027919

run [1950]:
Style Loss : 0.113629 Content Loss: 0.027939

run [2000]:
Style Loss : 0.113360 Content Loss: 0.027956

run [2050]:
Style Loss : 0.113122 Content Loss: 0.027975

run [2100]:
Style Loss : 0.112878 Content Loss: 0.027991

run [2150]:
Style Loss : 0.112648 Content Loss: 0.028015

run [2200]:
Style Loss : 0.112451 Content Loss: 0.028042

run [2250]:
Style Loss : 0.112200 Content Loss: 0.028067

run [2300]:
Style Loss : 0.111986 Content Loss: 0.028087

run [2350]:
Style Loss : 0.111788 Content Loss: 0.028111

run [2400]:
Style Loss : 0.111614 Content Loss: 0.028137

run [2450]:
Style Loss : 0.111474 Content Loss: 0.028170

run [2500]:
Style Loss : 0.111281 Content Loss: 0.028194

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.843058 Content Loss: 0.012042

run [100]:
Style Loss : 1.599912 Content Loss: 0.017296

run [150]:
Style Loss : 1.068729 Content Loss: 0.023669

run [200]:
Style Loss : 0.792069 Content Loss: 0.029581

run [250]:
Style Loss : 0.654565 Content Loss: 0.034032

run [300]:
Style Loss : 0.578284 Content Loss: 0.036369

run [350]:
Style Loss : 0.529779 Content Loss: 0.037717

run [400]:
Style Loss : 0.492814 Content Loss: 0.039029

run [450]:
Style Loss : 0.463954 Content Loss: 0.040150

run [500]:
Style Loss : 0.442391 Content Loss: 0.041150

run [550]:
Style Loss : 0.425464 Content Loss: 0.042092

run [600]:
Style Loss : 0.411864 Content Loss: 0.042774

run [650]:
Style Loss : 0.400056 Content Loss: 0.043454

run [700]:
Style Loss : 0.389984 Content Loss: 0.043938

run [750]:
Style Loss : 0.381290 Content Loss: 0.044383

run [800]:
Style Loss : 0.373094 Content Loss: 0.044740

run [850]:
Style Loss : 0.366524 Content Loss: 0.045085

run [900]:
Style Loss : 0.360525 Content Loss: 0.045411

run [950]:
Style Loss : 0.355014 Content Loss: 0.045663

run [1000]:
Style Loss : 0.349745 Content Loss: 0.045894

run [1050]:
Style Loss : 0.344967 Content Loss: 0.046075

run [1100]:
Style Loss : 0.340966 Content Loss: 0.046255

run [1150]:
Style Loss : 0.337225 Content Loss: 0.046385

run [1200]:
Style Loss : 0.334020 Content Loss: 0.046523

run [1250]:
Style Loss : 0.331007 Content Loss: 0.046608

run [1300]:
Style Loss : 0.327858 Content Loss: 0.046739

run [1350]:
Style Loss : 0.325283 Content Loss: 0.046840

run [1400]:
Style Loss : 0.322096 Content Loss: 0.046903

run [1450]:
Style Loss : 0.318900 Content Loss: 0.046947

run [1500]:
Style Loss : 0.315989 Content Loss: 0.047045

run [1550]:
Style Loss : 0.313446 Content Loss: 0.047100

run [1600]:
Style Loss : 0.311248 Content Loss: 0.047148

run [1650]:
Style Loss : 0.309170 Content Loss: 0.047209

run [1700]:
Style Loss : 0.307173 Content Loss: 0.047248

run [1750]:
Style Loss : 0.305461 Content Loss: 0.047286

run [1800]:
Style Loss : 0.303788 Content Loss: 0.047342

run [1850]:
Style Loss : 0.302162 Content Loss: 0.047367

run [1900]:
Style Loss : 0.300718 Content Loss: 0.047410

run [1950]:
Style Loss : 0.299322 Content Loss: 0.047423

run [2000]:
Style Loss : 0.297927 Content Loss: 0.047432

run [2050]:
Style Loss : 0.296640 Content Loss: 0.047467

run [2100]:
Style Loss : 0.295456 Content Loss: 0.047498

run [2150]:
Style Loss : 0.294350 Content Loss: 0.047532

run [2200]:
Style Loss : 0.293158 Content Loss: 0.047542

run [2250]:
Style Loss : 0.292035 Content Loss: 0.047558

run [2300]:
Style Loss : 0.291157 Content Loss: 0.047605

run [2350]:
Style Loss : 0.290164 Content Loss: 0.047623

run [2400]:
Style Loss : 0.289346 Content Loss: 0.047622

run [2450]:
Style Loss : 0.288555 Content Loss: 0.047624

run [2500]:
Style Loss : 0.287848 Content Loss: 0.047629

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.540714 Content Loss: 0.001350

run [100]:
Style Loss : 1.041193 Content Loss: 0.002161

run [150]:
Style Loss : 0.805264 Content Loss: 0.003291

run [200]:
Style Loss : 0.672482 Content Loss: 0.005112

run [250]:
Style Loss : 0.564626 Content Loss: 0.007387

run [300]:
Style Loss : 0.467779 Content Loss: 0.010731

run [350]:
Style Loss : 0.382925 Content Loss: 0.014875

run [400]:
Style Loss : 0.320039 Content Loss: 0.019141

run [450]:
Style Loss : 0.278552 Content Loss: 0.022554

run [500]:
Style Loss : 0.253829 Content Loss: 0.024482

run [550]:
Style Loss : 0.237761 Content Loss: 0.025576

run [600]:
Style Loss : 0.226186 Content Loss: 0.026238

run [650]:
Style Loss : 0.217294 Content Loss: 0.026621

run [700]:
Style Loss : 0.210465 Content Loss: 0.026995

run [750]:
Style Loss : 0.204461 Content Loss: 0.027311

run [800]:
Style Loss : 0.199333 Content Loss: 0.027590

run [850]:
Style Loss : 0.195092 Content Loss: 0.027854

run [900]:
Style Loss : 0.191072 Content Loss: 0.028121

run [950]:
Style Loss : 0.187232 Content Loss: 0.028356

run [1000]:
Style Loss : 0.183770 Content Loss: 0.028607

run [1050]:
Style Loss : 0.180470 Content Loss: 0.028857

run [1100]:
Style Loss : 0.177491 Content Loss: 0.029124

run [1150]:
Style Loss : 0.174131 Content Loss: 0.029384

run [1200]:
Style Loss : 0.171342 Content Loss: 0.029605

run [1250]:
Style Loss : 0.169107 Content Loss: 0.029814

run [1300]:
Style Loss : 0.166955 Content Loss: 0.030032

run [1350]:
Style Loss : 0.164987 Content Loss: 0.030265

run [1400]:
Style Loss : 0.163147 Content Loss: 0.030469

run [1450]:
Style Loss : 0.161394 Content Loss: 0.030700

run [1500]:
Style Loss : 0.159707 Content Loss: 0.030879

run [1550]:
Style Loss : 0.158108 Content Loss: 0.031050

run [1600]:
Style Loss : 0.156677 Content Loss: 0.031206

run [1650]:
Style Loss : 0.155372 Content Loss: 0.031335

run [1700]:
Style Loss : 0.154115 Content Loss: 0.031466

run [1750]:
Style Loss : 0.152928 Content Loss: 0.031582

run [1800]:
Style Loss : 0.151917 Content Loss: 0.031684

run [1850]:
Style Loss : 0.150650 Content Loss: 0.031801

run [1900]:
Style Loss : 0.149703 Content Loss: 0.031941

run [1950]:
Style Loss : 0.148624 Content Loss: 0.032032

run [2000]:
Style Loss : 0.147551 Content Loss: 0.032109

run [2050]:
Style Loss : 0.146579 Content Loss: 0.032217

run [2100]:
Style Loss : 0.145875 Content Loss: 0.032337

run [2150]:
Style Loss : 0.144404 Content Loss: 0.032391

run [2200]:
Style Loss : 0.143599 Content Loss: 0.032476

run [2250]:
Style Loss : 0.142601 Content Loss: 0.032548

run [2300]:
Style Loss : 0.141798 Content Loss: 0.032621

run [2350]:
Style Loss : 0.140956 Content Loss: 0.032695

run [2400]:
Style Loss : 0.140098 Content Loss: 0.032757

run [2450]:
Style Loss : 0.139466 Content Loss: 0.032854

run [2500]:
Style Loss : 0.138582 Content Loss: 0.032934

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.222528 Content Loss: 0.001694

run [100]:
Style Loss : 0.889341 Content Loss: 0.002774

run [150]:
Style Loss : 0.732626 Content Loss: 0.004475

run [200]:
Style Loss : 0.602003 Content Loss: 0.007443

run [250]:
Style Loss : 0.494142 Content Loss: 0.011153

run [300]:
Style Loss : 0.400133 Content Loss: 0.016003

run [350]:
Style Loss : 0.330371 Content Loss: 0.020039

run [400]:
Style Loss : 0.287022 Content Loss: 0.023294

run [450]:
Style Loss : 0.263179 Content Loss: 0.025032

run [500]:
Style Loss : 0.248355 Content Loss: 0.025976

run [550]:
Style Loss : 0.238135 Content Loss: 0.026300

run [600]:
Style Loss : 0.230568 Content Loss: 0.026564

run [650]:
Style Loss : 0.223938 Content Loss: 0.026827

run [700]:
Style Loss : 0.217781 Content Loss: 0.027136

run [750]:
Style Loss : 0.211993 Content Loss: 0.027391

run [800]:
Style Loss : 0.206619 Content Loss: 0.027623

run [850]:
Style Loss : 0.200876 Content Loss: 0.027846

run [900]:
Style Loss : 0.195495 Content Loss: 0.028074

run [950]:
Style Loss : 0.190924 Content Loss: 0.028301

run [1000]:
Style Loss : 0.186795 Content Loss: 0.028560

run [1050]:
Style Loss : 0.182927 Content Loss: 0.028839

run [1100]:
Style Loss : 0.179106 Content Loss: 0.029110

run [1150]:
Style Loss : 0.175435 Content Loss: 0.029406

run [1200]:
Style Loss : 0.172298 Content Loss: 0.029678

run [1250]:
Style Loss : 0.169294 Content Loss: 0.029973

run [1300]:
Style Loss : 0.166478 Content Loss: 0.030248

run [1350]:
Style Loss : 0.163734 Content Loss: 0.030520

run [1400]:
Style Loss : 0.161362 Content Loss: 0.030765

run [1450]:
Style Loss : 0.159271 Content Loss: 0.031016

run [1500]:
Style Loss : 0.157363 Content Loss: 0.031271

run [1550]:
Style Loss : 0.155554 Content Loss: 0.031514

run [1600]:
Style Loss : 0.153870 Content Loss: 0.031746

run [1650]:
Style Loss : 0.152468 Content Loss: 0.031981

run [1700]:
Style Loss : 0.151047 Content Loss: 0.032195

run [1750]:
Style Loss : 0.149753 Content Loss: 0.032391

run [1800]:
Style Loss : 0.148547 Content Loss: 0.032565

run [1850]:
Style Loss : 0.147601 Content Loss: 0.032773

run [1900]:
Style Loss : 0.146619 Content Loss: 0.032989

run [1950]:
Style Loss : 0.145756 Content Loss: 0.033200

run [2000]:
Style Loss : 0.144899 Content Loss: 0.033433

run [2050]:
Style Loss : 0.144518 Content Loss: 0.033590

run [2100]:
Style Loss : 0.143504 Content Loss: 0.033849

run [2150]:
Style Loss : 0.142634 Content Loss: 0.034042

run [2200]:
Style Loss : 0.141801 Content Loss: 0.034187

run [2250]:
Style Loss : 0.141288 Content Loss: 0.034388

run [2300]:
Style Loss : 0.140676 Content Loss: 0.034549

run [2350]:
Style Loss : 0.140140 Content Loss: 0.034680

run [2400]:
Style Loss : 0.139256 Content Loss: 0.034780

run [2450]:
Style Loss : 0.138806 Content Loss: 0.034921

run [2500]:
Style Loss : 0.138676 Content Loss: 0.035057

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.211504 Content Loss: 0.001365

run [100]:
Style Loss : 0.736661 Content Loss: 0.001961

run [150]:
Style Loss : 0.586574 Content Loss: 0.002779

run [200]:
Style Loss : 0.500111 Content Loss: 0.003999

run [250]:
Style Loss : 0.427746 Content Loss: 0.005660

run [300]:
Style Loss : 0.357121 Content Loss: 0.007913

run [350]:
Style Loss : 0.290674 Content Loss: 0.010830

run [400]:
Style Loss : 0.235343 Content Loss: 0.014271

run [450]:
Style Loss : 0.192912 Content Loss: 0.017658

run [500]:
Style Loss : 0.166736 Content Loss: 0.020012

run [550]:
Style Loss : 0.150594 Content Loss: 0.021686

run [600]:
Style Loss : 0.140329 Content Loss: 0.022498

run [650]:
Style Loss : 0.132394 Content Loss: 0.022948

run [700]:
Style Loss : 0.125550 Content Loss: 0.023265

run [750]:
Style Loss : 0.119455 Content Loss: 0.023413

run [800]:
Style Loss : 0.114571 Content Loss: 0.023563

run [850]:
Style Loss : 0.110521 Content Loss: 0.023688

run [900]:
Style Loss : 0.107161 Content Loss: 0.023803

run [950]:
Style Loss : 0.104121 Content Loss: 0.023946

run [1000]:
Style Loss : 0.101265 Content Loss: 0.024085

run [1050]:
Style Loss : 0.098899 Content Loss: 0.024203

run [1100]:
Style Loss : 0.096839 Content Loss: 0.024322

run [1150]:
Style Loss : 0.094955 Content Loss: 0.024437

run [1200]:
Style Loss : 0.093158 Content Loss: 0.024560

run [1250]:
Style Loss : 0.091559 Content Loss: 0.024664

run [1300]:
Style Loss : 0.090112 Content Loss: 0.024774

run [1350]:
Style Loss : 0.088879 Content Loss: 0.024860

run [1400]:
Style Loss : 0.087773 Content Loss: 0.024952

run [1450]:
Style Loss : 0.086691 Content Loss: 0.025029

run [1500]:
Style Loss : 0.085662 Content Loss: 0.025111

run [1550]:
Style Loss : 0.084713 Content Loss: 0.025189

run [1600]:
Style Loss : 0.083817 Content Loss: 0.025258

run [1650]:
Style Loss : 0.082973 Content Loss: 0.025324

run [1700]:
Style Loss : 0.081683 Content Loss: 0.025382

run [1750]:
Style Loss : 0.080676 Content Loss: 0.025443

run [1800]:
Style Loss : 0.079852 Content Loss: 0.025494

run [1850]:
Style Loss : 0.079180 Content Loss: 0.025546

run [1900]:
Style Loss : 0.078598 Content Loss: 0.025588

run [1950]:
Style Loss : 0.078089 Content Loss: 0.025630

run [2000]:
Style Loss : 0.077593 Content Loss: 0.025667

run [2050]:
Style Loss : 0.077135 Content Loss: 0.025700

run [2100]:
Style Loss : 0.076690 Content Loss: 0.025729

run [2150]:
Style Loss : 0.076285 Content Loss: 0.025751

run [2200]:
Style Loss : 0.075896 Content Loss: 0.025774

run [2250]:
Style Loss : 0.075539 Content Loss: 0.025794

run [2300]:
Style Loss : 0.075224 Content Loss: 0.025812

run [2350]:
Style Loss : 0.074907 Content Loss: 0.025832

run [2400]:
Style Loss : 0.074619 Content Loss: 0.025850

run [2450]:
Style Loss : 0.074328 Content Loss: 0.025861

run [2500]:
Style Loss : 0.074083 Content Loss: 0.025870

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.042933 Content Loss: 0.003722

run [100]:
Style Loss : 1.472806 Content Loss: 0.005935

run [150]:
Style Loss : 1.115842 Content Loss: 0.011223

run [200]:
Style Loss : 0.796634 Content Loss: 0.020571

run [250]:
Style Loss : 0.570361 Content Loss: 0.033500

run [300]:
Style Loss : 0.449062 Content Loss: 0.042192

run [350]:
Style Loss : 0.391227 Content Loss: 0.046699

run [400]:
Style Loss : 0.361115 Content Loss: 0.048096

run [450]:
Style Loss : 0.341079 Content Loss: 0.048853

run [500]:
Style Loss : 0.325959 Content Loss: 0.049253

run [550]:
Style Loss : 0.314291 Content Loss: 0.049584

run [600]:
Style Loss : 0.304327 Content Loss: 0.049988

run [650]:
Style Loss : 0.296075 Content Loss: 0.050395

run [700]:
Style Loss : 0.288667 Content Loss: 0.050857

run [750]:
Style Loss : 0.282582 Content Loss: 0.051310

run [800]:
Style Loss : 0.277307 Content Loss: 0.051663

run [850]:
Style Loss : 0.272827 Content Loss: 0.052007

run [900]:
Style Loss : 0.268680 Content Loss: 0.052269

run [950]:
Style Loss : 0.265024 Content Loss: 0.052602

run [1000]:
Style Loss : 0.261833 Content Loss: 0.052830

run [1050]:
Style Loss : 0.259176 Content Loss: 0.053126

run [1100]:
Style Loss : 0.256654 Content Loss: 0.053405

run [1150]:
Style Loss : 0.254284 Content Loss: 0.053683

run [1200]:
Style Loss : 0.252365 Content Loss: 0.054002

run [1250]:
Style Loss : 0.250636 Content Loss: 0.054294

run [1300]:
Style Loss : 0.248947 Content Loss: 0.054489

run [1350]:
Style Loss : 0.247691 Content Loss: 0.054784

run [1400]:
Style Loss : 0.246992 Content Loss: 0.055076

run [1450]:
Style Loss : 0.246511 Content Loss: 0.055434

run [1500]:
Style Loss : 0.243824 Content Loss: 0.055574

run [1550]:
Style Loss : 0.242733 Content Loss: 0.055832

run [1600]:
Style Loss : 0.241914 Content Loss: 0.055972

run [1650]:
Style Loss : 0.241166 Content Loss: 0.056247

run [1700]:
Style Loss : 0.241129 Content Loss: 0.056468

run [1750]:
Style Loss : 0.237533 Content Loss: 0.056617

run [1800]:
Style Loss : 0.236161 Content Loss: 0.056726

run [1850]:
Style Loss : 0.234834 Content Loss: 0.056790

run [1900]:
Style Loss : 0.233388 Content Loss: 0.056852

run [1950]:
Style Loss : 0.232595 Content Loss: 0.056904

run [2000]:
Style Loss : 0.234180 Content Loss: 0.056954

run [2050]:
Style Loss : 0.230606 Content Loss: 0.056911

run [2100]:
Style Loss : 0.230334 Content Loss: 0.056894

run [2150]:
Style Loss : 0.230325 Content Loss: 0.056825

run [2200]:
Style Loss : 0.232411 Content Loss: 0.056823

run [2250]:
Style Loss : 0.228691 Content Loss: 0.056756

run [2300]:
Style Loss : 0.227825 Content Loss: 0.056669

run [2350]:
Style Loss : 0.226188 Content Loss: 0.056733

run [2400]:
Style Loss : 0.225218 Content Loss: 0.056648

run [2450]:
Style Loss : 0.224772 Content Loss: 0.056550

run [2500]:
Style Loss : 0.224599 Content Loss: 0.056431

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.398222 Content Loss: 0.005915

run [100]:
Style Loss : 0.816567 Content Loss: 0.011459

run [150]:
Style Loss : 0.491550 Content Loss: 0.019840

run [200]:
Style Loss : 0.297449 Content Loss: 0.028463

run [250]:
Style Loss : 0.198592 Content Loss: 0.034973

run [300]:
Style Loss : 0.159106 Content Loss: 0.037062

run [350]:
Style Loss : 0.138075 Content Loss: 0.037543

run [400]:
Style Loss : 0.123030 Content Loss: 0.037908

run [450]:
Style Loss : 0.111334 Content Loss: 0.038393

run [500]:
Style Loss : 0.101674 Content Loss: 0.038798

run [550]:
Style Loss : 0.094326 Content Loss: 0.039261

run [600]:
Style Loss : 0.088740 Content Loss: 0.039589

run [650]:
Style Loss : 0.084177 Content Loss: 0.039922

run [700]:
Style Loss : 0.080347 Content Loss: 0.040218

run [750]:
Style Loss : 0.076325 Content Loss: 0.040424

run [800]:
Style Loss : 0.072792 Content Loss: 0.040585

run [850]:
Style Loss : 0.070091 Content Loss: 0.040729

run [900]:
Style Loss : 0.067890 Content Loss: 0.040875

run [950]:
Style Loss : 0.065889 Content Loss: 0.040980

run [1000]:
Style Loss : 0.064103 Content Loss: 0.041054

run [1050]:
Style Loss : 0.062598 Content Loss: 0.041106

run [1100]:
Style Loss : 0.061143 Content Loss: 0.041141

run [1150]:
Style Loss : 0.059910 Content Loss: 0.041149

run [1200]:
Style Loss : 0.058741 Content Loss: 0.041194

run [1250]:
Style Loss : 0.057753 Content Loss: 0.041222

run [1300]:
Style Loss : 0.056842 Content Loss: 0.041231

run [1350]:
Style Loss : 0.056076 Content Loss: 0.041208

run [1400]:
Style Loss : 0.055291 Content Loss: 0.041191

run [1450]:
Style Loss : 0.054460 Content Loss: 0.041185

run [1500]:
Style Loss : 0.053776 Content Loss: 0.041156

run [1550]:
Style Loss : 0.053243 Content Loss: 0.041154

run [1600]:
Style Loss : 0.052726 Content Loss: 0.041122

run [1650]:
Style Loss : 0.052456 Content Loss: 0.041100

run [1700]:
Style Loss : 0.051862 Content Loss: 0.041056

run [1750]:
Style Loss : 0.051398 Content Loss: 0.041000

run [1800]:
Style Loss : 0.051111 Content Loss: 0.040977

run [1850]:
Style Loss : 0.050667 Content Loss: 0.040922

run [1900]:
Style Loss : 0.050337 Content Loss: 0.040872

run [1950]:
Style Loss : 0.050022 Content Loss: 0.040827

run [2000]:
Style Loss : 0.049792 Content Loss: 0.040776

run [2050]:
Style Loss : 0.049559 Content Loss: 0.040722

run [2100]:
Style Loss : 0.049084 Content Loss: 0.040707

run [2150]:
Style Loss : 0.048821 Content Loss: 0.040668

run [2200]:
Style Loss : 0.048876 Content Loss: 0.040609

run [2250]:
Style Loss : 0.048304 Content Loss: 0.040623

run [2300]:
Style Loss : 0.047958 Content Loss: 0.040613

run [2350]:
Style Loss : 0.047711 Content Loss: 0.040607

run [2400]:
Style Loss : 0.047430 Content Loss: 0.040577

run [2450]:
Style Loss : 0.047247 Content Loss: 0.040563

run [2500]:
Style Loss : 0.047389 Content Loss: 0.040534

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.730190 Content Loss: 0.001873

run [100]:
Style Loss : 1.868539 Content Loss: 0.002516

run [150]:
Style Loss : 1.551275 Content Loss: 0.003184

run [200]:
Style Loss : 1.352172 Content Loss: 0.004231

run [250]:
Style Loss : 1.197049 Content Loss: 0.005482

run [300]:
Style Loss : 1.058559 Content Loss: 0.007310

run [350]:
Style Loss : 0.929589 Content Loss: 0.009507

run [400]:
Style Loss : 0.813993 Content Loss: 0.012228

run [450]:
Style Loss : 0.714152 Content Loss: 0.015562

run [500]:
Style Loss : 0.636478 Content Loss: 0.018702

run [550]:
Style Loss : 0.574227 Content Loss: 0.021948

run [600]:
Style Loss : 0.530338 Content Loss: 0.024547

run [650]:
Style Loss : 0.497229 Content Loss: 0.026591

run [700]:
Style Loss : 0.472333 Content Loss: 0.028156

run [750]:
Style Loss : 0.453618 Content Loss: 0.029339

run [800]:
Style Loss : 0.438980 Content Loss: 0.030122

run [850]:
Style Loss : 0.426423 Content Loss: 0.030773

run [900]:
Style Loss : 0.415975 Content Loss: 0.031275

run [950]:
Style Loss : 0.407441 Content Loss: 0.031638

run [1000]:
Style Loss : 0.400010 Content Loss: 0.032043

run [1050]:
Style Loss : 0.393467 Content Loss: 0.032324

run [1100]:
Style Loss : 0.387572 Content Loss: 0.032578

run [1150]:
Style Loss : 0.382530 Content Loss: 0.032784

run [1200]:
Style Loss : 0.378212 Content Loss: 0.032998

run [1250]:
Style Loss : 0.374145 Content Loss: 0.033175

run [1300]:
Style Loss : 0.370479 Content Loss: 0.033364

run [1350]:
Style Loss : 0.367215 Content Loss: 0.033557

run [1400]:
Style Loss : 0.364220 Content Loss: 0.033717

run [1450]:
Style Loss : 0.361503 Content Loss: 0.033870

run [1500]:
Style Loss : 0.358783 Content Loss: 0.034020

run [1550]:
Style Loss : 0.356257 Content Loss: 0.034144

run [1600]:
Style Loss : 0.353697 Content Loss: 0.034293

run [1650]:
Style Loss : 0.351337 Content Loss: 0.034402

run [1700]:
Style Loss : 0.349042 Content Loss: 0.034514

run [1750]:
Style Loss : 0.346889 Content Loss: 0.034611

run [1800]:
Style Loss : 0.344867 Content Loss: 0.034704

run [1850]:
Style Loss : 0.343008 Content Loss: 0.034797

run [1900]:
Style Loss : 0.341292 Content Loss: 0.034883

run [1950]:
Style Loss : 0.339634 Content Loss: 0.034967

run [2000]:
Style Loss : 0.337798 Content Loss: 0.035056

run [2050]:
Style Loss : 0.336200 Content Loss: 0.035129

run [2100]:
Style Loss : 0.334725 Content Loss: 0.035197

run [2150]:
Style Loss : 0.333412 Content Loss: 0.035262

run [2200]:
Style Loss : 0.332134 Content Loss: 0.035324

run [2250]:
Style Loss : 0.331002 Content Loss: 0.035375

run [2300]:
Style Loss : 0.329949 Content Loss: 0.035420

run [2350]:
Style Loss : 0.328883 Content Loss: 0.035472

run [2400]:
Style Loss : 0.327870 Content Loss: 0.035513

run [2450]:
Style Loss : 0.326989 Content Loss: 0.035548

run [2500]:
Style Loss : 0.326179 Content Loss: 0.035582

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.412941 Content Loss: 0.002058

run [100]:
Style Loss : 1.499903 Content Loss: 0.002176

run [150]:
Style Loss : 1.205736 Content Loss: 0.002538

run [200]:
Style Loss : 1.037713 Content Loss: 0.003122

run [250]:
Style Loss : 0.926072 Content Loss: 0.003856

run [300]:
Style Loss : 0.835324 Content Loss: 0.004888

run [350]:
Style Loss : 0.756546 Content Loss: 0.006097

run [400]:
Style Loss : 0.683589 Content Loss: 0.007495

run [450]:
Style Loss : 0.614744 Content Loss: 0.009383

run [500]:
Style Loss : 0.548457 Content Loss: 0.011572

run [550]:
Style Loss : 0.487410 Content Loss: 0.014032

run [600]:
Style Loss : 0.435734 Content Loss: 0.016594

run [650]:
Style Loss : 0.390000 Content Loss: 0.019515

run [700]:
Style Loss : 0.354512 Content Loss: 0.022038

run [750]:
Style Loss : 0.329134 Content Loss: 0.024064

run [800]:
Style Loss : 0.309012 Content Loss: 0.025951

run [850]:
Style Loss : 0.294245 Content Loss: 0.027004

run [900]:
Style Loss : 0.283315 Content Loss: 0.027582

run [950]:
Style Loss : 0.273973 Content Loss: 0.028124

run [1000]:
Style Loss : 0.265997 Content Loss: 0.028371

run [1050]:
Style Loss : 0.259168 Content Loss: 0.028628

run [1100]:
Style Loss : 0.252872 Content Loss: 0.028754

run [1150]:
Style Loss : 0.246607 Content Loss: 0.028896

run [1200]:
Style Loss : 0.241403 Content Loss: 0.028958

run [1250]:
Style Loss : 0.236588 Content Loss: 0.029055

run [1300]:
Style Loss : 0.232162 Content Loss: 0.029144

run [1350]:
Style Loss : 0.228013 Content Loss: 0.029242

run [1400]:
Style Loss : 0.224130 Content Loss: 0.029341

run [1450]:
Style Loss : 0.220415 Content Loss: 0.029463

run [1500]:
Style Loss : 0.216705 Content Loss: 0.029582

run [1550]:
Style Loss : 0.213000 Content Loss: 0.029700

run [1600]:
Style Loss : 0.209372 Content Loss: 0.029842

run [1650]:
Style Loss : 0.206023 Content Loss: 0.029961

run [1700]:
Style Loss : 0.202734 Content Loss: 0.030123

run [1750]:
Style Loss : 0.199377 Content Loss: 0.030281

run [1800]:
Style Loss : 0.196159 Content Loss: 0.030456

run [1850]:
Style Loss : 0.193143 Content Loss: 0.030650

run [1900]:
Style Loss : 0.190073 Content Loss: 0.030858

run [1950]:
Style Loss : 0.186857 Content Loss: 0.031093

run [2000]:
Style Loss : 0.183873 Content Loss: 0.031340

run [2050]:
Style Loss : 0.181025 Content Loss: 0.031583

run [2100]:
Style Loss : 0.178248 Content Loss: 0.031856

run [2150]:
Style Loss : 0.175514 Content Loss: 0.032153

run [2200]:
Style Loss : 0.172712 Content Loss: 0.032468

run [2250]:
Style Loss : 0.169924 Content Loss: 0.032781

run [2300]:
Style Loss : 0.167235 Content Loss: 0.033096

run [2350]:
Style Loss : 0.164656 Content Loss: 0.033420

run [2400]:
Style Loss : 0.162235 Content Loss: 0.033732

run [2450]:
Style Loss : 0.159851 Content Loss: 0.034085

run [2500]:
Style Loss : 0.157660 Content Loss: 0.034392

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.852752 Content Loss: 0.003262

run [100]:
Style Loss : 1.219748 Content Loss: 0.004141

run [150]:
Style Loss : 0.961341 Content Loss: 0.005637

run [200]:
Style Loss : 0.809326 Content Loss: 0.007648

run [250]:
Style Loss : 0.683857 Content Loss: 0.010036

run [300]:
Style Loss : 0.585093 Content Loss: 0.012894

run [350]:
Style Loss : 0.509612 Content Loss: 0.015427

run [400]:
Style Loss : 0.459881 Content Loss: 0.017676

run [450]:
Style Loss : 0.426135 Content Loss: 0.019462

run [500]:
Style Loss : 0.403392 Content Loss: 0.020733

run [550]:
Style Loss : 0.386411 Content Loss: 0.021676

run [600]:
Style Loss : 0.373195 Content Loss: 0.022359

run [650]:
Style Loss : 0.362027 Content Loss: 0.022980

run [700]:
Style Loss : 0.351564 Content Loss: 0.023465

run [750]:
Style Loss : 0.342372 Content Loss: 0.023926

run [800]:
Style Loss : 0.334599 Content Loss: 0.024312

run [850]:
Style Loss : 0.327699 Content Loss: 0.024700

run [900]:
Style Loss : 0.321294 Content Loss: 0.025052

run [950]:
Style Loss : 0.316004 Content Loss: 0.025368

run [1000]:
Style Loss : 0.310985 Content Loss: 0.025676

run [1050]:
Style Loss : 0.306009 Content Loss: 0.025967

run [1100]:
Style Loss : 0.301447 Content Loss: 0.026261

run [1150]:
Style Loss : 0.296974 Content Loss: 0.026526

run [1200]:
Style Loss : 0.292878 Content Loss: 0.026792

run [1250]:
Style Loss : 0.289183 Content Loss: 0.027054

run [1300]:
Style Loss : 0.285979 Content Loss: 0.027302

run [1350]:
Style Loss : 0.282386 Content Loss: 0.027568

run [1400]:
Style Loss : 0.278619 Content Loss: 0.027791

run [1450]:
Style Loss : 0.274764 Content Loss: 0.028026

run [1500]:
Style Loss : 0.270753 Content Loss: 0.028251

run [1550]:
Style Loss : 0.267117 Content Loss: 0.028440

run [1600]:
Style Loss : 0.263637 Content Loss: 0.028613

run [1650]:
Style Loss : 0.260602 Content Loss: 0.028773

run [1700]:
Style Loss : 0.258088 Content Loss: 0.028905

run [1750]:
Style Loss : 0.255874 Content Loss: 0.029058

run [1800]:
Style Loss : 0.253807 Content Loss: 0.029193

run [1850]:
Style Loss : 0.252020 Content Loss: 0.029308

run [1900]:
Style Loss : 0.250223 Content Loss: 0.029447

run [1950]:
Style Loss : 0.248571 Content Loss: 0.029552

run [2000]:
Style Loss : 0.247025 Content Loss: 0.029671

run [2050]:
Style Loss : 0.245588 Content Loss: 0.029780

run [2100]:
Style Loss : 0.244254 Content Loss: 0.029890

run [2150]:
Style Loss : 0.242955 Content Loss: 0.029983

run [2200]:
Style Loss : 0.241720 Content Loss: 0.030099

run [2250]:
Style Loss : 0.240446 Content Loss: 0.030187

run [2300]:
Style Loss : 0.239214 Content Loss: 0.030303

run [2350]:
Style Loss : 0.238061 Content Loss: 0.030395

run [2400]:
Style Loss : 0.236971 Content Loss: 0.030483

run [2450]:
Style Loss : 0.236023 Content Loss: 0.030563

run [2500]:
Style Loss : 0.235055 Content Loss: 0.030682

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.667902 Content Loss: 0.001518

run [100]:
Style Loss : 1.832570 Content Loss: 0.001692

run [150]:
Style Loss : 1.518406 Content Loss: 0.002124

run [200]:
Style Loss : 1.332233 Content Loss: 0.002759

run [250]:
Style Loss : 1.194776 Content Loss: 0.003406

run [300]:
Style Loss : 1.094621 Content Loss: 0.004044

run [350]:
Style Loss : 1.017147 Content Loss: 0.004764

run [400]:
Style Loss : 0.950689 Content Loss: 0.005591

run [450]:
Style Loss : 0.891230 Content Loss: 0.006448

run [500]:
Style Loss : 0.839101 Content Loss: 0.007365

run [550]:
Style Loss : 0.790235 Content Loss: 0.008409

run [600]:
Style Loss : 0.747935 Content Loss: 0.009421

run [650]:
Style Loss : 0.712093 Content Loss: 0.010515

run [700]:
Style Loss : 0.677020 Content Loss: 0.011812

run [750]:
Style Loss : 0.643841 Content Loss: 0.013052

run [800]:
Style Loss : 0.614474 Content Loss: 0.014261

run [850]:
Style Loss : 0.589837 Content Loss: 0.015298

run [900]:
Style Loss : 0.566866 Content Loss: 0.016402

run [950]:
Style Loss : 0.547202 Content Loss: 0.017400

run [1000]:
Style Loss : 0.530798 Content Loss: 0.018335

run [1050]:
Style Loss : 0.516580 Content Loss: 0.019134

run [1100]:
Style Loss : 0.504453 Content Loss: 0.019713

run [1150]:
Style Loss : 0.493668 Content Loss: 0.020389

run [1200]:
Style Loss : 0.484714 Content Loss: 0.020841

run [1250]:
Style Loss : 0.476627 Content Loss: 0.021248

run [1300]:
Style Loss : 0.469645 Content Loss: 0.021600

run [1350]:
Style Loss : 0.463511 Content Loss: 0.021928

run [1400]:
Style Loss : 0.457666 Content Loss: 0.022188

run [1450]:
Style Loss : 0.452201 Content Loss: 0.022406

run [1500]:
Style Loss : 0.447736 Content Loss: 0.022562

run [1550]:
Style Loss : 0.443588 Content Loss: 0.022713

run [1600]:
Style Loss : 0.439890 Content Loss: 0.022851

run [1650]:
Style Loss : 0.436318 Content Loss: 0.022952

run [1700]:
Style Loss : 0.432924 Content Loss: 0.023060

run [1750]:
Style Loss : 0.429555 Content Loss: 0.023139

run [1800]:
Style Loss : 0.426778 Content Loss: 0.023207

run [1850]:
Style Loss : 0.424225 Content Loss: 0.023265

run [1900]:
Style Loss : 0.421953 Content Loss: 0.023317

run [1950]:
Style Loss : 0.419849 Content Loss: 0.023382

run [2000]:
Style Loss : 0.417835 Content Loss: 0.023442

run [2050]:
Style Loss : 0.415913 Content Loss: 0.023494

run [2100]:
Style Loss : 0.414178 Content Loss: 0.023537

run [2150]:
Style Loss : 0.412454 Content Loss: 0.023585

run [2200]:
Style Loss : 0.410746 Content Loss: 0.023630

run [2250]:
Style Loss : 0.409169 Content Loss: 0.023668

run [2300]:
Style Loss : 0.407511 Content Loss: 0.023708

run [2350]:
Style Loss : 0.406043 Content Loss: 0.023747

run [2400]:
Style Loss : 0.404752 Content Loss: 0.023783

run [2450]:
Style Loss : 0.403301 Content Loss: 0.023821

run [2500]:
Style Loss : 0.401853 Content Loss: 0.023860

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.162364 Content Loss: 0.003276

run [100]:
Style Loss : 1.939259 Content Loss: 0.003264

run [150]:
Style Loss : 1.520201 Content Loss: 0.003853

run [200]:
Style Loss : 1.301526 Content Loss: 0.004572

run [250]:
Style Loss : 1.164716 Content Loss: 0.005422

run [300]:
Style Loss : 1.054347 Content Loss: 0.006565

run [350]:
Style Loss : 0.959445 Content Loss: 0.007760

run [400]:
Style Loss : 0.881798 Content Loss: 0.009039

run [450]:
Style Loss : 0.815406 Content Loss: 0.010521

run [500]:
Style Loss : 0.756802 Content Loss: 0.012224

run [550]:
Style Loss : 0.707943 Content Loss: 0.013963

run [600]:
Style Loss : 0.667391 Content Loss: 0.015661

run [650]:
Style Loss : 0.635521 Content Loss: 0.017215

run [700]:
Style Loss : 0.610571 Content Loss: 0.018646

run [750]:
Style Loss : 0.591202 Content Loss: 0.019728

run [800]:
Style Loss : 0.575482 Content Loss: 0.020613

run [850]:
Style Loss : 0.563067 Content Loss: 0.021343

run [900]:
Style Loss : 0.552979 Content Loss: 0.021991

run [950]:
Style Loss : 0.544416 Content Loss: 0.022486

run [1000]:
Style Loss : 0.536776 Content Loss: 0.022894

run [1050]:
Style Loss : 0.530431 Content Loss: 0.023272

run [1100]:
Style Loss : 0.524164 Content Loss: 0.023580

run [1150]:
Style Loss : 0.518800 Content Loss: 0.023852

run [1200]:
Style Loss : 0.513849 Content Loss: 0.024083

run [1250]:
Style Loss : 0.509515 Content Loss: 0.024293

run [1300]:
Style Loss : 0.505835 Content Loss: 0.024470

run [1350]:
Style Loss : 0.502165 Content Loss: 0.024624

run [1400]:
Style Loss : 0.498733 Content Loss: 0.024746

run [1450]:
Style Loss : 0.495576 Content Loss: 0.024864

run [1500]:
Style Loss : 0.492577 Content Loss: 0.024959

run [1550]:
Style Loss : 0.489230 Content Loss: 0.025058

run [1600]:
Style Loss : 0.485953 Content Loss: 0.025141

run [1650]:
Style Loss : 0.483138 Content Loss: 0.025208

run [1700]:
Style Loss : 0.480671 Content Loss: 0.025268

run [1750]:
Style Loss : 0.478489 Content Loss: 0.025337

run [1800]:
Style Loss : 0.476385 Content Loss: 0.025398

run [1850]:
Style Loss : 0.474430 Content Loss: 0.025442

run [1900]:
Style Loss : 0.472656 Content Loss: 0.025487

run [1950]:
Style Loss : 0.470975 Content Loss: 0.025534

run [2000]:
Style Loss : 0.469422 Content Loss: 0.025585

run [2050]:
Style Loss : 0.467983 Content Loss: 0.025630

run [2100]:
Style Loss : 0.466671 Content Loss: 0.025668

run [2150]:
Style Loss : 0.465314 Content Loss: 0.025705

run [2200]:
Style Loss : 0.464086 Content Loss: 0.025740

run [2250]:
Style Loss : 0.462946 Content Loss: 0.025776

run [2300]:
Style Loss : 0.461886 Content Loss: 0.025808

run [2350]:
Style Loss : 0.460857 Content Loss: 0.025839

run [2400]:
Style Loss : 0.459906 Content Loss: 0.025867

run [2450]:
Style Loss : 0.458002 Content Loss: 0.025908

run [2500]:
Style Loss : 0.455778 Content Loss: 0.025945

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.583148 Content Loss: 0.005238

run [100]:
Style Loss : 2.789078 Content Loss: 0.005287

run [150]:
Style Loss : 2.171974 Content Loss: 0.006061

run [200]:
Style Loss : 1.820749 Content Loss: 0.007120

run [250]:
Style Loss : 1.576617 Content Loss: 0.008453

run [300]:
Style Loss : 1.386229 Content Loss: 0.009805

run [350]:
Style Loss : 1.230271 Content Loss: 0.011344

run [400]:
Style Loss : 1.106331 Content Loss: 0.013122

run [450]:
Style Loss : 0.996300 Content Loss: 0.015131

run [500]:
Style Loss : 0.902701 Content Loss: 0.017196

run [550]:
Style Loss : 0.826638 Content Loss: 0.019141

run [600]:
Style Loss : 0.770666 Content Loss: 0.020755

run [650]:
Style Loss : 0.727780 Content Loss: 0.022358

run [700]:
Style Loss : 0.698482 Content Loss: 0.023616

run [750]:
Style Loss : 0.680363 Content Loss: 0.024410

run [800]:
Style Loss : 0.665981 Content Loss: 0.025275

run [850]:
Style Loss : 0.651817 Content Loss: 0.025807

run [900]:
Style Loss : 0.640580 Content Loss: 0.026448

run [950]:
Style Loss : 0.630234 Content Loss: 0.026780

run [1000]:
Style Loss : 0.621093 Content Loss: 0.027121

run [1050]:
Style Loss : 0.611317 Content Loss: 0.027526

run [1100]:
Style Loss : 0.602413 Content Loss: 0.027849

run [1150]:
Style Loss : 0.592841 Content Loss: 0.028153

run [1200]:
Style Loss : 0.585663 Content Loss: 0.028386

run [1250]:
Style Loss : 0.577508 Content Loss: 0.028555

run [1300]:
Style Loss : 0.569709 Content Loss: 0.028803

run [1350]:
Style Loss : 0.563138 Content Loss: 0.028978

run [1400]:
Style Loss : 0.557576 Content Loss: 0.029122

run [1450]:
Style Loss : 0.550608 Content Loss: 0.029280

run [1500]:
Style Loss : 0.545881 Content Loss: 0.029385

run [1550]:
Style Loss : 0.541166 Content Loss: 0.029512

run [1600]:
Style Loss : 0.536628 Content Loss: 0.029624

run [1650]:
Style Loss : 0.531749 Content Loss: 0.029776

run [1700]:
Style Loss : 0.525968 Content Loss: 0.029886

run [1750]:
Style Loss : 0.521297 Content Loss: 0.029992

run [1800]:
Style Loss : 0.517315 Content Loss: 0.030061

run [1850]:
Style Loss : 0.513856 Content Loss: 0.030148

run [1900]:
Style Loss : 0.510729 Content Loss: 0.030247

run [1950]:
Style Loss : 0.507941 Content Loss: 0.030323

run [2000]:
Style Loss : 0.505459 Content Loss: 0.030393

run [2050]:
Style Loss : 0.503041 Content Loss: 0.030472

run [2100]:
Style Loss : 0.500523 Content Loss: 0.030570

run [2150]:
Style Loss : 0.497899 Content Loss: 0.030638

run [2200]:
Style Loss : 0.495524 Content Loss: 0.030731

run [2250]:
Style Loss : 0.493281 Content Loss: 0.030791

run [2300]:
Style Loss : 0.490967 Content Loss: 0.030851

run [2350]:
Style Loss : 0.488851 Content Loss: 0.030920

run [2400]:
Style Loss : 0.486702 Content Loss: 0.030989

run [2450]:
Style Loss : 0.484607 Content Loss: 0.031053

run [2500]:
Style Loss : 0.482534 Content Loss: 0.031115

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.356649 Content Loss: 0.004139

run [100]:
Style Loss : 1.451833 Content Loss: 0.004300

run [150]:
Style Loss : 1.103093 Content Loss: 0.005294

run [200]:
Style Loss : 0.890675 Content Loss: 0.006581

run [250]:
Style Loss : 0.723731 Content Loss: 0.008901

run [300]:
Style Loss : 0.584906 Content Loss: 0.011347

run [350]:
Style Loss : 0.465289 Content Loss: 0.014781

run [400]:
Style Loss : 0.363657 Content Loss: 0.018359

run [450]:
Style Loss : 0.290556 Content Loss: 0.022369

run [500]:
Style Loss : 0.243566 Content Loss: 0.025033

run [550]:
Style Loss : 0.213450 Content Loss: 0.026857

run [600]:
Style Loss : 0.191175 Content Loss: 0.027796

run [650]:
Style Loss : 0.174779 Content Loss: 0.028198

run [700]:
Style Loss : 0.162711 Content Loss: 0.028490

run [750]:
Style Loss : 0.153133 Content Loss: 0.028683

run [800]:
Style Loss : 0.145367 Content Loss: 0.028936

run [850]:
Style Loss : 0.138514 Content Loss: 0.029260

run [900]:
Style Loss : 0.132457 Content Loss: 0.029403

run [950]:
Style Loss : 0.127123 Content Loss: 0.029511

run [1000]:
Style Loss : 0.122148 Content Loss: 0.029688

run [1050]:
Style Loss : 0.117532 Content Loss: 0.029826

run [1100]:
Style Loss : 0.113185 Content Loss: 0.030022

run [1150]:
Style Loss : 0.109240 Content Loss: 0.030166

run [1200]:
Style Loss : 0.105365 Content Loss: 0.030318

run [1250]:
Style Loss : 0.102221 Content Loss: 0.030437

run [1300]:
Style Loss : 0.098808 Content Loss: 0.030545

run [1350]:
Style Loss : 0.095644 Content Loss: 0.030640

run [1400]:
Style Loss : 0.093130 Content Loss: 0.030727

run [1450]:
Style Loss : 0.090959 Content Loss: 0.030809

run [1500]:
Style Loss : 0.089000 Content Loss: 0.030878

run [1550]:
Style Loss : 0.087124 Content Loss: 0.030941

run [1600]:
Style Loss : 0.085429 Content Loss: 0.030991

run [1650]:
Style Loss : 0.083906 Content Loss: 0.031030

run [1700]:
Style Loss : 0.082391 Content Loss: 0.031067

run [1750]:
Style Loss : 0.081045 Content Loss: 0.031078

run [1800]:
Style Loss : 0.079804 Content Loss: 0.031089

run [1850]:
Style Loss : 0.078592 Content Loss: 0.031111

run [1900]:
Style Loss : 0.077464 Content Loss: 0.031118

run [1950]:
Style Loss : 0.076476 Content Loss: 0.031138

run [2000]:
Style Loss : 0.075487 Content Loss: 0.031155

run [2050]:
Style Loss : 0.074566 Content Loss: 0.031162

run [2100]:
Style Loss : 0.073684 Content Loss: 0.031176

run [2150]:
Style Loss : 0.072878 Content Loss: 0.031186

run [2200]:
Style Loss : 0.072131 Content Loss: 0.031197

run [2250]:
Style Loss : 0.071375 Content Loss: 0.031203

run [2300]:
Style Loss : 0.070699 Content Loss: 0.031201

run [2350]:
Style Loss : 0.070083 Content Loss: 0.031199

run [2400]:
Style Loss : 0.069514 Content Loss: 0.031192

run [2450]:
Style Loss : 0.069000 Content Loss: 0.031184

run [2500]:
Style Loss : 0.068516 Content Loss: 0.031170

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.788159 Content Loss: 0.002964

run [100]:
Style Loss : 1.147307 Content Loss: 0.003353

run [150]:
Style Loss : 0.933218 Content Loss: 0.004135

run [200]:
Style Loss : 0.805665 Content Loss: 0.005426

run [250]:
Style Loss : 0.711512 Content Loss: 0.006884

run [300]:
Style Loss : 0.637223 Content Loss: 0.008571

run [350]:
Style Loss : 0.578426 Content Loss: 0.010422

run [400]:
Style Loss : 0.531814 Content Loss: 0.012444

run [450]:
Style Loss : 0.494040 Content Loss: 0.014518

run [500]:
Style Loss : 0.464986 Content Loss: 0.016362

run [550]:
Style Loss : 0.441426 Content Loss: 0.017684

run [600]:
Style Loss : 0.425083 Content Loss: 0.018765

run [650]:
Style Loss : 0.412543 Content Loss: 0.019624

run [700]:
Style Loss : 0.402750 Content Loss: 0.020292

run [750]:
Style Loss : 0.394494 Content Loss: 0.020861

run [800]:
Style Loss : 0.387220 Content Loss: 0.021362

run [850]:
Style Loss : 0.379807 Content Loss: 0.021777

run [900]:
Style Loss : 0.373706 Content Loss: 0.022148

run [950]:
Style Loss : 0.368121 Content Loss: 0.022491

run [1000]:
Style Loss : 0.362714 Content Loss: 0.022778

run [1050]:
Style Loss : 0.358008 Content Loss: 0.023016

run [1100]:
Style Loss : 0.353611 Content Loss: 0.023265

run [1150]:
Style Loss : 0.349548 Content Loss: 0.023458

run [1200]:
Style Loss : 0.345870 Content Loss: 0.023671

run [1250]:
Style Loss : 0.342510 Content Loss: 0.023851

run [1300]:
Style Loss : 0.339147 Content Loss: 0.024039

run [1350]:
Style Loss : 0.336157 Content Loss: 0.024206

run [1400]:
Style Loss : 0.333581 Content Loss: 0.024348

run [1450]:
Style Loss : 0.331293 Content Loss: 0.024476

run [1500]:
Style Loss : 0.329186 Content Loss: 0.024602

run [1550]:
Style Loss : 0.327234 Content Loss: 0.024730

run [1600]:
Style Loss : 0.325358 Content Loss: 0.024861

run [1650]:
Style Loss : 0.323619 Content Loss: 0.024973

run [1700]:
Style Loss : 0.321629 Content Loss: 0.025096

run [1750]:
Style Loss : 0.320005 Content Loss: 0.025196

run [1800]:
Style Loss : 0.318504 Content Loss: 0.025300

run [1850]:
Style Loss : 0.317107 Content Loss: 0.025409

run [1900]:
Style Loss : 0.315615 Content Loss: 0.025506

run [1950]:
Style Loss : 0.314267 Content Loss: 0.025615

run [2000]:
Style Loss : 0.312940 Content Loss: 0.025721

run [2050]:
Style Loss : 0.311790 Content Loss: 0.025811

run [2100]:
Style Loss : 0.310642 Content Loss: 0.025916

run [2150]:
Style Loss : 0.309545 Content Loss: 0.026017

run [2200]:
Style Loss : 0.308491 Content Loss: 0.026109

run [2250]:
Style Loss : 0.307529 Content Loss: 0.026199

run [2300]:
Style Loss : 0.306548 Content Loss: 0.026296

run [2350]:
Style Loss : 0.305589 Content Loss: 0.026390

run [2400]:
Style Loss : 0.304700 Content Loss: 0.026487

run [2450]:
Style Loss : 0.303759 Content Loss: 0.026595

run [2500]:
Style Loss : 0.302811 Content Loss: 0.026692

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.176403 Content Loss: 0.001725

run [100]:
Style Loss : 0.759101 Content Loss: 0.002249

run [150]:
Style Loss : 0.608247 Content Loss: 0.003003

run [200]:
Style Loss : 0.519011 Content Loss: 0.003865

run [250]:
Style Loss : 0.456379 Content Loss: 0.004906

run [300]:
Style Loss : 0.406888 Content Loss: 0.006098

run [350]:
Style Loss : 0.363951 Content Loss: 0.007426

run [400]:
Style Loss : 0.331968 Content Loss: 0.008694

run [450]:
Style Loss : 0.307679 Content Loss: 0.009894

run [500]:
Style Loss : 0.288965 Content Loss: 0.010990

run [550]:
Style Loss : 0.275124 Content Loss: 0.011912

run [600]:
Style Loss : 0.265266 Content Loss: 0.012676

run [650]:
Style Loss : 0.257653 Content Loss: 0.013224

run [700]:
Style Loss : 0.250677 Content Loss: 0.013812

run [750]:
Style Loss : 0.244719 Content Loss: 0.014197

run [800]:
Style Loss : 0.239776 Content Loss: 0.014559

run [850]:
Style Loss : 0.235615 Content Loss: 0.014867

run [900]:
Style Loss : 0.232032 Content Loss: 0.015105

run [950]:
Style Loss : 0.228642 Content Loss: 0.015336

run [1000]:
Style Loss : 0.225516 Content Loss: 0.015566

run [1050]:
Style Loss : 0.222394 Content Loss: 0.015784

run [1100]:
Style Loss : 0.219444 Content Loss: 0.015956

run [1150]:
Style Loss : 0.216521 Content Loss: 0.016132

run [1200]:
Style Loss : 0.213851 Content Loss: 0.016311

run [1250]:
Style Loss : 0.211222 Content Loss: 0.016482

run [1300]:
Style Loss : 0.208881 Content Loss: 0.016629

run [1350]:
Style Loss : 0.206556 Content Loss: 0.016791

run [1400]:
Style Loss : 0.204405 Content Loss: 0.016951

run [1450]:
Style Loss : 0.202338 Content Loss: 0.017120

run [1500]:
Style Loss : 0.200137 Content Loss: 0.017289

run [1550]:
Style Loss : 0.198302 Content Loss: 0.017459

run [1600]:
Style Loss : 0.196492 Content Loss: 0.017625

run [1650]:
Style Loss : 0.194718 Content Loss: 0.017813

run [1700]:
Style Loss : 0.193130 Content Loss: 0.018013

run [1750]:
Style Loss : 0.191442 Content Loss: 0.018205

run [1800]:
Style Loss : 0.189954 Content Loss: 0.018411

run [1850]:
Style Loss : 0.188373 Content Loss: 0.018626

run [1900]:
Style Loss : 0.186890 Content Loss: 0.018904

run [1950]:
Style Loss : 0.185024 Content Loss: 0.019113

run [2000]:
Style Loss : 0.183275 Content Loss: 0.019375

run [2050]:
Style Loss : 0.181170 Content Loss: 0.019632

run [2100]:
Style Loss : 0.178929 Content Loss: 0.019875

run [2150]:
Style Loss : 0.177039 Content Loss: 0.020140

run [2200]:
Style Loss : 0.175296 Content Loss: 0.020423

run [2250]:
Style Loss : 0.173909 Content Loss: 0.020762

run [2300]:
Style Loss : 0.172624 Content Loss: 0.021087

run [2350]:
Style Loss : 0.172393 Content Loss: 0.021536

run [2400]:
Style Loss : 0.170478 Content Loss: 0.021752

run [2450]:
Style Loss : 0.168290 Content Loss: 0.021979

run [2500]:
Style Loss : 0.167362 Content Loss: 0.022293

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.904837 Content Loss: 0.002070

run [100]:
Style Loss : 0.591395 Content Loss: 0.003344

run [150]:
Style Loss : 0.437055 Content Loss: 0.005765

run [200]:
Style Loss : 0.326890 Content Loss: 0.009277

run [250]:
Style Loss : 0.249360 Content Loss: 0.013725

run [300]:
Style Loss : 0.205310 Content Loss: 0.017245

run [350]:
Style Loss : 0.181328 Content Loss: 0.019295

run [400]:
Style Loss : 0.166072 Content Loss: 0.020485

run [450]:
Style Loss : 0.155361 Content Loss: 0.021220

run [500]:
Style Loss : 0.146858 Content Loss: 0.021961

run [550]:
Style Loss : 0.139610 Content Loss: 0.022600

run [600]:
Style Loss : 0.133665 Content Loss: 0.023240

run [650]:
Style Loss : 0.128688 Content Loss: 0.023725

run [700]:
Style Loss : 0.124590 Content Loss: 0.024172

run [750]:
Style Loss : 0.121307 Content Loss: 0.024536

run [800]:
Style Loss : 0.118197 Content Loss: 0.024881

run [850]:
Style Loss : 0.115549 Content Loss: 0.025146

run [900]:
Style Loss : 0.113228 Content Loss: 0.025383

run [950]:
Style Loss : 0.111211 Content Loss: 0.025593

run [1000]:
Style Loss : 0.109274 Content Loss: 0.025771

run [1050]:
Style Loss : 0.107254 Content Loss: 0.025927

run [1100]:
Style Loss : 0.105273 Content Loss: 0.026055

run [1150]:
Style Loss : 0.103552 Content Loss: 0.026151

run [1200]:
Style Loss : 0.102293 Content Loss: 0.026229

run [1250]:
Style Loss : 0.101177 Content Loss: 0.026322

run [1300]:
Style Loss : 0.100098 Content Loss: 0.026397

run [1350]:
Style Loss : 0.099254 Content Loss: 0.026499

run [1400]:
Style Loss : 0.098593 Content Loss: 0.026597

run [1450]:
Style Loss : 0.097535 Content Loss: 0.026628

run [1500]:
Style Loss : 0.096920 Content Loss: 0.026728

run [1550]:
Style Loss : 0.100730 Content Loss: 0.027027

run [1600]:
Style Loss : 0.096267 Content Loss: 0.026982

run [1650]:
Style Loss : 0.094651 Content Loss: 0.027011

run [1700]:
Style Loss : 0.093745 Content Loss: 0.027029

run [1750]:
Style Loss : 0.093776 Content Loss: 0.027099

run [1800]:
Style Loss : 0.093072 Content Loss: 0.027118

run [1850]:
Style Loss : 0.093429 Content Loss: 0.027198

run [1900]:
Style Loss : 0.092144 Content Loss: 0.027188

run [1950]:
Style Loss : 0.091316 Content Loss: 0.027241

run [2000]:
Style Loss : 0.091462 Content Loss: 0.027264

run [2050]:
Style Loss : 0.090145 Content Loss: 0.027275

run [2100]:
Style Loss : 0.089909 Content Loss: 0.027304

run [2150]:
Style Loss : 0.090711 Content Loss: 0.027397

run [2200]:
Style Loss : 0.845747 Content Loss: 0.026958

run [2250]:
Style Loss : 0.092388 Content Loss: 0.027445

run [2300]:
Style Loss : 0.088676 Content Loss: 0.027465

run [2350]:
Style Loss : 0.087273 Content Loss: 0.027505

run [2400]:
Style Loss : 0.086469 Content Loss: 0.027525

run [2450]:
Style Loss : 0.085912 Content Loss: 0.027531

run [2500]:
Style Loss : 0.085498 Content Loss: 0.027526

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.988778 Content Loss: 0.001172

run [100]:
Style Loss : 0.687400 Content Loss: 0.001816

run [150]:
Style Loss : 0.564583 Content Loss: 0.002666

run [200]:
Style Loss : 0.487141 Content Loss: 0.003739

run [250]:
Style Loss : 0.429169 Content Loss: 0.004910

run [300]:
Style Loss : 0.383037 Content Loss: 0.006177

run [350]:
Style Loss : 0.347422 Content Loss: 0.007455

run [400]:
Style Loss : 0.318657 Content Loss: 0.008774

run [450]:
Style Loss : 0.295814 Content Loss: 0.010048

run [500]:
Style Loss : 0.278064 Content Loss: 0.011166

run [550]:
Style Loss : 0.263145 Content Loss: 0.012224

run [600]:
Style Loss : 0.251955 Content Loss: 0.013016

run [650]:
Style Loss : 0.243477 Content Loss: 0.013677

run [700]:
Style Loss : 0.236715 Content Loss: 0.014180

run [750]:
Style Loss : 0.231013 Content Loss: 0.014624

run [800]:
Style Loss : 0.225787 Content Loss: 0.014995

run [850]:
Style Loss : 0.221430 Content Loss: 0.015297

run [900]:
Style Loss : 0.217485 Content Loss: 0.015566

run [950]:
Style Loss : 0.213957 Content Loss: 0.015825

run [1000]:
Style Loss : 0.210661 Content Loss: 0.016073

run [1050]:
Style Loss : 0.207487 Content Loss: 0.016296

run [1100]:
Style Loss : 0.204390 Content Loss: 0.016520

run [1150]:
Style Loss : 0.201785 Content Loss: 0.016713

run [1200]:
Style Loss : 0.199381 Content Loss: 0.016897

run [1250]:
Style Loss : 0.197274 Content Loss: 0.017056

run [1300]:
Style Loss : 0.195364 Content Loss: 0.017219

run [1350]:
Style Loss : 0.193635 Content Loss: 0.017373

run [1400]:
Style Loss : 0.192046 Content Loss: 0.017516

run [1450]:
Style Loss : 0.190533 Content Loss: 0.017663

run [1500]:
Style Loss : 0.189160 Content Loss: 0.017802

run [1550]:
Style Loss : 0.187701 Content Loss: 0.017945

run [1600]:
Style Loss : 0.186270 Content Loss: 0.018088

run [1650]:
Style Loss : 0.184893 Content Loss: 0.018222

run [1700]:
Style Loss : 0.183633 Content Loss: 0.018341

run [1750]:
Style Loss : 0.182355 Content Loss: 0.018451

run [1800]:
Style Loss : 0.181156 Content Loss: 0.018560

run [1850]:
Style Loss : 0.179972 Content Loss: 0.018665

run [1900]:
Style Loss : 0.178881 Content Loss: 0.018770

run [1950]:
Style Loss : 0.177730 Content Loss: 0.018880

run [2000]:
Style Loss : 0.176560 Content Loss: 0.018985

run [2050]:
Style Loss : 0.175078 Content Loss: 0.019115

run [2100]:
Style Loss : 0.173787 Content Loss: 0.019215

run [2150]:
Style Loss : 0.172641 Content Loss: 0.019315

run [2200]:
Style Loss : 0.171338 Content Loss: 0.019427

run [2250]:
Style Loss : 0.170229 Content Loss: 0.019533

run [2300]:
Style Loss : 0.169060 Content Loss: 0.019637

run [2350]:
Style Loss : 0.167908 Content Loss: 0.019742

run [2400]:
Style Loss : 0.166897 Content Loss: 0.019827

run [2450]:
Style Loss : 0.165915 Content Loss: 0.019921

run [2500]:
Style Loss : 0.165009 Content Loss: 0.020009

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.913028 Content Loss: 0.002022

run [100]:
Style Loss : 1.716167 Content Loss: 0.001921

run [150]:
Style Loss : 1.350801 Content Loss: 0.002309

run [200]:
Style Loss : 1.154358 Content Loss: 0.002835

run [250]:
Style Loss : 1.026844 Content Loss: 0.003477

run [300]:
Style Loss : 0.932972 Content Loss: 0.004059

run [350]:
Style Loss : 0.860546 Content Loss: 0.004788

run [400]:
Style Loss : 0.794373 Content Loss: 0.005523

run [450]:
Style Loss : 0.736033 Content Loss: 0.006389

run [500]:
Style Loss : 0.685714 Content Loss: 0.007384

run [550]:
Style Loss : 0.640496 Content Loss: 0.008490

run [600]:
Style Loss : 0.601482 Content Loss: 0.009781

run [650]:
Style Loss : 0.567445 Content Loss: 0.011081

run [700]:
Style Loss : 0.535636 Content Loss: 0.012584

run [750]:
Style Loss : 0.508200 Content Loss: 0.013882

run [800]:
Style Loss : 0.486730 Content Loss: 0.015050

run [850]:
Style Loss : 0.468116 Content Loss: 0.016213

run [900]:
Style Loss : 0.453141 Content Loss: 0.017083

run [950]:
Style Loss : 0.441350 Content Loss: 0.017844

run [1000]:
Style Loss : 0.431810 Content Loss: 0.018519

run [1050]:
Style Loss : 0.423901 Content Loss: 0.019048

run [1100]:
Style Loss : 0.417366 Content Loss: 0.019491

run [1150]:
Style Loss : 0.411664 Content Loss: 0.019911

run [1200]:
Style Loss : 0.406628 Content Loss: 0.020255

run [1250]:
Style Loss : 0.402183 Content Loss: 0.020535

run [1300]:
Style Loss : 0.398017 Content Loss: 0.020801

run [1350]:
Style Loss : 0.394220 Content Loss: 0.021028

run [1400]:
Style Loss : 0.390910 Content Loss: 0.021192

run [1450]:
Style Loss : 0.387843 Content Loss: 0.021357

run [1500]:
Style Loss : 0.385145 Content Loss: 0.021488

run [1550]:
Style Loss : 0.382733 Content Loss: 0.021626

run [1600]:
Style Loss : 0.380151 Content Loss: 0.021751

run [1650]:
Style Loss : 0.377749 Content Loss: 0.021882

run [1700]:
Style Loss : 0.375415 Content Loss: 0.021998

run [1750]:
Style Loss : 0.373164 Content Loss: 0.022108

run [1800]:
Style Loss : 0.370802 Content Loss: 0.022202

run [1850]:
Style Loss : 0.368643 Content Loss: 0.022291

run [1900]:
Style Loss : 0.366536 Content Loss: 0.022361

run [1950]:
Style Loss : 0.364524 Content Loss: 0.022434

run [2000]:
Style Loss : 0.362531 Content Loss: 0.022511

run [2050]:
Style Loss : 0.360607 Content Loss: 0.022590

run [2100]:
Style Loss : 0.358806 Content Loss: 0.022649

run [2150]:
Style Loss : 0.357059 Content Loss: 0.022716

run [2200]:
Style Loss : 0.355482 Content Loss: 0.022772

run [2250]:
Style Loss : 0.354000 Content Loss: 0.022824

run [2300]:
Style Loss : 0.352627 Content Loss: 0.022877

run [2350]:
Style Loss : 0.351291 Content Loss: 0.022938

run [2400]:
Style Loss : 0.349935 Content Loss: 0.022987

run [2450]:
Style Loss : 0.348601 Content Loss: 0.023036

run [2500]:
Style Loss : 0.347333 Content Loss: 0.023082

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.855392 Content Loss: 0.001451

run [100]:
Style Loss : 0.576543 Content Loss: 0.002542

run [150]:
Style Loss : 0.433221 Content Loss: 0.004144

run [200]:
Style Loss : 0.334975 Content Loss: 0.006250

run [250]:
Style Loss : 0.260599 Content Loss: 0.008674

run [300]:
Style Loss : 0.209482 Content Loss: 0.011190

run [350]:
Style Loss : 0.176654 Content Loss: 0.013489

run [400]:
Style Loss : 0.155307 Content Loss: 0.015358

run [450]:
Style Loss : 0.141700 Content Loss: 0.016599

run [500]:
Style Loss : 0.132348 Content Loss: 0.017399

run [550]:
Style Loss : 0.124820 Content Loss: 0.017913

run [600]:
Style Loss : 0.118687 Content Loss: 0.018228

run [650]:
Style Loss : 0.113410 Content Loss: 0.018563

run [700]:
Style Loss : 0.108899 Content Loss: 0.018896

run [750]:
Style Loss : 0.104995 Content Loss: 0.019193

run [800]:
Style Loss : 0.101590 Content Loss: 0.019497

run [850]:
Style Loss : 0.098924 Content Loss: 0.019738

run [900]:
Style Loss : 0.096578 Content Loss: 0.019976

run [950]:
Style Loss : 0.094583 Content Loss: 0.020187

run [1000]:
Style Loss : 0.092811 Content Loss: 0.020368

run [1050]:
Style Loss : 0.091190 Content Loss: 0.020522

run [1100]:
Style Loss : 0.089656 Content Loss: 0.020651

run [1150]:
Style Loss : 0.088324 Content Loss: 0.020770

run [1200]:
Style Loss : 0.087134 Content Loss: 0.020886

run [1250]:
Style Loss : 0.085949 Content Loss: 0.021000

run [1300]:
Style Loss : 0.084860 Content Loss: 0.021101

run [1350]:
Style Loss : 0.083890 Content Loss: 0.021190

run [1400]:
Style Loss : 0.082993 Content Loss: 0.021275

run [1450]:
Style Loss : 0.082213 Content Loss: 0.021350

run [1500]:
Style Loss : 0.081488 Content Loss: 0.021418

run [1550]:
Style Loss : 0.080799 Content Loss: 0.021471

run [1600]:
Style Loss : 0.080213 Content Loss: 0.021514

run [1650]:
Style Loss : 0.079630 Content Loss: 0.021560

run [1700]:
Style Loss : 0.079125 Content Loss: 0.021601

run [1750]:
Style Loss : 0.078607 Content Loss: 0.021637

run [1800]:
Style Loss : 0.078122 Content Loss: 0.021669

run [1850]:
Style Loss : 0.077690 Content Loss: 0.021703

run [1900]:
Style Loss : 0.077285 Content Loss: 0.021727

run [1950]:
Style Loss : 0.076865 Content Loss: 0.021750

run [2000]:
Style Loss : 0.076481 Content Loss: 0.021777

run [2050]:
Style Loss : 0.076059 Content Loss: 0.021801

run [2100]:
Style Loss : 0.075689 Content Loss: 0.021825

run [2150]:
Style Loss : 0.075345 Content Loss: 0.021842

run [2200]:
Style Loss : 0.075005 Content Loss: 0.021859

run [2250]:
Style Loss : 0.074675 Content Loss: 0.021876

run [2300]:
Style Loss : 0.074344 Content Loss: 0.021894

run [2350]:
Style Loss : 0.074039 Content Loss: 0.021916

run [2400]:
Style Loss : 0.073729 Content Loss: 0.021937

run [2450]:
Style Loss : 0.073423 Content Loss: 0.021951

run [2500]:
Style Loss : 0.073117 Content Loss: 0.021963

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.855341 Content Loss: 0.001970

run [100]:
Style Loss : 1.268560 Content Loss: 0.002656

run [150]:
Style Loss : 1.033802 Content Loss: 0.003569

run [200]:
Style Loss : 0.876260 Content Loss: 0.005129

run [250]:
Style Loss : 0.743123 Content Loss: 0.007163

run [300]:
Style Loss : 0.635870 Content Loss: 0.009782

run [350]:
Style Loss : 0.547111 Content Loss: 0.012808

run [400]:
Style Loss : 0.475744 Content Loss: 0.016322

run [450]:
Style Loss : 0.426117 Content Loss: 0.019574

run [500]:
Style Loss : 0.394031 Content Loss: 0.021885

run [550]:
Style Loss : 0.372348 Content Loss: 0.023415

run [600]:
Style Loss : 0.355934 Content Loss: 0.024450

run [650]:
Style Loss : 0.343255 Content Loss: 0.025102

run [700]:
Style Loss : 0.332288 Content Loss: 0.025657

run [750]:
Style Loss : 0.323392 Content Loss: 0.026101

run [800]:
Style Loss : 0.315852 Content Loss: 0.026499

run [850]:
Style Loss : 0.310114 Content Loss: 0.026889

run [900]:
Style Loss : 0.305193 Content Loss: 0.027216

run [950]:
Style Loss : 0.300931 Content Loss: 0.027507

run [1000]:
Style Loss : 0.297299 Content Loss: 0.027760

run [1050]:
Style Loss : 0.294007 Content Loss: 0.027983

run [1100]:
Style Loss : 0.291200 Content Loss: 0.028180

run [1150]:
Style Loss : 0.288519 Content Loss: 0.028369

run [1200]:
Style Loss : 0.285942 Content Loss: 0.028520

run [1250]:
Style Loss : 0.283481 Content Loss: 0.028661

run [1300]:
Style Loss : 0.281229 Content Loss: 0.028778

run [1350]:
Style Loss : 0.279390 Content Loss: 0.028879

run [1400]:
Style Loss : 0.277728 Content Loss: 0.028982

run [1450]:
Style Loss : 0.276257 Content Loss: 0.029072

run [1500]:
Style Loss : 0.274955 Content Loss: 0.029158

run [1550]:
Style Loss : 0.273817 Content Loss: 0.029245

run [1600]:
Style Loss : 0.272630 Content Loss: 0.029326

run [1650]:
Style Loss : 0.271619 Content Loss: 0.029391

run [1700]:
Style Loss : 0.270520 Content Loss: 0.029468

run [1750]:
Style Loss : 0.269609 Content Loss: 0.029524

run [1800]:
Style Loss : 0.268753 Content Loss: 0.029580

run [1850]:
Style Loss : 0.267907 Content Loss: 0.029632

run [1900]:
Style Loss : 0.267155 Content Loss: 0.029674

run [1950]:
Style Loss : 0.266399 Content Loss: 0.029723

run [2000]:
Style Loss : 0.265648 Content Loss: 0.029761

run [2050]:
Style Loss : 0.264899 Content Loss: 0.029805

run [2100]:
Style Loss : 0.264174 Content Loss: 0.029843

run [2150]:
Style Loss : 0.263555 Content Loss: 0.029877

run [2200]:
Style Loss : 0.262974 Content Loss: 0.029912

run [2250]:
Style Loss : 0.262390 Content Loss: 0.029946

run [2300]:
Style Loss : 0.261886 Content Loss: 0.029974

run [2350]:
Style Loss : 0.261423 Content Loss: 0.030000

run [2400]:
Style Loss : 0.260944 Content Loss: 0.030032

run [2450]:
Style Loss : 0.260447 Content Loss: 0.030062

run [2500]:
Style Loss : 0.260012 Content Loss: 0.030086

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.673227 Content Loss: 0.004080

run [100]:
Style Loss : 1.022285 Content Loss: 0.007403

run [150]:
Style Loss : 0.768240 Content Loss: 0.009484

run [200]:
Style Loss : 0.629430 Content Loss: 0.011347

run [250]:
Style Loss : 0.546302 Content Loss: 0.012831

run [300]:
Style Loss : 0.492273 Content Loss: 0.013969

run [350]:
Style Loss : 0.456366 Content Loss: 0.014884

run [400]:
Style Loss : 0.430140 Content Loss: 0.015717

run [450]:
Style Loss : 0.408521 Content Loss: 0.016307

run [500]:
Style Loss : 0.390225 Content Loss: 0.016771

run [550]:
Style Loss : 0.373462 Content Loss: 0.017182

run [600]:
Style Loss : 0.360387 Content Loss: 0.017526

run [650]:
Style Loss : 0.350261 Content Loss: 0.017889

run [700]:
Style Loss : 0.341555 Content Loss: 0.018203

run [750]:
Style Loss : 0.334168 Content Loss: 0.018524

run [800]:
Style Loss : 0.328069 Content Loss: 0.018801

run [850]:
Style Loss : 0.322738 Content Loss: 0.019059

run [900]:
Style Loss : 0.318304 Content Loss: 0.019273

run [950]:
Style Loss : 0.314540 Content Loss: 0.019459

run [1000]:
Style Loss : 0.311272 Content Loss: 0.019608

run [1050]:
Style Loss : 0.308459 Content Loss: 0.019736

run [1100]:
Style Loss : 0.305762 Content Loss: 0.019855

run [1150]:
Style Loss : 0.303376 Content Loss: 0.019970

run [1200]:
Style Loss : 0.301117 Content Loss: 0.020081

run [1250]:
Style Loss : 0.298914 Content Loss: 0.020186

run [1300]:
Style Loss : 0.296932 Content Loss: 0.020282

run [1350]:
Style Loss : 0.294926 Content Loss: 0.020387

run [1400]:
Style Loss : 0.293033 Content Loss: 0.020475

run [1450]:
Style Loss : 0.291152 Content Loss: 0.020564

run [1500]:
Style Loss : 0.289481 Content Loss: 0.020633

run [1550]:
Style Loss : 0.287914 Content Loss: 0.020714

run [1600]:
Style Loss : 0.286426 Content Loss: 0.020770

run [1650]:
Style Loss : 0.285106 Content Loss: 0.020830

run [1700]:
Style Loss : 0.283821 Content Loss: 0.020890

run [1750]:
Style Loss : 0.282699 Content Loss: 0.020944

run [1800]:
Style Loss : 0.281598 Content Loss: 0.021000

run [1850]:
Style Loss : 0.280538 Content Loss: 0.021052

run [1900]:
Style Loss : 0.279432 Content Loss: 0.021100

run [1950]:
Style Loss : 0.278445 Content Loss: 0.021147

run [2000]:
Style Loss : 0.277523 Content Loss: 0.021191

run [2050]:
Style Loss : 0.276642 Content Loss: 0.021238

run [2100]:
Style Loss : 0.275841 Content Loss: 0.021277

run [2150]:
Style Loss : 0.275084 Content Loss: 0.021308

run [2200]:
Style Loss : 0.274344 Content Loss: 0.021345

run [2250]:
Style Loss : 0.273628 Content Loss: 0.021384

run [2300]:
Style Loss : 0.272873 Content Loss: 0.021423

run [2350]:
Style Loss : 0.272143 Content Loss: 0.021462

run [2400]:
Style Loss : 0.271483 Content Loss: 0.021489

run [2450]:
Style Loss : 0.270836 Content Loss: 0.021523

run [2500]:
Style Loss : 0.270223 Content Loss: 0.021557

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.840498 Content Loss: 0.003906

run [100]:
Style Loss : 0.906439 Content Loss: 0.007505

run [150]:
Style Loss : 0.628056 Content Loss: 0.009522

run [200]:
Style Loss : 0.490943 Content Loss: 0.010923

run [250]:
Style Loss : 0.414640 Content Loss: 0.012376

run [300]:
Style Loss : 0.366864 Content Loss: 0.013575

run [350]:
Style Loss : 0.332184 Content Loss: 0.014704

run [400]:
Style Loss : 0.305025 Content Loss: 0.015509

run [450]:
Style Loss : 0.282834 Content Loss: 0.016167

run [500]:
Style Loss : 0.265250 Content Loss: 0.016631

run [550]:
Style Loss : 0.249268 Content Loss: 0.017048

run [600]:
Style Loss : 0.234532 Content Loss: 0.017453

run [650]:
Style Loss : 0.221720 Content Loss: 0.017774

run [700]:
Style Loss : 0.211533 Content Loss: 0.018024

run [750]:
Style Loss : 0.201871 Content Loss: 0.018274

run [800]:
Style Loss : 0.192663 Content Loss: 0.018497

run [850]:
Style Loss : 0.185149 Content Loss: 0.018681

run [900]:
Style Loss : 0.179230 Content Loss: 0.018852

run [950]:
Style Loss : 0.174479 Content Loss: 0.019002

run [1000]:
Style Loss : 0.170276 Content Loss: 0.019157

run [1050]:
Style Loss : 0.166352 Content Loss: 0.019314

run [1100]:
Style Loss : 0.162570 Content Loss: 0.019457

run [1150]:
Style Loss : 0.159314 Content Loss: 0.019595

run [1200]:
Style Loss : 0.156089 Content Loss: 0.019717

run [1250]:
Style Loss : 0.153239 Content Loss: 0.019846

run [1300]:
Style Loss : 0.150698 Content Loss: 0.019947

run [1350]:
Style Loss : 0.148670 Content Loss: 0.020049

run [1400]:
Style Loss : 0.146870 Content Loss: 0.020136

run [1450]:
Style Loss : 0.145208 Content Loss: 0.020241

run [1500]:
Style Loss : 0.143768 Content Loss: 0.020339

run [1550]:
Style Loss : 0.142271 Content Loss: 0.020445

run [1600]:
Style Loss : 0.140957 Content Loss: 0.020524

run [1650]:
Style Loss : 0.139848 Content Loss: 0.020594

run [1700]:
Style Loss : 0.138588 Content Loss: 0.020659

run [1750]:
Style Loss : 0.137852 Content Loss: 0.020748

run [1800]:
Style Loss : 0.136435 Content Loss: 0.020799

run [1850]:
Style Loss : 0.135598 Content Loss: 0.020863

run [1900]:
Style Loss : 0.134421 Content Loss: 0.020899

run [1950]:
Style Loss : 0.133699 Content Loss: 0.020957

run [2000]:
Style Loss : 0.133255 Content Loss: 0.021028

run [2050]:
Style Loss : 0.131796 Content Loss: 0.021055

run [2100]:
Style Loss : 0.130562 Content Loss: 0.021079

run [2150]:
Style Loss : 0.129712 Content Loss: 0.021132

run [2200]:
Style Loss : 0.129019 Content Loss: 0.021188

run [2250]:
Style Loss : 0.128295 Content Loss: 0.021235

run [2300]:
Style Loss : 0.127269 Content Loss: 0.021271

run [2350]:
Style Loss : 0.127003 Content Loss: 0.021332

run [2400]:
Style Loss : 0.126329 Content Loss: 0.021396

run [2450]:
Style Loss : 0.125334 Content Loss: 0.021434

run [2500]:
Style Loss : 0.198087 Content Loss: 0.022121

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.936507 Content Loss: 0.004230

run [100]:
Style Loss : 1.278216 Content Loss: 0.007286

run [150]:
Style Loss : 0.846394 Content Loss: 0.009327

run [200]:
Style Loss : 0.668292 Content Loss: 0.010764

run [250]:
Style Loss : 0.564067 Content Loss: 0.011907

run [300]:
Style Loss : 0.496218 Content Loss: 0.012826

run [350]:
Style Loss : 0.446830 Content Loss: 0.013595

run [400]:
Style Loss : 0.399305 Content Loss: 0.014142

run [450]:
Style Loss : 0.369255 Content Loss: 0.014757

run [500]:
Style Loss : 0.347544 Content Loss: 0.015324

run [550]:
Style Loss : 0.332067 Content Loss: 0.015724

run [600]:
Style Loss : 0.319568 Content Loss: 0.016125

run [650]:
Style Loss : 0.308632 Content Loss: 0.016457

run [700]:
Style Loss : 0.298724 Content Loss: 0.016684

run [750]:
Style Loss : 0.289465 Content Loss: 0.016924

run [800]:
Style Loss : 0.281512 Content Loss: 0.017119

run [850]:
Style Loss : 0.274087 Content Loss: 0.017304

run [900]:
Style Loss : 0.268128 Content Loss: 0.017453

run [950]:
Style Loss : 0.262659 Content Loss: 0.017602

run [1000]:
Style Loss : 0.258041 Content Loss: 0.017759

run [1050]:
Style Loss : 0.253407 Content Loss: 0.017923

run [1100]:
Style Loss : 0.249379 Content Loss: 0.018067

run [1150]:
Style Loss : 0.245623 Content Loss: 0.018195

run [1200]:
Style Loss : 0.241912 Content Loss: 0.018328

run [1250]:
Style Loss : 0.238713 Content Loss: 0.018458

run [1300]:
Style Loss : 0.236098 Content Loss: 0.018559

run [1350]:
Style Loss : 0.233495 Content Loss: 0.018641

run [1400]:
Style Loss : 0.231584 Content Loss: 0.018747

run [1450]:
Style Loss : 0.229291 Content Loss: 0.018795

run [1500]:
Style Loss : 0.227592 Content Loss: 0.018873

run [1550]:
Style Loss : 0.225719 Content Loss: 0.018940

run [1600]:
Style Loss : 0.223836 Content Loss: 0.019009

run [1650]:
Style Loss : 0.225074 Content Loss: 0.019099

run [1700]:
Style Loss : 0.220160 Content Loss: 0.019108

run [1750]:
Style Loss : 0.218428 Content Loss: 0.019164

run [1800]:
Style Loss : 0.221003 Content Loss: 0.019252

run [1850]:
Style Loss : 0.216325 Content Loss: 0.019304

run [1900]:
Style Loss : 0.213711 Content Loss: 0.019376

run [1950]:
Style Loss : 0.213772 Content Loss: 0.019482

run [2000]:
Style Loss : 0.210682 Content Loss: 0.019499

run [2050]:
Style Loss : 0.209324 Content Loss: 0.019578

run [2100]:
Style Loss : 0.218907 Content Loss: 0.019984

run [2150]:
Style Loss : 0.207112 Content Loss: 0.019858

run [2200]:
Style Loss : 0.203865 Content Loss: 0.019822

run [2250]:
Style Loss : 0.209246 Content Loss: 0.020007

run [2300]:
Style Loss : 0.200325 Content Loss: 0.019964

run [2350]:
Style Loss : 0.202981 Content Loss: 0.020093

run [2400]:
Style Loss : 0.196486 Content Loss: 0.020061

run [2450]:
Style Loss : 0.194618 Content Loss: 0.020109

run [2500]:
Style Loss : 0.193284 Content Loss: 0.020144

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.820712 Content Loss: 0.006290

run [100]:
Style Loss : 0.463502 Content Loss: 0.009444

run [150]:
Style Loss : 0.359277 Content Loss: 0.011133

run [200]:
Style Loss : 0.306911 Content Loss: 0.012432

run [250]:
Style Loss : 0.276932 Content Loss: 0.013261

run [300]:
Style Loss : 0.255155 Content Loss: 0.013712

run [350]:
Style Loss : 0.236896 Content Loss: 0.014262

run [400]:
Style Loss : 0.223166 Content Loss: 0.014661

run [450]:
Style Loss : 0.212840 Content Loss: 0.015083

run [500]:
Style Loss : 0.203007 Content Loss: 0.015439

run [550]:
Style Loss : 0.194312 Content Loss: 0.015674

run [600]:
Style Loss : 0.187579 Content Loss: 0.015885

run [650]:
Style Loss : 0.181858 Content Loss: 0.016056

run [700]:
Style Loss : 0.176759 Content Loss: 0.016226

run [750]:
Style Loss : 0.172565 Content Loss: 0.016358

run [800]:
Style Loss : 0.169228 Content Loss: 0.016460

run [850]:
Style Loss : 0.166315 Content Loss: 0.016564

run [900]:
Style Loss : 0.163524 Content Loss: 0.016649

run [950]:
Style Loss : 0.160939 Content Loss: 0.016722

run [1000]:
Style Loss : 0.158673 Content Loss: 0.016778

run [1050]:
Style Loss : 0.156650 Content Loss: 0.016848

run [1100]:
Style Loss : 0.155043 Content Loss: 0.016897

run [1150]:
Style Loss : 0.153577 Content Loss: 0.016957

run [1200]:
Style Loss : 0.152262 Content Loss: 0.017010

run [1250]:
Style Loss : 0.151097 Content Loss: 0.017050

run [1300]:
Style Loss : 0.150093 Content Loss: 0.017077

run [1350]:
Style Loss : 0.149120 Content Loss: 0.017111

run [1400]:
Style Loss : 0.148155 Content Loss: 0.017147

run [1450]:
Style Loss : 0.147042 Content Loss: 0.017189

run [1500]:
Style Loss : 0.146197 Content Loss: 0.017222

run [1550]:
Style Loss : 0.145398 Content Loss: 0.017260

run [1600]:
Style Loss : 0.144646 Content Loss: 0.017283

run [1650]:
Style Loss : 0.143352 Content Loss: 0.017314

run [1700]:
Style Loss : 0.142384 Content Loss: 0.017352

run [1750]:
Style Loss : 0.141552 Content Loss: 0.017387

run [1800]:
Style Loss : 0.140858 Content Loss: 0.017423

run [1850]:
Style Loss : 0.140286 Content Loss: 0.017448

run [1900]:
Style Loss : 0.139501 Content Loss: 0.017489

run [1950]:
Style Loss : 0.138676 Content Loss: 0.017525

run [2000]:
Style Loss : 0.137825 Content Loss: 0.017553

run [2050]:
Style Loss : 0.137109 Content Loss: 0.017576

run [2100]:
Style Loss : 0.136545 Content Loss: 0.017594

run [2150]:
Style Loss : 0.136026 Content Loss: 0.017609

run [2200]:
Style Loss : 0.135561 Content Loss: 0.017620

run [2250]:
Style Loss : 0.135138 Content Loss: 0.017639

run [2300]:
Style Loss : 0.134718 Content Loss: 0.017658

run [2350]:
Style Loss : 0.134350 Content Loss: 0.017686

run [2400]:
Style Loss : 0.134003 Content Loss: 0.017700

run [2450]:
Style Loss : 0.133684 Content Loss: 0.017717

run [2500]:
Style Loss : 0.133383 Content Loss: 0.017736

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.638856 Content Loss: 0.006920

run [100]:
Style Loss : 0.353653 Content Loss: 0.009844

run [150]:
Style Loss : 0.271393 Content Loss: 0.011672

run [200]:
Style Loss : 0.219955 Content Loss: 0.012780

run [250]:
Style Loss : 0.188365 Content Loss: 0.013871

run [300]:
Style Loss : 0.169572 Content Loss: 0.014585

run [350]:
Style Loss : 0.157497 Content Loss: 0.015011

run [400]:
Style Loss : 0.147144 Content Loss: 0.015281

run [450]:
Style Loss : 0.139551 Content Loss: 0.015476

run [500]:
Style Loss : 0.134306 Content Loss: 0.015689

run [550]:
Style Loss : 0.129991 Content Loss: 0.015938

run [600]:
Style Loss : 0.126535 Content Loss: 0.016220

run [650]:
Style Loss : 0.123503 Content Loss: 0.016462

run [700]:
Style Loss : 0.120914 Content Loss: 0.016713

run [750]:
Style Loss : 0.117781 Content Loss: 0.016976

run [800]:
Style Loss : 0.115436 Content Loss: 0.017212

run [850]:
Style Loss : 0.113485 Content Loss: 0.017439

run [900]:
Style Loss : 0.111774 Content Loss: 0.017664

run [950]:
Style Loss : 0.109947 Content Loss: 0.017889

run [1000]:
Style Loss : 0.108510 Content Loss: 0.018083

run [1050]:
Style Loss : 0.107240 Content Loss: 0.018294

run [1100]:
Style Loss : 0.106037 Content Loss: 0.018474

run [1150]:
Style Loss : 0.104911 Content Loss: 0.018635

run [1200]:
Style Loss : 0.103972 Content Loss: 0.018768

run [1250]:
Style Loss : 0.103120 Content Loss: 0.018893

run [1300]:
Style Loss : 0.102354 Content Loss: 0.018998

run [1350]:
Style Loss : 0.101660 Content Loss: 0.019089

run [1400]:
Style Loss : 0.101028 Content Loss: 0.019183

run [1450]:
Style Loss : 0.100234 Content Loss: 0.019279

run [1500]:
Style Loss : 0.098522 Content Loss: 0.019339

run [1550]:
Style Loss : 0.097804 Content Loss: 0.019374

run [1600]:
Style Loss : 0.097283 Content Loss: 0.019415

run [1650]:
Style Loss : 0.096727 Content Loss: 0.019469

run [1700]:
Style Loss : 0.096224 Content Loss: 0.019505

run [1750]:
Style Loss : 0.095824 Content Loss: 0.019516

run [1800]:
Style Loss : 0.095507 Content Loss: 0.019529

run [1850]:
Style Loss : 0.095232 Content Loss: 0.019530

run [1900]:
Style Loss : 0.094951 Content Loss: 0.019536

run [1950]:
Style Loss : 0.094628 Content Loss: 0.019544

run [2000]:
Style Loss : 0.094339 Content Loss: 0.019548

run [2050]:
Style Loss : 0.094109 Content Loss: 0.019558

run [2100]:
Style Loss : 0.093893 Content Loss: 0.019561

run [2150]:
Style Loss : 0.093705 Content Loss: 0.019560

run [2200]:
Style Loss : 0.093525 Content Loss: 0.019559

run [2250]:
Style Loss : 0.093356 Content Loss: 0.019565

run [2300]:
Style Loss : 0.093190 Content Loss: 0.019576

run [2350]:
Style Loss : 0.093028 Content Loss: 0.019598

run [2400]:
Style Loss : 0.092865 Content Loss: 0.019615

run [2450]:
Style Loss : 0.092685 Content Loss: 0.019621

run [2500]:
Style Loss : 0.092548 Content Loss: 0.019640

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.276884 Content Loss: 0.007764

run [100]:
Style Loss : 1.351290 Content Loss: 0.010723

run [150]:
Style Loss : 1.034581 Content Loss: 0.013371

run [200]:
Style Loss : 0.884060 Content Loss: 0.015247

run [250]:
Style Loss : 0.798704 Content Loss: 0.016584

run [300]:
Style Loss : 0.728450 Content Loss: 0.017754

run [350]:
Style Loss : 0.675595 Content Loss: 0.018716

run [400]:
Style Loss : 0.639230 Content Loss: 0.019481

run [450]:
Style Loss : 0.607545 Content Loss: 0.020225

run [500]:
Style Loss : 0.582746 Content Loss: 0.020844

run [550]:
Style Loss : 0.564307 Content Loss: 0.021445

run [600]:
Style Loss : 0.547038 Content Loss: 0.021872

run [650]:
Style Loss : 0.530693 Content Loss: 0.022412

run [700]:
Style Loss : 0.516548 Content Loss: 0.022886

run [750]:
Style Loss : 0.503157 Content Loss: 0.023198

run [800]:
Style Loss : 0.486714 Content Loss: 0.023498

run [850]:
Style Loss : 0.473352 Content Loss: 0.023734

run [900]:
Style Loss : 0.458268 Content Loss: 0.024038

run [950]:
Style Loss : 0.446537 Content Loss: 0.024247

run [1000]:
Style Loss : 0.436093 Content Loss: 0.024532

run [1050]:
Style Loss : 0.427984 Content Loss: 0.024702

run [1100]:
Style Loss : 0.420801 Content Loss: 0.024879

run [1150]:
Style Loss : 0.412636 Content Loss: 0.025038

run [1200]:
Style Loss : 0.404799 Content Loss: 0.025258

run [1250]:
Style Loss : 0.398040 Content Loss: 0.025367

run [1300]:
Style Loss : 0.391037 Content Loss: 0.025485

run [1350]:
Style Loss : 0.384699 Content Loss: 0.025633

run [1400]:
Style Loss : 0.379000 Content Loss: 0.025778

run [1450]:
Style Loss : 0.373556 Content Loss: 0.025887

run [1500]:
Style Loss : 0.368968 Content Loss: 0.025950

run [1550]:
Style Loss : 0.364652 Content Loss: 0.026042

run [1600]:
Style Loss : 0.360474 Content Loss: 0.026108

run [1650]:
Style Loss : 0.356677 Content Loss: 0.026182

run [1700]:
Style Loss : 0.352968 Content Loss: 0.026235

run [1750]:
Style Loss : 0.349613 Content Loss: 0.026301

run [1800]:
Style Loss : 0.346191 Content Loss: 0.026337

run [1850]:
Style Loss : 0.342290 Content Loss: 0.026366

run [1900]:
Style Loss : 0.338303 Content Loss: 0.026413

run [1950]:
Style Loss : 0.335197 Content Loss: 0.026429

run [2000]:
Style Loss : 0.332767 Content Loss: 0.026457

run [2050]:
Style Loss : 0.329892 Content Loss: 0.026472

run [2100]:
Style Loss : 0.327091 Content Loss: 0.026513

run [2150]:
Style Loss : 0.324912 Content Loss: 0.026545

run [2200]:
Style Loss : 0.322855 Content Loss: 0.026563

run [2250]:
Style Loss : 0.320525 Content Loss: 0.026580

run [2300]:
Style Loss : 0.318682 Content Loss: 0.026591

run [2350]:
Style Loss : 0.317013 Content Loss: 0.026595

run [2400]:
Style Loss : 0.315682 Content Loss: 0.026605

run [2450]:
Style Loss : 0.314273 Content Loss: 0.026607

run [2500]:
Style Loss : 0.312982 Content Loss: 0.026595

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.761520 Content Loss: 0.004810

run [100]:
Style Loss : 0.902751 Content Loss: 0.008349

run [150]:
Style Loss : 0.645584 Content Loss: 0.011038

run [200]:
Style Loss : 0.514417 Content Loss: 0.012980

run [250]:
Style Loss : 0.446540 Content Loss: 0.014727

run [300]:
Style Loss : 0.385272 Content Loss: 0.016195

run [350]:
Style Loss : 0.347075 Content Loss: 0.017151

run [400]:
Style Loss : 0.318236 Content Loss: 0.018061

run [450]:
Style Loss : 0.297617 Content Loss: 0.018689

run [500]:
Style Loss : 0.282325 Content Loss: 0.019269

run [550]:
Style Loss : 0.270218 Content Loss: 0.019770

run [600]:
Style Loss : 0.259239 Content Loss: 0.020100

run [650]:
Style Loss : 0.250546 Content Loss: 0.020442

run [700]:
Style Loss : 0.243773 Content Loss: 0.020740

run [750]:
Style Loss : 0.237343 Content Loss: 0.021015

run [800]:
Style Loss : 0.231513 Content Loss: 0.021185

run [850]:
Style Loss : 0.226656 Content Loss: 0.021354

run [900]:
Style Loss : 0.222729 Content Loss: 0.021513

run [950]:
Style Loss : 0.219418 Content Loss: 0.021643

run [1000]:
Style Loss : 0.216259 Content Loss: 0.021776

run [1050]:
Style Loss : 0.212955 Content Loss: 0.021889

run [1100]:
Style Loss : 0.209901 Content Loss: 0.021990

run [1150]:
Style Loss : 0.207448 Content Loss: 0.022062

run [1200]:
Style Loss : 0.205164 Content Loss: 0.022154

run [1250]:
Style Loss : 0.203084 Content Loss: 0.022225

run [1300]:
Style Loss : 0.201141 Content Loss: 0.022298

run [1350]:
Style Loss : 0.199356 Content Loss: 0.022367

run [1400]:
Style Loss : 0.197657 Content Loss: 0.022448

run [1450]:
Style Loss : 0.196127 Content Loss: 0.022517

run [1500]:
Style Loss : 0.194528 Content Loss: 0.022584

run [1550]:
Style Loss : 0.193113 Content Loss: 0.022666

run [1600]:
Style Loss : 0.191694 Content Loss: 0.022718

run [1650]:
Style Loss : 0.190330 Content Loss: 0.022769

run [1700]:
Style Loss : 0.189171 Content Loss: 0.022831

run [1750]:
Style Loss : 0.188094 Content Loss: 0.022900

run [1800]:
Style Loss : 0.187056 Content Loss: 0.022958

run [1850]:
Style Loss : 0.186059 Content Loss: 0.023015

run [1900]:
Style Loss : 0.185103 Content Loss: 0.023084

run [1950]:
Style Loss : 0.184221 Content Loss: 0.023158

run [2000]:
Style Loss : 0.183392 Content Loss: 0.023230

run [2050]:
Style Loss : 0.182561 Content Loss: 0.023304

run [2100]:
Style Loss : 0.182362 Content Loss: 0.023439

run [2150]:
Style Loss : 0.181020 Content Loss: 0.023530

run [2200]:
Style Loss : 0.179783 Content Loss: 0.023595

run [2250]:
Style Loss : 0.178907 Content Loss: 0.023689

run [2300]:
Style Loss : 0.178072 Content Loss: 0.023810

run [2350]:
Style Loss : 0.178866 Content Loss: 0.024036

run [2400]:
Style Loss : 0.176473 Content Loss: 0.024112

run [2450]:
Style Loss : 0.175428 Content Loss: 0.024232

run [2500]:
Style Loss : 0.174762 Content Loss: 0.024462

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.099889 Content Loss: 0.006253

run [100]:
Style Loss : 0.588156 Content Loss: 0.010824

run [150]:
Style Loss : 0.411774 Content Loss: 0.014880

run [200]:
Style Loss : 0.328158 Content Loss: 0.018258

run [250]:
Style Loss : 0.280078 Content Loss: 0.020116

run [300]:
Style Loss : 0.250351 Content Loss: 0.021033

run [350]:
Style Loss : 0.228864 Content Loss: 0.021646

run [400]:
Style Loss : 0.212806 Content Loss: 0.022098

run [450]:
Style Loss : 0.201889 Content Loss: 0.022454

run [500]:
Style Loss : 0.193849 Content Loss: 0.022719

run [550]:
Style Loss : 0.188249 Content Loss: 0.022920

run [600]:
Style Loss : 0.183570 Content Loss: 0.023087

run [650]:
Style Loss : 0.179771 Content Loss: 0.023239

run [700]:
Style Loss : 0.175727 Content Loss: 0.023394

run [750]:
Style Loss : 0.172292 Content Loss: 0.023514

run [800]:
Style Loss : 0.169606 Content Loss: 0.023594

run [850]:
Style Loss : 0.167282 Content Loss: 0.023693

run [900]:
Style Loss : 0.165278 Content Loss: 0.023775

run [950]:
Style Loss : 0.163546 Content Loss: 0.023858

run [1000]:
Style Loss : 0.161812 Content Loss: 0.023919

run [1050]:
Style Loss : 0.160146 Content Loss: 0.023992

run [1100]:
Style Loss : 0.158646 Content Loss: 0.024057

run [1150]:
Style Loss : 0.157137 Content Loss: 0.024125

run [1200]:
Style Loss : 0.155591 Content Loss: 0.024184

run [1250]:
Style Loss : 0.154174 Content Loss: 0.024246

run [1300]:
Style Loss : 0.152771 Content Loss: 0.024292

run [1350]:
Style Loss : 0.151516 Content Loss: 0.024360

run [1400]:
Style Loss : 0.150396 Content Loss: 0.024414

run [1450]:
Style Loss : 0.149161 Content Loss: 0.024476

run [1500]:
Style Loss : 0.147332 Content Loss: 0.024538

run [1550]:
Style Loss : 0.146092 Content Loss: 0.024606

run [1600]:
Style Loss : 0.145006 Content Loss: 0.024676

run [1650]:
Style Loss : 0.144075 Content Loss: 0.024741

run [1700]:
Style Loss : 0.143279 Content Loss: 0.024793

run [1750]:
Style Loss : 0.142395 Content Loss: 0.024837

run [1800]:
Style Loss : 0.141851 Content Loss: 0.024878

run [1850]:
Style Loss : 0.140929 Content Loss: 0.024911

run [1900]:
Style Loss : 0.140408 Content Loss: 0.024986

run [1950]:
Style Loss : 0.139763 Content Loss: 0.025018

run [2000]:
Style Loss : 0.139540 Content Loss: 0.025102

run [2050]:
Style Loss : 0.138747 Content Loss: 0.025103

run [2100]:
Style Loss : 0.138736 Content Loss: 0.025136

run [2150]:
Style Loss : 0.137969 Content Loss: 0.025139

run [2200]:
Style Loss : 0.137593 Content Loss: 0.025165

run [2250]:
Style Loss : 0.137257 Content Loss: 0.025202

run [2300]:
Style Loss : 0.136933 Content Loss: 0.025229

run [2350]:
Style Loss : 0.136595 Content Loss: 0.025250

run [2400]:
Style Loss : 0.136271 Content Loss: 0.025267

run [2450]:
Style Loss : 0.135917 Content Loss: 0.025279

run [2500]:
Style Loss : 0.135697 Content Loss: 0.025310

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.447496 Content Loss: 0.004378

run [100]:
Style Loss : 0.592461 Content Loss: 0.008344

run [150]:
Style Loss : 0.408803 Content Loss: 0.010617

run [200]:
Style Loss : 0.317945 Content Loss: 0.012042

run [250]:
Style Loss : 0.257125 Content Loss: 0.013277

run [300]:
Style Loss : 0.219586 Content Loss: 0.014380

run [350]:
Style Loss : 0.189069 Content Loss: 0.015080

run [400]:
Style Loss : 0.168711 Content Loss: 0.015657

run [450]:
Style Loss : 0.154145 Content Loss: 0.016139

run [500]:
Style Loss : 0.143453 Content Loss: 0.016612

run [550]:
Style Loss : 0.135081 Content Loss: 0.016956

run [600]:
Style Loss : 0.127914 Content Loss: 0.017335

run [650]:
Style Loss : 0.121281 Content Loss: 0.017588

run [700]:
Style Loss : 0.115571 Content Loss: 0.017779

run [750]:
Style Loss : 0.110891 Content Loss: 0.017961

run [800]:
Style Loss : 0.106972 Content Loss: 0.018095

run [850]:
Style Loss : 0.103921 Content Loss: 0.018213

run [900]:
Style Loss : 0.101364 Content Loss: 0.018325

run [950]:
Style Loss : 0.099178 Content Loss: 0.018420

run [1000]:
Style Loss : 0.097282 Content Loss: 0.018494

run [1050]:
Style Loss : 0.095509 Content Loss: 0.018576

run [1100]:
Style Loss : 0.093981 Content Loss: 0.018632

run [1150]:
Style Loss : 0.092691 Content Loss: 0.018680

run [1200]:
Style Loss : 0.091493 Content Loss: 0.018728

run [1250]:
Style Loss : 0.090401 Content Loss: 0.018757

run [1300]:
Style Loss : 0.089287 Content Loss: 0.018788

run [1350]:
Style Loss : 0.088159 Content Loss: 0.018824

run [1400]:
Style Loss : 0.087100 Content Loss: 0.018848

run [1450]:
Style Loss : 0.086111 Content Loss: 0.018889

run [1500]:
Style Loss : 0.085199 Content Loss: 0.018919

run [1550]:
Style Loss : 0.084311 Content Loss: 0.018942

run [1600]:
Style Loss : 0.083541 Content Loss: 0.018961

run [1650]:
Style Loss : 0.082885 Content Loss: 0.018973

run [1700]:
Style Loss : 0.082266 Content Loss: 0.018988

run [1750]:
Style Loss : 0.081714 Content Loss: 0.019003

run [1800]:
Style Loss : 0.081141 Content Loss: 0.019020

run [1850]:
Style Loss : 0.080638 Content Loss: 0.019035

run [1900]:
Style Loss : 0.080145 Content Loss: 0.019052

run [1950]:
Style Loss : 0.079659 Content Loss: 0.019073

run [2000]:
Style Loss : 0.079185 Content Loss: 0.019093

run [2050]:
Style Loss : 0.078724 Content Loss: 0.019110

run [2100]:
Style Loss : 0.078277 Content Loss: 0.019126

run [2150]:
Style Loss : 0.077858 Content Loss: 0.019146

run [2200]:
Style Loss : 0.077448 Content Loss: 0.019166

run [2250]:
Style Loss : 0.077062 Content Loss: 0.019183

run [2300]:
Style Loss : 0.076665 Content Loss: 0.019205

run [2350]:
Style Loss : 0.076300 Content Loss: 0.019225

run [2400]:
Style Loss : 0.075966 Content Loss: 0.019249

run [2450]:
Style Loss : 0.075645 Content Loss: 0.019272

run [2500]:
Style Loss : 0.075346 Content Loss: 0.019294

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.473083 Content Loss: 0.005925

run [100]:
Style Loss : 0.851874 Content Loss: 0.010951

run [150]:
Style Loss : 0.595362 Content Loss: 0.016159

run [200]:
Style Loss : 0.456878 Content Loss: 0.020601

run [250]:
Style Loss : 0.386758 Content Loss: 0.022833

run [300]:
Style Loss : 0.349715 Content Loss: 0.023936

run [350]:
Style Loss : 0.325739 Content Loss: 0.024256

run [400]:
Style Loss : 0.309741 Content Loss: 0.024540

run [450]:
Style Loss : 0.296641 Content Loss: 0.024868

run [500]:
Style Loss : 0.285716 Content Loss: 0.025219

run [550]:
Style Loss : 0.276920 Content Loss: 0.025518

run [600]:
Style Loss : 0.270219 Content Loss: 0.025749

run [650]:
Style Loss : 0.264301 Content Loss: 0.025982

run [700]:
Style Loss : 0.258676 Content Loss: 0.026212

run [750]:
Style Loss : 0.253942 Content Loss: 0.026473

run [800]:
Style Loss : 0.249882 Content Loss: 0.026722

run [850]:
Style Loss : 0.246286 Content Loss: 0.026935

run [900]:
Style Loss : 0.242477 Content Loss: 0.027147

run [950]:
Style Loss : 0.239217 Content Loss: 0.027368

run [1000]:
Style Loss : 0.235748 Content Loss: 0.027523

run [1050]:
Style Loss : 0.232811 Content Loss: 0.027662

run [1100]:
Style Loss : 0.230043 Content Loss: 0.027812

run [1150]:
Style Loss : 0.228110 Content Loss: 0.027983

run [1200]:
Style Loss : 0.225417 Content Loss: 0.028033

run [1250]:
Style Loss : 0.223487 Content Loss: 0.028121

run [1300]:
Style Loss : 0.221911 Content Loss: 0.028194

run [1350]:
Style Loss : 0.220442 Content Loss: 0.028244

run [1400]:
Style Loss : 0.219199 Content Loss: 0.028317

run [1450]:
Style Loss : 0.217890 Content Loss: 0.028387

run [1500]:
Style Loss : 0.216929 Content Loss: 0.028467

run [1550]:
Style Loss : 0.215436 Content Loss: 0.028524

run [1600]:
Style Loss : 0.214154 Content Loss: 0.028543

run [1650]:
Style Loss : 0.213049 Content Loss: 0.028585

run [1700]:
Style Loss : 0.212079 Content Loss: 0.028636

run [1750]:
Style Loss : 0.211090 Content Loss: 0.028677

run [1800]:
Style Loss : 0.210299 Content Loss: 0.028723

run [1850]:
Style Loss : 0.209541 Content Loss: 0.028767

run [1900]:
Style Loss : 0.208852 Content Loss: 0.028801

run [1950]:
Style Loss : 0.208279 Content Loss: 0.028828

run [2000]:
Style Loss : 0.207686 Content Loss: 0.028844

run [2050]:
Style Loss : 0.207484 Content Loss: 0.028871

run [2100]:
Style Loss : 0.207673 Content Loss: 0.028941

run [2150]:
Style Loss : 0.206091 Content Loss: 0.028949

run [2200]:
Style Loss : 0.205695 Content Loss: 0.029003

run [2250]:
Style Loss : 0.205110 Content Loss: 0.029043

run [2300]:
Style Loss : 0.204363 Content Loss: 0.029070

run [2350]:
Style Loss : 0.203821 Content Loss: 0.029135

run [2400]:
Style Loss : 0.203358 Content Loss: 0.029203

run [2450]:
Style Loss : 0.202698 Content Loss: 0.029249

run [2500]:
Style Loss : 0.201927 Content Loss: 0.029269

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.719923 Content Loss: 0.007285

run [100]:
Style Loss : 0.399157 Content Loss: 0.010371

run [150]:
Style Loss : 0.295834 Content Loss: 0.011791

run [200]:
Style Loss : 0.241518 Content Loss: 0.012874

run [250]:
Style Loss : 0.209838 Content Loss: 0.013671

run [300]:
Style Loss : 0.189384 Content Loss: 0.014158

run [350]:
Style Loss : 0.175910 Content Loss: 0.014329

run [400]:
Style Loss : 0.165575 Content Loss: 0.014482

run [450]:
Style Loss : 0.157616 Content Loss: 0.014628

run [500]:
Style Loss : 0.150474 Content Loss: 0.014790

run [550]:
Style Loss : 0.144944 Content Loss: 0.014890

run [600]:
Style Loss : 0.139861 Content Loss: 0.015015

run [650]:
Style Loss : 0.135681 Content Loss: 0.015118

run [700]:
Style Loss : 0.131129 Content Loss: 0.015198

run [750]:
Style Loss : 0.127220 Content Loss: 0.015252

run [800]:
Style Loss : 0.124027 Content Loss: 0.015292

run [850]:
Style Loss : 0.121471 Content Loss: 0.015347

run [900]:
Style Loss : 0.119095 Content Loss: 0.015385

run [950]:
Style Loss : 0.117088 Content Loss: 0.015393

run [1000]:
Style Loss : 0.115336 Content Loss: 0.015408

run [1050]:
Style Loss : 0.113853 Content Loss: 0.015414

run [1100]:
Style Loss : 0.112472 Content Loss: 0.015417

run [1150]:
Style Loss : 0.111377 Content Loss: 0.015431

run [1200]:
Style Loss : 0.110364 Content Loss: 0.015443

run [1250]:
Style Loss : 0.109444 Content Loss: 0.015434

run [1300]:
Style Loss : 0.108559 Content Loss: 0.015441

run [1350]:
Style Loss : 0.107718 Content Loss: 0.015454

run [1400]:
Style Loss : 0.106951 Content Loss: 0.015459

run [1450]:
Style Loss : 0.106192 Content Loss: 0.015469

run [1500]:
Style Loss : 0.105464 Content Loss: 0.015480

run [1550]:
Style Loss : 0.104887 Content Loss: 0.015487

run [1600]:
Style Loss : 0.104286 Content Loss: 0.015495

run [1650]:
Style Loss : 0.103783 Content Loss: 0.015498

run [1700]:
Style Loss : 0.103302 Content Loss: 0.015497

run [1750]:
Style Loss : 0.102860 Content Loss: 0.015503

run [1800]:
Style Loss : 0.102413 Content Loss: 0.015507

run [1850]:
Style Loss : 0.101980 Content Loss: 0.015506

run [1900]:
Style Loss : 0.101564 Content Loss: 0.015496

run [1950]:
Style Loss : 0.101197 Content Loss: 0.015497

run [2000]:
Style Loss : 0.100862 Content Loss: 0.015500

run [2050]:
Style Loss : 0.100466 Content Loss: 0.015509

run [2100]:
Style Loss : 0.100078 Content Loss: 0.015527

run [2150]:
Style Loss : 0.099665 Content Loss: 0.015539

run [2200]:
Style Loss : 0.099528 Content Loss: 0.015537

run [2250]:
Style Loss : 0.098972 Content Loss: 0.015540

run [2300]:
Style Loss : 0.098642 Content Loss: 0.015537

run [2350]:
Style Loss : 0.098321 Content Loss: 0.015536

run [2400]:
Style Loss : 0.098043 Content Loss: 0.015546

run [2450]:
Style Loss : 0.097763 Content Loss: 0.015547

run [2500]:
Style Loss : 0.097516 Content Loss: 0.015554

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.979372 Content Loss: 0.003101

run [100]:
Style Loss : 1.613467 Content Loss: 0.005658

run [150]:
Style Loss : 1.152453 Content Loss: 0.007544

run [200]:
Style Loss : 0.918737 Content Loss: 0.009148

run [250]:
Style Loss : 0.781457 Content Loss: 0.010276

run [300]:
Style Loss : 0.695129 Content Loss: 0.011509

run [350]:
Style Loss : 0.633933 Content Loss: 0.012525

run [400]:
Style Loss : 0.587317 Content Loss: 0.013467

run [450]:
Style Loss : 0.550280 Content Loss: 0.014362

run [500]:
Style Loss : 0.523275 Content Loss: 0.015227

run [550]:
Style Loss : 0.501563 Content Loss: 0.016035

run [600]:
Style Loss : 0.482083 Content Loss: 0.016722

run [650]:
Style Loss : 0.467595 Content Loss: 0.017226

run [700]:
Style Loss : 0.455670 Content Loss: 0.017745

run [750]:
Style Loss : 0.445672 Content Loss: 0.018158

run [800]:
Style Loss : 0.437131 Content Loss: 0.018581

run [850]:
Style Loss : 0.429775 Content Loss: 0.018894

run [900]:
Style Loss : 0.423076 Content Loss: 0.019191

run [950]:
Style Loss : 0.417688 Content Loss: 0.019433

run [1000]:
Style Loss : 0.412728 Content Loss: 0.019680

run [1050]:
Style Loss : 0.408004 Content Loss: 0.019888

run [1100]:
Style Loss : 0.404066 Content Loss: 0.020048

run [1150]:
Style Loss : 0.400574 Content Loss: 0.020219

run [1200]:
Style Loss : 0.397292 Content Loss: 0.020363

run [1250]:
Style Loss : 0.394236 Content Loss: 0.020505

run [1300]:
Style Loss : 0.391458 Content Loss: 0.020673

run [1350]:
Style Loss : 0.389018 Content Loss: 0.020788

run [1400]:
Style Loss : 0.386706 Content Loss: 0.020912

run [1450]:
Style Loss : 0.384465 Content Loss: 0.021013

run [1500]:
Style Loss : 0.382371 Content Loss: 0.021096

run [1550]:
Style Loss : 0.380402 Content Loss: 0.021170

run [1600]:
Style Loss : 0.378563 Content Loss: 0.021252

run [1650]:
Style Loss : 0.376773 Content Loss: 0.021326

run [1700]:
Style Loss : 0.374996 Content Loss: 0.021397

run [1750]:
Style Loss : 0.373337 Content Loss: 0.021461

run [1800]:
Style Loss : 0.371804 Content Loss: 0.021512

run [1850]:
Style Loss : 0.370411 Content Loss: 0.021567

run [1900]:
Style Loss : 0.369151 Content Loss: 0.021608

run [1950]:
Style Loss : 0.367933 Content Loss: 0.021654

run [2000]:
Style Loss : 0.366878 Content Loss: 0.021698

run [2050]:
Style Loss : 0.365876 Content Loss: 0.021742

run [2100]:
Style Loss : 0.364918 Content Loss: 0.021781

run [2150]:
Style Loss : 0.363975 Content Loss: 0.021821

run [2200]:
Style Loss : 0.363062 Content Loss: 0.021859

run [2250]:
Style Loss : 0.362159 Content Loss: 0.021892

run [2300]:
Style Loss : 0.361326 Content Loss: 0.021922

run [2350]:
Style Loss : 0.360567 Content Loss: 0.021948

run [2400]:
Style Loss : 0.359797 Content Loss: 0.021977

run [2450]:
Style Loss : 0.359074 Content Loss: 0.022000

run [2500]:
Style Loss : 0.358327 Content Loss: 0.022025

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.110528 Content Loss: 0.002623

run [100]:
Style Loss : 1.573400 Content Loss: 0.005054

run [150]:
Style Loss : 1.047191 Content Loss: 0.007065

run [200]:
Style Loss : 0.788346 Content Loss: 0.008761

run [250]:
Style Loss : 0.646538 Content Loss: 0.010086

run [300]:
Style Loss : 0.545512 Content Loss: 0.011189

run [350]:
Style Loss : 0.480714 Content Loss: 0.012085

run [400]:
Style Loss : 0.437064 Content Loss: 0.012917

run [450]:
Style Loss : 0.405105 Content Loss: 0.013696

run [500]:
Style Loss : 0.380302 Content Loss: 0.014333

run [550]:
Style Loss : 0.359612 Content Loss: 0.014964

run [600]:
Style Loss : 0.342181 Content Loss: 0.015474

run [650]:
Style Loss : 0.327738 Content Loss: 0.015849

run [700]:
Style Loss : 0.315633 Content Loss: 0.016259

run [750]:
Style Loss : 0.305317 Content Loss: 0.016584

run [800]:
Style Loss : 0.295950 Content Loss: 0.016859

run [850]:
Style Loss : 0.288221 Content Loss: 0.017084

run [900]:
Style Loss : 0.280950 Content Loss: 0.017320

run [950]:
Style Loss : 0.274352 Content Loss: 0.017532

run [1000]:
Style Loss : 0.268833 Content Loss: 0.017716

run [1050]:
Style Loss : 0.263865 Content Loss: 0.017863

run [1100]:
Style Loss : 0.259555 Content Loss: 0.018017

run [1150]:
Style Loss : 0.255539 Content Loss: 0.018125

run [1200]:
Style Loss : 0.251832 Content Loss: 0.018242

run [1250]:
Style Loss : 0.248487 Content Loss: 0.018359

run [1300]:
Style Loss : 0.245359 Content Loss: 0.018450

run [1350]:
Style Loss : 0.242515 Content Loss: 0.018556

run [1400]:
Style Loss : 0.239777 Content Loss: 0.018670

run [1450]:
Style Loss : 0.237040 Content Loss: 0.018743

run [1500]:
Style Loss : 0.234591 Content Loss: 0.018831

run [1550]:
Style Loss : 0.232091 Content Loss: 0.018933

run [1600]:
Style Loss : 0.229618 Content Loss: 0.019005

run [1650]:
Style Loss : 0.227365 Content Loss: 0.019099

run [1700]:
Style Loss : 0.225226 Content Loss: 0.019162

run [1750]:
Style Loss : 0.223283 Content Loss: 0.019236

run [1800]:
Style Loss : 0.221227 Content Loss: 0.019305

run [1850]:
Style Loss : 0.219698 Content Loss: 0.019382

run [1900]:
Style Loss : 0.217766 Content Loss: 0.019457

run [1950]:
Style Loss : 0.215902 Content Loss: 0.019517

run [2000]:
Style Loss : 0.214158 Content Loss: 0.019579

run [2050]:
Style Loss : 0.212591 Content Loss: 0.019675

run [2100]:
Style Loss : 0.210986 Content Loss: 0.019730

run [2150]:
Style Loss : 0.209564 Content Loss: 0.019794

run [2200]:
Style Loss : 0.210697 Content Loss: 0.019908

run [2250]:
Style Loss : 0.207072 Content Loss: 0.019956

run [2300]:
Style Loss : 0.206062 Content Loss: 0.020047

run [2350]:
Style Loss : 0.204101 Content Loss: 0.020100

run [2400]:
Style Loss : 0.202819 Content Loss: 0.020192

run [2450]:
Style Loss : 0.201551 Content Loss: 0.020270

run [2500]:
Style Loss : 0.201672 Content Loss: 0.020423

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.947775 Content Loss: 0.004847

run [100]:
Style Loss : 1.013421 Content Loss: 0.008549

run [150]:
Style Loss : 0.714299 Content Loss: 0.011426

run [200]:
Style Loss : 0.557622 Content Loss: 0.013860

run [250]:
Style Loss : 0.459967 Content Loss: 0.015686

run [300]:
Style Loss : 0.396017 Content Loss: 0.016897

run [350]:
Style Loss : 0.351622 Content Loss: 0.017626

run [400]:
Style Loss : 0.322334 Content Loss: 0.018407

run [450]:
Style Loss : 0.302635 Content Loss: 0.018998

run [500]:
Style Loss : 0.287749 Content Loss: 0.019558

run [550]:
Style Loss : 0.275473 Content Loss: 0.019975

run [600]:
Style Loss : 0.265384 Content Loss: 0.020399

run [650]:
Style Loss : 0.257489 Content Loss: 0.020744

run [700]:
Style Loss : 0.250243 Content Loss: 0.021102

run [750]:
Style Loss : 0.244560 Content Loss: 0.021414

run [800]:
Style Loss : 0.240454 Content Loss: 0.021680

run [850]:
Style Loss : 0.236356 Content Loss: 0.021978

run [900]:
Style Loss : 0.232673 Content Loss: 0.022222

run [950]:
Style Loss : 0.229294 Content Loss: 0.022459

run [1000]:
Style Loss : 0.225848 Content Loss: 0.022698

run [1050]:
Style Loss : 0.223291 Content Loss: 0.022907

run [1100]:
Style Loss : 0.221586 Content Loss: 0.023216

run [1150]:
Style Loss : 0.216637 Content Loss: 0.023179

run [1200]:
Style Loss : 0.214220 Content Loss: 0.023394

run [1250]:
Style Loss : 0.212225 Content Loss: 0.023544

run [1300]:
Style Loss : 0.209573 Content Loss: 0.023628

run [1350]:
Style Loss : 0.207643 Content Loss: 0.023807

run [1400]:
Style Loss : 0.755462 Content Loss: 0.025227

run [1450]:
Style Loss : 0.236877 Content Loss: 0.024716

run [1500]:
Style Loss : 0.216617 Content Loss: 0.024711

run [1550]:
Style Loss : 0.206821 Content Loss: 0.024736

run [1600]:
Style Loss : 0.201361 Content Loss: 0.024720

run [1650]:
Style Loss : 0.197950 Content Loss: 0.024709

run [1700]:
Style Loss : 0.195454 Content Loss: 0.024665

run [1750]:
Style Loss : 0.193467 Content Loss: 0.024632

run [1800]:
Style Loss : 0.191878 Content Loss: 0.024607

run [1850]:
Style Loss : 0.190408 Content Loss: 0.024587

run [1900]:
Style Loss : 0.188975 Content Loss: 0.024584

run [1950]:
Style Loss : 0.187463 Content Loss: 0.024574

run [2000]:
Style Loss : 0.186359 Content Loss: 0.024577

run [2050]:
Style Loss : 0.184888 Content Loss: 0.024572

run [2100]:
Style Loss : 0.183675 Content Loss: 0.024577

run [2150]:
Style Loss : 0.182473 Content Loss: 0.024585

run [2200]:
Style Loss : 0.217682 Content Loss: 0.024839

run [2250]:
Style Loss : 0.181855 Content Loss: 0.024708

run [2300]:
Style Loss : 0.179434 Content Loss: 0.024674

run [2350]:
Style Loss : 0.178242 Content Loss: 0.024690

run [2400]:
Style Loss : 0.177610 Content Loss: 0.024756

run [2450]:
Style Loss : 0.176364 Content Loss: 0.024788

run [2500]:
Style Loss : 0.176341 Content Loss: 0.024905

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.913472 Content Loss: 0.002358

run [100]:
Style Loss : 1.972895 Content Loss: 0.005038

run [150]:
Style Loss : 1.311530 Content Loss: 0.007045

run [200]:
Style Loss : 1.013655 Content Loss: 0.008391

run [250]:
Style Loss : 0.861369 Content Loss: 0.009655

run [300]:
Style Loss : 0.762433 Content Loss: 0.010479

run [350]:
Style Loss : 0.696626 Content Loss: 0.011036

run [400]:
Style Loss : 0.649909 Content Loss: 0.011583

run [450]:
Style Loss : 0.611040 Content Loss: 0.012123

run [500]:
Style Loss : 0.581039 Content Loss: 0.012420

run [550]:
Style Loss : 0.556370 Content Loss: 0.012787

run [600]:
Style Loss : 0.537923 Content Loss: 0.013115

run [650]:
Style Loss : 0.521959 Content Loss: 0.013375

run [700]:
Style Loss : 0.507556 Content Loss: 0.013573

run [750]:
Style Loss : 0.493423 Content Loss: 0.013809

run [800]:
Style Loss : 0.482773 Content Loss: 0.013983

run [850]:
Style Loss : 0.472909 Content Loss: 0.014166

run [900]:
Style Loss : 0.463886 Content Loss: 0.014344

run [950]:
Style Loss : 0.456904 Content Loss: 0.014481

run [1000]:
Style Loss : 0.450176 Content Loss: 0.014617

run [1050]:
Style Loss : 0.444963 Content Loss: 0.014744

run [1100]:
Style Loss : 0.439713 Content Loss: 0.014859

run [1150]:
Style Loss : 0.435214 Content Loss: 0.014956

run [1200]:
Style Loss : 0.431026 Content Loss: 0.015056

run [1250]:
Style Loss : 0.426889 Content Loss: 0.015157

run [1300]:
Style Loss : 0.423354 Content Loss: 0.015243

run [1350]:
Style Loss : 0.419892 Content Loss: 0.015315

run [1400]:
Style Loss : 0.416757 Content Loss: 0.015367

run [1450]:
Style Loss : 0.413559 Content Loss: 0.015441

run [1500]:
Style Loss : 0.410705 Content Loss: 0.015517

run [1550]:
Style Loss : 0.407940 Content Loss: 0.015594

run [1600]:
Style Loss : 0.405446 Content Loss: 0.015644

run [1650]:
Style Loss : 0.403328 Content Loss: 0.015694

run [1700]:
Style Loss : 0.401322 Content Loss: 0.015746

run [1750]:
Style Loss : 0.399630 Content Loss: 0.015795

run [1800]:
Style Loss : 0.397994 Content Loss: 0.015833

run [1850]:
Style Loss : 0.396474 Content Loss: 0.015870

run [1900]:
Style Loss : 0.395146 Content Loss: 0.015910

run [1950]:
Style Loss : 0.393773 Content Loss: 0.015941

run [2000]:
Style Loss : 0.392300 Content Loss: 0.015971

run [2050]:
Style Loss : 0.390998 Content Loss: 0.015998

run [2100]:
Style Loss : 0.389703 Content Loss: 0.016034

run [2150]:
Style Loss : 0.388585 Content Loss: 0.016061

run [2200]:
Style Loss : 0.387543 Content Loss: 0.016080

run [2250]:
Style Loss : 0.386626 Content Loss: 0.016103

run [2300]:
Style Loss : 0.385680 Content Loss: 0.016127

run [2350]:
Style Loss : 0.384722 Content Loss: 0.016156

run [2400]:
Style Loss : 0.383725 Content Loss: 0.016178

run [2450]:
Style Loss : 0.382871 Content Loss: 0.016203

run [2500]:
Style Loss : 0.382041 Content Loss: 0.016226

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.122734 Content Loss: 0.004071

run [100]:
Style Loss : 1.701451 Content Loss: 0.006500

run [150]:
Style Loss : 1.323913 Content Loss: 0.008104

run [200]:
Style Loss : 1.132758 Content Loss: 0.009433

run [250]:
Style Loss : 1.010211 Content Loss: 0.010373

run [300]:
Style Loss : 0.930684 Content Loss: 0.011121

run [350]:
Style Loss : 0.873940 Content Loss: 0.011805

run [400]:
Style Loss : 0.824843 Content Loss: 0.012348

run [450]:
Style Loss : 0.786043 Content Loss: 0.012874

run [500]:
Style Loss : 0.757144 Content Loss: 0.013316

run [550]:
Style Loss : 0.732013 Content Loss: 0.013691

run [600]:
Style Loss : 0.713433 Content Loss: 0.013993

run [650]:
Style Loss : 0.698312 Content Loss: 0.014271

run [700]:
Style Loss : 0.685458 Content Loss: 0.014553

run [750]:
Style Loss : 0.673090 Content Loss: 0.014833

run [800]:
Style Loss : 0.660897 Content Loss: 0.015058

run [850]:
Style Loss : 0.648595 Content Loss: 0.015328

run [900]:
Style Loss : 0.637521 Content Loss: 0.015552

run [950]:
Style Loss : 0.626736 Content Loss: 0.015755

run [1000]:
Style Loss : 0.616148 Content Loss: 0.015970

run [1050]:
Style Loss : 0.606462 Content Loss: 0.016140

run [1100]:
Style Loss : 0.597279 Content Loss: 0.016301

run [1150]:
Style Loss : 0.589187 Content Loss: 0.016445

run [1200]:
Style Loss : 0.582124 Content Loss: 0.016576

run [1250]:
Style Loss : 0.575356 Content Loss: 0.016716

run [1300]:
Style Loss : 0.569744 Content Loss: 0.016823

run [1350]:
Style Loss : 0.562963 Content Loss: 0.016943

run [1400]:
Style Loss : 0.556498 Content Loss: 0.017058

run [1450]:
Style Loss : 0.551251 Content Loss: 0.017147

run [1500]:
Style Loss : 0.546889 Content Loss: 0.017232

run [1550]:
Style Loss : 0.542825 Content Loss: 0.017332

run [1600]:
Style Loss : 0.539491 Content Loss: 0.017423

run [1650]:
Style Loss : 0.536505 Content Loss: 0.017495

run [1700]:
Style Loss : 0.533694 Content Loss: 0.017575

run [1750]:
Style Loss : 0.531020 Content Loss: 0.017647

run [1800]:
Style Loss : 0.528581 Content Loss: 0.017723

run [1850]:
Style Loss : 0.526433 Content Loss: 0.017788

run [1900]:
Style Loss : 0.524340 Content Loss: 0.017860

run [1950]:
Style Loss : 0.522338 Content Loss: 0.017927

run [2000]:
Style Loss : 0.520544 Content Loss: 0.017988

run [2050]:
Style Loss : 0.518826 Content Loss: 0.018049

run [2100]:
Style Loss : 0.517233 Content Loss: 0.018101

run [2150]:
Style Loss : 0.515772 Content Loss: 0.018153

run [2200]:
Style Loss : 0.514457 Content Loss: 0.018200

run [2250]:
Style Loss : 0.513140 Content Loss: 0.018246

run [2300]:
Style Loss : 0.511857 Content Loss: 0.018298

run [2350]:
Style Loss : 0.510653 Content Loss: 0.018344

run [2400]:
Style Loss : 0.509492 Content Loss: 0.018387

run [2450]:
Style Loss : 0.508259 Content Loss: 0.018432

run [2500]:
Style Loss : 0.507137 Content Loss: 0.018469

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.490373 Content Loss: 0.003968

run [100]:
Style Loss : 2.069962 Content Loss: 0.005663

run [150]:
Style Loss : 1.601564 Content Loss: 0.007083

run [200]:
Style Loss : 1.360755 Content Loss: 0.008457

run [250]:
Style Loss : 1.215751 Content Loss: 0.009528

run [300]:
Style Loss : 1.121615 Content Loss: 0.010407

run [350]:
Style Loss : 1.047469 Content Loss: 0.011108

run [400]:
Style Loss : 0.985362 Content Loss: 0.011863

run [450]:
Style Loss : 0.932996 Content Loss: 0.012406

run [500]:
Style Loss : 0.891058 Content Loss: 0.012943

run [550]:
Style Loss : 0.854632 Content Loss: 0.013501

run [600]:
Style Loss : 0.822562 Content Loss: 0.013931

run [650]:
Style Loss : 0.795919 Content Loss: 0.014346

run [700]:
Style Loss : 0.774281 Content Loss: 0.014687

run [750]:
Style Loss : 0.753699 Content Loss: 0.015092

run [800]:
Style Loss : 0.734060 Content Loss: 0.015398

run [850]:
Style Loss : 0.716968 Content Loss: 0.015696

run [900]:
Style Loss : 0.703305 Content Loss: 0.015931

run [950]:
Style Loss : 0.691523 Content Loss: 0.016187

run [1000]:
Style Loss : 0.680619 Content Loss: 0.016368

run [1050]:
Style Loss : 0.671156 Content Loss: 0.016605

run [1100]:
Style Loss : 0.661967 Content Loss: 0.016805

run [1150]:
Style Loss : 0.653893 Content Loss: 0.017003

run [1200]:
Style Loss : 0.646857 Content Loss: 0.017183

run [1250]:
Style Loss : 0.640288 Content Loss: 0.017353

run [1300]:
Style Loss : 0.633946 Content Loss: 0.017502

run [1350]:
Style Loss : 0.628139 Content Loss: 0.017677

run [1400]:
Style Loss : 0.622917 Content Loss: 0.017812

run [1450]:
Style Loss : 0.618143 Content Loss: 0.017964

run [1500]:
Style Loss : 0.613460 Content Loss: 0.018104

run [1550]:
Style Loss : 0.608991 Content Loss: 0.018189

run [1600]:
Style Loss : 0.604798 Content Loss: 0.018311

run [1650]:
Style Loss : 0.600953 Content Loss: 0.018401

run [1700]:
Style Loss : 0.596395 Content Loss: 0.018478

run [1750]:
Style Loss : 0.592491 Content Loss: 0.018576

run [1800]:
Style Loss : 0.588950 Content Loss: 0.018646

run [1850]:
Style Loss : 0.585668 Content Loss: 0.018712

run [1900]:
Style Loss : 0.582456 Content Loss: 0.018776

run [1950]:
Style Loss : 0.579368 Content Loss: 0.018845

run [2000]:
Style Loss : 0.576747 Content Loss: 0.018900

run [2050]:
Style Loss : 0.574292 Content Loss: 0.018951

run [2100]:
Style Loss : 0.572112 Content Loss: 0.018990

run [2150]:
Style Loss : 0.570267 Content Loss: 0.019038

run [2200]:
Style Loss : 0.568460 Content Loss: 0.019085

run [2250]:
Style Loss : 0.566855 Content Loss: 0.019109

run [2300]:
Style Loss : 0.565398 Content Loss: 0.019138

run [2350]:
Style Loss : 0.563932 Content Loss: 0.019168

run [2400]:
Style Loss : 0.562416 Content Loss: 0.019186

run [2450]:
Style Loss : 0.560997 Content Loss: 0.019206

run [2500]:
Style Loss : 0.559771 Content Loss: 0.019228

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.582154 Content Loss: 0.003135

run [100]:
Style Loss : 1.170594 Content Loss: 0.004694

run [150]:
Style Loss : 0.721901 Content Loss: 0.006152

run [200]:
Style Loss : 0.513396 Content Loss: 0.007451

run [250]:
Style Loss : 0.408335 Content Loss: 0.008311

run [300]:
Style Loss : 0.343133 Content Loss: 0.009248

run [350]:
Style Loss : 0.298633 Content Loss: 0.010066

run [400]:
Style Loss : 0.264364 Content Loss: 0.010951

run [450]:
Style Loss : 0.237865 Content Loss: 0.011641

run [500]:
Style Loss : 0.217114 Content Loss: 0.012292

run [550]:
Style Loss : 0.201672 Content Loss: 0.012723

run [600]:
Style Loss : 0.189319 Content Loss: 0.013125

run [650]:
Style Loss : 0.178717 Content Loss: 0.013512

run [700]:
Style Loss : 0.169551 Content Loss: 0.013832

run [750]:
Style Loss : 0.162280 Content Loss: 0.014042

run [800]:
Style Loss : 0.156098 Content Loss: 0.014238

run [850]:
Style Loss : 0.150765 Content Loss: 0.014418

run [900]:
Style Loss : 0.146273 Content Loss: 0.014552

run [950]:
Style Loss : 0.142026 Content Loss: 0.014680

run [1000]:
Style Loss : 0.138237 Content Loss: 0.014785

run [1050]:
Style Loss : 0.134965 Content Loss: 0.014875

run [1100]:
Style Loss : 0.131805 Content Loss: 0.014954

run [1150]:
Style Loss : 0.128814 Content Loss: 0.015008

run [1200]:
Style Loss : 0.126256 Content Loss: 0.015060

run [1250]:
Style Loss : 0.124214 Content Loss: 0.015082

run [1300]:
Style Loss : 0.122560 Content Loss: 0.015108

run [1350]:
Style Loss : 0.120847 Content Loss: 0.015106

run [1400]:
Style Loss : 0.119272 Content Loss: 0.015110

run [1450]:
Style Loss : 0.117842 Content Loss: 0.015114

run [1500]:
Style Loss : 0.116499 Content Loss: 0.015106

run [1550]:
Style Loss : 0.115209 Content Loss: 0.015106

run [1600]:
Style Loss : 0.113954 Content Loss: 0.015104

run [1650]:
Style Loss : 0.112764 Content Loss: 0.015095

run [1700]:
Style Loss : 0.111592 Content Loss: 0.015094

run [1750]:
Style Loss : 0.110186 Content Loss: 0.015091

run [1800]:
Style Loss : 0.108998 Content Loss: 0.015090

run [1850]:
Style Loss : 0.107839 Content Loss: 0.015082

run [1900]:
Style Loss : 0.106693 Content Loss: 0.015074

run [1950]:
Style Loss : 0.105658 Content Loss: 0.015064

run [2000]:
Style Loss : 0.104705 Content Loss: 0.015051

run [2050]:
Style Loss : 0.103769 Content Loss: 0.015039

run [2100]:
Style Loss : 0.102848 Content Loss: 0.015028

run [2150]:
Style Loss : 0.102028 Content Loss: 0.015010

run [2200]:
Style Loss : 0.101166 Content Loss: 0.014993

run [2250]:
Style Loss : 0.100373 Content Loss: 0.014975

run [2300]:
Style Loss : 0.099648 Content Loss: 0.014966

run [2350]:
Style Loss : 0.098918 Content Loss: 0.014959

run [2400]:
Style Loss : 0.098253 Content Loss: 0.014944

run [2450]:
Style Loss : 0.097632 Content Loss: 0.014925

run [2500]:
Style Loss : 0.097061 Content Loss: 0.014904

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.270097 Content Loss: 0.004829

run [100]:
Style Loss : 1.222302 Content Loss: 0.007601

run [150]:
Style Loss : 0.916607 Content Loss: 0.009271

run [200]:
Style Loss : 0.774181 Content Loss: 0.010521

run [250]:
Style Loss : 0.685219 Content Loss: 0.011448

run [300]:
Style Loss : 0.617517 Content Loss: 0.012265

run [350]:
Style Loss : 0.577465 Content Loss: 0.012952

run [400]:
Style Loss : 0.546801 Content Loss: 0.013518

run [450]:
Style Loss : 0.519731 Content Loss: 0.014089

run [500]:
Style Loss : 0.499408 Content Loss: 0.014596

run [550]:
Style Loss : 0.479390 Content Loss: 0.015050

run [600]:
Style Loss : 0.462986 Content Loss: 0.015481

run [650]:
Style Loss : 0.451510 Content Loss: 0.015862

run [700]:
Style Loss : 0.442000 Content Loss: 0.016216

run [750]:
Style Loss : 0.434436 Content Loss: 0.016571

run [800]:
Style Loss : 0.426860 Content Loss: 0.016899

run [850]:
Style Loss : 0.419280 Content Loss: 0.017236

run [900]:
Style Loss : 0.413000 Content Loss: 0.017611

run [950]:
Style Loss : 0.407505 Content Loss: 0.017896

run [1000]:
Style Loss : 0.401560 Content Loss: 0.018111

run [1050]:
Style Loss : 0.396665 Content Loss: 0.018324

run [1100]:
Style Loss : 0.391984 Content Loss: 0.018553

run [1150]:
Style Loss : 0.387672 Content Loss: 0.018797

run [1200]:
Style Loss : 0.383014 Content Loss: 0.018987

run [1250]:
Style Loss : 0.378548 Content Loss: 0.019133

run [1300]:
Style Loss : 0.373719 Content Loss: 0.019322

run [1350]:
Style Loss : 0.368589 Content Loss: 0.019471

run [1400]:
Style Loss : 0.364423 Content Loss: 0.019580

run [1450]:
Style Loss : 0.360985 Content Loss: 0.019703

run [1500]:
Style Loss : 0.357514 Content Loss: 0.019813

run [1550]:
Style Loss : 0.354209 Content Loss: 0.019926

run [1600]:
Style Loss : 0.351543 Content Loss: 0.020029

run [1650]:
Style Loss : 0.348728 Content Loss: 0.020106

run [1700]:
Style Loss : 0.346818 Content Loss: 0.020208

run [1750]:
Style Loss : 0.344375 Content Loss: 0.020287

run [1800]:
Style Loss : 0.341873 Content Loss: 0.020339

run [1850]:
Style Loss : 0.340062 Content Loss: 0.020449

run [1900]:
Style Loss : 0.337959 Content Loss: 0.020516

run [1950]:
Style Loss : 0.335972 Content Loss: 0.020599

run [2000]:
Style Loss : 0.334327 Content Loss: 0.020664

run [2050]:
Style Loss : 0.332417 Content Loss: 0.020711

run [2100]:
Style Loss : 0.330988 Content Loss: 0.020763

run [2150]:
Style Loss : 0.329470 Content Loss: 0.020833

run [2200]:
Style Loss : 0.328005 Content Loss: 0.020899

run [2250]:
Style Loss : 0.327117 Content Loss: 0.020993

run [2300]:
Style Loss : 0.325639 Content Loss: 0.021039

run [2350]:
Style Loss : 0.324511 Content Loss: 0.021130

run [2400]:
Style Loss : 0.324829 Content Loss: 0.021293

run [2450]:
Style Loss : 0.322166 Content Loss: 0.021243

run [2500]:
Style Loss : 0.321553 Content Loss: 0.021332

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.608013 Content Loss: 0.005467

run [100]:
Style Loss : 0.830178 Content Loss: 0.008333

run [150]:
Style Loss : 0.572863 Content Loss: 0.009650

run [200]:
Style Loss : 0.470514 Content Loss: 0.010536

run [250]:
Style Loss : 0.410930 Content Loss: 0.011289

run [300]:
Style Loss : 0.373987 Content Loss: 0.011934

run [350]:
Style Loss : 0.345476 Content Loss: 0.012485

run [400]:
Style Loss : 0.325173 Content Loss: 0.012909

run [450]:
Style Loss : 0.311415 Content Loss: 0.013316

run [500]:
Style Loss : 0.300945 Content Loss: 0.013637

run [550]:
Style Loss : 0.292293 Content Loss: 0.013909

run [600]:
Style Loss : 0.285033 Content Loss: 0.014164

run [650]:
Style Loss : 0.278536 Content Loss: 0.014362

run [700]:
Style Loss : 0.273222 Content Loss: 0.014553

run [750]:
Style Loss : 0.268526 Content Loss: 0.014772

run [800]:
Style Loss : 0.264310 Content Loss: 0.014965

run [850]:
Style Loss : 0.260480 Content Loss: 0.015134

run [900]:
Style Loss : 0.256988 Content Loss: 0.015263

run [950]:
Style Loss : 0.254114 Content Loss: 0.015401

run [1000]:
Style Loss : 0.251554 Content Loss: 0.015525

run [1050]:
Style Loss : 0.249336 Content Loss: 0.015656

run [1100]:
Style Loss : 0.247096 Content Loss: 0.015760

run [1150]:
Style Loss : 0.245181 Content Loss: 0.015863

run [1200]:
Style Loss : 0.243277 Content Loss: 0.015968

run [1250]:
Style Loss : 0.241545 Content Loss: 0.016071

run [1300]:
Style Loss : 0.239991 Content Loss: 0.016176

run [1350]:
Style Loss : 0.238372 Content Loss: 0.016272

run [1400]:
Style Loss : 0.236894 Content Loss: 0.016361

run [1450]:
Style Loss : 0.235542 Content Loss: 0.016432

run [1500]:
Style Loss : 0.234302 Content Loss: 0.016523

run [1550]:
Style Loss : 0.233402 Content Loss: 0.016656

run [1600]:
Style Loss : 0.232027 Content Loss: 0.016704

run [1650]:
Style Loss : 0.230859 Content Loss: 0.016773

run [1700]:
Style Loss : 0.229809 Content Loss: 0.016880

run [1750]:
Style Loss : 0.228651 Content Loss: 0.016940

run [1800]:
Style Loss : 0.227553 Content Loss: 0.017023

run [1850]:
Style Loss : 0.226434 Content Loss: 0.017226

run [1900]:
Style Loss : 0.224014 Content Loss: 0.017206

run [1950]:
Style Loss : 0.223564 Content Loss: 0.017297

run [2000]:
Style Loss : 0.221472 Content Loss: 0.017403

run [2050]:
Style Loss : 0.219839 Content Loss: 0.017459

run [2100]:
Style Loss : 0.218688 Content Loss: 0.017569

run [2150]:
Style Loss : 0.217580 Content Loss: 0.017689

run [2200]:
Style Loss : 0.216213 Content Loss: 0.017747

run [2250]:
Style Loss : 0.215149 Content Loss: 0.017860

run [2300]:
Style Loss : 0.214068 Content Loss: 0.017974

run [2350]:
Style Loss : 0.212958 Content Loss: 0.018078

run [2400]:
Style Loss : 0.211973 Content Loss: 0.018173

run [2450]:
Style Loss : 0.210939 Content Loss: 0.018271

run [2500]:
Style Loss : 0.210188 Content Loss: 0.018419

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.717020 Content Loss: 0.006152

run [100]:
Style Loss : 0.406199 Content Loss: 0.009140

run [150]:
Style Loss : 0.312185 Content Loss: 0.011056

run [200]:
Style Loss : 0.269564 Content Loss: 0.012428

run [250]:
Style Loss : 0.245102 Content Loss: 0.013310

run [300]:
Style Loss : 0.228904 Content Loss: 0.014129

run [350]:
Style Loss : 0.217073 Content Loss: 0.014837

run [400]:
Style Loss : 0.206679 Content Loss: 0.015453

run [450]:
Style Loss : 0.192010 Content Loss: 0.015890

run [500]:
Style Loss : 0.183250 Content Loss: 0.016306

run [550]:
Style Loss : 0.176486 Content Loss: 0.016694

run [600]:
Style Loss : 0.170333 Content Loss: 0.017035

run [650]:
Style Loss : 0.165191 Content Loss: 0.017331

run [700]:
Style Loss : 0.160545 Content Loss: 0.017601

run [750]:
Style Loss : 0.156694 Content Loss: 0.017808

run [800]:
Style Loss : 0.153543 Content Loss: 0.017984

run [850]:
Style Loss : 0.150928 Content Loss: 0.018151

run [900]:
Style Loss : 0.148432 Content Loss: 0.018322

run [950]:
Style Loss : 0.146081 Content Loss: 0.018481

run [1000]:
Style Loss : 0.143973 Content Loss: 0.018664

run [1050]:
Style Loss : 0.142047 Content Loss: 0.018881

run [1100]:
Style Loss : 0.140181 Content Loss: 0.019096

run [1150]:
Style Loss : 0.138506 Content Loss: 0.019310

run [1200]:
Style Loss : 0.136944 Content Loss: 0.019493

run [1250]:
Style Loss : 0.135502 Content Loss: 0.019717

run [1300]:
Style Loss : 0.134024 Content Loss: 0.019939

run [1350]:
Style Loss : 0.132763 Content Loss: 0.020226

run [1400]:
Style Loss : 0.131292 Content Loss: 0.020400

run [1450]:
Style Loss : 0.130175 Content Loss: 0.020650

run [1500]:
Style Loss : 0.129328 Content Loss: 0.020896

run [1550]:
Style Loss : 0.128388 Content Loss: 0.021140

run [1600]:
Style Loss : 0.127290 Content Loss: 0.021349

run [1650]:
Style Loss : 0.127143 Content Loss: 0.021706

run [1700]:
Style Loss : 0.161551 Content Loss: 0.023606

run [1750]:
Style Loss : 0.129577 Content Loss: 0.023165

run [1800]:
Style Loss : 0.124624 Content Loss: 0.022995

run [1850]:
Style Loss : 0.122381 Content Loss: 0.022808

run [1900]:
Style Loss : 0.121080 Content Loss: 0.022656

run [1950]:
Style Loss : 0.120216 Content Loss: 0.022536

run [2000]:
Style Loss : 0.119619 Content Loss: 0.022430

run [2050]:
Style Loss : 0.119147 Content Loss: 0.022333

run [2100]:
Style Loss : 0.118781 Content Loss: 0.022244

run [2150]:
Style Loss : 0.118458 Content Loss: 0.022164

run [2200]:
Style Loss : 0.118161 Content Loss: 0.022086

run [2250]:
Style Loss : 0.117888 Content Loss: 0.022017

run [2300]:
Style Loss : 0.117628 Content Loss: 0.021955

run [2350]:
Style Loss : 0.117411 Content Loss: 0.021895

run [2400]:
Style Loss : 0.117325 Content Loss: 0.021832

run [2450]:
Style Loss : 0.117055 Content Loss: 0.021782

run [2500]:
Style Loss : 0.116877 Content Loss: 0.021734

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.482239 Content Loss: 0.004079

run [100]:
Style Loss : 0.658884 Content Loss: 0.007546

run [150]:
Style Loss : 0.477300 Content Loss: 0.009095

run [200]:
Style Loss : 0.392454 Content Loss: 0.010255

run [250]:
Style Loss : 0.340178 Content Loss: 0.011168

run [300]:
Style Loss : 0.303500 Content Loss: 0.011941

run [350]:
Style Loss : 0.275903 Content Loss: 0.012521

run [400]:
Style Loss : 0.255666 Content Loss: 0.013015

run [450]:
Style Loss : 0.240570 Content Loss: 0.013432

run [500]:
Style Loss : 0.228624 Content Loss: 0.013824

run [550]:
Style Loss : 0.218569 Content Loss: 0.014199

run [600]:
Style Loss : 0.211046 Content Loss: 0.014511

run [650]:
Style Loss : 0.204451 Content Loss: 0.014848

run [700]:
Style Loss : 0.198756 Content Loss: 0.015147

run [750]:
Style Loss : 0.194243 Content Loss: 0.015390

run [800]:
Style Loss : 0.190643 Content Loss: 0.015612

run [850]:
Style Loss : 0.187706 Content Loss: 0.015789

run [900]:
Style Loss : 0.184795 Content Loss: 0.015981

run [950]:
Style Loss : 0.182039 Content Loss: 0.016185

run [1000]:
Style Loss : 0.179697 Content Loss: 0.016337

run [1050]:
Style Loss : 0.177640 Content Loss: 0.016466

run [1100]:
Style Loss : 0.175690 Content Loss: 0.016588

run [1150]:
Style Loss : 0.174058 Content Loss: 0.016681

run [1200]:
Style Loss : 0.172546 Content Loss: 0.016752

run [1250]:
Style Loss : 0.171187 Content Loss: 0.016827

run [1300]:
Style Loss : 0.169925 Content Loss: 0.016914

run [1350]:
Style Loss : 0.168671 Content Loss: 0.016981

run [1400]:
Style Loss : 0.167491 Content Loss: 0.017046

run [1450]:
Style Loss : 0.166445 Content Loss: 0.017111

run [1500]:
Style Loss : 0.165507 Content Loss: 0.017153

run [1550]:
Style Loss : 0.164580 Content Loss: 0.017199

run [1600]:
Style Loss : 0.163668 Content Loss: 0.017254

run [1650]:
Style Loss : 0.162659 Content Loss: 0.017296

run [1700]:
Style Loss : 0.161755 Content Loss: 0.017338

run [1750]:
Style Loss : 0.160910 Content Loss: 0.017385

run [1800]:
Style Loss : 0.160025 Content Loss: 0.017422

run [1850]:
Style Loss : 0.159461 Content Loss: 0.017479

run [1900]:
Style Loss : 0.158953 Content Loss: 0.017525

run [1950]:
Style Loss : 0.157807 Content Loss: 0.017559

run [2000]:
Style Loss : 0.156815 Content Loss: 0.017612

run [2050]:
Style Loss : 0.155908 Content Loss: 0.017650

run [2100]:
Style Loss : 0.155207 Content Loss: 0.017737

run [2150]:
Style Loss : 0.154455 Content Loss: 0.017741

run [2200]:
Style Loss : 0.153872 Content Loss: 0.017789

run [2250]:
Style Loss : 0.153183 Content Loss: 0.017827

run [2300]:
Style Loss : 0.152654 Content Loss: 0.017878

run [2350]:
Style Loss : 0.151969 Content Loss: 0.017915

run [2400]:
Style Loss : 0.151326 Content Loss: 0.017970

run [2450]:
Style Loss : 0.150809 Content Loss: 0.018039

run [2500]:
Style Loss : 0.150179 Content Loss: 0.018100

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.900164 Content Loss: 0.002815

run [100]:
Style Loss : 1.482344 Content Loss: 0.005765

run [150]:
Style Loss : 1.054265 Content Loss: 0.007833

run [200]:
Style Loss : 0.860015 Content Loss: 0.009180

run [250]:
Style Loss : 0.750219 Content Loss: 0.010340

run [300]:
Style Loss : 0.675353 Content Loss: 0.011158

run [350]:
Style Loss : 0.622892 Content Loss: 0.011848

run [400]:
Style Loss : 0.583408 Content Loss: 0.012493

run [450]:
Style Loss : 0.550536 Content Loss: 0.013037

run [500]:
Style Loss : 0.521158 Content Loss: 0.013508

run [550]:
Style Loss : 0.495406 Content Loss: 0.013988

run [600]:
Style Loss : 0.469819 Content Loss: 0.014283

run [650]:
Style Loss : 0.449215 Content Loss: 0.014586

run [700]:
Style Loss : 0.432492 Content Loss: 0.014887

run [750]:
Style Loss : 0.418170 Content Loss: 0.015161

run [800]:
Style Loss : 0.405476 Content Loss: 0.015376

run [850]:
Style Loss : 0.394333 Content Loss: 0.015603

run [900]:
Style Loss : 0.385112 Content Loss: 0.015813

run [950]:
Style Loss : 0.377756 Content Loss: 0.015997

run [1000]:
Style Loss : 0.370957 Content Loss: 0.016186

run [1050]:
Style Loss : 0.364338 Content Loss: 0.016359

run [1100]:
Style Loss : 0.358723 Content Loss: 0.016531

run [1150]:
Style Loss : 0.353755 Content Loss: 0.016694

run [1200]:
Style Loss : 0.349163 Content Loss: 0.016840

run [1250]:
Style Loss : 0.344723 Content Loss: 0.016983

run [1300]:
Style Loss : 0.340627 Content Loss: 0.017135

run [1350]:
Style Loss : 0.336771 Content Loss: 0.017292

run [1400]:
Style Loss : 0.333273 Content Loss: 0.017414

run [1450]:
Style Loss : 0.330312 Content Loss: 0.017536

run [1500]:
Style Loss : 0.327018 Content Loss: 0.017667

run [1550]:
Style Loss : 0.323748 Content Loss: 0.017794

run [1600]:
Style Loss : 0.320767 Content Loss: 0.017896

run [1650]:
Style Loss : 0.317985 Content Loss: 0.018001

run [1700]:
Style Loss : 0.315482 Content Loss: 0.018103

run [1750]:
Style Loss : 0.313070 Content Loss: 0.018198

run [1800]:
Style Loss : 0.310737 Content Loss: 0.018275

run [1850]:
Style Loss : 0.308404 Content Loss: 0.018367

run [1900]:
Style Loss : 0.305871 Content Loss: 0.018458

run [1950]:
Style Loss : 0.303629 Content Loss: 0.018538

run [2000]:
Style Loss : 0.301556 Content Loss: 0.018602

run [2050]:
Style Loss : 0.299478 Content Loss: 0.018681

run [2100]:
Style Loss : 0.297378 Content Loss: 0.018759

run [2150]:
Style Loss : 0.295197 Content Loss: 0.018825

run [2200]:
Style Loss : 0.293278 Content Loss: 0.018886

run [2250]:
Style Loss : 0.291580 Content Loss: 0.018937

run [2300]:
Style Loss : 0.290008 Content Loss: 0.018991

run [2350]:
Style Loss : 0.288454 Content Loss: 0.019050

run [2400]:
Style Loss : 0.286928 Content Loss: 0.019108

run [2450]:
Style Loss : 0.285413 Content Loss: 0.019163

run [2500]:
Style Loss : 0.283929 Content Loss: 0.019216

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.685631 Content Loss: 0.006478

run [100]:
Style Loss : 0.372573 Content Loss: 0.009483

run [150]:
Style Loss : 0.281646 Content Loss: 0.011491

run [200]:
Style Loss : 0.238351 Content Loss: 0.012762

run [250]:
Style Loss : 0.211107 Content Loss: 0.013687

run [300]:
Style Loss : 0.190971 Content Loss: 0.014363

run [350]:
Style Loss : 0.174068 Content Loss: 0.015091

run [400]:
Style Loss : 0.159144 Content Loss: 0.015681

run [450]:
Style Loss : 0.148265 Content Loss: 0.016127

run [500]:
Style Loss : 0.140544 Content Loss: 0.016524

run [550]:
Style Loss : 0.134642 Content Loss: 0.016891

run [600]:
Style Loss : 0.130257 Content Loss: 0.017133

run [650]:
Style Loss : 0.126455 Content Loss: 0.017346

run [700]:
Style Loss : 0.123105 Content Loss: 0.017539

run [750]:
Style Loss : 0.120218 Content Loss: 0.017674

run [800]:
Style Loss : 0.117810 Content Loss: 0.017762

run [850]:
Style Loss : 0.115987 Content Loss: 0.017823

run [900]:
Style Loss : 0.114462 Content Loss: 0.017875

run [950]:
Style Loss : 0.113110 Content Loss: 0.017929

run [1000]:
Style Loss : 0.111921 Content Loss: 0.017959

run [1050]:
Style Loss : 0.110960 Content Loss: 0.017970

run [1100]:
Style Loss : 0.110174 Content Loss: 0.017963

run [1150]:
Style Loss : 0.109496 Content Loss: 0.017965

run [1200]:
Style Loss : 0.108888 Content Loss: 0.017972

run [1250]:
Style Loss : 0.108352 Content Loss: 0.017976

run [1300]:
Style Loss : 0.107840 Content Loss: 0.017985

run [1350]:
Style Loss : 0.107392 Content Loss: 0.017991

run [1400]:
Style Loss : 0.106934 Content Loss: 0.018001

run [1450]:
Style Loss : 0.106489 Content Loss: 0.018007

run [1500]:
Style Loss : 0.106033 Content Loss: 0.018014

run [1550]:
Style Loss : 0.105561 Content Loss: 0.018024

run [1600]:
Style Loss : 0.105110 Content Loss: 0.018038

run [1650]:
Style Loss : 0.104729 Content Loss: 0.018054

run [1700]:
Style Loss : 0.104325 Content Loss: 0.018066

run [1750]:
Style Loss : 0.103914 Content Loss: 0.018080

run [1800]:
Style Loss : 0.103521 Content Loss: 0.018101

run [1850]:
Style Loss : 0.103071 Content Loss: 0.018120

run [1900]:
Style Loss : 0.102658 Content Loss: 0.018143

run [1950]:
Style Loss : 0.102248 Content Loss: 0.018155

run [2000]:
Style Loss : 0.101932 Content Loss: 0.018166

run [2050]:
Style Loss : 0.101585 Content Loss: 0.018186

run [2100]:
Style Loss : 0.101257 Content Loss: 0.018201

run [2150]:
Style Loss : 0.100933 Content Loss: 0.018219

run [2200]:
Style Loss : 0.100658 Content Loss: 0.018228

run [2250]:
Style Loss : 0.100393 Content Loss: 0.018240

run [2300]:
Style Loss : 0.100147 Content Loss: 0.018253

run [2350]:
Style Loss : 0.099919 Content Loss: 0.018260

run [2400]:
Style Loss : 0.099713 Content Loss: 0.018270

run [2450]:
Style Loss : 0.099491 Content Loss: 0.018279

run [2500]:
Style Loss : 0.099274 Content Loss: 0.018295

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.551996 Content Loss: 0.003670

run [100]:
Style Loss : 1.208938 Content Loss: 0.007155

run [150]:
Style Loss : 0.837208 Content Loss: 0.008786

run [200]:
Style Loss : 0.657250 Content Loss: 0.010355

run [250]:
Style Loss : 0.554069 Content Loss: 0.011668

run [300]:
Style Loss : 0.480194 Content Loss: 0.012696

run [350]:
Style Loss : 0.433300 Content Loss: 0.013620

run [400]:
Style Loss : 0.393933 Content Loss: 0.014514

run [450]:
Style Loss : 0.364020 Content Loss: 0.015194

run [500]:
Style Loss : 0.342957 Content Loss: 0.015838

run [550]:
Style Loss : 0.326560 Content Loss: 0.016445

run [600]:
Style Loss : 0.313134 Content Loss: 0.016920

run [650]:
Style Loss : 0.302932 Content Loss: 0.017277

run [700]:
Style Loss : 0.294944 Content Loss: 0.017593

run [750]:
Style Loss : 0.288836 Content Loss: 0.017871

run [800]:
Style Loss : 0.283484 Content Loss: 0.018107

run [850]:
Style Loss : 0.279242 Content Loss: 0.018302

run [900]:
Style Loss : 0.275402 Content Loss: 0.018502

run [950]:
Style Loss : 0.271917 Content Loss: 0.018673

run [1000]:
Style Loss : 0.269056 Content Loss: 0.018803

run [1050]:
Style Loss : 0.266713 Content Loss: 0.018933

run [1100]:
Style Loss : 0.264432 Content Loss: 0.019054

run [1150]:
Style Loss : 0.262428 Content Loss: 0.019162

run [1200]:
Style Loss : 0.260547 Content Loss: 0.019256

run [1250]:
Style Loss : 0.259013 Content Loss: 0.019331

run [1300]:
Style Loss : 0.257541 Content Loss: 0.019392

run [1350]:
Style Loss : 0.256036 Content Loss: 0.019444

run [1400]:
Style Loss : 0.254444 Content Loss: 0.019494

run [1450]:
Style Loss : 0.253059 Content Loss: 0.019540

run [1500]:
Style Loss : 0.251722 Content Loss: 0.019587

run [1550]:
Style Loss : 0.250494 Content Loss: 0.019621

run [1600]:
Style Loss : 0.249360 Content Loss: 0.019655

run [1650]:
Style Loss : 0.248205 Content Loss: 0.019685

run [1700]:
Style Loss : 0.247138 Content Loss: 0.019721

run [1750]:
Style Loss : 0.246163 Content Loss: 0.019750

run [1800]:
Style Loss : 0.245261 Content Loss: 0.019779

run [1850]:
Style Loss : 0.244445 Content Loss: 0.019807

run [1900]:
Style Loss : 0.243574 Content Loss: 0.019847

run [1950]:
Style Loss : 0.242631 Content Loss: 0.019885

run [2000]:
Style Loss : 0.241696 Content Loss: 0.019927

run [2050]:
Style Loss : 0.240801 Content Loss: 0.019964

run [2100]:
Style Loss : 0.239927 Content Loss: 0.019995

run [2150]:
Style Loss : 0.239030 Content Loss: 0.020037

run [2200]:
Style Loss : 0.238284 Content Loss: 0.020062

run [2250]:
Style Loss : 0.237545 Content Loss: 0.020095

run [2300]:
Style Loss : 0.236876 Content Loss: 0.020125

run [2350]:
Style Loss : 0.236258 Content Loss: 0.020152

run [2400]:
Style Loss : 0.235699 Content Loss: 0.020181

run [2450]:
Style Loss : 0.235153 Content Loss: 0.020210

run [2500]:
Style Loss : 0.234643 Content Loss: 0.020234

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.150619 Content Loss: 0.001619

run [100]:
Style Loss : 0.728803 Content Loss: 0.002095

run [150]:
Style Loss : 0.568648 Content Loss: 0.002623

run [200]:
Style Loss : 0.488484 Content Loss: 0.003058

run [250]:
Style Loss : 0.440901 Content Loss: 0.003515

run [300]:
Style Loss : 0.407966 Content Loss: 0.003908

run [350]:
Style Loss : 0.384295 Content Loss: 0.004204

run [400]:
Style Loss : 0.366070 Content Loss: 0.004512

run [450]:
Style Loss : 0.352730 Content Loss: 0.004779

run [500]:
Style Loss : 0.342380 Content Loss: 0.005007

run [550]:
Style Loss : 0.333784 Content Loss: 0.005220

run [600]:
Style Loss : 0.327076 Content Loss: 0.005378

run [650]:
Style Loss : 0.321218 Content Loss: 0.005552

run [700]:
Style Loss : 0.315849 Content Loss: 0.005723

run [750]:
Style Loss : 0.311265 Content Loss: 0.005890

run [800]:
Style Loss : 0.307103 Content Loss: 0.006056

run [850]:
Style Loss : 0.303319 Content Loss: 0.006186

run [900]:
Style Loss : 0.299868 Content Loss: 0.006323

run [950]:
Style Loss : 0.296861 Content Loss: 0.006462

run [1000]:
Style Loss : 0.294233 Content Loss: 0.006578

run [1050]:
Style Loss : 0.291750 Content Loss: 0.006693

run [1100]:
Style Loss : 0.289508 Content Loss: 0.006784

run [1150]:
Style Loss : 0.287473 Content Loss: 0.006884

run [1200]:
Style Loss : 0.285595 Content Loss: 0.006982

run [1250]:
Style Loss : 0.283902 Content Loss: 0.007064

run [1300]:
Style Loss : 0.282338 Content Loss: 0.007144

run [1350]:
Style Loss : 0.280903 Content Loss: 0.007219

run [1400]:
Style Loss : 0.279575 Content Loss: 0.007279

run [1450]:
Style Loss : 0.278382 Content Loss: 0.007339

run [1500]:
Style Loss : 0.277218 Content Loss: 0.007400

run [1550]:
Style Loss : 0.276165 Content Loss: 0.007464

run [1600]:
Style Loss : 0.275200 Content Loss: 0.007516

run [1650]:
Style Loss : 0.274300 Content Loss: 0.007565

run [1700]:
Style Loss : 0.273408 Content Loss: 0.007623

run [1750]:
Style Loss : 0.272563 Content Loss: 0.007673

run [1800]:
Style Loss : 0.271736 Content Loss: 0.007725

run [1850]:
Style Loss : 0.271037 Content Loss: 0.007765

run [1900]:
Style Loss : 0.270338 Content Loss: 0.007808

run [1950]:
Style Loss : 0.269637 Content Loss: 0.007852

run [2000]:
Style Loss : 0.268956 Content Loss: 0.007895

run [2050]:
Style Loss : 0.268310 Content Loss: 0.007932

run [2100]:
Style Loss : 0.267653 Content Loss: 0.007972

run [2150]:
Style Loss : 0.267083 Content Loss: 0.008007

run [2200]:
Style Loss : 0.266451 Content Loss: 0.008047

run [2250]:
Style Loss : 0.265892 Content Loss: 0.008078

run [2300]:
Style Loss : 0.265376 Content Loss: 0.008108

run [2350]:
Style Loss : 0.264843 Content Loss: 0.008139

run [2400]:
Style Loss : 0.264339 Content Loss: 0.008171

run [2450]:
Style Loss : 0.263838 Content Loss: 0.008200

run [2500]:
Style Loss : 0.263337 Content Loss: 0.008232

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.021060 Content Loss: 0.001273

run [100]:
Style Loss : 0.620497 Content Loss: 0.001545

run [150]:
Style Loss : 0.475466 Content Loss: 0.001910

run [200]:
Style Loss : 0.400439 Content Loss: 0.002328

run [250]:
Style Loss : 0.347045 Content Loss: 0.002771

run [300]:
Style Loss : 0.308554 Content Loss: 0.003163

run [350]:
Style Loss : 0.279046 Content Loss: 0.003522

run [400]:
Style Loss : 0.256884 Content Loss: 0.003810

run [450]:
Style Loss : 0.239369 Content Loss: 0.004071

run [500]:
Style Loss : 0.225525 Content Loss: 0.004349

run [550]:
Style Loss : 0.214140 Content Loss: 0.004592

run [600]:
Style Loss : 0.204205 Content Loss: 0.004805

run [650]:
Style Loss : 0.196411 Content Loss: 0.004986

run [700]:
Style Loss : 0.189786 Content Loss: 0.005198

run [750]:
Style Loss : 0.184217 Content Loss: 0.005374

run [800]:
Style Loss : 0.179423 Content Loss: 0.005532

run [850]:
Style Loss : 0.175404 Content Loss: 0.005686

run [900]:
Style Loss : 0.171853 Content Loss: 0.005851

run [950]:
Style Loss : 0.168600 Content Loss: 0.006005

run [1000]:
Style Loss : 0.165802 Content Loss: 0.006147

run [1050]:
Style Loss : 0.163154 Content Loss: 0.006310

run [1100]:
Style Loss : 0.160703 Content Loss: 0.006443

run [1150]:
Style Loss : 0.158498 Content Loss: 0.006552

run [1200]:
Style Loss : 0.156348 Content Loss: 0.006670

run [1250]:
Style Loss : 0.154480 Content Loss: 0.006773

run [1300]:
Style Loss : 0.152715 Content Loss: 0.006857

run [1350]:
Style Loss : 0.151062 Content Loss: 0.006964

run [1400]:
Style Loss : 0.149525 Content Loss: 0.007070

run [1450]:
Style Loss : 0.147991 Content Loss: 0.007171

run [1500]:
Style Loss : 0.146483 Content Loss: 0.007269

run [1550]:
Style Loss : 0.145074 Content Loss: 0.007378

run [1600]:
Style Loss : 0.143636 Content Loss: 0.007475

run [1650]:
Style Loss : 0.142229 Content Loss: 0.007584

run [1700]:
Style Loss : 0.140906 Content Loss: 0.007692

run [1750]:
Style Loss : 0.139620 Content Loss: 0.007803

run [1800]:
Style Loss : 0.138355 Content Loss: 0.007912

run [1850]:
Style Loss : 0.137200 Content Loss: 0.008019

run [1900]:
Style Loss : 0.136108 Content Loss: 0.008136

run [1950]:
Style Loss : 0.135047 Content Loss: 0.008221

run [2000]:
Style Loss : 0.134096 Content Loss: 0.008337

run [2050]:
Style Loss : 0.133131 Content Loss: 0.008451

run [2100]:
Style Loss : 0.132212 Content Loss: 0.008555

run [2150]:
Style Loss : 0.131214 Content Loss: 0.008649

run [2200]:
Style Loss : 0.130555 Content Loss: 0.008793

run [2250]:
Style Loss : 0.129593 Content Loss: 0.008914

run [2300]:
Style Loss : 0.128739 Content Loss: 0.009025

run [2350]:
Style Loss : 0.127828 Content Loss: 0.009126

run [2400]:
Style Loss : 0.126894 Content Loss: 0.009256

run [2450]:
Style Loss : 0.126079 Content Loss: 0.009399

run [2500]:
Style Loss : 0.125549 Content Loss: 0.009598

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.303825 Content Loss: 0.001579

run [100]:
Style Loss : 1.388823 Content Loss: 0.001978

run [150]:
Style Loss : 1.019685 Content Loss: 0.002363

run [200]:
Style Loss : 0.833196 Content Loss: 0.002797

run [250]:
Style Loss : 0.719912 Content Loss: 0.003250

run [300]:
Style Loss : 0.653037 Content Loss: 0.003559

run [350]:
Style Loss : 0.605964 Content Loss: 0.003991

run [400]:
Style Loss : 0.571291 Content Loss: 0.004317

run [450]:
Style Loss : 0.543828 Content Loss: 0.004572

run [500]:
Style Loss : 0.520207 Content Loss: 0.004860

run [550]:
Style Loss : 0.499246 Content Loss: 0.005122

run [600]:
Style Loss : 0.480072 Content Loss: 0.005380

run [650]:
Style Loss : 0.461597 Content Loss: 0.005580

run [700]:
Style Loss : 0.445120 Content Loss: 0.005764

run [750]:
Style Loss : 0.432861 Content Loss: 0.005930

run [800]:
Style Loss : 0.422356 Content Loss: 0.006054

run [850]:
Style Loss : 0.412554 Content Loss: 0.006198

run [900]:
Style Loss : 0.403447 Content Loss: 0.006321

run [950]:
Style Loss : 0.395831 Content Loss: 0.006429

run [1000]:
Style Loss : 0.389241 Content Loss: 0.006564

run [1050]:
Style Loss : 0.382635 Content Loss: 0.006653

run [1100]:
Style Loss : 0.377452 Content Loss: 0.006737

run [1150]:
Style Loss : 0.373052 Content Loss: 0.006829

run [1200]:
Style Loss : 0.368949 Content Loss: 0.006897

run [1250]:
Style Loss : 0.365485 Content Loss: 0.006964

run [1300]:
Style Loss : 0.362075 Content Loss: 0.007043

run [1350]:
Style Loss : 0.358967 Content Loss: 0.007111

run [1400]:
Style Loss : 0.356212 Content Loss: 0.007176

run [1450]:
Style Loss : 0.353606 Content Loss: 0.007235

run [1500]:
Style Loss : 0.350607 Content Loss: 0.007285

run [1550]:
Style Loss : 0.348124 Content Loss: 0.007351

run [1600]:
Style Loss : 0.345527 Content Loss: 0.007422

run [1650]:
Style Loss : 0.342863 Content Loss: 0.007475

run [1700]:
Style Loss : 0.340159 Content Loss: 0.007538

run [1750]:
Style Loss : 0.337658 Content Loss: 0.007588

run [1800]:
Style Loss : 0.335579 Content Loss: 0.007634

run [1850]:
Style Loss : 0.333461 Content Loss: 0.007683

run [1900]:
Style Loss : 0.331516 Content Loss: 0.007719

run [1950]:
Style Loss : 0.329927 Content Loss: 0.007765

run [2000]:
Style Loss : 0.328433 Content Loss: 0.007797

run [2050]:
Style Loss : 0.327109 Content Loss: 0.007836

run [2100]:
Style Loss : 0.325825 Content Loss: 0.007866

run [2150]:
Style Loss : 0.324560 Content Loss: 0.007904

run [2200]:
Style Loss : 0.323273 Content Loss: 0.007947

run [2250]:
Style Loss : 0.322024 Content Loss: 0.007992

run [2300]:
Style Loss : 0.320737 Content Loss: 0.008034

run [2350]:
Style Loss : 0.319412 Content Loss: 0.008090

run [2400]:
Style Loss : 0.318007 Content Loss: 0.008126

run [2450]:
Style Loss : 0.316659 Content Loss: 0.008174

run [2500]:
Style Loss : 0.315298 Content Loss: 0.008214

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.862088 Content Loss: 0.002541

run [100]:
Style Loss : 0.477005 Content Loss: 0.003572

run [150]:
Style Loss : 0.351251 Content Loss: 0.004699

run [200]:
Style Loss : 0.289776 Content Loss: 0.005445

run [250]:
Style Loss : 0.249802 Content Loss: 0.006234

run [300]:
Style Loss : 0.213196 Content Loss: 0.006727

run [350]:
Style Loss : 0.192958 Content Loss: 0.007283

run [400]:
Style Loss : 0.180561 Content Loss: 0.007747

run [450]:
Style Loss : 0.172218 Content Loss: 0.008152

run [500]:
Style Loss : 0.164826 Content Loss: 0.008499

run [550]:
Style Loss : 0.158843 Content Loss: 0.008775

run [600]:
Style Loss : 0.153961 Content Loss: 0.009027

run [650]:
Style Loss : 0.149808 Content Loss: 0.009222

run [700]:
Style Loss : 0.146578 Content Loss: 0.009401

run [750]:
Style Loss : 0.143947 Content Loss: 0.009574

run [800]:
Style Loss : 0.141833 Content Loss: 0.009711

run [850]:
Style Loss : 0.139899 Content Loss: 0.009866

run [900]:
Style Loss : 0.138132 Content Loss: 0.009978

run [950]:
Style Loss : 0.136468 Content Loss: 0.010088

run [1000]:
Style Loss : 0.134876 Content Loss: 0.010194

run [1050]:
Style Loss : 0.133510 Content Loss: 0.010270

run [1100]:
Style Loss : 0.132322 Content Loss: 0.010341

run [1150]:
Style Loss : 0.131314 Content Loss: 0.010400

run [1200]:
Style Loss : 0.130364 Content Loss: 0.010462

run [1250]:
Style Loss : 0.129563 Content Loss: 0.010514

run [1300]:
Style Loss : 0.128708 Content Loss: 0.010556

run [1350]:
Style Loss : 0.127919 Content Loss: 0.010602

run [1400]:
Style Loss : 0.127221 Content Loss: 0.010635

run [1450]:
Style Loss : 0.126641 Content Loss: 0.010661

run [1500]:
Style Loss : 0.126053 Content Loss: 0.010682

run [1550]:
Style Loss : 0.125500 Content Loss: 0.010712

run [1600]:
Style Loss : 0.124969 Content Loss: 0.010726

run [1650]:
Style Loss : 0.124328 Content Loss: 0.010759

run [1700]:
Style Loss : 0.123714 Content Loss: 0.010776

run [1750]:
Style Loss : 0.123161 Content Loss: 0.010803

run [1800]:
Style Loss : 0.122648 Content Loss: 0.010816

run [1850]:
Style Loss : 0.122151 Content Loss: 0.010832

run [1900]:
Style Loss : 0.121701 Content Loss: 0.010854

run [1950]:
Style Loss : 0.121191 Content Loss: 0.010879

run [2000]:
Style Loss : 0.120698 Content Loss: 0.010896

run [2050]:
Style Loss : 0.120098 Content Loss: 0.010925

run [2100]:
Style Loss : 0.119561 Content Loss: 0.010949

run [2150]:
Style Loss : 0.119042 Content Loss: 0.010971

run [2200]:
Style Loss : 0.118595 Content Loss: 0.010995

run [2250]:
Style Loss : 0.118098 Content Loss: 0.011006

run [2300]:
Style Loss : 0.117658 Content Loss: 0.011030

run [2350]:
Style Loss : 0.117297 Content Loss: 0.011056

run [2400]:
Style Loss : 0.116847 Content Loss: 0.011071

run [2450]:
Style Loss : 0.116474 Content Loss: 0.011092

run [2500]:
Style Loss : 0.116072 Content Loss: 0.011111

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.776752 Content Loss: 0.002323

run [100]:
Style Loss : 0.420899 Content Loss: 0.004411

run [150]:
Style Loss : 0.303893 Content Loss: 0.007588

run [200]:
Style Loss : 0.251832 Content Loss: 0.010089

run [250]:
Style Loss : 0.219900 Content Loss: 0.011418

run [300]:
Style Loss : 0.200144 Content Loss: 0.012244

run [350]:
Style Loss : 0.185646 Content Loss: 0.012929

run [400]:
Style Loss : 0.175659 Content Loss: 0.013497

run [450]:
Style Loss : 0.168114 Content Loss: 0.014019

run [500]:
Style Loss : 0.161952 Content Loss: 0.014414

run [550]:
Style Loss : 0.156485 Content Loss: 0.014818

run [600]:
Style Loss : 0.151244 Content Loss: 0.015223

run [650]:
Style Loss : 0.146942 Content Loss: 0.015578

run [700]:
Style Loss : 0.143327 Content Loss: 0.015846

run [750]:
Style Loss : 0.140370 Content Loss: 0.016132

run [800]:
Style Loss : 0.137585 Content Loss: 0.016352

run [850]:
Style Loss : 0.135137 Content Loss: 0.016533

run [900]:
Style Loss : 0.133008 Content Loss: 0.016707

run [950]:
Style Loss : 0.131214 Content Loss: 0.016832

run [1000]:
Style Loss : 0.129632 Content Loss: 0.016946

run [1050]:
Style Loss : 0.128267 Content Loss: 0.017057

run [1100]:
Style Loss : 0.127072 Content Loss: 0.017164

run [1150]:
Style Loss : 0.126052 Content Loss: 0.017266

run [1200]:
Style Loss : 0.124817 Content Loss: 0.017366

run [1250]:
Style Loss : 0.123775 Content Loss: 0.017452

run [1300]:
Style Loss : 0.122959 Content Loss: 0.017548

run [1350]:
Style Loss : 0.122256 Content Loss: 0.017619

run [1400]:
Style Loss : 0.121653 Content Loss: 0.017680

run [1450]:
Style Loss : 0.121114 Content Loss: 0.017745

run [1500]:
Style Loss : 0.120620 Content Loss: 0.017803

run [1550]:
Style Loss : 0.120167 Content Loss: 0.017847

run [1600]:
Style Loss : 0.119734 Content Loss: 0.017897

run [1650]:
Style Loss : 0.119332 Content Loss: 0.017947

run [1700]:
Style Loss : 0.118953 Content Loss: 0.017993

run [1750]:
Style Loss : 0.118612 Content Loss: 0.018025

run [1800]:
Style Loss : 0.118275 Content Loss: 0.018064

run [1850]:
Style Loss : 0.117952 Content Loss: 0.018095

run [1900]:
Style Loss : 0.117660 Content Loss: 0.018129

run [1950]:
Style Loss : 0.117394 Content Loss: 0.018157

run [2000]:
Style Loss : 0.117146 Content Loss: 0.018182

run [2050]:
Style Loss : 0.116869 Content Loss: 0.018212

run [2100]:
Style Loss : 0.116621 Content Loss: 0.018238

run [2150]:
Style Loss : 0.116397 Content Loss: 0.018265

run [2200]:
Style Loss : 0.116184 Content Loss: 0.018284

run [2250]:
Style Loss : 0.115986 Content Loss: 0.018302

run [2300]:
Style Loss : 0.115818 Content Loss: 0.018321

run [2350]:
Style Loss : 0.115655 Content Loss: 0.018338

run [2400]:
Style Loss : 0.115495 Content Loss: 0.018353

run [2450]:
Style Loss : 0.115341 Content Loss: 0.018368

run [2500]:
Style Loss : 0.115212 Content Loss: 0.018375

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.755803 Content Loss: 0.014154

run [100]:
Style Loss : 1.018221 Content Loss: 0.016437

run [150]:
Style Loss : 0.785132 Content Loss: 0.018100

run [200]:
Style Loss : 0.678703 Content Loss: 0.019183

run [250]:
Style Loss : 0.615251 Content Loss: 0.020127

run [300]:
Style Loss : 0.570839 Content Loss: 0.020777

run [350]:
Style Loss : 0.541019 Content Loss: 0.021364

run [400]:
Style Loss : 0.519610 Content Loss: 0.021800

run [450]:
Style Loss : 0.500783 Content Loss: 0.022203

run [500]:
Style Loss : 0.484136 Content Loss: 0.022629

run [550]:
Style Loss : 0.468460 Content Loss: 0.022914

run [600]:
Style Loss : 0.453622 Content Loss: 0.023218

run [650]:
Style Loss : 0.440317 Content Loss: 0.023411

run [700]:
Style Loss : 0.429757 Content Loss: 0.023595

run [750]:
Style Loss : 0.420828 Content Loss: 0.023762

run [800]:
Style Loss : 0.412835 Content Loss: 0.023898

run [850]:
Style Loss : 0.406233 Content Loss: 0.024046

run [900]:
Style Loss : 0.400673 Content Loss: 0.024166

run [950]:
Style Loss : 0.395400 Content Loss: 0.024306

run [1000]:
Style Loss : 0.390459 Content Loss: 0.024414

run [1050]:
Style Loss : 0.386077 Content Loss: 0.024535

run [1100]:
Style Loss : 0.382166 Content Loss: 0.024609

run [1150]:
Style Loss : 0.378694 Content Loss: 0.024657

run [1200]:
Style Loss : 0.375487 Content Loss: 0.024710

run [1250]:
Style Loss : 0.372474 Content Loss: 0.024777

run [1300]:
Style Loss : 0.369572 Content Loss: 0.024827

run [1350]:
Style Loss : 0.366814 Content Loss: 0.024902

run [1400]:
Style Loss : 0.363830 Content Loss: 0.024971

run [1450]:
Style Loss : 0.360739 Content Loss: 0.025014

run [1500]:
Style Loss : 0.357438 Content Loss: 0.025083

run [1550]:
Style Loss : 0.354530 Content Loss: 0.025130

run [1600]:
Style Loss : 0.352059 Content Loss: 0.025166

run [1650]:
Style Loss : 0.349452 Content Loss: 0.025226

run [1700]:
Style Loss : 0.347023 Content Loss: 0.025272

run [1750]:
Style Loss : 0.344435 Content Loss: 0.025308

run [1800]:
Style Loss : 0.342336 Content Loss: 0.025313

run [1850]:
Style Loss : 0.340179 Content Loss: 0.025358

run [1900]:
Style Loss : 0.338116 Content Loss: 0.025384

run [1950]:
Style Loss : 0.336387 Content Loss: 0.025407

run [2000]:
Style Loss : 0.334595 Content Loss: 0.025451

run [2050]:
Style Loss : 0.332671 Content Loss: 0.025491

run [2100]:
Style Loss : 0.330968 Content Loss: 0.025510

run [2150]:
Style Loss : 0.329256 Content Loss: 0.025545

run [2200]:
Style Loss : 0.327383 Content Loss: 0.025572

run [2250]:
Style Loss : 0.325655 Content Loss: 0.025587

run [2300]:
Style Loss : 0.324185 Content Loss: 0.025616

run [2350]:
Style Loss : 0.322601 Content Loss: 0.025631

run [2400]:
Style Loss : 0.321154 Content Loss: 0.025647

run [2450]:
Style Loss : 0.319774 Content Loss: 0.025666

run [2500]:
Style Loss : 0.318546 Content Loss: 0.025687

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.225319 Content Loss: 0.001355

run [100]:
Style Loss : 0.670454 Content Loss: 0.001889

run [150]:
Style Loss : 0.492375 Content Loss: 0.002445

run [200]:
Style Loss : 0.409617 Content Loss: 0.002933

run [250]:
Style Loss : 0.362615 Content Loss: 0.003396

run [300]:
Style Loss : 0.327530 Content Loss: 0.003913

run [350]:
Style Loss : 0.303279 Content Loss: 0.004330

run [400]:
Style Loss : 0.285335 Content Loss: 0.004734

run [450]:
Style Loss : 0.270440 Content Loss: 0.005109

run [500]:
Style Loss : 0.257380 Content Loss: 0.005464

run [550]:
Style Loss : 0.247120 Content Loss: 0.005774

run [600]:
Style Loss : 0.238929 Content Loss: 0.005996

run [650]:
Style Loss : 0.232564 Content Loss: 0.006203

run [700]:
Style Loss : 0.226981 Content Loss: 0.006402

run [750]:
Style Loss : 0.221982 Content Loss: 0.006564

run [800]:
Style Loss : 0.217503 Content Loss: 0.006714

run [850]:
Style Loss : 0.213552 Content Loss: 0.006862

run [900]:
Style Loss : 0.210002 Content Loss: 0.007002

run [950]:
Style Loss : 0.206708 Content Loss: 0.007143

run [1000]:
Style Loss : 0.203728 Content Loss: 0.007260

run [1050]:
Style Loss : 0.201247 Content Loss: 0.007357

run [1100]:
Style Loss : 0.199100 Content Loss: 0.007471

run [1150]:
Style Loss : 0.197116 Content Loss: 0.007567

run [1200]:
Style Loss : 0.195403 Content Loss: 0.007664

run [1250]:
Style Loss : 0.193762 Content Loss: 0.007763

run [1300]:
Style Loss : 0.192226 Content Loss: 0.007848

run [1350]:
Style Loss : 0.190886 Content Loss: 0.007914

run [1400]:
Style Loss : 0.189666 Content Loss: 0.007996

run [1450]:
Style Loss : 0.188590 Content Loss: 0.008060

run [1500]:
Style Loss : 0.187516 Content Loss: 0.008129

run [1550]:
Style Loss : 0.186493 Content Loss: 0.008205

run [1600]:
Style Loss : 0.185431 Content Loss: 0.008281

run [1650]:
Style Loss : 0.184354 Content Loss: 0.008351

run [1700]:
Style Loss : 0.183207 Content Loss: 0.008434

run [1750]:
Style Loss : 0.181919 Content Loss: 0.008500

run [1800]:
Style Loss : 0.180746 Content Loss: 0.008561

run [1850]:
Style Loss : 0.179742 Content Loss: 0.008649

run [1900]:
Style Loss : 0.178505 Content Loss: 0.008695

run [1950]:
Style Loss : 0.177416 Content Loss: 0.008765

run [2000]:
Style Loss : 0.176398 Content Loss: 0.008814

run [2050]:
Style Loss : 0.175542 Content Loss: 0.008859

run [2100]:
Style Loss : 0.174764 Content Loss: 0.008916

run [2150]:
Style Loss : 0.173900 Content Loss: 0.008955

run [2200]:
Style Loss : 0.173207 Content Loss: 0.008994

run [2250]:
Style Loss : 0.172702 Content Loss: 0.009063

run [2300]:
Style Loss : 0.171879 Content Loss: 0.009102

run [2350]:
Style Loss : 0.171637 Content Loss: 0.009179

run [2400]:
Style Loss : 0.170541 Content Loss: 0.009209

run [2450]:
Style Loss : 0.171406 Content Loss: 0.009315

run [2500]:
Style Loss : 0.169209 Content Loss: 0.009325

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.124279 Content Loss: 0.001873

run [100]:
Style Loss : 0.614773 Content Loss: 0.002605

run [150]:
Style Loss : 0.465693 Content Loss: 0.003771

run [200]:
Style Loss : 0.380984 Content Loss: 0.004921

run [250]:
Style Loss : 0.325847 Content Loss: 0.005746

run [300]:
Style Loss : 0.291997 Content Loss: 0.006456

run [350]:
Style Loss : 0.266456 Content Loss: 0.006949

run [400]:
Style Loss : 0.247351 Content Loss: 0.007269

run [450]:
Style Loss : 0.234018 Content Loss: 0.007519

run [500]:
Style Loss : 0.222974 Content Loss: 0.007712

run [550]:
Style Loss : 0.213147 Content Loss: 0.007894

run [600]:
Style Loss : 0.205788 Content Loss: 0.008065

run [650]:
Style Loss : 0.200258 Content Loss: 0.008187

run [700]:
Style Loss : 0.195734 Content Loss: 0.008321

run [750]:
Style Loss : 0.192081 Content Loss: 0.008450

run [800]:
Style Loss : 0.188794 Content Loss: 0.008561

run [850]:
Style Loss : 0.185262 Content Loss: 0.008666

run [900]:
Style Loss : 0.182559 Content Loss: 0.008766

run [950]:
Style Loss : 0.179949 Content Loss: 0.008857

run [1000]:
Style Loss : 0.177572 Content Loss: 0.008933

run [1050]:
Style Loss : 0.175359 Content Loss: 0.009005

run [1100]:
Style Loss : 0.173295 Content Loss: 0.009079

run [1150]:
Style Loss : 0.171347 Content Loss: 0.009145

run [1200]:
Style Loss : 0.169580 Content Loss: 0.009201

run [1250]:
Style Loss : 0.167946 Content Loss: 0.009261

run [1300]:
Style Loss : 0.165920 Content Loss: 0.009329

run [1350]:
Style Loss : 0.164262 Content Loss: 0.009406

run [1400]:
Style Loss : 0.162704 Content Loss: 0.009478

run [1450]:
Style Loss : 0.161252 Content Loss: 0.009544

run [1500]:
Style Loss : 0.159936 Content Loss: 0.009608

run [1550]:
Style Loss : 0.158798 Content Loss: 0.009668

run [1600]:
Style Loss : 0.157689 Content Loss: 0.009722

run [1650]:
Style Loss : 0.156560 Content Loss: 0.009780

run [1700]:
Style Loss : 0.155470 Content Loss: 0.009837

run [1750]:
Style Loss : 0.154432 Content Loss: 0.009887

run [1800]:
Style Loss : 0.153450 Content Loss: 0.009946

run [1850]:
Style Loss : 0.152538 Content Loss: 0.009996

run [1900]:
Style Loss : 0.151689 Content Loss: 0.010059

run [1950]:
Style Loss : 0.150864 Content Loss: 0.010124

run [2000]:
Style Loss : 0.150140 Content Loss: 0.010194

run [2050]:
Style Loss : 0.149309 Content Loss: 0.010255

run [2100]:
Style Loss : 0.148545 Content Loss: 0.010326

run [2150]:
Style Loss : 0.147937 Content Loss: 0.010403

run [2200]:
Style Loss : 0.147145 Content Loss: 0.010463

run [2250]:
Style Loss : 0.146476 Content Loss: 0.010531

run [2300]:
Style Loss : 0.145774 Content Loss: 0.010605

run [2350]:
Style Loss : 0.145146 Content Loss: 0.010684

run [2400]:
Style Loss : 0.144502 Content Loss: 0.010771

run [2450]:
Style Loss : 0.144126 Content Loss: 0.010873

run [2500]:
Style Loss : 0.143423 Content Loss: 0.010955

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.732134 Content Loss: 0.001044

run [100]:
Style Loss : 0.377438 Content Loss: 0.001441

run [150]:
Style Loss : 0.271044 Content Loss: 0.002008

run [200]:
Style Loss : 0.211803 Content Loss: 0.002539

run [250]:
Style Loss : 0.180283 Content Loss: 0.003005

run [300]:
Style Loss : 0.160817 Content Loss: 0.003368

run [350]:
Style Loss : 0.147664 Content Loss: 0.003703

run [400]:
Style Loss : 0.137084 Content Loss: 0.004077

run [450]:
Style Loss : 0.123701 Content Loss: 0.004383

run [500]:
Style Loss : 0.113998 Content Loss: 0.004581

run [550]:
Style Loss : 0.106884 Content Loss: 0.004767

run [600]:
Style Loss : 0.101947 Content Loss: 0.004971

run [650]:
Style Loss : 0.098087 Content Loss: 0.005144

run [700]:
Style Loss : 0.095192 Content Loss: 0.005303

run [750]:
Style Loss : 0.092716 Content Loss: 0.005431

run [800]:
Style Loss : 0.090662 Content Loss: 0.005543

run [850]:
Style Loss : 0.089033 Content Loss: 0.005624

run [900]:
Style Loss : 0.087623 Content Loss: 0.005705

run [950]:
Style Loss : 0.086444 Content Loss: 0.005777

run [1000]:
Style Loss : 0.085374 Content Loss: 0.005856

run [1050]:
Style Loss : 0.084405 Content Loss: 0.005917

run [1100]:
Style Loss : 0.083481 Content Loss: 0.005977

run [1150]:
Style Loss : 0.082686 Content Loss: 0.006035

run [1200]:
Style Loss : 0.081981 Content Loss: 0.006079

run [1250]:
Style Loss : 0.081261 Content Loss: 0.006120

run [1300]:
Style Loss : 0.080623 Content Loss: 0.006162

run [1350]:
Style Loss : 0.080031 Content Loss: 0.006207

run [1400]:
Style Loss : 0.079485 Content Loss: 0.006249

run [1450]:
Style Loss : 0.078961 Content Loss: 0.006295

run [1500]:
Style Loss : 0.078440 Content Loss: 0.006342

run [1550]:
Style Loss : 0.077951 Content Loss: 0.006384

run [1600]:
Style Loss : 0.077473 Content Loss: 0.006421

run [1650]:
Style Loss : 0.077081 Content Loss: 0.006455

run [1700]:
Style Loss : 0.076701 Content Loss: 0.006485

run [1750]:
Style Loss : 0.076353 Content Loss: 0.006518

run [1800]:
Style Loss : 0.076051 Content Loss: 0.006546

run [1850]:
Style Loss : 0.075767 Content Loss: 0.006568

run [1900]:
Style Loss : 0.075507 Content Loss: 0.006598

run [1950]:
Style Loss : 0.075241 Content Loss: 0.006620

run [2000]:
Style Loss : 0.075007 Content Loss: 0.006641

run [2050]:
Style Loss : 0.074804 Content Loss: 0.006673

run [2100]:
Style Loss : 0.074656 Content Loss: 0.006695

run [2150]:
Style Loss : 0.074356 Content Loss: 0.006702

run [2200]:
Style Loss : 0.074143 Content Loss: 0.006725

run [2250]:
Style Loss : 0.073945 Content Loss: 0.006742

run [2300]:
Style Loss : 0.073749 Content Loss: 0.006755

run [2350]:
Style Loss : 0.073563 Content Loss: 0.006770

run [2400]:
Style Loss : 0.073357 Content Loss: 0.006787

run [2450]:
Style Loss : 0.073168 Content Loss: 0.006804

run [2500]:
Style Loss : 0.072982 Content Loss: 0.006814

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.332440 Content Loss: 0.003914

run [100]:
Style Loss : 0.817421 Content Loss: 0.005735

run [150]:
Style Loss : 0.616715 Content Loss: 0.008227

run [200]:
Style Loss : 0.500463 Content Loss: 0.010892

run [250]:
Style Loss : 0.436541 Content Loss: 0.013021

run [300]:
Style Loss : 0.399129 Content Loss: 0.014476

run [350]:
Style Loss : 0.374862 Content Loss: 0.015295

run [400]:
Style Loss : 0.356764 Content Loss: 0.015781

run [450]:
Style Loss : 0.342496 Content Loss: 0.016096

run [500]:
Style Loss : 0.330850 Content Loss: 0.016524

run [550]:
Style Loss : 0.321945 Content Loss: 0.016949

run [600]:
Style Loss : 0.315127 Content Loss: 0.017367

run [650]:
Style Loss : 0.309264 Content Loss: 0.017742

run [700]:
Style Loss : 0.303622 Content Loss: 0.018219

run [750]:
Style Loss : 0.298753 Content Loss: 0.018688

run [800]:
Style Loss : 0.293169 Content Loss: 0.019137

run [850]:
Style Loss : 0.287480 Content Loss: 0.019562

run [900]:
Style Loss : 0.282356 Content Loss: 0.020042

run [950]:
Style Loss : 0.278101 Content Loss: 0.020361

run [1000]:
Style Loss : 0.274240 Content Loss: 0.020709

run [1050]:
Style Loss : 0.270819 Content Loss: 0.021057

run [1100]:
Style Loss : 0.268420 Content Loss: 0.021420

run [1150]:
Style Loss : 0.265015 Content Loss: 0.021698

run [1200]:
Style Loss : 0.262227 Content Loss: 0.021868

run [1250]:
Style Loss : 0.260086 Content Loss: 0.022089

run [1300]:
Style Loss : 0.258131 Content Loss: 0.022353

run [1350]:
Style Loss : 0.256212 Content Loss: 0.022584

run [1400]:
Style Loss : 0.254695 Content Loss: 0.022816

run [1450]:
Style Loss : 0.252785 Content Loss: 0.022988

run [1500]:
Style Loss : 0.251397 Content Loss: 0.023183

run [1550]:
Style Loss : 0.250673 Content Loss: 0.023422

run [1600]:
Style Loss : 0.248906 Content Loss: 0.023581

run [1650]:
Style Loss : 0.246933 Content Loss: 0.023654

run [1700]:
Style Loss : 0.245797 Content Loss: 0.023827

run [1750]:
Style Loss : 0.244595 Content Loss: 0.023976

run [1800]:
Style Loss : 0.245574 Content Loss: 0.024273

run [1850]:
Style Loss : 0.246064 Content Loss: 0.024586

run [1900]:
Style Loss : 0.243730 Content Loss: 0.024598

run [1950]:
Style Loss : 0.244012 Content Loss: 0.024936

run [2000]:
Style Loss : 0.239935 Content Loss: 0.024899

run [2050]:
Style Loss : 0.239139 Content Loss: 0.025075

run [2100]:
Style Loss : 0.240365 Content Loss: 0.025296

run [2150]:
Style Loss : 0.240202 Content Loss: 0.025431

run [2200]:
Style Loss : 0.236538 Content Loss: 0.025450

run [2250]:
Style Loss : 0.240495 Content Loss: 0.025652

run [2300]:
Style Loss : 0.235153 Content Loss: 0.025568

run [2350]:
Style Loss : 0.234215 Content Loss: 0.025688

run [2400]:
Style Loss : 0.234275 Content Loss: 0.025827

run [2450]:
Style Loss : 0.234133 Content Loss: 0.025848

run [2500]:
Style Loss : 0.231894 Content Loss: 0.025890

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.035606 Content Loss: 0.005957

run [100]:
Style Loss : 0.501335 Content Loss: 0.009127

run [150]:
Style Loss : 0.330064 Content Loss: 0.012188

run [200]:
Style Loss : 0.253362 Content Loss: 0.014207

run [250]:
Style Loss : 0.213605 Content Loss: 0.014868

run [300]:
Style Loss : 0.191172 Content Loss: 0.015213

run [350]:
Style Loss : 0.175922 Content Loss: 0.015490

run [400]:
Style Loss : 0.164550 Content Loss: 0.015791

run [450]:
Style Loss : 0.155707 Content Loss: 0.015918

run [500]:
Style Loss : 0.147696 Content Loss: 0.016055

run [550]:
Style Loss : 0.142038 Content Loss: 0.016250

run [600]:
Style Loss : 0.136474 Content Loss: 0.016364

run [650]:
Style Loss : 0.122918 Content Loss: 0.016393

run [700]:
Style Loss : 0.117863 Content Loss: 0.016488

run [750]:
Style Loss : 0.114034 Content Loss: 0.016598

run [800]:
Style Loss : 0.111097 Content Loss: 0.016648

run [850]:
Style Loss : 0.108589 Content Loss: 0.016725

run [900]:
Style Loss : 0.106515 Content Loss: 0.016761

run [950]:
Style Loss : 0.104500 Content Loss: 0.016806

run [1000]:
Style Loss : 0.102621 Content Loss: 0.016842

run [1050]:
Style Loss : 0.100841 Content Loss: 0.016879

run [1100]:
Style Loss : 0.099231 Content Loss: 0.016908

run [1150]:
Style Loss : 0.097752 Content Loss: 0.016927

run [1200]:
Style Loss : 0.096363 Content Loss: 0.016945

run [1250]:
Style Loss : 0.095231 Content Loss: 0.016958

run [1300]:
Style Loss : 0.094240 Content Loss: 0.016974

run [1350]:
Style Loss : 0.093276 Content Loss: 0.016988

run [1400]:
Style Loss : 0.092336 Content Loss: 0.017007

run [1450]:
Style Loss : 0.091403 Content Loss: 0.017015

run [1500]:
Style Loss : 0.090523 Content Loss: 0.017020

run [1550]:
Style Loss : 0.089754 Content Loss: 0.017022

run [1600]:
Style Loss : 0.089141 Content Loss: 0.017020

run [1650]:
Style Loss : 0.088572 Content Loss: 0.017026

run [1700]:
Style Loss : 0.088044 Content Loss: 0.017032

run [1750]:
Style Loss : 0.087532 Content Loss: 0.017034

run [1800]:
Style Loss : 0.087090 Content Loss: 0.017033

run [1850]:
Style Loss : 0.086662 Content Loss: 0.017037

run [1900]:
Style Loss : 0.086272 Content Loss: 0.017048

run [1950]:
Style Loss : 0.085916 Content Loss: 0.017056

run [2000]:
Style Loss : 0.085562 Content Loss: 0.017059

run [2050]:
Style Loss : 0.085249 Content Loss: 0.017063

run [2100]:
Style Loss : 0.084980 Content Loss: 0.017061

run [2150]:
Style Loss : 0.084712 Content Loss: 0.017057

run [2200]:
Style Loss : 0.084463 Content Loss: 0.017050

run [2250]:
Style Loss : 0.084228 Content Loss: 0.017048

run [2300]:
Style Loss : 0.083987 Content Loss: 0.017040

run [2350]:
Style Loss : 0.083700 Content Loss: 0.017041

run [2400]:
Style Loss : 0.083442 Content Loss: 0.017041

run [2450]:
Style Loss : 0.083204 Content Loss: 0.017037

run [2500]:
Style Loss : 0.082964 Content Loss: 0.017036

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.032622 Content Loss: 0.002426

run [100]:
Style Loss : 1.260410 Content Loss: 0.002998

run [150]:
Style Loss : 0.933968 Content Loss: 0.003498

run [200]:
Style Loss : 0.741610 Content Loss: 0.004037

run [250]:
Style Loss : 0.637070 Content Loss: 0.004387

run [300]:
Style Loss : 0.567791 Content Loss: 0.004810

run [350]:
Style Loss : 0.520930 Content Loss: 0.005334

run [400]:
Style Loss : 0.484048 Content Loss: 0.005895

run [450]:
Style Loss : 0.452568 Content Loss: 0.006415

run [500]:
Style Loss : 0.426964 Content Loss: 0.006930

run [550]:
Style Loss : 0.405579 Content Loss: 0.007406

run [600]:
Style Loss : 0.387842 Content Loss: 0.007868

run [650]:
Style Loss : 0.372737 Content Loss: 0.008333

run [700]:
Style Loss : 0.359589 Content Loss: 0.008745

run [750]:
Style Loss : 0.349200 Content Loss: 0.009114

run [800]:
Style Loss : 0.339463 Content Loss: 0.009422

run [850]:
Style Loss : 0.331035 Content Loss: 0.009679

run [900]:
Style Loss : 0.323603 Content Loss: 0.009943

run [950]:
Style Loss : 0.316517 Content Loss: 0.010195

run [1000]:
Style Loss : 0.310236 Content Loss: 0.010409

run [1050]:
Style Loss : 0.304364 Content Loss: 0.010592

run [1100]:
Style Loss : 0.299318 Content Loss: 0.010802

run [1150]:
Style Loss : 0.294802 Content Loss: 0.010950

run [1200]:
Style Loss : 0.290594 Content Loss: 0.011102

run [1250]:
Style Loss : 0.286938 Content Loss: 0.011233

run [1300]:
Style Loss : 0.283870 Content Loss: 0.011360

run [1350]:
Style Loss : 0.280954 Content Loss: 0.011477

run [1400]:
Style Loss : 0.278551 Content Loss: 0.011578

run [1450]:
Style Loss : 0.276283 Content Loss: 0.011679

run [1500]:
Style Loss : 0.274122 Content Loss: 0.011786

run [1550]:
Style Loss : 0.272299 Content Loss: 0.011874

run [1600]:
Style Loss : 0.270604 Content Loss: 0.011963

run [1650]:
Style Loss : 0.269097 Content Loss: 0.012039

run [1700]:
Style Loss : 0.267680 Content Loss: 0.012114

run [1750]:
Style Loss : 0.266352 Content Loss: 0.012190

run [1800]:
Style Loss : 0.265087 Content Loss: 0.012258

run [1850]:
Style Loss : 0.263600 Content Loss: 0.012327

run [1900]:
Style Loss : 0.262249 Content Loss: 0.012383

run [1950]:
Style Loss : 0.260947 Content Loss: 0.012440

run [2000]:
Style Loss : 0.259731 Content Loss: 0.012495

run [2050]:
Style Loss : 0.258604 Content Loss: 0.012547

run [2100]:
Style Loss : 0.257596 Content Loss: 0.012604

run [2150]:
Style Loss : 0.256717 Content Loss: 0.012648

run [2200]:
Style Loss : 0.255912 Content Loss: 0.012695

run [2250]:
Style Loss : 0.255075 Content Loss: 0.012742

run [2300]:
Style Loss : 0.254300 Content Loss: 0.012783

run [2350]:
Style Loss : 0.253587 Content Loss: 0.012822

run [2400]:
Style Loss : 0.252943 Content Loss: 0.012855

run [2450]:
Style Loss : 0.252302 Content Loss: 0.012892

run [2500]:
Style Loss : 0.251729 Content Loss: 0.012927

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.605782 Content Loss: 0.001985

run [100]:
Style Loss : 0.850032 Content Loss: 0.002030

run [150]:
Style Loss : 0.636627 Content Loss: 0.002223

run [200]:
Style Loss : 0.533019 Content Loss: 0.002607

run [250]:
Style Loss : 0.468085 Content Loss: 0.002962

run [300]:
Style Loss : 0.418442 Content Loss: 0.003322

run [350]:
Style Loss : 0.379243 Content Loss: 0.003702

run [400]:
Style Loss : 0.350437 Content Loss: 0.004027

run [450]:
Style Loss : 0.326657 Content Loss: 0.004310

run [500]:
Style Loss : 0.310875 Content Loss: 0.004655

run [550]:
Style Loss : 0.296015 Content Loss: 0.004889

run [600]:
Style Loss : 0.283773 Content Loss: 0.005169

run [650]:
Style Loss : 0.273207 Content Loss: 0.005419

run [700]:
Style Loss : 0.264226 Content Loss: 0.005702

run [750]:
Style Loss : 0.256355 Content Loss: 0.005974

run [800]:
Style Loss : 0.249879 Content Loss: 0.006175

run [850]:
Style Loss : 0.243687 Content Loss: 0.006398

run [900]:
Style Loss : 0.238219 Content Loss: 0.006619

run [950]:
Style Loss : 0.233736 Content Loss: 0.006778

run [1000]:
Style Loss : 0.229336 Content Loss: 0.006946

run [1050]:
Style Loss : 0.225274 Content Loss: 0.007092

run [1100]:
Style Loss : 0.221642 Content Loss: 0.007245

run [1150]:
Style Loss : 0.218169 Content Loss: 0.007370

run [1200]:
Style Loss : 0.215117 Content Loss: 0.007504

run [1250]:
Style Loss : 0.212417 Content Loss: 0.007629

run [1300]:
Style Loss : 0.209777 Content Loss: 0.007740

run [1350]:
Style Loss : 0.207317 Content Loss: 0.007879

run [1400]:
Style Loss : 0.204799 Content Loss: 0.007976

run [1450]:
Style Loss : 0.202657 Content Loss: 0.008064

run [1500]:
Style Loss : 0.200397 Content Loss: 0.008166

run [1550]:
Style Loss : 0.198231 Content Loss: 0.008258

run [1600]:
Style Loss : 0.196154 Content Loss: 0.008332

run [1650]:
Style Loss : 0.194139 Content Loss: 0.008398

run [1700]:
Style Loss : 0.192430 Content Loss: 0.008477

run [1750]:
Style Loss : 0.190749 Content Loss: 0.008536

run [1800]:
Style Loss : 0.188992 Content Loss: 0.008596

run [1850]:
Style Loss : 0.187364 Content Loss: 0.008663

run [1900]:
Style Loss : 0.185551 Content Loss: 0.008735

run [1950]:
Style Loss : 0.183868 Content Loss: 0.008792

run [2000]:
Style Loss : 0.182243 Content Loss: 0.008865

run [2050]:
Style Loss : 0.180612 Content Loss: 0.008922

run [2100]:
Style Loss : 0.179273 Content Loss: 0.009012

run [2150]:
Style Loss : 0.177525 Content Loss: 0.009070

run [2200]:
Style Loss : 0.175841 Content Loss: 0.009125

run [2250]:
Style Loss : 0.173995 Content Loss: 0.009200

run [2300]:
Style Loss : 0.172220 Content Loss: 0.009256

run [2350]:
Style Loss : 0.170700 Content Loss: 0.009338

run [2400]:
Style Loss : 0.169136 Content Loss: 0.009405

run [2450]:
Style Loss : 0.167634 Content Loss: 0.009484

run [2500]:
Style Loss : 0.166033 Content Loss: 0.009559

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.167670 Content Loss: 0.003809

run [100]:
Style Loss : 1.113869 Content Loss: 0.004164

run [150]:
Style Loss : 0.774004 Content Loss: 0.004526

run [200]:
Style Loss : 0.634746 Content Loss: 0.005025

run [250]:
Style Loss : 0.544851 Content Loss: 0.005582

run [300]:
Style Loss : 0.490648 Content Loss: 0.006132

run [350]:
Style Loss : 0.455002 Content Loss: 0.006636

run [400]:
Style Loss : 0.429380 Content Loss: 0.006963

run [450]:
Style Loss : 0.410377 Content Loss: 0.007333

run [500]:
Style Loss : 0.394817 Content Loss: 0.007634

run [550]:
Style Loss : 0.379678 Content Loss: 0.007929

run [600]:
Style Loss : 0.365817 Content Loss: 0.008150

run [650]:
Style Loss : 0.354042 Content Loss: 0.008426

run [700]:
Style Loss : 0.343094 Content Loss: 0.008628

run [750]:
Style Loss : 0.334303 Content Loss: 0.008831

run [800]:
Style Loss : 0.326902 Content Loss: 0.009074

run [850]:
Style Loss : 0.317810 Content Loss: 0.009255

run [900]:
Style Loss : 0.311111 Content Loss: 0.009440

run [950]:
Style Loss : 0.305981 Content Loss: 0.009609

run [1000]:
Style Loss : 0.301171 Content Loss: 0.009782

run [1050]:
Style Loss : 0.296435 Content Loss: 0.009980

run [1100]:
Style Loss : 0.292035 Content Loss: 0.010165

run [1150]:
Style Loss : 0.288069 Content Loss: 0.010334

run [1200]:
Style Loss : 0.284668 Content Loss: 0.010504

run [1250]:
Style Loss : 0.281449 Content Loss: 0.010636

run [1300]:
Style Loss : 0.278366 Content Loss: 0.010776

run [1350]:
Style Loss : 0.275448 Content Loss: 0.010888

run [1400]:
Style Loss : 0.272970 Content Loss: 0.011016

run [1450]:
Style Loss : 0.270772 Content Loss: 0.011136

run [1500]:
Style Loss : 0.268701 Content Loss: 0.011252

run [1550]:
Style Loss : 0.266799 Content Loss: 0.011349

run [1600]:
Style Loss : 0.264710 Content Loss: 0.011464

run [1650]:
Style Loss : 0.262777 Content Loss: 0.011576

run [1700]:
Style Loss : 0.260927 Content Loss: 0.011690

run [1750]:
Style Loss : 0.259080 Content Loss: 0.011792

run [1800]:
Style Loss : 0.257360 Content Loss: 0.011891

run [1850]:
Style Loss : 0.255878 Content Loss: 0.011982

run [1900]:
Style Loss : 0.254537 Content Loss: 0.012066

run [1950]:
Style Loss : 0.253281 Content Loss: 0.012161

run [2000]:
Style Loss : 0.252110 Content Loss: 0.012253

run [2050]:
Style Loss : 0.251045 Content Loss: 0.012359

run [2100]:
Style Loss : 0.249889 Content Loss: 0.012448

run [2150]:
Style Loss : 0.248778 Content Loss: 0.012549

run [2200]:
Style Loss : 0.247653 Content Loss: 0.012624

run [2250]:
Style Loss : 0.246581 Content Loss: 0.012723

run [2300]:
Style Loss : 0.245571 Content Loss: 0.012830

run [2350]:
Style Loss : 0.244595 Content Loss: 0.012914

run [2400]:
Style Loss : 0.243710 Content Loss: 0.013005

run [2450]:
Style Loss : 0.242887 Content Loss: 0.013104

run [2500]:
Style Loss : 0.242135 Content Loss: 0.013207

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.734616 Content Loss: 0.001584

run [100]:
Style Loss : 1.708294 Content Loss: 0.001840

run [150]:
Style Loss : 1.328654 Content Loss: 0.002008

run [200]:
Style Loss : 1.144803 Content Loss: 0.002365

run [250]:
Style Loss : 1.018364 Content Loss: 0.002757

run [300]:
Style Loss : 0.923285 Content Loss: 0.003121

run [350]:
Style Loss : 0.827155 Content Loss: 0.003430

run [400]:
Style Loss : 0.767434 Content Loss: 0.003756

run [450]:
Style Loss : 0.720133 Content Loss: 0.004070

run [500]:
Style Loss : 0.671701 Content Loss: 0.004364

run [550]:
Style Loss : 0.629283 Content Loss: 0.004619

run [600]:
Style Loss : 0.598509 Content Loss: 0.004858

run [650]:
Style Loss : 0.572576 Content Loss: 0.005053

run [700]:
Style Loss : 0.552099 Content Loss: 0.005303

run [750]:
Style Loss : 0.536529 Content Loss: 0.005502

run [800]:
Style Loss : 0.521306 Content Loss: 0.005675

run [850]:
Style Loss : 0.508743 Content Loss: 0.005871

run [900]:
Style Loss : 0.497264 Content Loss: 0.006009

run [950]:
Style Loss : 0.486949 Content Loss: 0.006186

run [1000]:
Style Loss : 0.476575 Content Loss: 0.006359

run [1050]:
Style Loss : 0.464981 Content Loss: 0.006494

run [1100]:
Style Loss : 0.454996 Content Loss: 0.006619

run [1150]:
Style Loss : 0.445886 Content Loss: 0.006759

run [1200]:
Style Loss : 0.437908 Content Loss: 0.006875

run [1250]:
Style Loss : 0.431668 Content Loss: 0.006979

run [1300]:
Style Loss : 0.426111 Content Loss: 0.007072

run [1350]:
Style Loss : 0.420846 Content Loss: 0.007140

run [1400]:
Style Loss : 0.415591 Content Loss: 0.007227

run [1450]:
Style Loss : 0.411016 Content Loss: 0.007313

run [1500]:
Style Loss : 0.406705 Content Loss: 0.007390

run [1550]:
Style Loss : 0.402931 Content Loss: 0.007459

run [1600]:
Style Loss : 0.399668 Content Loss: 0.007523

run [1650]:
Style Loss : 0.396657 Content Loss: 0.007594

run [1700]:
Style Loss : 0.393293 Content Loss: 0.007674

run [1750]:
Style Loss : 0.390330 Content Loss: 0.007735

run [1800]:
Style Loss : 0.387308 Content Loss: 0.007798

run [1850]:
Style Loss : 0.384004 Content Loss: 0.007858

run [1900]:
Style Loss : 0.380539 Content Loss: 0.007922

run [1950]:
Style Loss : 0.376785 Content Loss: 0.007978

run [2000]:
Style Loss : 0.373754 Content Loss: 0.008013

run [2050]:
Style Loss : 0.371121 Content Loss: 0.008054

run [2100]:
Style Loss : 0.368926 Content Loss: 0.008092

run [2150]:
Style Loss : 0.366953 Content Loss: 0.008135

run [2200]:
Style Loss : 0.364957 Content Loss: 0.008165

run [2250]:
Style Loss : 0.363258 Content Loss: 0.008196

run [2300]:
Style Loss : 0.360614 Content Loss: 0.008240

run [2350]:
Style Loss : 0.358505 Content Loss: 0.008288

run [2400]:
Style Loss : 0.356840 Content Loss: 0.008309

run [2450]:
Style Loss : 0.355171 Content Loss: 0.008341

run [2500]:
Style Loss : 0.354146 Content Loss: 0.008382

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.324929 Content Loss: 0.003832

run [100]:
Style Loss : 1.866987 Content Loss: 0.003621

run [150]:
Style Loss : 1.469846 Content Loss: 0.003921

run [200]:
Style Loss : 1.247141 Content Loss: 0.004391

run [250]:
Style Loss : 1.063372 Content Loss: 0.004819

run [300]:
Style Loss : 0.906998 Content Loss: 0.005169

run [350]:
Style Loss : 0.804907 Content Loss: 0.005445

run [400]:
Style Loss : 0.732416 Content Loss: 0.005802

run [450]:
Style Loss : 0.679112 Content Loss: 0.006109

run [500]:
Style Loss : 0.641291 Content Loss: 0.006446

run [550]:
Style Loss : 0.609469 Content Loss: 0.006784

run [600]:
Style Loss : 0.582598 Content Loss: 0.007069

run [650]:
Style Loss : 0.555803 Content Loss: 0.007374

run [700]:
Style Loss : 0.531558 Content Loss: 0.007592

run [750]:
Style Loss : 0.512532 Content Loss: 0.007785

run [800]:
Style Loss : 0.494926 Content Loss: 0.007954

run [850]:
Style Loss : 0.481300 Content Loss: 0.008110

run [900]:
Style Loss : 0.469193 Content Loss: 0.008271

run [950]:
Style Loss : 0.458591 Content Loss: 0.008429

run [1000]:
Style Loss : 0.449459 Content Loss: 0.008564

run [1050]:
Style Loss : 0.442206 Content Loss: 0.008672

run [1100]:
Style Loss : 0.436162 Content Loss: 0.008786

run [1150]:
Style Loss : 0.430488 Content Loss: 0.008895

run [1200]:
Style Loss : 0.425641 Content Loss: 0.008989

run [1250]:
Style Loss : 0.421646 Content Loss: 0.009076

run [1300]:
Style Loss : 0.417774 Content Loss: 0.009172

run [1350]:
Style Loss : 0.413894 Content Loss: 0.009263

run [1400]:
Style Loss : 0.410153 Content Loss: 0.009342

run [1450]:
Style Loss : 0.406749 Content Loss: 0.009404

run [1500]:
Style Loss : 0.403642 Content Loss: 0.009474

run [1550]:
Style Loss : 0.400877 Content Loss: 0.009538

run [1600]:
Style Loss : 0.398227 Content Loss: 0.009606

run [1650]:
Style Loss : 0.395641 Content Loss: 0.009662

run [1700]:
Style Loss : 0.393052 Content Loss: 0.009719

run [1750]:
Style Loss : 0.390816 Content Loss: 0.009771

run [1800]:
Style Loss : 0.388801 Content Loss: 0.009819

run [1850]:
Style Loss : 0.386919 Content Loss: 0.009864

run [1900]:
Style Loss : 0.385289 Content Loss: 0.009913

run [1950]:
Style Loss : 0.383838 Content Loss: 0.009955

run [2000]:
Style Loss : 0.382350 Content Loss: 0.009998

run [2050]:
Style Loss : 0.380939 Content Loss: 0.010034

run [2100]:
Style Loss : 0.379704 Content Loss: 0.010064

run [2150]:
Style Loss : 0.378588 Content Loss: 0.010096

run [2200]:
Style Loss : 0.377461 Content Loss: 0.010128

run [2250]:
Style Loss : 0.376463 Content Loss: 0.010149

run [2300]:
Style Loss : 0.375629 Content Loss: 0.010172

run [2350]:
Style Loss : 0.374848 Content Loss: 0.010194

run [2400]:
Style Loss : 0.374075 Content Loss: 0.010213

run [2450]:
Style Loss : 0.373297 Content Loss: 0.010238

run [2500]:
Style Loss : 0.372522 Content Loss: 0.010259

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.056415 Content Loss: 0.004654

run [100]:
Style Loss : 2.589887 Content Loss: 0.005554

run [150]:
Style Loss : 2.043267 Content Loss: 0.006006

run [200]:
Style Loss : 1.738048 Content Loss: 0.006631

run [250]:
Style Loss : 1.539737 Content Loss: 0.007247

run [300]:
Style Loss : 1.407150 Content Loss: 0.007859

run [350]:
Style Loss : 1.305571 Content Loss: 0.008422

run [400]:
Style Loss : 1.241512 Content Loss: 0.008987

run [450]:
Style Loss : 1.191088 Content Loss: 0.009403

run [500]:
Style Loss : 1.150398 Content Loss: 0.009797

run [550]:
Style Loss : 1.110378 Content Loss: 0.010112

run [600]:
Style Loss : 1.079898 Content Loss: 0.010471

run [650]:
Style Loss : 1.053203 Content Loss: 0.010804

run [700]:
Style Loss : 1.023962 Content Loss: 0.011061

run [750]:
Style Loss : 1.000098 Content Loss: 0.011335

run [800]:
Style Loss : 0.977170 Content Loss: 0.011563

run [850]:
Style Loss : 0.958011 Content Loss: 0.011831

run [900]:
Style Loss : 0.940177 Content Loss: 0.012013

run [950]:
Style Loss : 0.923051 Content Loss: 0.012181

run [1000]:
Style Loss : 0.908035 Content Loss: 0.012385

run [1050]:
Style Loss : 0.897092 Content Loss: 0.012529

run [1100]:
Style Loss : 0.884902 Content Loss: 0.012667

run [1150]:
Style Loss : 0.875469 Content Loss: 0.012845

run [1200]:
Style Loss : 0.865014 Content Loss: 0.012952

run [1250]:
Style Loss : 0.855347 Content Loss: 0.013100

run [1300]:
Style Loss : 0.845210 Content Loss: 0.013232

run [1350]:
Style Loss : 0.837058 Content Loss: 0.013350

run [1400]:
Style Loss : 0.830329 Content Loss: 0.013435

run [1450]:
Style Loss : 0.823994 Content Loss: 0.013557

run [1500]:
Style Loss : 0.817986 Content Loss: 0.013675

run [1550]:
Style Loss : 0.812080 Content Loss: 0.013782

run [1600]:
Style Loss : 0.806820 Content Loss: 0.013892

run [1650]:
Style Loss : 0.801043 Content Loss: 0.013986

run [1700]:
Style Loss : 0.796839 Content Loss: 0.014124

run [1750]:
Style Loss : 0.790508 Content Loss: 0.014186

run [1800]:
Style Loss : 0.785518 Content Loss: 0.014296

run [1850]:
Style Loss : 0.780842 Content Loss: 0.014374

run [1900]:
Style Loss : 0.776922 Content Loss: 0.014439

run [1950]:
Style Loss : 0.772561 Content Loss: 0.014536

run [2000]:
Style Loss : 0.768557 Content Loss: 0.014599

run [2050]:
Style Loss : 0.765388 Content Loss: 0.014680

run [2100]:
Style Loss : 0.761962 Content Loss: 0.014745

run [2150]:
Style Loss : 0.758080 Content Loss: 0.014820

run [2200]:
Style Loss : 0.754431 Content Loss: 0.014865

run [2250]:
Style Loss : 0.751257 Content Loss: 0.014909

run [2300]:
Style Loss : 0.747775 Content Loss: 0.014991

run [2350]:
Style Loss : 0.744506 Content Loss: 0.015063

run [2400]:
Style Loss : 0.741305 Content Loss: 0.015103

run [2450]:
Style Loss : 0.738256 Content Loss: 0.015132

run [2500]:
Style Loss : 0.735806 Content Loss: 0.015190

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.892611 Content Loss: 0.004698

run [100]:
Style Loss : 0.859486 Content Loss: 0.004488

run [150]:
Style Loss : 0.564954 Content Loss: 0.004597

run [200]:
Style Loss : 0.424006 Content Loss: 0.004984

run [250]:
Style Loss : 0.343391 Content Loss: 0.005542

run [300]:
Style Loss : 0.289287 Content Loss: 0.006072

run [350]:
Style Loss : 0.250807 Content Loss: 0.006528

run [400]:
Style Loss : 0.223559 Content Loss: 0.007008

run [450]:
Style Loss : 0.202730 Content Loss: 0.007443

run [500]:
Style Loss : 0.187207 Content Loss: 0.007683

run [550]:
Style Loss : 0.174894 Content Loss: 0.007990

run [600]:
Style Loss : 0.165224 Content Loss: 0.008222

run [650]:
Style Loss : 0.158651 Content Loss: 0.008390

run [700]:
Style Loss : 0.153730 Content Loss: 0.008559

run [750]:
Style Loss : 0.148697 Content Loss: 0.008711

run [800]:
Style Loss : 0.144328 Content Loss: 0.008851

run [850]:
Style Loss : 0.139744 Content Loss: 0.009007

run [900]:
Style Loss : 0.136129 Content Loss: 0.009122

run [950]:
Style Loss : 0.132723 Content Loss: 0.009252

run [1000]:
Style Loss : 0.129636 Content Loss: 0.009364

run [1050]:
Style Loss : 0.126985 Content Loss: 0.009472

run [1100]:
Style Loss : 0.124645 Content Loss: 0.009563

run [1150]:
Style Loss : 0.122612 Content Loss: 0.009614

run [1200]:
Style Loss : 0.120667 Content Loss: 0.009681

run [1250]:
Style Loss : 0.119064 Content Loss: 0.009738

run [1300]:
Style Loss : 0.117500 Content Loss: 0.009781

run [1350]:
Style Loss : 0.116017 Content Loss: 0.009818

run [1400]:
Style Loss : 0.114604 Content Loss: 0.009870

run [1450]:
Style Loss : 0.113290 Content Loss: 0.009910

run [1500]:
Style Loss : 0.111980 Content Loss: 0.009960

run [1550]:
Style Loss : 0.110650 Content Loss: 0.010006

run [1600]:
Style Loss : 0.109260 Content Loss: 0.010055

run [1650]:
Style Loss : 0.108136 Content Loss: 0.010089

run [1700]:
Style Loss : 0.107103 Content Loss: 0.010139

run [1750]:
Style Loss : 0.105998 Content Loss: 0.010169

run [1800]:
Style Loss : 0.104881 Content Loss: 0.010199

run [1850]:
Style Loss : 0.103806 Content Loss: 0.010231

run [1900]:
Style Loss : 0.102967 Content Loss: 0.010253

run [1950]:
Style Loss : 0.102124 Content Loss: 0.010277

run [2000]:
Style Loss : 0.101235 Content Loss: 0.010297

run [2050]:
Style Loss : 0.100257 Content Loss: 0.010317

run [2100]:
Style Loss : 0.099438 Content Loss: 0.010345

run [2150]:
Style Loss : 0.098541 Content Loss: 0.010357

run [2200]:
Style Loss : 0.097710 Content Loss: 0.010381

run [2250]:
Style Loss : 0.096916 Content Loss: 0.010409

run [2300]:
Style Loss : 0.096377 Content Loss: 0.010429

run [2350]:
Style Loss : 0.095741 Content Loss: 0.010440

run [2400]:
Style Loss : 0.095103 Content Loss: 0.010462

run [2450]:
Style Loss : 0.094520 Content Loss: 0.010470

run [2500]:
Style Loss : 0.093973 Content Loss: 0.010485

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.678486 Content Loss: 0.002219

run [100]:
Style Loss : 1.004570 Content Loss: 0.002633

run [150]:
Style Loss : 0.783822 Content Loss: 0.003126

run [200]:
Style Loss : 0.683297 Content Loss: 0.003586

run [250]:
Style Loss : 0.622159 Content Loss: 0.004080

run [300]:
Style Loss : 0.579785 Content Loss: 0.004575

run [350]:
Style Loss : 0.552374 Content Loss: 0.005026

run [400]:
Style Loss : 0.532028 Content Loss: 0.005477

run [450]:
Style Loss : 0.515245 Content Loss: 0.005880

run [500]:
Style Loss : 0.502142 Content Loss: 0.006230

run [550]:
Style Loss : 0.490124 Content Loss: 0.006543

run [600]:
Style Loss : 0.479389 Content Loss: 0.006872

run [650]:
Style Loss : 0.470059 Content Loss: 0.007139

run [700]:
Style Loss : 0.462400 Content Loss: 0.007375

run [750]:
Style Loss : 0.455847 Content Loss: 0.007632

run [800]:
Style Loss : 0.449788 Content Loss: 0.007856

run [850]:
Style Loss : 0.443979 Content Loss: 0.008079

run [900]:
Style Loss : 0.438889 Content Loss: 0.008318

run [950]:
Style Loss : 0.433839 Content Loss: 0.008503

run [1000]:
Style Loss : 0.429689 Content Loss: 0.008662

run [1050]:
Style Loss : 0.425990 Content Loss: 0.008831

run [1100]:
Style Loss : 0.422026 Content Loss: 0.009011

run [1150]:
Style Loss : 0.418744 Content Loss: 0.009165

run [1200]:
Style Loss : 0.415808 Content Loss: 0.009278

run [1250]:
Style Loss : 0.413144 Content Loss: 0.009398

run [1300]:
Style Loss : 0.410778 Content Loss: 0.009513

run [1350]:
Style Loss : 0.408623 Content Loss: 0.009612

run [1400]:
Style Loss : 0.406604 Content Loss: 0.009715

run [1450]:
Style Loss : 0.404551 Content Loss: 0.009802

run [1500]:
Style Loss : 0.402671 Content Loss: 0.009878

run [1550]:
Style Loss : 0.400894 Content Loss: 0.009959

run [1600]:
Style Loss : 0.397608 Content Loss: 0.010050

run [1650]:
Style Loss : 0.395290 Content Loss: 0.010118

run [1700]:
Style Loss : 0.393174 Content Loss: 0.010187

run [1750]:
Style Loss : 0.391447 Content Loss: 0.010242

run [1800]:
Style Loss : 0.389835 Content Loss: 0.010290

run [1850]:
Style Loss : 0.388300 Content Loss: 0.010339

run [1900]:
Style Loss : 0.387008 Content Loss: 0.010388

run [1950]:
Style Loss : 0.385727 Content Loss: 0.010440

run [2000]:
Style Loss : 0.384549 Content Loss: 0.010487

run [2050]:
Style Loss : 0.383468 Content Loss: 0.010527

run [2100]:
Style Loss : 0.382411 Content Loss: 0.010570

run [2150]:
Style Loss : 0.381433 Content Loss: 0.010613

run [2200]:
Style Loss : 0.380510 Content Loss: 0.010653

run [2250]:
Style Loss : 0.379522 Content Loss: 0.010717

run [2300]:
Style Loss : 0.378592 Content Loss: 0.010761

run [2350]:
Style Loss : 0.377713 Content Loss: 0.010808

run [2400]:
Style Loss : 0.376802 Content Loss: 0.010859

run [2450]:
Style Loss : 0.375959 Content Loss: 0.010902

run [2500]:
Style Loss : 0.375168 Content Loss: 0.010938

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.064656 Content Loss: 0.001569

run [100]:
Style Loss : 0.721839 Content Loss: 0.002059

run [150]:
Style Loss : 0.583732 Content Loss: 0.002639

run [200]:
Style Loss : 0.500655 Content Loss: 0.003199

run [250]:
Style Loss : 0.445706 Content Loss: 0.003720

run [300]:
Style Loss : 0.407258 Content Loss: 0.004209

run [350]:
Style Loss : 0.381130 Content Loss: 0.004695

run [400]:
Style Loss : 0.359584 Content Loss: 0.005180

run [450]:
Style Loss : 0.341212 Content Loss: 0.005645

run [500]:
Style Loss : 0.326896 Content Loss: 0.005996

run [550]:
Style Loss : 0.315702 Content Loss: 0.006308

run [600]:
Style Loss : 0.305604 Content Loss: 0.006596

run [650]:
Style Loss : 0.296937 Content Loss: 0.006868

run [700]:
Style Loss : 0.288126 Content Loss: 0.007086

run [750]:
Style Loss : 0.280696 Content Loss: 0.007257

run [800]:
Style Loss : 0.274127 Content Loss: 0.007362

run [850]:
Style Loss : 0.268891 Content Loss: 0.007488

run [900]:
Style Loss : 0.264601 Content Loss: 0.007593

run [950]:
Style Loss : 0.260509 Content Loss: 0.007716

run [1000]:
Style Loss : 0.256893 Content Loss: 0.007818

run [1050]:
Style Loss : 0.253110 Content Loss: 0.007925

run [1100]:
Style Loss : 0.249121 Content Loss: 0.008014

run [1150]:
Style Loss : 0.245580 Content Loss: 0.008101

run [1200]:
Style Loss : 0.241524 Content Loss: 0.008214

run [1250]:
Style Loss : 0.237856 Content Loss: 0.008288

run [1300]:
Style Loss : 0.234460 Content Loss: 0.008368

run [1350]:
Style Loss : 0.231349 Content Loss: 0.008430

run [1400]:
Style Loss : 0.228584 Content Loss: 0.008503

run [1450]:
Style Loss : 0.225983 Content Loss: 0.008595

run [1500]:
Style Loss : 0.223356 Content Loss: 0.008697

run [1550]:
Style Loss : 0.220795 Content Loss: 0.008804

run [1600]:
Style Loss : 0.218337 Content Loss: 0.008911

run [1650]:
Style Loss : 0.215851 Content Loss: 0.009036

run [1700]:
Style Loss : 0.213287 Content Loss: 0.009140

run [1750]:
Style Loss : 0.210760 Content Loss: 0.009248

run [1800]:
Style Loss : 0.208564 Content Loss: 0.009329

run [1850]:
Style Loss : 0.206615 Content Loss: 0.009402

run [1900]:
Style Loss : 0.204985 Content Loss: 0.009484

run [1950]:
Style Loss : 0.203548 Content Loss: 0.009530

run [2000]:
Style Loss : 0.202258 Content Loss: 0.009607

run [2050]:
Style Loss : 0.200951 Content Loss: 0.009689

run [2100]:
Style Loss : 0.199529 Content Loss: 0.009762

run [2150]:
Style Loss : 0.198163 Content Loss: 0.009857

run [2200]:
Style Loss : 0.197025 Content Loss: 0.009925

run [2250]:
Style Loss : 0.195902 Content Loss: 0.009975

run [2300]:
Style Loss : 0.194957 Content Loss: 0.010070

run [2350]:
Style Loss : 0.193724 Content Loss: 0.010135

run [2400]:
Style Loss : 0.192578 Content Loss: 0.010196

run [2450]:
Style Loss : 0.191678 Content Loss: 0.010264

run [2500]:
Style Loss : 0.190740 Content Loss: 0.010346

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.809811 Content Loss: 0.001938

run [100]:
Style Loss : 0.552396 Content Loss: 0.002711

run [150]:
Style Loss : 0.430348 Content Loss: 0.003336

run [200]:
Style Loss : 0.365744 Content Loss: 0.004011

run [250]:
Style Loss : 0.325604 Content Loss: 0.004634

run [300]:
Style Loss : 0.294992 Content Loss: 0.005137

run [350]:
Style Loss : 0.273169 Content Loss: 0.005603

run [400]:
Style Loss : 0.256928 Content Loss: 0.006071

run [450]:
Style Loss : 0.244957 Content Loss: 0.006480

run [500]:
Style Loss : 0.234252 Content Loss: 0.006893

run [550]:
Style Loss : 0.225432 Content Loss: 0.007269

run [600]:
Style Loss : 0.218032 Content Loss: 0.007590

run [650]:
Style Loss : 0.209462 Content Loss: 0.007962

run [700]:
Style Loss : 0.199651 Content Loss: 0.008167

run [750]:
Style Loss : 0.192449 Content Loss: 0.008407

run [800]:
Style Loss : 0.184805 Content Loss: 0.008639

run [850]:
Style Loss : 0.175707 Content Loss: 0.008835

run [900]:
Style Loss : 0.168547 Content Loss: 0.009027

run [950]:
Style Loss : 0.161931 Content Loss: 0.009194

run [1000]:
Style Loss : 0.156000 Content Loss: 0.009356

run [1050]:
Style Loss : 0.151222 Content Loss: 0.009516

run [1100]:
Style Loss : 0.146948 Content Loss: 0.009656

run [1150]:
Style Loss : 0.143493 Content Loss: 0.009772

run [1200]:
Style Loss : 0.140755 Content Loss: 0.009892

run [1250]:
Style Loss : 0.137982 Content Loss: 0.010010

run [1300]:
Style Loss : 0.134845 Content Loss: 0.010109

run [1350]:
Style Loss : 0.132074 Content Loss: 0.010210

run [1400]:
Style Loss : 0.129764 Content Loss: 0.010302

run [1450]:
Style Loss : 0.127846 Content Loss: 0.010381

run [1500]:
Style Loss : 0.126097 Content Loss: 0.010460

run [1550]:
Style Loss : 0.124401 Content Loss: 0.010541

run [1600]:
Style Loss : 0.122950 Content Loss: 0.010619

run [1650]:
Style Loss : 0.121643 Content Loss: 0.010705

run [1700]:
Style Loss : 0.120466 Content Loss: 0.010784

run [1750]:
Style Loss : 0.119230 Content Loss: 0.010877

run [1800]:
Style Loss : 0.118244 Content Loss: 0.010967

run [1850]:
Style Loss : 0.116993 Content Loss: 0.011066

run [1900]:
Style Loss : 0.115796 Content Loss: 0.011128

run [1950]:
Style Loss : 0.114584 Content Loss: 0.011228

run [2000]:
Style Loss : 0.113471 Content Loss: 0.011326

run [2050]:
Style Loss : 0.114181 Content Loss: 0.011635

run [2100]:
Style Loss : 0.111351 Content Loss: 0.011564

run [2150]:
Style Loss : 0.111043 Content Loss: 0.011682

run [2200]:
Style Loss : 0.109247 Content Loss: 0.011818

run [2250]:
Style Loss : 0.108770 Content Loss: 0.011941

run [2300]:
Style Loss : 0.733045 Content Loss: 0.014883

run [2350]:
Style Loss : 0.125447 Content Loss: 0.013249

run [2400]:
Style Loss : 0.110029 Content Loss: 0.013077

run [2450]:
Style Loss : 0.104859 Content Loss: 0.013041

run [2500]:
Style Loss : 0.102182 Content Loss: 0.012968

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.711221 Content Loss: 0.001051

run [100]:
Style Loss : 0.440131 Content Loss: 0.001435

run [150]:
Style Loss : 0.353344 Content Loss: 0.001915

run [200]:
Style Loss : 0.306503 Content Loss: 0.002411

run [250]:
Style Loss : 0.273606 Content Loss: 0.002857

run [300]:
Style Loss : 0.250473 Content Loss: 0.003349

run [350]:
Style Loss : 0.233823 Content Loss: 0.003857

run [400]:
Style Loss : 0.220671 Content Loss: 0.004390

run [450]:
Style Loss : 0.210474 Content Loss: 0.004859

run [500]:
Style Loss : 0.202499 Content Loss: 0.005239

run [550]:
Style Loss : 0.196060 Content Loss: 0.005615

run [600]:
Style Loss : 0.191119 Content Loss: 0.005881

run [650]:
Style Loss : 0.186990 Content Loss: 0.006114

run [700]:
Style Loss : 0.183364 Content Loss: 0.006330

run [750]:
Style Loss : 0.180137 Content Loss: 0.006495

run [800]:
Style Loss : 0.177435 Content Loss: 0.006665

run [850]:
Style Loss : 0.175035 Content Loss: 0.006791

run [900]:
Style Loss : 0.172969 Content Loss: 0.006913

run [950]:
Style Loss : 0.171283 Content Loss: 0.007004

run [1000]:
Style Loss : 0.169840 Content Loss: 0.007091

run [1050]:
Style Loss : 0.168475 Content Loss: 0.007174

run [1100]:
Style Loss : 0.167191 Content Loss: 0.007246

run [1150]:
Style Loss : 0.166015 Content Loss: 0.007322

run [1200]:
Style Loss : 0.164923 Content Loss: 0.007382

run [1250]:
Style Loss : 0.163701 Content Loss: 0.007458

run [1300]:
Style Loss : 0.162553 Content Loss: 0.007524

run [1350]:
Style Loss : 0.161477 Content Loss: 0.007575

run [1400]:
Style Loss : 0.160510 Content Loss: 0.007630

run [1450]:
Style Loss : 0.159622 Content Loss: 0.007685

run [1500]:
Style Loss : 0.158713 Content Loss: 0.007745

run [1550]:
Style Loss : 0.157799 Content Loss: 0.007811

run [1600]:
Style Loss : 0.156925 Content Loss: 0.007862

run [1650]:
Style Loss : 0.156118 Content Loss: 0.007913

run [1700]:
Style Loss : 0.155367 Content Loss: 0.007960

run [1750]:
Style Loss : 0.154623 Content Loss: 0.008011

run [1800]:
Style Loss : 0.153879 Content Loss: 0.008058

run [1850]:
Style Loss : 0.153176 Content Loss: 0.008111

run [1900]:
Style Loss : 0.152481 Content Loss: 0.008162

run [1950]:
Style Loss : 0.151822 Content Loss: 0.008209

run [2000]:
Style Loss : 0.151135 Content Loss: 0.008267

run [2050]:
Style Loss : 0.150490 Content Loss: 0.008317

run [2100]:
Style Loss : 0.149849 Content Loss: 0.008367

run [2150]:
Style Loss : 0.149278 Content Loss: 0.008409

run [2200]:
Style Loss : 0.148711 Content Loss: 0.008452

run [2250]:
Style Loss : 0.148153 Content Loss: 0.008492

run [2300]:
Style Loss : 0.147649 Content Loss: 0.008531

run [2350]:
Style Loss : 0.147124 Content Loss: 0.008577

run [2400]:
Style Loss : 0.146648 Content Loss: 0.008614

run [2450]:
Style Loss : 0.146182 Content Loss: 0.008650

run [2500]:
Style Loss : 0.145711 Content Loss: 0.008686

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.144692 Content Loss: 0.002618

run [100]:
Style Loss : 1.500756 Content Loss: 0.002318

run [150]:
Style Loss : 1.033811 Content Loss: 0.002316

run [200]:
Style Loss : 0.838463 Content Loss: 0.002487

run [250]:
Style Loss : 0.727039 Content Loss: 0.002781

run [300]:
Style Loss : 0.653858 Content Loss: 0.003107

run [350]:
Style Loss : 0.601873 Content Loss: 0.003445

run [400]:
Style Loss : 0.562717 Content Loss: 0.003797

run [450]:
Style Loss : 0.528874 Content Loss: 0.004167

run [500]:
Style Loss : 0.502408 Content Loss: 0.004493

run [550]:
Style Loss : 0.482175 Content Loss: 0.004814

run [600]:
Style Loss : 0.464724 Content Loss: 0.005129

run [650]:
Style Loss : 0.450630 Content Loss: 0.005383

run [700]:
Style Loss : 0.438080 Content Loss: 0.005660

run [750]:
Style Loss : 0.426885 Content Loss: 0.005905

run [800]:
Style Loss : 0.417384 Content Loss: 0.006101

run [850]:
Style Loss : 0.409581 Content Loss: 0.006304

run [900]:
Style Loss : 0.402549 Content Loss: 0.006486

run [950]:
Style Loss : 0.396222 Content Loss: 0.006664

run [1000]:
Style Loss : 0.390116 Content Loss: 0.006796

run [1050]:
Style Loss : 0.384425 Content Loss: 0.006940

run [1100]:
Style Loss : 0.378711 Content Loss: 0.007068

run [1150]:
Style Loss : 0.372795 Content Loss: 0.007192

run [1200]:
Style Loss : 0.366740 Content Loss: 0.007288

run [1250]:
Style Loss : 0.361657 Content Loss: 0.007387

run [1300]:
Style Loss : 0.357030 Content Loss: 0.007475

run [1350]:
Style Loss : 0.352856 Content Loss: 0.007558

run [1400]:
Style Loss : 0.349211 Content Loss: 0.007615

run [1450]:
Style Loss : 0.345654 Content Loss: 0.007690

run [1500]:
Style Loss : 0.342717 Content Loss: 0.007746

run [1550]:
Style Loss : 0.340027 Content Loss: 0.007796

run [1600]:
Style Loss : 0.337725 Content Loss: 0.007848

run [1650]:
Style Loss : 0.335555 Content Loss: 0.007899

run [1700]:
Style Loss : 0.333440 Content Loss: 0.007947

run [1750]:
Style Loss : 0.331276 Content Loss: 0.008003

run [1800]:
Style Loss : 0.329259 Content Loss: 0.008038

run [1850]:
Style Loss : 0.327221 Content Loss: 0.008081

run [1900]:
Style Loss : 0.325345 Content Loss: 0.008118

run [1950]:
Style Loss : 0.323417 Content Loss: 0.008168

run [2000]:
Style Loss : 0.321412 Content Loss: 0.008207

run [2050]:
Style Loss : 0.319722 Content Loss: 0.008244

run [2100]:
Style Loss : 0.317838 Content Loss: 0.008290

run [2150]:
Style Loss : 0.316166 Content Loss: 0.008328

run [2200]:
Style Loss : 0.314779 Content Loss: 0.008364

run [2250]:
Style Loss : 0.313528 Content Loss: 0.008398

run [2300]:
Style Loss : 0.312293 Content Loss: 0.008432

run [2350]:
Style Loss : 0.311234 Content Loss: 0.008467

run [2400]:
Style Loss : 0.310119 Content Loss: 0.008507

run [2450]:
Style Loss : 0.309386 Content Loss: 0.008584

run [2500]:
Style Loss : 0.307807 Content Loss: 0.008581

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.631434 Content Loss: 0.001322

run [100]:
Style Loss : 0.388092 Content Loss: 0.002027

run [150]:
Style Loss : 0.296505 Content Loss: 0.002681

run [200]:
Style Loss : 0.242421 Content Loss: 0.003321

run [250]:
Style Loss : 0.208995 Content Loss: 0.003931

run [300]:
Style Loss : 0.185781 Content Loss: 0.004447

run [350]:
Style Loss : 0.168213 Content Loss: 0.004945

run [400]:
Style Loss : 0.155807 Content Loss: 0.005360

run [450]:
Style Loss : 0.146707 Content Loss: 0.005768

run [500]:
Style Loss : 0.140250 Content Loss: 0.006107

run [550]:
Style Loss : 0.134664 Content Loss: 0.006417

run [600]:
Style Loss : 0.130136 Content Loss: 0.006654

run [650]:
Style Loss : 0.126507 Content Loss: 0.006871

run [700]:
Style Loss : 0.123336 Content Loss: 0.007055

run [750]:
Style Loss : 0.120728 Content Loss: 0.007224

run [800]:
Style Loss : 0.118163 Content Loss: 0.007387

run [850]:
Style Loss : 0.112883 Content Loss: 0.007564

run [900]:
Style Loss : 0.108413 Content Loss: 0.007707

run [950]:
Style Loss : 0.105574 Content Loss: 0.007838

run [1000]:
Style Loss : 0.103103 Content Loss: 0.007974

run [1050]:
Style Loss : 0.100830 Content Loss: 0.008092

run [1100]:
Style Loss : 0.098877 Content Loss: 0.008197

run [1150]:
Style Loss : 0.097027 Content Loss: 0.008288

run [1200]:
Style Loss : 0.095345 Content Loss: 0.008368

run [1250]:
Style Loss : 0.093846 Content Loss: 0.008444

run [1300]:
Style Loss : 0.092533 Content Loss: 0.008519

run [1350]:
Style Loss : 0.091309 Content Loss: 0.008582

run [1400]:
Style Loss : 0.090234 Content Loss: 0.008628

run [1450]:
Style Loss : 0.089154 Content Loss: 0.008684

run [1500]:
Style Loss : 0.088158 Content Loss: 0.008738

run [1550]:
Style Loss : 0.087281 Content Loss: 0.008789

run [1600]:
Style Loss : 0.086433 Content Loss: 0.008835

run [1650]:
Style Loss : 0.085673 Content Loss: 0.008874

run [1700]:
Style Loss : 0.084988 Content Loss: 0.008900

run [1750]:
Style Loss : 0.084366 Content Loss: 0.008924

run [1800]:
Style Loss : 0.083834 Content Loss: 0.008939

run [1850]:
Style Loss : 0.083318 Content Loss: 0.008951

run [1900]:
Style Loss : 0.082822 Content Loss: 0.008968

run [1950]:
Style Loss : 0.082357 Content Loss: 0.008977

run [2000]:
Style Loss : 0.081729 Content Loss: 0.008994

run [2050]:
Style Loss : 0.081161 Content Loss: 0.009014

run [2100]:
Style Loss : 0.080646 Content Loss: 0.009026

run [2150]:
Style Loss : 0.080165 Content Loss: 0.009034

run [2200]:
Style Loss : 0.079751 Content Loss: 0.009055

run [2250]:
Style Loss : 0.079323 Content Loss: 0.009072

run [2300]:
Style Loss : 0.078934 Content Loss: 0.009100

run [2350]:
Style Loss : 0.078586 Content Loss: 0.009114

run [2400]:
Style Loss : 0.078285 Content Loss: 0.009134

run [2450]:
Style Loss : 0.077981 Content Loss: 0.009149

run [2500]:
Style Loss : 0.077686 Content Loss: 0.009165

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.645411 Content Loss: 0.001904

run [100]:
Style Loss : 1.043940 Content Loss: 0.002386

run [150]:
Style Loss : 0.788473 Content Loss: 0.002949

run [200]:
Style Loss : 0.663201 Content Loss: 0.003524

run [250]:
Style Loss : 0.575604 Content Loss: 0.003981

run [300]:
Style Loss : 0.516609 Content Loss: 0.004417

run [350]:
Style Loss : 0.464501 Content Loss: 0.004792

run [400]:
Style Loss : 0.427527 Content Loss: 0.005105

run [450]:
Style Loss : 0.398643 Content Loss: 0.005356

run [500]:
Style Loss : 0.376573 Content Loss: 0.005666

run [550]:
Style Loss : 0.359189 Content Loss: 0.005960

run [600]:
Style Loss : 0.346465 Content Loss: 0.006255

run [650]:
Style Loss : 0.336165 Content Loss: 0.006512

run [700]:
Style Loss : 0.328476 Content Loss: 0.006776

run [750]:
Style Loss : 0.321751 Content Loss: 0.007013

run [800]:
Style Loss : 0.316160 Content Loss: 0.007229

run [850]:
Style Loss : 0.311102 Content Loss: 0.007426

run [900]:
Style Loss : 0.306800 Content Loss: 0.007595

run [950]:
Style Loss : 0.302560 Content Loss: 0.007756

run [1000]:
Style Loss : 0.298807 Content Loss: 0.007872

run [1050]:
Style Loss : 0.295728 Content Loss: 0.007993

run [1100]:
Style Loss : 0.293188 Content Loss: 0.008105

run [1150]:
Style Loss : 0.290907 Content Loss: 0.008214

run [1200]:
Style Loss : 0.288719 Content Loss: 0.008320

run [1250]:
Style Loss : 0.286689 Content Loss: 0.008418

run [1300]:
Style Loss : 0.284916 Content Loss: 0.008506

run [1350]:
Style Loss : 0.283203 Content Loss: 0.008592

run [1400]:
Style Loss : 0.281529 Content Loss: 0.008679

run [1450]:
Style Loss : 0.279871 Content Loss: 0.008763

run [1500]:
Style Loss : 0.278507 Content Loss: 0.008837

run [1550]:
Style Loss : 0.277199 Content Loss: 0.008910

run [1600]:
Style Loss : 0.276009 Content Loss: 0.008973

run [1650]:
Style Loss : 0.274924 Content Loss: 0.009041

run [1700]:
Style Loss : 0.273964 Content Loss: 0.009096

run [1750]:
Style Loss : 0.273046 Content Loss: 0.009146

run [1800]:
Style Loss : 0.272188 Content Loss: 0.009203

run [1850]:
Style Loss : 0.271339 Content Loss: 0.009263

run [1900]:
Style Loss : 0.270418 Content Loss: 0.009322

run [1950]:
Style Loss : 0.269500 Content Loss: 0.009373

run [2000]:
Style Loss : 0.268668 Content Loss: 0.009420

run [2050]:
Style Loss : 0.267942 Content Loss: 0.009462

run [2100]:
Style Loss : 0.267275 Content Loss: 0.009507

run [2150]:
Style Loss : 0.266631 Content Loss: 0.009546

run [2200]:
Style Loss : 0.266042 Content Loss: 0.009581

run [2250]:
Style Loss : 0.265413 Content Loss: 0.009627

run [2300]:
Style Loss : 0.264832 Content Loss: 0.009664

run [2350]:
Style Loss : 0.264254 Content Loss: 0.009702

run [2400]:
Style Loss : 0.263694 Content Loss: 0.009737

run [2450]:
Style Loss : 0.263121 Content Loss: 0.009773

run [2500]:
Style Loss : 0.262609 Content Loss: 0.009806

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.526070 Content Loss: 0.002014

run [100]:
Style Loss : 0.919139 Content Loss: 0.004280

run [150]:
Style Loss : 0.718851 Content Loss: 0.006158

run [200]:
Style Loss : 0.618104 Content Loss: 0.007485

run [250]:
Style Loss : 0.560139 Content Loss: 0.008535

run [300]:
Style Loss : 0.516574 Content Loss: 0.009268

run [350]:
Style Loss : 0.484912 Content Loss: 0.009855

run [400]:
Style Loss : 0.460015 Content Loss: 0.010327

run [450]:
Style Loss : 0.440647 Content Loss: 0.010690

run [500]:
Style Loss : 0.425362 Content Loss: 0.010983

run [550]:
Style Loss : 0.412074 Content Loss: 0.011332

run [600]:
Style Loss : 0.399505 Content Loss: 0.011668

run [650]:
Style Loss : 0.388887 Content Loss: 0.011961

run [700]:
Style Loss : 0.379023 Content Loss: 0.012278

run [750]:
Style Loss : 0.369790 Content Loss: 0.012599

run [800]:
Style Loss : 0.360764 Content Loss: 0.012960

run [850]:
Style Loss : 0.352488 Content Loss: 0.013315

run [900]:
Style Loss : 0.344675 Content Loss: 0.013676

run [950]:
Style Loss : 0.337142 Content Loss: 0.014034

run [1000]:
Style Loss : 0.329904 Content Loss: 0.014451

run [1050]:
Style Loss : 0.322941 Content Loss: 0.014828

run [1100]:
Style Loss : 0.315999 Content Loss: 0.015253

run [1150]:
Style Loss : 0.309179 Content Loss: 0.015721

run [1200]:
Style Loss : 0.302541 Content Loss: 0.016224

run [1250]:
Style Loss : 0.296209 Content Loss: 0.016711

run [1300]:
Style Loss : 0.289988 Content Loss: 0.017207

run [1350]:
Style Loss : 0.283808 Content Loss: 0.017669

run [1400]:
Style Loss : 0.277831 Content Loss: 0.018158

run [1450]:
Style Loss : 0.272208 Content Loss: 0.018586

run [1500]:
Style Loss : 0.267054 Content Loss: 0.019007

run [1550]:
Style Loss : 0.262193 Content Loss: 0.019417

run [1600]:
Style Loss : 0.257770 Content Loss: 0.019776

run [1650]:
Style Loss : 0.253702 Content Loss: 0.020099

run [1700]:
Style Loss : 0.249920 Content Loss: 0.020395

run [1750]:
Style Loss : 0.246547 Content Loss: 0.020665

run [1800]:
Style Loss : 0.243596 Content Loss: 0.020886

run [1850]:
Style Loss : 0.241076 Content Loss: 0.021080

run [1900]:
Style Loss : 0.238936 Content Loss: 0.021233

run [1950]:
Style Loss : 0.237186 Content Loss: 0.021353

run [2000]:
Style Loss : 0.235614 Content Loss: 0.021478

run [2050]:
Style Loss : 0.234213 Content Loss: 0.021566

run [2100]:
Style Loss : 0.232853 Content Loss: 0.021645

run [2150]:
Style Loss : 0.231656 Content Loss: 0.021711

run [2200]:
Style Loss : 0.230608 Content Loss: 0.021767

run [2250]:
Style Loss : 0.229594 Content Loss: 0.021815

run [2300]:
Style Loss : 0.228678 Content Loss: 0.021854

run [2350]:
Style Loss : 0.227867 Content Loss: 0.021884

run [2400]:
Style Loss : 0.227178 Content Loss: 0.021903

run [2450]:
Style Loss : 0.226549 Content Loss: 0.021917

run [2500]:
Style Loss : 0.225922 Content Loss: 0.021932

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.385958 Content Loss: 0.001452

run [100]:
Style Loss : 0.685154 Content Loss: 0.004273

run [150]:
Style Loss : 0.459053 Content Loss: 0.006674

run [200]:
Style Loss : 0.370433 Content Loss: 0.008405

run [250]:
Style Loss : 0.319554 Content Loss: 0.009399

run [300]:
Style Loss : 0.288578 Content Loss: 0.010036

run [350]:
Style Loss : 0.268039 Content Loss: 0.010730

run [400]:
Style Loss : 0.251822 Content Loss: 0.011125

run [450]:
Style Loss : 0.237652 Content Loss: 0.011528

run [500]:
Style Loss : 0.225930 Content Loss: 0.011835

run [550]:
Style Loss : 0.216470 Content Loss: 0.012069

run [600]:
Style Loss : 0.209040 Content Loss: 0.012256

run [650]:
Style Loss : 0.202754 Content Loss: 0.012469

run [700]:
Style Loss : 0.196796 Content Loss: 0.012686

run [750]:
Style Loss : 0.191606 Content Loss: 0.012884

run [800]:
Style Loss : 0.187112 Content Loss: 0.013055

run [850]:
Style Loss : 0.183018 Content Loss: 0.013206

run [900]:
Style Loss : 0.179134 Content Loss: 0.013329

run [950]:
Style Loss : 0.175608 Content Loss: 0.013439

run [1000]:
Style Loss : 0.172359 Content Loss: 0.013539

run [1050]:
Style Loss : 0.169599 Content Loss: 0.013643

run [1100]:
Style Loss : 0.166752 Content Loss: 0.013770

run [1150]:
Style Loss : 0.164112 Content Loss: 0.013871

run [1200]:
Style Loss : 0.161565 Content Loss: 0.013987

run [1250]:
Style Loss : 0.159383 Content Loss: 0.014090

run [1300]:
Style Loss : 0.157343 Content Loss: 0.014196

run [1350]:
Style Loss : 0.155394 Content Loss: 0.014294

run [1400]:
Style Loss : 0.153486 Content Loss: 0.014400

run [1450]:
Style Loss : 0.151506 Content Loss: 0.014503

run [1500]:
Style Loss : 0.149652 Content Loss: 0.014609

run [1550]:
Style Loss : 0.147935 Content Loss: 0.014689

run [1600]:
Style Loss : 0.146211 Content Loss: 0.014789

run [1650]:
Style Loss : 0.144685 Content Loss: 0.014877

run [1700]:
Style Loss : 0.143225 Content Loss: 0.014960

run [1750]:
Style Loss : 0.141779 Content Loss: 0.015042

run [1800]:
Style Loss : 0.140205 Content Loss: 0.015128

run [1850]:
Style Loss : 0.138456 Content Loss: 0.015207

run [1900]:
Style Loss : 0.137011 Content Loss: 0.015291

run [1950]:
Style Loss : 0.135487 Content Loss: 0.015385

run [2000]:
Style Loss : 0.133860 Content Loss: 0.015475

run [2050]:
Style Loss : 0.132420 Content Loss: 0.015550

run [2100]:
Style Loss : 0.131058 Content Loss: 0.015628

run [2150]:
Style Loss : 0.129808 Content Loss: 0.015690

run [2200]:
Style Loss : 0.128378 Content Loss: 0.015768

run [2250]:
Style Loss : 0.126973 Content Loss: 0.015831

run [2300]:
Style Loss : 0.125604 Content Loss: 0.015878

run [2350]:
Style Loss : 0.124290 Content Loss: 0.015929

run [2400]:
Style Loss : 0.123001 Content Loss: 0.015979

run [2450]:
Style Loss : 0.121879 Content Loss: 0.016022

run [2500]:
Style Loss : 0.120856 Content Loss: 0.016059

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.718511 Content Loss: 0.002019

run [100]:
Style Loss : 1.578062 Content Loss: 0.004863

run [150]:
Style Loss : 1.142561 Content Loss: 0.008014

run [200]:
Style Loss : 0.928797 Content Loss: 0.010021

run [250]:
Style Loss : 0.806275 Content Loss: 0.011488

run [300]:
Style Loss : 0.721815 Content Loss: 0.012525

run [350]:
Style Loss : 0.664331 Content Loss: 0.013283

run [400]:
Style Loss : 0.624916 Content Loss: 0.013892

run [450]:
Style Loss : 0.595435 Content Loss: 0.014403

run [500]:
Style Loss : 0.573400 Content Loss: 0.014717

run [550]:
Style Loss : 0.556775 Content Loss: 0.014985

run [600]:
Style Loss : 0.543777 Content Loss: 0.015215

run [650]:
Style Loss : 0.532521 Content Loss: 0.015411

run [700]:
Style Loss : 0.524055 Content Loss: 0.015573

run [750]:
Style Loss : 0.516388 Content Loss: 0.015732

run [800]:
Style Loss : 0.509662 Content Loss: 0.015876

run [850]:
Style Loss : 0.503780 Content Loss: 0.015995

run [900]:
Style Loss : 0.498643 Content Loss: 0.016106

run [950]:
Style Loss : 0.493570 Content Loss: 0.016219

run [1000]:
Style Loss : 0.488218 Content Loss: 0.016324

run [1050]:
Style Loss : 0.483832 Content Loss: 0.016405

run [1100]:
Style Loss : 0.480038 Content Loss: 0.016476

run [1150]:
Style Loss : 0.476010 Content Loss: 0.016562

run [1200]:
Style Loss : 0.472597 Content Loss: 0.016639

run [1250]:
Style Loss : 0.469851 Content Loss: 0.016709

run [1300]:
Style Loss : 0.467447 Content Loss: 0.016763

run [1350]:
Style Loss : 0.465134 Content Loss: 0.016822

run [1400]:
Style Loss : 0.462952 Content Loss: 0.016871

run [1450]:
Style Loss : 0.460760 Content Loss: 0.016922

run [1500]:
Style Loss : 0.458514 Content Loss: 0.016960

run [1550]:
Style Loss : 0.455361 Content Loss: 0.017016

run [1600]:
Style Loss : 0.452454 Content Loss: 0.017070

run [1650]:
Style Loss : 0.449342 Content Loss: 0.017128

run [1700]:
Style Loss : 0.446463 Content Loss: 0.017168

run [1750]:
Style Loss : 0.443951 Content Loss: 0.017213

run [1800]:
Style Loss : 0.441558 Content Loss: 0.017255

run [1850]:
Style Loss : 0.439463 Content Loss: 0.017297

run [1900]:
Style Loss : 0.437450 Content Loss: 0.017344

run [1950]:
Style Loss : 0.435424 Content Loss: 0.017392

run [2000]:
Style Loss : 0.433497 Content Loss: 0.017438

run [2050]:
Style Loss : 0.431769 Content Loss: 0.017472

run [2100]:
Style Loss : 0.430141 Content Loss: 0.017506

run [2150]:
Style Loss : 0.428533 Content Loss: 0.017535

run [2200]:
Style Loss : 0.426862 Content Loss: 0.017567

run [2250]:
Style Loss : 0.425105 Content Loss: 0.017595

run [2300]:
Style Loss : 0.423290 Content Loss: 0.017624

run [2350]:
Style Loss : 0.421681 Content Loss: 0.017649

run [2400]:
Style Loss : 0.420220 Content Loss: 0.017676

run [2450]:
Style Loss : 0.418875 Content Loss: 0.017704

run [2500]:
Style Loss : 0.417721 Content Loss: 0.017725

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.854398 Content Loss: 0.004442

run [100]:
Style Loss : 0.532626 Content Loss: 0.007513

run [150]:
Style Loss : 0.450101 Content Loss: 0.008988

run [200]:
Style Loss : 0.407743 Content Loss: 0.009940

run [250]:
Style Loss : 0.372490 Content Loss: 0.011028

run [300]:
Style Loss : 0.344117 Content Loss: 0.011619

run [350]:
Style Loss : 0.321564 Content Loss: 0.012312

run [400]:
Style Loss : 0.302190 Content Loss: 0.012992

run [450]:
Style Loss : 0.284294 Content Loss: 0.013686

run [500]:
Style Loss : 0.267018 Content Loss: 0.014272

run [550]:
Style Loss : 0.252530 Content Loss: 0.014982

run [600]:
Style Loss : 0.238877 Content Loss: 0.015809

run [650]:
Style Loss : 0.226627 Content Loss: 0.016621

run [700]:
Style Loss : 0.214695 Content Loss: 0.017575

run [750]:
Style Loss : 0.203687 Content Loss: 0.018501

run [800]:
Style Loss : 0.193869 Content Loss: 0.019363

run [850]:
Style Loss : 0.185519 Content Loss: 0.020196

run [900]:
Style Loss : 0.178924 Content Loss: 0.020935

run [950]:
Style Loss : 0.171281 Content Loss: 0.021518

run [1000]:
Style Loss : 0.166709 Content Loss: 0.021935

run [1050]:
Style Loss : 0.162957 Content Loss: 0.022252

run [1100]:
Style Loss : 0.160045 Content Loss: 0.022446

run [1150]:
Style Loss : 0.157575 Content Loss: 0.022622

run [1200]:
Style Loss : 0.155569 Content Loss: 0.022703

run [1250]:
Style Loss : 0.154107 Content Loss: 0.022815

run [1300]:
Style Loss : 0.152766 Content Loss: 0.022891

run [1350]:
Style Loss : 0.151585 Content Loss: 0.022933

run [1400]:
Style Loss : 0.150642 Content Loss: 0.022931

run [1450]:
Style Loss : 0.149816 Content Loss: 0.022927

run [1500]:
Style Loss : 0.149120 Content Loss: 0.022918

run [1550]:
Style Loss : 0.148537 Content Loss: 0.022905

run [1600]:
Style Loss : 0.147969 Content Loss: 0.022887

run [1650]:
Style Loss : 0.147479 Content Loss: 0.022869

run [1700]:
Style Loss : 0.147044 Content Loss: 0.022847

run [1750]:
Style Loss : 0.146653 Content Loss: 0.022833

run [1800]:
Style Loss : 0.146289 Content Loss: 0.022823

run [1850]:
Style Loss : 0.145918 Content Loss: 0.022811

run [1900]:
Style Loss : 0.145571 Content Loss: 0.022799

run [1950]:
Style Loss : 0.145252 Content Loss: 0.022786

run [2000]:
Style Loss : 0.144960 Content Loss: 0.022765

run [2050]:
Style Loss : 0.144693 Content Loss: 0.022754

run [2100]:
Style Loss : 0.144445 Content Loss: 0.022736

run [2150]:
Style Loss : 0.144181 Content Loss: 0.022717

run [2200]:
Style Loss : 0.143954 Content Loss: 0.022701

run [2250]:
Style Loss : 0.143661 Content Loss: 0.022687

run [2300]:
Style Loss : 0.143381 Content Loss: 0.022675

run [2350]:
Style Loss : 0.143071 Content Loss: 0.022661

run [2400]:
Style Loss : 0.142852 Content Loss: 0.022648

run [2450]:
Style Loss : 0.142620 Content Loss: 0.022631

run [2500]:
Style Loss : 0.142444 Content Loss: 0.022619

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.776836 Content Loss: 0.005832

run [100]:
Style Loss : 0.458238 Content Loss: 0.009902

run [150]:
Style Loss : 0.365982 Content Loss: 0.012650

run [200]:
Style Loss : 0.313657 Content Loss: 0.014742

run [250]:
Style Loss : 0.279648 Content Loss: 0.016876

run [300]:
Style Loss : 0.253485 Content Loss: 0.018844

run [350]:
Style Loss : 0.230814 Content Loss: 0.020784

run [400]:
Style Loss : 0.213833 Content Loss: 0.022527

run [450]:
Style Loss : 0.198984 Content Loss: 0.023974

run [500]:
Style Loss : 0.185902 Content Loss: 0.024959

run [550]:
Style Loss : 0.175021 Content Loss: 0.025731

run [600]:
Style Loss : 0.165092 Content Loss: 0.026413

run [650]:
Style Loss : 0.156744 Content Loss: 0.026975

run [700]:
Style Loss : 0.149026 Content Loss: 0.027518

run [750]:
Style Loss : 0.142632 Content Loss: 0.028021

run [800]:
Style Loss : 0.137360 Content Loss: 0.028583

run [850]:
Style Loss : 0.132877 Content Loss: 0.029144

run [900]:
Style Loss : 0.129308 Content Loss: 0.029609

run [950]:
Style Loss : 0.126465 Content Loss: 0.029942

run [1000]:
Style Loss : 0.124097 Content Loss: 0.030260

run [1050]:
Style Loss : 0.122151 Content Loss: 0.030446

run [1100]:
Style Loss : 0.120600 Content Loss: 0.030592

run [1150]:
Style Loss : 0.119323 Content Loss: 0.030724

run [1200]:
Style Loss : 0.118289 Content Loss: 0.030819

run [1250]:
Style Loss : 0.117262 Content Loss: 0.030918

run [1300]:
Style Loss : 0.116320 Content Loss: 0.030972

run [1350]:
Style Loss : 0.115518 Content Loss: 0.031007

run [1400]:
Style Loss : 0.114785 Content Loss: 0.031036

run [1450]:
Style Loss : 0.114062 Content Loss: 0.031066

run [1500]:
Style Loss : 0.113359 Content Loss: 0.031113

run [1550]:
Style Loss : 0.112609 Content Loss: 0.031165

run [1600]:
Style Loss : 0.111901 Content Loss: 0.031196

run [1650]:
Style Loss : 0.111223 Content Loss: 0.031232

run [1700]:
Style Loss : 0.110597 Content Loss: 0.031272

run [1750]:
Style Loss : 0.110019 Content Loss: 0.031283

run [1800]:
Style Loss : 0.109552 Content Loss: 0.031285

run [1850]:
Style Loss : 0.109137 Content Loss: 0.031276

run [1900]:
Style Loss : 0.108749 Content Loss: 0.031266

run [1950]:
Style Loss : 0.108394 Content Loss: 0.031271

run [2000]:
Style Loss : 0.108022 Content Loss: 0.031252

run [2050]:
Style Loss : 0.107697 Content Loss: 0.031234

run [2100]:
Style Loss : 0.107349 Content Loss: 0.031212

run [2150]:
Style Loss : 0.107094 Content Loss: 0.031187

run [2200]:
Style Loss : 0.106806 Content Loss: 0.031157

run [2250]:
Style Loss : 0.106527 Content Loss: 0.031121

run [2300]:
Style Loss : 0.106251 Content Loss: 0.031109

run [2350]:
Style Loss : 0.106035 Content Loss: 0.031077

run [2400]:
Style Loss : 0.105975 Content Loss: 0.031032

run [2450]:
Style Loss : 0.105390 Content Loss: 0.031016

run [2500]:
Style Loss : 0.104918 Content Loss: 0.030992

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.956487 Content Loss: 0.009757

run [100]:
Style Loss : 1.228832 Content Loss: 0.011722

run [150]:
Style Loss : 0.998873 Content Loss: 0.013381

run [200]:
Style Loss : 0.873462 Content Loss: 0.014926

run [250]:
Style Loss : 0.782618 Content Loss: 0.016350

run [300]:
Style Loss : 0.718234 Content Loss: 0.017658

run [350]:
Style Loss : 0.667212 Content Loss: 0.018863

run [400]:
Style Loss : 0.623393 Content Loss: 0.020063

run [450]:
Style Loss : 0.588872 Content Loss: 0.021252

run [500]:
Style Loss : 0.558122 Content Loss: 0.022388

run [550]:
Style Loss : 0.531191 Content Loss: 0.023530

run [600]:
Style Loss : 0.506913 Content Loss: 0.024653

run [650]:
Style Loss : 0.483522 Content Loss: 0.025609

run [700]:
Style Loss : 0.458191 Content Loss: 0.026732

run [750]:
Style Loss : 0.436342 Content Loss: 0.027604

run [800]:
Style Loss : 0.415856 Content Loss: 0.028564

run [850]:
Style Loss : 0.399444 Content Loss: 0.029467

run [900]:
Style Loss : 0.386518 Content Loss: 0.030087

run [950]:
Style Loss : 0.373996 Content Loss: 0.031032

run [1000]:
Style Loss : 0.361867 Content Loss: 0.031427

run [1050]:
Style Loss : 0.352451 Content Loss: 0.031843

run [1100]:
Style Loss : 0.345173 Content Loss: 0.032299

run [1150]:
Style Loss : 0.339252 Content Loss: 0.032821

run [1200]:
Style Loss : 0.332539 Content Loss: 0.032842

run [1250]:
Style Loss : 0.328441 Content Loss: 0.033212

run [1300]:
Style Loss : 0.323709 Content Loss: 0.033399

run [1350]:
Style Loss : 0.319171 Content Loss: 0.033463

run [1400]:
Style Loss : 0.315533 Content Loss: 0.033574

run [1450]:
Style Loss : 0.313047 Content Loss: 0.033713

run [1500]:
Style Loss : 0.309873 Content Loss: 0.033820

run [1550]:
Style Loss : 0.308275 Content Loss: 0.033809

run [1600]:
Style Loss : 0.305258 Content Loss: 0.033948

run [1650]:
Style Loss : 0.302192 Content Loss: 0.033943

run [1700]:
Style Loss : 0.300333 Content Loss: 0.034041

run [1750]:
Style Loss : 0.306193 Content Loss: 0.034478

run [1800]:
Style Loss : 0.296160 Content Loss: 0.034317

run [1850]:
Style Loss : 0.293088 Content Loss: 0.034193

run [1900]:
Style Loss : 0.291292 Content Loss: 0.034083

run [1950]:
Style Loss : 0.290385 Content Loss: 0.033981

run [2000]:
Style Loss : 0.288289 Content Loss: 0.033943

run [2050]:
Style Loss : 0.286610 Content Loss: 0.033907

run [2100]:
Style Loss : 0.286204 Content Loss: 0.033946

run [2150]:
Style Loss : 0.284498 Content Loss: 0.033896

run [2200]:
Style Loss : 0.282761 Content Loss: 0.033843

run [2250]:
Style Loss : 0.282353 Content Loss: 0.033846

run [2300]:
Style Loss : 0.280444 Content Loss: 0.033804

run [2350]:
Style Loss : 0.280007 Content Loss: 0.033756

run [2400]:
Style Loss : 0.278072 Content Loss: 0.033728

run [2450]:
Style Loss : 0.277112 Content Loss: 0.033715

run [2500]:
Style Loss : 0.276273 Content Loss: 0.033663

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.626931 Content Loss: 0.001593

run [100]:
Style Loss : 0.860963 Content Loss: 0.004702

run [150]:
Style Loss : 0.609076 Content Loss: 0.007681

run [200]:
Style Loss : 0.499443 Content Loss: 0.009348

run [250]:
Style Loss : 0.437121 Content Loss: 0.010487

run [300]:
Style Loss : 0.398019 Content Loss: 0.011385

run [350]:
Style Loss : 0.369514 Content Loss: 0.011974

run [400]:
Style Loss : 0.345900 Content Loss: 0.012566

run [450]:
Style Loss : 0.326484 Content Loss: 0.013030

run [500]:
Style Loss : 0.311038 Content Loss: 0.013418

run [550]:
Style Loss : 0.296988 Content Loss: 0.013843

run [600]:
Style Loss : 0.285409 Content Loss: 0.014227

run [650]:
Style Loss : 0.275599 Content Loss: 0.014547

run [700]:
Style Loss : 0.266123 Content Loss: 0.014877

run [750]:
Style Loss : 0.257790 Content Loss: 0.015108

run [800]:
Style Loss : 0.250227 Content Loss: 0.015334

run [850]:
Style Loss : 0.243026 Content Loss: 0.015563

run [900]:
Style Loss : 0.236479 Content Loss: 0.015806

run [950]:
Style Loss : 0.230444 Content Loss: 0.016073

run [1000]:
Style Loss : 0.224705 Content Loss: 0.016321

run [1050]:
Style Loss : 0.219579 Content Loss: 0.016602

run [1100]:
Style Loss : 0.214233 Content Loss: 0.016905

run [1150]:
Style Loss : 0.208870 Content Loss: 0.017205

run [1200]:
Style Loss : 0.203643 Content Loss: 0.017497

run [1250]:
Style Loss : 0.198651 Content Loss: 0.017821

run [1300]:
Style Loss : 0.193580 Content Loss: 0.018173

run [1350]:
Style Loss : 0.188876 Content Loss: 0.018527

run [1400]:
Style Loss : 0.184553 Content Loss: 0.018888

run [1450]:
Style Loss : 0.180809 Content Loss: 0.019209

run [1500]:
Style Loss : 0.177445 Content Loss: 0.019534

run [1550]:
Style Loss : 0.174440 Content Loss: 0.019853

run [1600]:
Style Loss : 0.171823 Content Loss: 0.020171

run [1650]:
Style Loss : 0.169323 Content Loss: 0.020496

run [1700]:
Style Loss : 0.167120 Content Loss: 0.020790

run [1750]:
Style Loss : 0.165123 Content Loss: 0.021094

run [1800]:
Style Loss : 0.163347 Content Loss: 0.021346

run [1850]:
Style Loss : 0.161898 Content Loss: 0.021613

run [1900]:
Style Loss : 0.160455 Content Loss: 0.021845

run [1950]:
Style Loss : 0.159180 Content Loss: 0.022150

run [2000]:
Style Loss : 0.158239 Content Loss: 0.022320

run [2050]:
Style Loss : 0.157041 Content Loss: 0.022524

run [2100]:
Style Loss : 0.156143 Content Loss: 0.022737

run [2150]:
Style Loss : 0.155096 Content Loss: 0.022900

run [2200]:
Style Loss : 0.154256 Content Loss: 0.023109

run [2250]:
Style Loss : 0.154381 Content Loss: 0.023423

run [2300]:
Style Loss : 0.152729 Content Loss: 0.023568

run [2350]:
Style Loss : 0.151533 Content Loss: 0.023629

run [2400]:
Style Loss : 0.150901 Content Loss: 0.023814

run [2450]:
Style Loss : 0.150706 Content Loss: 0.024019

run [2500]:
Style Loss : 0.149859 Content Loss: 0.024161

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.181605 Content Loss: 0.003398

run [100]:
Style Loss : 0.654319 Content Loss: 0.008004

run [150]:
Style Loss : 0.502307 Content Loss: 0.011123

run [200]:
Style Loss : 0.421109 Content Loss: 0.013233

run [250]:
Style Loss : 0.370135 Content Loss: 0.014532

run [300]:
Style Loss : 0.333820 Content Loss: 0.015498

run [350]:
Style Loss : 0.308800 Content Loss: 0.016138

run [400]:
Style Loss : 0.291217 Content Loss: 0.016548

run [450]:
Style Loss : 0.277629 Content Loss: 0.016882

run [500]:
Style Loss : 0.267200 Content Loss: 0.017159

run [550]:
Style Loss : 0.258381 Content Loss: 0.017422

run [600]:
Style Loss : 0.251022 Content Loss: 0.017656

run [650]:
Style Loss : 0.244158 Content Loss: 0.017866

run [700]:
Style Loss : 0.238009 Content Loss: 0.018048

run [750]:
Style Loss : 0.232374 Content Loss: 0.018193

run [800]:
Style Loss : 0.226960 Content Loss: 0.018322

run [850]:
Style Loss : 0.222355 Content Loss: 0.018430

run [900]:
Style Loss : 0.217884 Content Loss: 0.018559

run [950]:
Style Loss : 0.212969 Content Loss: 0.018679

run [1000]:
Style Loss : 0.207256 Content Loss: 0.018818

run [1050]:
Style Loss : 0.203634 Content Loss: 0.018909

run [1100]:
Style Loss : 0.200404 Content Loss: 0.018999

run [1150]:
Style Loss : 0.197437 Content Loss: 0.019090

run [1200]:
Style Loss : 0.194809 Content Loss: 0.019185

run [1250]:
Style Loss : 0.192090 Content Loss: 0.019274

run [1300]:
Style Loss : 0.189551 Content Loss: 0.019362

run [1350]:
Style Loss : 0.187354 Content Loss: 0.019438

run [1400]:
Style Loss : 0.185361 Content Loss: 0.019505

run [1450]:
Style Loss : 0.183560 Content Loss: 0.019578

run [1500]:
Style Loss : 0.181928 Content Loss: 0.019643

run [1550]:
Style Loss : 0.180319 Content Loss: 0.019710

run [1600]:
Style Loss : 0.178780 Content Loss: 0.019779

run [1650]:
Style Loss : 0.177353 Content Loss: 0.019829

run [1700]:
Style Loss : 0.175760 Content Loss: 0.019892

run [1750]:
Style Loss : 0.174288 Content Loss: 0.019952

run [1800]:
Style Loss : 0.172819 Content Loss: 0.020009

run [1850]:
Style Loss : 0.171395 Content Loss: 0.020054

run [1900]:
Style Loss : 0.169997 Content Loss: 0.020101

run [1950]:
Style Loss : 0.168705 Content Loss: 0.020157

run [2000]:
Style Loss : 0.167112 Content Loss: 0.020223

run [2050]:
Style Loss : 0.165667 Content Loss: 0.020286

run [2100]:
Style Loss : 0.164363 Content Loss: 0.020340

run [2150]:
Style Loss : 0.163198 Content Loss: 0.020385

run [2200]:
Style Loss : 0.162110 Content Loss: 0.020430

run [2250]:
Style Loss : 0.161091 Content Loss: 0.020477

run [2300]:
Style Loss : 0.160033 Content Loss: 0.020525

run [2350]:
Style Loss : 0.158336 Content Loss: 0.020570

run [2400]:
Style Loss : 0.157176 Content Loss: 0.020613

run [2450]:
Style Loss : 0.156231 Content Loss: 0.020653

run [2500]:
Style Loss : 0.155358 Content Loss: 0.020691

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.047963 Content Loss: 0.002985

run [100]:
Style Loss : 0.528359 Content Loss: 0.007308

run [150]:
Style Loss : 0.371853 Content Loss: 0.009424

run [200]:
Style Loss : 0.306676 Content Loss: 0.010655

run [250]:
Style Loss : 0.271120 Content Loss: 0.011437

run [300]:
Style Loss : 0.245912 Content Loss: 0.012101

run [350]:
Style Loss : 0.226952 Content Loss: 0.012612

run [400]:
Style Loss : 0.212013 Content Loss: 0.013013

run [450]:
Style Loss : 0.200501 Content Loss: 0.013371

run [500]:
Style Loss : 0.191290 Content Loss: 0.013651

run [550]:
Style Loss : 0.183270 Content Loss: 0.013982

run [600]:
Style Loss : 0.176100 Content Loss: 0.014318

run [650]:
Style Loss : 0.162639 Content Loss: 0.014635

run [700]:
Style Loss : 0.154121 Content Loss: 0.014929

run [750]:
Style Loss : 0.147896 Content Loss: 0.015256

run [800]:
Style Loss : 0.142290 Content Loss: 0.015564

run [850]:
Style Loss : 0.136310 Content Loss: 0.015904

run [900]:
Style Loss : 0.130609 Content Loss: 0.016250

run [950]:
Style Loss : 0.124997 Content Loss: 0.016606

run [1000]:
Style Loss : 0.119692 Content Loss: 0.016976

run [1050]:
Style Loss : 0.114738 Content Loss: 0.017350

run [1100]:
Style Loss : 0.110131 Content Loss: 0.017725

run [1150]:
Style Loss : 0.105549 Content Loss: 0.018114

run [1200]:
Style Loss : 0.101263 Content Loss: 0.018549

run [1250]:
Style Loss : 0.097341 Content Loss: 0.019032

run [1300]:
Style Loss : 0.093968 Content Loss: 0.019417

run [1350]:
Style Loss : 0.090888 Content Loss: 0.019794

run [1400]:
Style Loss : 0.088224 Content Loss: 0.020180

run [1450]:
Style Loss : 0.085925 Content Loss: 0.020583

run [1500]:
Style Loss : 0.083974 Content Loss: 0.020858

run [1550]:
Style Loss : 0.082161 Content Loss: 0.021076

run [1600]:
Style Loss : 0.080681 Content Loss: 0.021337

run [1650]:
Style Loss : 0.079409 Content Loss: 0.021535

run [1700]:
Style Loss : 0.078432 Content Loss: 0.021686

run [1750]:
Style Loss : 0.077601 Content Loss: 0.021824

run [1800]:
Style Loss : 0.076856 Content Loss: 0.021964

run [1850]:
Style Loss : 0.076245 Content Loss: 0.022035

run [1900]:
Style Loss : 0.075683 Content Loss: 0.022090

run [1950]:
Style Loss : 0.075251 Content Loss: 0.022165

run [2000]:
Style Loss : 0.074829 Content Loss: 0.022221

run [2050]:
Style Loss : 0.074423 Content Loss: 0.022272

run [2100]:
Style Loss : 0.074053 Content Loss: 0.022329

run [2150]:
Style Loss : 0.073725 Content Loss: 0.022351

run [2200]:
Style Loss : 0.073442 Content Loss: 0.022381

run [2250]:
Style Loss : 0.073193 Content Loss: 0.022410

run [2300]:
Style Loss : 0.073021 Content Loss: 0.022436

run [2350]:
Style Loss : 0.072694 Content Loss: 0.022452

run [2400]:
Style Loss : 0.072489 Content Loss: 0.022484

run [2450]:
Style Loss : 0.072197 Content Loss: 0.022504

run [2500]:
Style Loss : 0.071893 Content Loss: 0.022529

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.317827 Content Loss: 0.005563

run [100]:
Style Loss : 0.825620 Content Loss: 0.009284

run [150]:
Style Loss : 0.614701 Content Loss: 0.012746

run [200]:
Style Loss : 0.488707 Content Loss: 0.015921

run [250]:
Style Loss : 0.417891 Content Loss: 0.018257

run [300]:
Style Loss : 0.369428 Content Loss: 0.019486

run [350]:
Style Loss : 0.338061 Content Loss: 0.020254

run [400]:
Style Loss : 0.317934 Content Loss: 0.020679

run [450]:
Style Loss : 0.303781 Content Loss: 0.020891

run [500]:
Style Loss : 0.293135 Content Loss: 0.021141

run [550]:
Style Loss : 0.284484 Content Loss: 0.021350

run [600]:
Style Loss : 0.277878 Content Loss: 0.021544

run [650]:
Style Loss : 0.272112 Content Loss: 0.021757

run [700]:
Style Loss : 0.266010 Content Loss: 0.022054

run [750]:
Style Loss : 0.260143 Content Loss: 0.022375

run [800]:
Style Loss : 0.254960 Content Loss: 0.022714

run [850]:
Style Loss : 0.250462 Content Loss: 0.023012

run [900]:
Style Loss : 0.246358 Content Loss: 0.023309

run [950]:
Style Loss : 0.242645 Content Loss: 0.023620

run [1000]:
Style Loss : 0.239335 Content Loss: 0.023890

run [1050]:
Style Loss : 0.235676 Content Loss: 0.024157

run [1100]:
Style Loss : 0.232467 Content Loss: 0.024379

run [1150]:
Style Loss : 0.229553 Content Loss: 0.024608

run [1200]:
Style Loss : 0.227105 Content Loss: 0.024781

run [1250]:
Style Loss : 0.224762 Content Loss: 0.024961

run [1300]:
Style Loss : 0.222829 Content Loss: 0.025112

run [1350]:
Style Loss : 0.221033 Content Loss: 0.025248

run [1400]:
Style Loss : 0.219077 Content Loss: 0.025359

run [1450]:
Style Loss : 0.217337 Content Loss: 0.025454

run [1500]:
Style Loss : 0.215557 Content Loss: 0.025551

run [1550]:
Style Loss : 0.214049 Content Loss: 0.025642

run [1600]:
Style Loss : 0.212435 Content Loss: 0.025716

run [1650]:
Style Loss : 0.211103 Content Loss: 0.025791

run [1700]:
Style Loss : 0.209698 Content Loss: 0.025859

run [1750]:
Style Loss : 0.208488 Content Loss: 0.025913

run [1800]:
Style Loss : 0.207546 Content Loss: 0.025981

run [1850]:
Style Loss : 0.206516 Content Loss: 0.026042

run [1900]:
Style Loss : 0.205695 Content Loss: 0.026086

run [1950]:
Style Loss : 0.204936 Content Loss: 0.026138

run [2000]:
Style Loss : 0.204199 Content Loss: 0.026172

run [2050]:
Style Loss : 0.203512 Content Loss: 0.026217

run [2100]:
Style Loss : 0.202859 Content Loss: 0.026261

run [2150]:
Style Loss : 0.202292 Content Loss: 0.026301

run [2200]:
Style Loss : 0.201735 Content Loss: 0.026342

run [2250]:
Style Loss : 0.201299 Content Loss: 0.026384

run [2300]:
Style Loss : 0.200758 Content Loss: 0.026409

run [2350]:
Style Loss : 0.200274 Content Loss: 0.026439

run [2400]:
Style Loss : 0.199922 Content Loss: 0.026467

run [2450]:
Style Loss : 0.199468 Content Loss: 0.026493

run [2500]:
Style Loss : 0.199119 Content Loss: 0.026522

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.909991 Content Loss: 0.006814

run [100]:
Style Loss : 0.516795 Content Loss: 0.012226

run [150]:
Style Loss : 0.383853 Content Loss: 0.015479

run [200]:
Style Loss : 0.316686 Content Loss: 0.017109

run [250]:
Style Loss : 0.275055 Content Loss: 0.018169

run [300]:
Style Loss : 0.248660 Content Loss: 0.018858

run [350]:
Style Loss : 0.230973 Content Loss: 0.019205

run [400]:
Style Loss : 0.217789 Content Loss: 0.019600

run [450]:
Style Loss : 0.205721 Content Loss: 0.020040

run [500]:
Style Loss : 0.195875 Content Loss: 0.020440

run [550]:
Style Loss : 0.187535 Content Loss: 0.020883

run [600]:
Style Loss : 0.179758 Content Loss: 0.021256

run [650]:
Style Loss : 0.172308 Content Loss: 0.021667

run [700]:
Style Loss : 0.165952 Content Loss: 0.022014

run [750]:
Style Loss : 0.160100 Content Loss: 0.022311

run [800]:
Style Loss : 0.155051 Content Loss: 0.022603

run [850]:
Style Loss : 0.150604 Content Loss: 0.022870

run [900]:
Style Loss : 0.146701 Content Loss: 0.023126

run [950]:
Style Loss : 0.143171 Content Loss: 0.023337

run [1000]:
Style Loss : 0.140060 Content Loss: 0.023499

run [1050]:
Style Loss : 0.137317 Content Loss: 0.023622

run [1100]:
Style Loss : 0.127223 Content Loss: 0.023737

run [1150]:
Style Loss : 0.123156 Content Loss: 0.023828

run [1200]:
Style Loss : 0.120275 Content Loss: 0.023896

run [1250]:
Style Loss : 0.117903 Content Loss: 0.023969

run [1300]:
Style Loss : 0.116007 Content Loss: 0.024017

run [1350]:
Style Loss : 0.114500 Content Loss: 0.024043

run [1400]:
Style Loss : 0.112924 Content Loss: 0.024060

run [1450]:
Style Loss : 0.111141 Content Loss: 0.024069

run [1500]:
Style Loss : 0.109761 Content Loss: 0.024075

run [1550]:
Style Loss : 0.108576 Content Loss: 0.024071

run [1600]:
Style Loss : 0.107578 Content Loss: 0.024057

run [1650]:
Style Loss : 0.106772 Content Loss: 0.024029

run [1700]:
Style Loss : 0.106073 Content Loss: 0.024017

run [1750]:
Style Loss : 0.105407 Content Loss: 0.024005

run [1800]:
Style Loss : 0.104816 Content Loss: 0.023988

run [1850]:
Style Loss : 0.104222 Content Loss: 0.023978

run [1900]:
Style Loss : 0.103632 Content Loss: 0.023969

run [1950]:
Style Loss : 0.103096 Content Loss: 0.023959

run [2000]:
Style Loss : 0.102591 Content Loss: 0.023950

run [2050]:
Style Loss : 0.102141 Content Loss: 0.023938

run [2100]:
Style Loss : 0.101615 Content Loss: 0.023930

run [2150]:
Style Loss : 0.101202 Content Loss: 0.023917

run [2200]:
Style Loss : 0.100825 Content Loss: 0.023896

run [2250]:
Style Loss : 0.100516 Content Loss: 0.023875

run [2300]:
Style Loss : 0.100237 Content Loss: 0.023851

run [2350]:
Style Loss : 0.099977 Content Loss: 0.023829

run [2400]:
Style Loss : 0.099721 Content Loss: 0.023811

run [2450]:
Style Loss : 0.099476 Content Loss: 0.023790

run [2500]:
Style Loss : 0.099223 Content Loss: 0.023770

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.573244 Content Loss: 0.002229

run [100]:
Style Loss : 1.533522 Content Loss: 0.003740

run [150]:
Style Loss : 1.152232 Content Loss: 0.005464

run [200]:
Style Loss : 0.943495 Content Loss: 0.006746

run [250]:
Style Loss : 0.823794 Content Loss: 0.007716

run [300]:
Style Loss : 0.748682 Content Loss: 0.008692

run [350]:
Style Loss : 0.693926 Content Loss: 0.009481

run [400]:
Style Loss : 0.653090 Content Loss: 0.010217

run [450]:
Style Loss : 0.618314 Content Loss: 0.010945

run [500]:
Style Loss : 0.586819 Content Loss: 0.011677

run [550]:
Style Loss : 0.558711 Content Loss: 0.012327

run [600]:
Style Loss : 0.535246 Content Loss: 0.012911

run [650]:
Style Loss : 0.514308 Content Loss: 0.013473

run [700]:
Style Loss : 0.496048 Content Loss: 0.014009

run [750]:
Style Loss : 0.479695 Content Loss: 0.014502

run [800]:
Style Loss : 0.465728 Content Loss: 0.014922

run [850]:
Style Loss : 0.452949 Content Loss: 0.015396

run [900]:
Style Loss : 0.441780 Content Loss: 0.015751

run [950]:
Style Loss : 0.431024 Content Loss: 0.016100

run [1000]:
Style Loss : 0.420503 Content Loss: 0.016444

run [1050]:
Style Loss : 0.410858 Content Loss: 0.016778

run [1100]:
Style Loss : 0.401354 Content Loss: 0.017135

run [1150]:
Style Loss : 0.391889 Content Loss: 0.017481

run [1200]:
Style Loss : 0.382605 Content Loss: 0.017842

run [1250]:
Style Loss : 0.372951 Content Loss: 0.018182

run [1300]:
Style Loss : 0.363654 Content Loss: 0.018534

run [1350]:
Style Loss : 0.355539 Content Loss: 0.018850

run [1400]:
Style Loss : 0.347327 Content Loss: 0.019233

run [1450]:
Style Loss : 0.339190 Content Loss: 0.019628

run [1500]:
Style Loss : 0.331720 Content Loss: 0.019990

run [1550]:
Style Loss : 0.323895 Content Loss: 0.020395

run [1600]:
Style Loss : 0.316875 Content Loss: 0.020808

run [1650]:
Style Loss : 0.309844 Content Loss: 0.021229

run [1700]:
Style Loss : 0.303205 Content Loss: 0.021614

run [1750]:
Style Loss : 0.297227 Content Loss: 0.021996

run [1800]:
Style Loss : 0.291329 Content Loss: 0.022393

run [1850]:
Style Loss : 0.285213 Content Loss: 0.022769

run [1900]:
Style Loss : 0.279746 Content Loss: 0.023129

run [1950]:
Style Loss : 0.274945 Content Loss: 0.023473

run [2000]:
Style Loss : 0.270524 Content Loss: 0.023776

run [2050]:
Style Loss : 0.266549 Content Loss: 0.024059

run [2100]:
Style Loss : 0.263018 Content Loss: 0.024320

run [2150]:
Style Loss : 0.259601 Content Loss: 0.024565

run [2200]:
Style Loss : 0.256614 Content Loss: 0.024774

run [2250]:
Style Loss : 0.254016 Content Loss: 0.024986

run [2300]:
Style Loss : 0.251838 Content Loss: 0.025132

run [2350]:
Style Loss : 0.249953 Content Loss: 0.025274

run [2400]:
Style Loss : 0.248307 Content Loss: 0.025417

run [2450]:
Style Loss : 0.246433 Content Loss: 0.025497

run [2500]:
Style Loss : 0.244818 Content Loss: 0.025602

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.121377 Content Loss: 0.001950

run [100]:
Style Loss : 1.167377 Content Loss: 0.003372

run [150]:
Style Loss : 0.781098 Content Loss: 0.005626

run [200]:
Style Loss : 0.607957 Content Loss: 0.007519

run [250]:
Style Loss : 0.513326 Content Loss: 0.009052

run [300]:
Style Loss : 0.452178 Content Loss: 0.010308

run [350]:
Style Loss : 0.404641 Content Loss: 0.011082

run [400]:
Style Loss : 0.370283 Content Loss: 0.011606

run [450]:
Style Loss : 0.342867 Content Loss: 0.012142

run [500]:
Style Loss : 0.320396 Content Loss: 0.012635

run [550]:
Style Loss : 0.300113 Content Loss: 0.013024

run [600]:
Style Loss : 0.284142 Content Loss: 0.013357

run [650]:
Style Loss : 0.271156 Content Loss: 0.013651

run [700]:
Style Loss : 0.260424 Content Loss: 0.013904

run [750]:
Style Loss : 0.250673 Content Loss: 0.014154

run [800]:
Style Loss : 0.242878 Content Loss: 0.014366

run [850]:
Style Loss : 0.236592 Content Loss: 0.014555

run [900]:
Style Loss : 0.231243 Content Loss: 0.014745

run [950]:
Style Loss : 0.226656 Content Loss: 0.014904

run [1000]:
Style Loss : 0.222611 Content Loss: 0.015041

run [1050]:
Style Loss : 0.218387 Content Loss: 0.015168

run [1100]:
Style Loss : 0.214917 Content Loss: 0.015279

run [1150]:
Style Loss : 0.211834 Content Loss: 0.015376

run [1200]:
Style Loss : 0.209206 Content Loss: 0.015459

run [1250]:
Style Loss : 0.206845 Content Loss: 0.015540

run [1300]:
Style Loss : 0.204636 Content Loss: 0.015606

run [1350]:
Style Loss : 0.202531 Content Loss: 0.015673

run [1400]:
Style Loss : 0.200516 Content Loss: 0.015727

run [1450]:
Style Loss : 0.198640 Content Loss: 0.015775

run [1500]:
Style Loss : 0.196904 Content Loss: 0.015806

run [1550]:
Style Loss : 0.195213 Content Loss: 0.015845

run [1600]:
Style Loss : 0.193598 Content Loss: 0.015876

run [1650]:
Style Loss : 0.192237 Content Loss: 0.015890

run [1700]:
Style Loss : 0.190914 Content Loss: 0.015916

run [1750]:
Style Loss : 0.189734 Content Loss: 0.015941

run [1800]:
Style Loss : 0.188654 Content Loss: 0.015961

run [1850]:
Style Loss : 0.187624 Content Loss: 0.015985

run [1900]:
Style Loss : 0.186642 Content Loss: 0.016004

run [1950]:
Style Loss : 0.185680 Content Loss: 0.016017

run [2000]:
Style Loss : 0.184709 Content Loss: 0.016036

run [2050]:
Style Loss : 0.183834 Content Loss: 0.016052

run [2100]:
Style Loss : 0.182988 Content Loss: 0.016067

run [2150]:
Style Loss : 0.182023 Content Loss: 0.016083

run [2200]:
Style Loss : 0.181223 Content Loss: 0.016093

run [2250]:
Style Loss : 0.180488 Content Loss: 0.016097

run [2300]:
Style Loss : 0.179756 Content Loss: 0.016101

run [2350]:
Style Loss : 0.179052 Content Loss: 0.016107

run [2400]:
Style Loss : 0.178375 Content Loss: 0.016114

run [2450]:
Style Loss : 0.177744 Content Loss: 0.016123

run [2500]:
Style Loss : 0.177147 Content Loss: 0.016131

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.723493 Content Loss: 0.002680

run [100]:
Style Loss : 0.964318 Content Loss: 0.004893

run [150]:
Style Loss : 0.735109 Content Loss: 0.007352

run [200]:
Style Loss : 0.617607 Content Loss: 0.008896

run [250]:
Style Loss : 0.543828 Content Loss: 0.010144

run [300]:
Style Loss : 0.486515 Content Loss: 0.011117

run [350]:
Style Loss : 0.447784 Content Loss: 0.011717

run [400]:
Style Loss : 0.422418 Content Loss: 0.012185

run [450]:
Style Loss : 0.404688 Content Loss: 0.012664

run [500]:
Style Loss : 0.389420 Content Loss: 0.013126

run [550]:
Style Loss : 0.377222 Content Loss: 0.013519

run [600]:
Style Loss : 0.365997 Content Loss: 0.013925

run [650]:
Style Loss : 0.356398 Content Loss: 0.014290

run [700]:
Style Loss : 0.347162 Content Loss: 0.014689

run [750]:
Style Loss : 0.338815 Content Loss: 0.014994

run [800]:
Style Loss : 0.331505 Content Loss: 0.015297

run [850]:
Style Loss : 0.325232 Content Loss: 0.015552

run [900]:
Style Loss : 0.319475 Content Loss: 0.015815

run [950]:
Style Loss : 0.314194 Content Loss: 0.016071

run [1000]:
Style Loss : 0.307499 Content Loss: 0.016286

run [1050]:
Style Loss : 0.302298 Content Loss: 0.016493

run [1100]:
Style Loss : 0.297425 Content Loss: 0.016694

run [1150]:
Style Loss : 0.292162 Content Loss: 0.016873

run [1200]:
Style Loss : 0.287082 Content Loss: 0.017044

run [1250]:
Style Loss : 0.282682 Content Loss: 0.017198

run [1300]:
Style Loss : 0.279100 Content Loss: 0.017317

run [1350]:
Style Loss : 0.276057 Content Loss: 0.017437

run [1400]:
Style Loss : 0.273343 Content Loss: 0.017547

run [1450]:
Style Loss : 0.270834 Content Loss: 0.017658

run [1500]:
Style Loss : 0.268439 Content Loss: 0.017780

run [1550]:
Style Loss : 0.266363 Content Loss: 0.017879

run [1600]:
Style Loss : 0.264449 Content Loss: 0.017975

run [1650]:
Style Loss : 0.262798 Content Loss: 0.018069

run [1700]:
Style Loss : 0.261320 Content Loss: 0.018149

run [1750]:
Style Loss : 0.259796 Content Loss: 0.018232

run [1800]:
Style Loss : 0.258577 Content Loss: 0.018291

run [1850]:
Style Loss : 0.257401 Content Loss: 0.018362

run [1900]:
Style Loss : 0.256325 Content Loss: 0.018421

run [1950]:
Style Loss : 0.255189 Content Loss: 0.018484

run [2000]:
Style Loss : 0.254177 Content Loss: 0.018539

run [2050]:
Style Loss : 0.253231 Content Loss: 0.018597

run [2100]:
Style Loss : 0.252285 Content Loss: 0.018646

run [2150]:
Style Loss : 0.251431 Content Loss: 0.018688

run [2200]:
Style Loss : 0.250572 Content Loss: 0.018741

run [2250]:
Style Loss : 0.249842 Content Loss: 0.018776

run [2300]:
Style Loss : 0.249090 Content Loss: 0.018826

run [2350]:
Style Loss : 0.248357 Content Loss: 0.018865

run [2400]:
Style Loss : 0.247708 Content Loss: 0.018904

run [2450]:
Style Loss : 0.247083 Content Loss: 0.018938

run [2500]:
Style Loss : 0.246508 Content Loss: 0.018974

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.293392 Content Loss: 0.001880

run [100]:
Style Loss : 1.908849 Content Loss: 0.003128

run [150]:
Style Loss : 1.395563 Content Loss: 0.005022

run [200]:
Style Loss : 1.149361 Content Loss: 0.006891

run [250]:
Style Loss : 1.010408 Content Loss: 0.008408

run [300]:
Style Loss : 0.922314 Content Loss: 0.009695

run [350]:
Style Loss : 0.861499 Content Loss: 0.010605

run [400]:
Style Loss : 0.819252 Content Loss: 0.011361

run [450]:
Style Loss : 0.784360 Content Loss: 0.011903

run [500]:
Style Loss : 0.754661 Content Loss: 0.012431

run [550]:
Style Loss : 0.728993 Content Loss: 0.012826

run [600]:
Style Loss : 0.706559 Content Loss: 0.013184

run [650]:
Style Loss : 0.688568 Content Loss: 0.013493

run [700]:
Style Loss : 0.671702 Content Loss: 0.013750

run [750]:
Style Loss : 0.657398 Content Loss: 0.013955

run [800]:
Style Loss : 0.644589 Content Loss: 0.014152

run [850]:
Style Loss : 0.632822 Content Loss: 0.014297

run [900]:
Style Loss : 0.621812 Content Loss: 0.014473

run [950]:
Style Loss : 0.611907 Content Loss: 0.014618

run [1000]:
Style Loss : 0.602441 Content Loss: 0.014777

run [1050]:
Style Loss : 0.594241 Content Loss: 0.014872

run [1100]:
Style Loss : 0.586448 Content Loss: 0.014982

run [1150]:
Style Loss : 0.578390 Content Loss: 0.015094

run [1200]:
Style Loss : 0.571232 Content Loss: 0.015196

run [1250]:
Style Loss : 0.562882 Content Loss: 0.015318

run [1300]:
Style Loss : 0.553829 Content Loss: 0.015450

run [1350]:
Style Loss : 0.545827 Content Loss: 0.015533

run [1400]:
Style Loss : 0.538972 Content Loss: 0.015628

run [1450]:
Style Loss : 0.533250 Content Loss: 0.015715

run [1500]:
Style Loss : 0.528023 Content Loss: 0.015783

run [1550]:
Style Loss : 0.523149 Content Loss: 0.015853

run [1600]:
Style Loss : 0.518772 Content Loss: 0.015921

run [1650]:
Style Loss : 0.514591 Content Loss: 0.016001

run [1700]:
Style Loss : 0.510907 Content Loss: 0.016071

run [1750]:
Style Loss : 0.507460 Content Loss: 0.016138

run [1800]:
Style Loss : 0.504294 Content Loss: 0.016196

run [1850]:
Style Loss : 0.501304 Content Loss: 0.016252

run [1900]:
Style Loss : 0.498505 Content Loss: 0.016312

run [1950]:
Style Loss : 0.495711 Content Loss: 0.016371

run [2000]:
Style Loss : 0.493103 Content Loss: 0.016433

run [2050]:
Style Loss : 0.490583 Content Loss: 0.016496

run [2100]:
Style Loss : 0.486932 Content Loss: 0.016571

run [2150]:
Style Loss : 0.477227 Content Loss: 0.016641

run [2200]:
Style Loss : 0.471512 Content Loss: 0.016699

run [2250]:
Style Loss : 0.466663 Content Loss: 0.016774

run [2300]:
Style Loss : 0.462310 Content Loss: 0.016831

run [2350]:
Style Loss : 0.458625 Content Loss: 0.016879

run [2400]:
Style Loss : 0.455109 Content Loss: 0.016927

run [2450]:
Style Loss : 0.452145 Content Loss: 0.016982

run [2500]:
Style Loss : 0.449627 Content Loss: 0.017031

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.279469 Content Loss: 0.003483

run [100]:
Style Loss : 2.304939 Content Loss: 0.004785

run [150]:
Style Loss : 1.613163 Content Loss: 0.006415

run [200]:
Style Loss : 1.290638 Content Loss: 0.007937

run [250]:
Style Loss : 1.064778 Content Loss: 0.009362

run [300]:
Style Loss : 0.922886 Content Loss: 0.010231

run [350]:
Style Loss : 0.842058 Content Loss: 0.010992

run [400]:
Style Loss : 0.784712 Content Loss: 0.011663

run [450]:
Style Loss : 0.740744 Content Loss: 0.012135

run [500]:
Style Loss : 0.704798 Content Loss: 0.012528

run [550]:
Style Loss : 0.675441 Content Loss: 0.012917

run [600]:
Style Loss : 0.649342 Content Loss: 0.013306

run [650]:
Style Loss : 0.628745 Content Loss: 0.013593

run [700]:
Style Loss : 0.611855 Content Loss: 0.013873

run [750]:
Style Loss : 0.597969 Content Loss: 0.014115

run [800]:
Style Loss : 0.584857 Content Loss: 0.014338

run [850]:
Style Loss : 0.573800 Content Loss: 0.014539

run [900]:
Style Loss : 0.564304 Content Loss: 0.014746

run [950]:
Style Loss : 0.556178 Content Loss: 0.014949

run [1000]:
Style Loss : 0.547789 Content Loss: 0.015160

run [1050]:
Style Loss : 0.539069 Content Loss: 0.015350

run [1100]:
Style Loss : 0.531727 Content Loss: 0.015511

run [1150]:
Style Loss : 0.524301 Content Loss: 0.015672

run [1200]:
Style Loss : 0.517477 Content Loss: 0.015820

run [1250]:
Style Loss : 0.510926 Content Loss: 0.015953

run [1300]:
Style Loss : 0.505167 Content Loss: 0.016088

run [1350]:
Style Loss : 0.499784 Content Loss: 0.016212

run [1400]:
Style Loss : 0.494345 Content Loss: 0.016348

run [1450]:
Style Loss : 0.488909 Content Loss: 0.016492

run [1500]:
Style Loss : 0.483557 Content Loss: 0.016605

run [1550]:
Style Loss : 0.478100 Content Loss: 0.016736

run [1600]:
Style Loss : 0.473123 Content Loss: 0.016858

run [1650]:
Style Loss : 0.468668 Content Loss: 0.016973

run [1700]:
Style Loss : 0.464513 Content Loss: 0.017102

run [1750]:
Style Loss : 0.460541 Content Loss: 0.017221

run [1800]:
Style Loss : 0.456332 Content Loss: 0.017333

run [1850]:
Style Loss : 0.452513 Content Loss: 0.017439

run [1900]:
Style Loss : 0.449126 Content Loss: 0.017554

run [1950]:
Style Loss : 0.446215 Content Loss: 0.017654

run [2000]:
Style Loss : 0.443587 Content Loss: 0.017754

run [2050]:
Style Loss : 0.441155 Content Loss: 0.017845

run [2100]:
Style Loss : 0.438862 Content Loss: 0.017932

run [2150]:
Style Loss : 0.436827 Content Loss: 0.018025

run [2200]:
Style Loss : 0.434905 Content Loss: 0.018092

run [2250]:
Style Loss : 0.432878 Content Loss: 0.018174

run [2300]:
Style Loss : 0.430898 Content Loss: 0.018245

run [2350]:
Style Loss : 0.428942 Content Loss: 0.018323

run [2400]:
Style Loss : 0.427058 Content Loss: 0.018397

run [2450]:
Style Loss : 0.425281 Content Loss: 0.018476

run [2500]:
Style Loss : 0.423345 Content Loss: 0.018548

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.025163 Content Loss: 0.003455

run [100]:
Style Loss : 2.657453 Content Loss: 0.004948

run [150]:
Style Loss : 2.043481 Content Loss: 0.006562

run [200]:
Style Loss : 1.738370 Content Loss: 0.007837

run [250]:
Style Loss : 1.553004 Content Loss: 0.009029

run [300]:
Style Loss : 1.425881 Content Loss: 0.010192

run [350]:
Style Loss : 1.333047 Content Loss: 0.011155

run [400]:
Style Loss : 1.262286 Content Loss: 0.011887

run [450]:
Style Loss : 1.207563 Content Loss: 0.012631

run [500]:
Style Loss : 1.163557 Content Loss: 0.013232

run [550]:
Style Loss : 1.123837 Content Loss: 0.013833

run [600]:
Style Loss : 1.093808 Content Loss: 0.014264

run [650]:
Style Loss : 1.067308 Content Loss: 0.014705

run [700]:
Style Loss : 1.041847 Content Loss: 0.015024

run [750]:
Style Loss : 1.019781 Content Loss: 0.015373

run [800]:
Style Loss : 1.001724 Content Loss: 0.015612

run [850]:
Style Loss : 0.985747 Content Loss: 0.015848

run [900]:
Style Loss : 0.971679 Content Loss: 0.016062

run [950]:
Style Loss : 0.957775 Content Loss: 0.016317

run [1000]:
Style Loss : 0.940995 Content Loss: 0.016557

run [1050]:
Style Loss : 0.927208 Content Loss: 0.016788

run [1100]:
Style Loss : 0.915168 Content Loss: 0.017019

run [1150]:
Style Loss : 0.904167 Content Loss: 0.017251

run [1200]:
Style Loss : 0.893618 Content Loss: 0.017466

run [1250]:
Style Loss : 0.884145 Content Loss: 0.017657

run [1300]:
Style Loss : 0.875857 Content Loss: 0.017859

run [1350]:
Style Loss : 0.867852 Content Loss: 0.018014

run [1400]:
Style Loss : 0.859965 Content Loss: 0.018189

run [1450]:
Style Loss : 0.852764 Content Loss: 0.018362

run [1500]:
Style Loss : 0.845855 Content Loss: 0.018480

run [1550]:
Style Loss : 0.840294 Content Loss: 0.018625

run [1600]:
Style Loss : 0.834789 Content Loss: 0.018764

run [1650]:
Style Loss : 0.828862 Content Loss: 0.018949

run [1700]:
Style Loss : 0.823226 Content Loss: 0.019072

run [1750]:
Style Loss : 0.817737 Content Loss: 0.019207

run [1800]:
Style Loss : 0.813067 Content Loss: 0.019326

run [1850]:
Style Loss : 0.809055 Content Loss: 0.019450

run [1900]:
Style Loss : 0.804975 Content Loss: 0.019562

run [1950]:
Style Loss : 0.801045 Content Loss: 0.019666

run [2000]:
Style Loss : 0.796962 Content Loss: 0.019796

run [2050]:
Style Loss : 0.794014 Content Loss: 0.019944

run [2100]:
Style Loss : 0.789829 Content Loss: 0.020001

run [2150]:
Style Loss : 0.786657 Content Loss: 0.020080

run [2200]:
Style Loss : 0.783157 Content Loss: 0.020191

run [2250]:
Style Loss : 0.779636 Content Loss: 0.020288

run [2300]:
Style Loss : 0.776286 Content Loss: 0.020384

run [2350]:
Style Loss : 0.773114 Content Loss: 0.020483

run [2400]:
Style Loss : 0.769928 Content Loss: 0.020586

run [2450]:
Style Loss : 0.766472 Content Loss: 0.020659

run [2500]:
Style Loss : 0.763280 Content Loss: 0.020758

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.620979 Content Loss: 0.004213

run [100]:
Style Loss : 1.506155 Content Loss: 0.005171

run [150]:
Style Loss : 1.110344 Content Loss: 0.007043

run [200]:
Style Loss : 0.912050 Content Loss: 0.008461

run [250]:
Style Loss : 0.782552 Content Loss: 0.009916

run [300]:
Style Loss : 0.697414 Content Loss: 0.010943

run [350]:
Style Loss : 0.639303 Content Loss: 0.011705

run [400]:
Style Loss : 0.595890 Content Loss: 0.012547

run [450]:
Style Loss : 0.562284 Content Loss: 0.013342

run [500]:
Style Loss : 0.536226 Content Loss: 0.014008

run [550]:
Style Loss : 0.514138 Content Loss: 0.014597

run [600]:
Style Loss : 0.495143 Content Loss: 0.015172

run [650]:
Style Loss : 0.479135 Content Loss: 0.015684

run [700]:
Style Loss : 0.465116 Content Loss: 0.016146

run [750]:
Style Loss : 0.452489 Content Loss: 0.016535

run [800]:
Style Loss : 0.441181 Content Loss: 0.016932

run [850]:
Style Loss : 0.430413 Content Loss: 0.017314

run [900]:
Style Loss : 0.420726 Content Loss: 0.017651

run [950]:
Style Loss : 0.412173 Content Loss: 0.017948

run [1000]:
Style Loss : 0.403824 Content Loss: 0.018282

run [1050]:
Style Loss : 0.396675 Content Loss: 0.018541

run [1100]:
Style Loss : 0.389591 Content Loss: 0.018829

run [1150]:
Style Loss : 0.382346 Content Loss: 0.019155

run [1200]:
Style Loss : 0.375551 Content Loss: 0.019429

run [1250]:
Style Loss : 0.369321 Content Loss: 0.019701

run [1300]:
Style Loss : 0.363018 Content Loss: 0.019922

run [1350]:
Style Loss : 0.357079 Content Loss: 0.020167

run [1400]:
Style Loss : 0.352155 Content Loss: 0.020380

run [1450]:
Style Loss : 0.347523 Content Loss: 0.020574

run [1500]:
Style Loss : 0.342913 Content Loss: 0.020797

run [1550]:
Style Loss : 0.338573 Content Loss: 0.020988

run [1600]:
Style Loss : 0.334647 Content Loss: 0.021124

run [1650]:
Style Loss : 0.331092 Content Loss: 0.021271

run [1700]:
Style Loss : 0.327618 Content Loss: 0.021439

run [1750]:
Style Loss : 0.323987 Content Loss: 0.021582

run [1800]:
Style Loss : 0.320497 Content Loss: 0.021714

run [1850]:
Style Loss : 0.317111 Content Loss: 0.021854

run [1900]:
Style Loss : 0.314294 Content Loss: 0.021997

run [1950]:
Style Loss : 0.371028 Content Loss: 0.022187

run [2000]:
Style Loss : 0.309075 Content Loss: 0.022223

run [2050]:
Style Loss : 0.307205 Content Loss: 0.022377

run [2100]:
Style Loss : 0.306806 Content Loss: 0.022455

run [2150]:
Style Loss : 0.303372 Content Loss: 0.022547

run [2200]:
Style Loss : 0.311474 Content Loss: 0.022517

run [2250]:
Style Loss : 0.299377 Content Loss: 0.022664

run [2300]:
Style Loss : 0.297729 Content Loss: 0.022706

run [2350]:
Style Loss : 0.324381 Content Loss: 0.022937

run [2400]:
Style Loss : 0.295399 Content Loss: 0.022881

run [2450]:
Style Loss : 0.293759 Content Loss: 0.022885

run [2500]:
Style Loss : 0.317541 Content Loss: 0.022974

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.634622 Content Loss: 0.002127

run [100]:
Style Loss : 0.949917 Content Loss: 0.004675

run [150]:
Style Loss : 0.719577 Content Loss: 0.006399

run [200]:
Style Loss : 0.597059 Content Loss: 0.007732

run [250]:
Style Loss : 0.519671 Content Loss: 0.008601

run [300]:
Style Loss : 0.468935 Content Loss: 0.009098

run [350]:
Style Loss : 0.435815 Content Loss: 0.009576

run [400]:
Style Loss : 0.411290 Content Loss: 0.010012

run [450]:
Style Loss : 0.391358 Content Loss: 0.010432

run [500]:
Style Loss : 0.376510 Content Loss: 0.010762

run [550]:
Style Loss : 0.365252 Content Loss: 0.011070

run [600]:
Style Loss : 0.355444 Content Loss: 0.011326

run [650]:
Style Loss : 0.347597 Content Loss: 0.011542

run [700]:
Style Loss : 0.341137 Content Loss: 0.011740

run [750]:
Style Loss : 0.335104 Content Loss: 0.011926

run [800]:
Style Loss : 0.329736 Content Loss: 0.012085

run [850]:
Style Loss : 0.325561 Content Loss: 0.012204

run [900]:
Style Loss : 0.322205 Content Loss: 0.012304

run [950]:
Style Loss : 0.319280 Content Loss: 0.012401

run [1000]:
Style Loss : 0.316807 Content Loss: 0.012495

run [1050]:
Style Loss : 0.314684 Content Loss: 0.012568

run [1100]:
Style Loss : 0.312806 Content Loss: 0.012643

run [1150]:
Style Loss : 0.310824 Content Loss: 0.012714

run [1200]:
Style Loss : 0.309161 Content Loss: 0.012774

run [1250]:
Style Loss : 0.307595 Content Loss: 0.012843

run [1300]:
Style Loss : 0.306188 Content Loss: 0.012894

run [1350]:
Style Loss : 0.304844 Content Loss: 0.012954

run [1400]:
Style Loss : 0.303525 Content Loss: 0.013012

run [1450]:
Style Loss : 0.302222 Content Loss: 0.013071

run [1500]:
Style Loss : 0.300943 Content Loss: 0.013129

run [1550]:
Style Loss : 0.299818 Content Loss: 0.013165

run [1600]:
Style Loss : 0.298666 Content Loss: 0.013213

run [1650]:
Style Loss : 0.297701 Content Loss: 0.013249

run [1700]:
Style Loss : 0.296671 Content Loss: 0.013295

run [1750]:
Style Loss : 0.295614 Content Loss: 0.013342

run [1800]:
Style Loss : 0.294568 Content Loss: 0.013383

run [1850]:
Style Loss : 0.293639 Content Loss: 0.013418

run [1900]:
Style Loss : 0.292778 Content Loss: 0.013448

run [1950]:
Style Loss : 0.291915 Content Loss: 0.013479

run [2000]:
Style Loss : 0.291027 Content Loss: 0.013515

run [2050]:
Style Loss : 0.290333 Content Loss: 0.013546

run [2100]:
Style Loss : 0.289660 Content Loss: 0.013572

run [2150]:
Style Loss : 0.289053 Content Loss: 0.013600

run [2200]:
Style Loss : 0.288415 Content Loss: 0.013633

run [2250]:
Style Loss : 0.287772 Content Loss: 0.013661

run [2300]:
Style Loss : 0.287159 Content Loss: 0.013691

run [2350]:
Style Loss : 0.286594 Content Loss: 0.013724

run [2400]:
Style Loss : 0.286064 Content Loss: 0.013748

run [2450]:
Style Loss : 0.285587 Content Loss: 0.013776

run [2500]:
Style Loss : 0.285127 Content Loss: 0.013803

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.267079 Content Loss: 0.002611

run [100]:
Style Loss : 0.661896 Content Loss: 0.005500

run [150]:
Style Loss : 0.480534 Content Loss: 0.007402

run [200]:
Style Loss : 0.406666 Content Loss: 0.008466

run [250]:
Style Loss : 0.363770 Content Loss: 0.009213

run [300]:
Style Loss : 0.329382 Content Loss: 0.009698

run [350]:
Style Loss : 0.305080 Content Loss: 0.010138

run [400]:
Style Loss : 0.287312 Content Loss: 0.010536

run [450]:
Style Loss : 0.272957 Content Loss: 0.010855

run [500]:
Style Loss : 0.263442 Content Loss: 0.011111

run [550]:
Style Loss : 0.256054 Content Loss: 0.011356

run [600]:
Style Loss : 0.250019 Content Loss: 0.011576

run [650]:
Style Loss : 0.245166 Content Loss: 0.011763

run [700]:
Style Loss : 0.240956 Content Loss: 0.011895

run [750]:
Style Loss : 0.237324 Content Loss: 0.012036

run [800]:
Style Loss : 0.234219 Content Loss: 0.012142

run [850]:
Style Loss : 0.231419 Content Loss: 0.012256

run [900]:
Style Loss : 0.228959 Content Loss: 0.012348

run [950]:
Style Loss : 0.226913 Content Loss: 0.012433

run [1000]:
Style Loss : 0.224700 Content Loss: 0.012525

run [1050]:
Style Loss : 0.222516 Content Loss: 0.012615

run [1100]:
Style Loss : 0.220476 Content Loss: 0.012709

run [1150]:
Style Loss : 0.218278 Content Loss: 0.012793

run [1200]:
Style Loss : 0.216440 Content Loss: 0.012862

run [1250]:
Style Loss : 0.214811 Content Loss: 0.012935

run [1300]:
Style Loss : 0.213406 Content Loss: 0.013004

run [1350]:
Style Loss : 0.212118 Content Loss: 0.013064

run [1400]:
Style Loss : 0.210888 Content Loss: 0.013114

run [1450]:
Style Loss : 0.209799 Content Loss: 0.013158

run [1500]:
Style Loss : 0.208823 Content Loss: 0.013194

run [1550]:
Style Loss : 0.207963 Content Loss: 0.013226

run [1600]:
Style Loss : 0.207062 Content Loss: 0.013259

run [1650]:
Style Loss : 0.206255 Content Loss: 0.013289

run [1700]:
Style Loss : 0.205522 Content Loss: 0.013311

run [1750]:
Style Loss : 0.204829 Content Loss: 0.013330

run [1800]:
Style Loss : 0.204170 Content Loss: 0.013352

run [1850]:
Style Loss : 0.203555 Content Loss: 0.013370

run [1900]:
Style Loss : 0.202926 Content Loss: 0.013393

run [1950]:
Style Loss : 0.202339 Content Loss: 0.013416

run [2000]:
Style Loss : 0.201708 Content Loss: 0.013443

run [2050]:
Style Loss : 0.201074 Content Loss: 0.013472

run [2100]:
Style Loss : 0.200476 Content Loss: 0.013493

run [2150]:
Style Loss : 0.199958 Content Loss: 0.013513

run [2200]:
Style Loss : 0.199438 Content Loss: 0.013535

run [2250]:
Style Loss : 0.198876 Content Loss: 0.013557

run [2300]:
Style Loss : 0.198356 Content Loss: 0.013576

run [2350]:
Style Loss : 0.197801 Content Loss: 0.013601

run [2400]:
Style Loss : 0.197288 Content Loss: 0.013620

run [2450]:
Style Loss : 0.196818 Content Loss: 0.013639

run [2500]:
Style Loss : 0.196360 Content Loss: 0.013661

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.818968 Content Loss: 0.003173

run [100]:
Style Loss : 0.520028 Content Loss: 0.005238

run [150]:
Style Loss : 0.418434 Content Loss: 0.006362

run [200]:
Style Loss : 0.367791 Content Loss: 0.007134

run [250]:
Style Loss : 0.336077 Content Loss: 0.007850

run [300]:
Style Loss : 0.312628 Content Loss: 0.008523

run [350]:
Style Loss : 0.292672 Content Loss: 0.009273

run [400]:
Style Loss : 0.274551 Content Loss: 0.009957

run [450]:
Style Loss : 0.259648 Content Loss: 0.010635

run [500]:
Style Loss : 0.245820 Content Loss: 0.011385

run [550]:
Style Loss : 0.232948 Content Loss: 0.012193

run [600]:
Style Loss : 0.220741 Content Loss: 0.013069

run [650]:
Style Loss : 0.208422 Content Loss: 0.013964

run [700]:
Style Loss : 0.195349 Content Loss: 0.014952

run [750]:
Style Loss : 0.183585 Content Loss: 0.015939

run [800]:
Style Loss : 0.172977 Content Loss: 0.016947

run [850]:
Style Loss : 0.163482 Content Loss: 0.018021

run [900]:
Style Loss : 0.155511 Content Loss: 0.019037

run [950]:
Style Loss : 0.149105 Content Loss: 0.019988

run [1000]:
Style Loss : 0.143975 Content Loss: 0.020877

run [1050]:
Style Loss : 0.139639 Content Loss: 0.021692

run [1100]:
Style Loss : 0.136722 Content Loss: 0.022633

run [1150]:
Style Loss : 0.133461 Content Loss: 0.023238

run [1200]:
Style Loss : 0.130967 Content Loss: 0.023642

run [1250]:
Style Loss : 0.128993 Content Loss: 0.024077

run [1300]:
Style Loss : 0.127445 Content Loss: 0.024458

run [1350]:
Style Loss : 0.125734 Content Loss: 0.024706

run [1400]:
Style Loss : 0.124117 Content Loss: 0.024915

run [1450]:
Style Loss : 0.122715 Content Loss: 0.025105

run [1500]:
Style Loss : 0.121404 Content Loss: 0.025245

run [1550]:
Style Loss : 0.120300 Content Loss: 0.025383

run [1600]:
Style Loss : 0.119172 Content Loss: 0.025441

run [1650]:
Style Loss : 0.118279 Content Loss: 0.025532

run [1700]:
Style Loss : 0.117277 Content Loss: 0.025603

run [1750]:
Style Loss : 0.116458 Content Loss: 0.025684

run [1800]:
Style Loss : 0.115954 Content Loss: 0.025765

run [1850]:
Style Loss : 0.114902 Content Loss: 0.025808

run [1900]:
Style Loss : 0.114172 Content Loss: 0.025847

run [1950]:
Style Loss : 0.113515 Content Loss: 0.025929

run [2000]:
Style Loss : 0.113285 Content Loss: 0.026004

run [2050]:
Style Loss : 0.112405 Content Loss: 0.026045

run [2100]:
Style Loss : 0.111699 Content Loss: 0.026075

run [2150]:
Style Loss : 0.111104 Content Loss: 0.026089

run [2200]:
Style Loss : 0.110658 Content Loss: 0.026124

run [2250]:
Style Loss : 0.110238 Content Loss: 0.026154

run [2300]:
Style Loss : 0.109644 Content Loss: 0.026159

run [2350]:
Style Loss : 0.109267 Content Loss: 0.026196

run [2400]:
Style Loss : 0.108532 Content Loss: 0.026199

run [2450]:
Style Loss : 0.108364 Content Loss: 0.026247

run [2500]:
Style Loss : 0.107753 Content Loss: 0.026212

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.156436 Content Loss: 0.001621

run [100]:
Style Loss : 0.600076 Content Loss: 0.004305

run [150]:
Style Loss : 0.428978 Content Loss: 0.006460

run [200]:
Style Loss : 0.358582 Content Loss: 0.007600

run [250]:
Style Loss : 0.318187 Content Loss: 0.008230

run [300]:
Style Loss : 0.289178 Content Loss: 0.008739

run [350]:
Style Loss : 0.264990 Content Loss: 0.009122

run [400]:
Style Loss : 0.247532 Content Loss: 0.009424

run [450]:
Style Loss : 0.234772 Content Loss: 0.009727

run [500]:
Style Loss : 0.225206 Content Loss: 0.009987

run [550]:
Style Loss : 0.217496 Content Loss: 0.010218

run [600]:
Style Loss : 0.211146 Content Loss: 0.010432

run [650]:
Style Loss : 0.205905 Content Loss: 0.010635

run [700]:
Style Loss : 0.201679 Content Loss: 0.010824

run [750]:
Style Loss : 0.198116 Content Loss: 0.010977

run [800]:
Style Loss : 0.194811 Content Loss: 0.011130

run [850]:
Style Loss : 0.191559 Content Loss: 0.011272

run [900]:
Style Loss : 0.188550 Content Loss: 0.011417

run [950]:
Style Loss : 0.185713 Content Loss: 0.011549

run [1000]:
Style Loss : 0.183188 Content Loss: 0.011662

run [1050]:
Style Loss : 0.180951 Content Loss: 0.011767

run [1100]:
Style Loss : 0.178904 Content Loss: 0.011870

run [1150]:
Style Loss : 0.176955 Content Loss: 0.011952

run [1200]:
Style Loss : 0.175192 Content Loss: 0.012029

run [1250]:
Style Loss : 0.173533 Content Loss: 0.012105

run [1300]:
Style Loss : 0.171813 Content Loss: 0.012191

run [1350]:
Style Loss : 0.170149 Content Loss: 0.012278

run [1400]:
Style Loss : 0.168738 Content Loss: 0.012349

run [1450]:
Style Loss : 0.167326 Content Loss: 0.012414

run [1500]:
Style Loss : 0.165877 Content Loss: 0.012477

run [1550]:
Style Loss : 0.164641 Content Loss: 0.012537

run [1600]:
Style Loss : 0.163448 Content Loss: 0.012591

run [1650]:
Style Loss : 0.162364 Content Loss: 0.012644

run [1700]:
Style Loss : 0.161264 Content Loss: 0.012691

run [1750]:
Style Loss : 0.160165 Content Loss: 0.012740

run [1800]:
Style Loss : 0.159218 Content Loss: 0.012786

run [1850]:
Style Loss : 0.158291 Content Loss: 0.012829

run [1900]:
Style Loss : 0.157431 Content Loss: 0.012876

run [1950]:
Style Loss : 0.156662 Content Loss: 0.012914

run [2000]:
Style Loss : 0.155916 Content Loss: 0.012951

run [2050]:
Style Loss : 0.155217 Content Loss: 0.012988

run [2100]:
Style Loss : 0.154548 Content Loss: 0.013025

run [2150]:
Style Loss : 0.153913 Content Loss: 0.013063

run [2200]:
Style Loss : 0.153275 Content Loss: 0.013108

run [2250]:
Style Loss : 0.152666 Content Loss: 0.013145

run [2300]:
Style Loss : 0.152092 Content Loss: 0.013184

run [2350]:
Style Loss : 0.151551 Content Loss: 0.013224

run [2400]:
Style Loss : 0.151043 Content Loss: 0.013265

run [2450]:
Style Loss : 0.150572 Content Loss: 0.013305

run [2500]:
Style Loss : 0.150110 Content Loss: 0.013345

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.860873 Content Loss: 0.002815

run [100]:
Style Loss : 2.137850 Content Loss: 0.003943

run [150]:
Style Loss : 1.513153 Content Loss: 0.005913

run [200]:
Style Loss : 1.208470 Content Loss: 0.007714

run [250]:
Style Loss : 1.051461 Content Loss: 0.009121

run [300]:
Style Loss : 0.950275 Content Loss: 0.010306

run [350]:
Style Loss : 0.880749 Content Loss: 0.011222

run [400]:
Style Loss : 0.831062 Content Loss: 0.011888

run [450]:
Style Loss : 0.792096 Content Loss: 0.012486

run [500]:
Style Loss : 0.761072 Content Loss: 0.013034

run [550]:
Style Loss : 0.735696 Content Loss: 0.013431

run [600]:
Style Loss : 0.712336 Content Loss: 0.013764

run [650]:
Style Loss : 0.691645 Content Loss: 0.014128

run [700]:
Style Loss : 0.675462 Content Loss: 0.014398

run [750]:
Style Loss : 0.661973 Content Loss: 0.014639

run [800]:
Style Loss : 0.648870 Content Loss: 0.014902

run [850]:
Style Loss : 0.637652 Content Loss: 0.015135

run [900]:
Style Loss : 0.626855 Content Loss: 0.015352

run [950]:
Style Loss : 0.616974 Content Loss: 0.015557

run [1000]:
Style Loss : 0.608058 Content Loss: 0.015764

run [1050]:
Style Loss : 0.599561 Content Loss: 0.015958

run [1100]:
Style Loss : 0.590910 Content Loss: 0.016147

run [1150]:
Style Loss : 0.582782 Content Loss: 0.016338

run [1200]:
Style Loss : 0.574334 Content Loss: 0.016519

run [1250]:
Style Loss : 0.566314 Content Loss: 0.016693

run [1300]:
Style Loss : 0.558516 Content Loss: 0.016902

run [1350]:
Style Loss : 0.551223 Content Loss: 0.017074

run [1400]:
Style Loss : 0.544170 Content Loss: 0.017277

run [1450]:
Style Loss : 0.537163 Content Loss: 0.017478

run [1500]:
Style Loss : 0.530450 Content Loss: 0.017685

run [1550]:
Style Loss : 0.523808 Content Loss: 0.017912

run [1600]:
Style Loss : 0.516915 Content Loss: 0.018131

run [1650]:
Style Loss : 0.510162 Content Loss: 0.018378

run [1700]:
Style Loss : 0.503522 Content Loss: 0.018593

run [1750]:
Style Loss : 0.497058 Content Loss: 0.018810

run [1800]:
Style Loss : 0.490617 Content Loss: 0.019028

run [1850]:
Style Loss : 0.484410 Content Loss: 0.019254

run [1900]:
Style Loss : 0.478549 Content Loss: 0.019474

run [1950]:
Style Loss : 0.472689 Content Loss: 0.019726

run [2000]:
Style Loss : 0.467283 Content Loss: 0.019965

run [2050]:
Style Loss : 0.461684 Content Loss: 0.020237

run [2100]:
Style Loss : 0.456461 Content Loss: 0.020533

run [2150]:
Style Loss : 0.451149 Content Loss: 0.020791

run [2200]:
Style Loss : 0.445953 Content Loss: 0.021104

run [2250]:
Style Loss : 0.441142 Content Loss: 0.021378

run [2300]:
Style Loss : 0.436153 Content Loss: 0.021695

run [2350]:
Style Loss : 0.431727 Content Loss: 0.022007

run [2400]:
Style Loss : 0.427937 Content Loss: 0.022408

run [2450]:
Style Loss : 0.422773 Content Loss: 0.022594

run [2500]:
Style Loss : 0.420501 Content Loss: 0.023046

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.761317 Content Loss: 0.003700

run [100]:
Style Loss : 0.446338 Content Loss: 0.006966

run [150]:
Style Loss : 0.356211 Content Loss: 0.008529

run [200]:
Style Loss : 0.306954 Content Loss: 0.009393

run [250]:
Style Loss : 0.273610 Content Loss: 0.010135

run [300]:
Style Loss : 0.248251 Content Loss: 0.010779

run [350]:
Style Loss : 0.231059 Content Loss: 0.011313

run [400]:
Style Loss : 0.218043 Content Loss: 0.011827

run [450]:
Style Loss : 0.207532 Content Loss: 0.012258

run [500]:
Style Loss : 0.198768 Content Loss: 0.012651

run [550]:
Style Loss : 0.191010 Content Loss: 0.012997

run [600]:
Style Loss : 0.182973 Content Loss: 0.013360

run [650]:
Style Loss : 0.175421 Content Loss: 0.013673

run [700]:
Style Loss : 0.168856 Content Loss: 0.014028

run [750]:
Style Loss : 0.162650 Content Loss: 0.014366

run [800]:
Style Loss : 0.157311 Content Loss: 0.014681

run [850]:
Style Loss : 0.152379 Content Loss: 0.015017

run [900]:
Style Loss : 0.147964 Content Loss: 0.015336

run [950]:
Style Loss : 0.143695 Content Loss: 0.015666

run [1000]:
Style Loss : 0.139671 Content Loss: 0.015954

run [1050]:
Style Loss : 0.135885 Content Loss: 0.016231

run [1100]:
Style Loss : 0.132828 Content Loss: 0.016437

run [1150]:
Style Loss : 0.130257 Content Loss: 0.016618

run [1200]:
Style Loss : 0.128014 Content Loss: 0.016763

run [1250]:
Style Loss : 0.126163 Content Loss: 0.016876

run [1300]:
Style Loss : 0.124464 Content Loss: 0.016974

run [1350]:
Style Loss : 0.122996 Content Loss: 0.017062

run [1400]:
Style Loss : 0.121653 Content Loss: 0.017131

run [1450]:
Style Loss : 0.120292 Content Loss: 0.017182

run [1500]:
Style Loss : 0.119219 Content Loss: 0.017210

run [1550]:
Style Loss : 0.118224 Content Loss: 0.017240

run [1600]:
Style Loss : 0.117303 Content Loss: 0.017272

run [1650]:
Style Loss : 0.116527 Content Loss: 0.017299

run [1700]:
Style Loss : 0.115855 Content Loss: 0.017315

run [1750]:
Style Loss : 0.115254 Content Loss: 0.017325

run [1800]:
Style Loss : 0.114717 Content Loss: 0.017330

run [1850]:
Style Loss : 0.114225 Content Loss: 0.017339

run [1900]:
Style Loss : 0.113791 Content Loss: 0.017346

run [1950]:
Style Loss : 0.113386 Content Loss: 0.017352

run [2000]:
Style Loss : 0.112985 Content Loss: 0.017359

run [2050]:
Style Loss : 0.112640 Content Loss: 0.017368

run [2100]:
Style Loss : 0.112287 Content Loss: 0.017372

run [2150]:
Style Loss : 0.111999 Content Loss: 0.017376

run [2200]:
Style Loss : 0.111751 Content Loss: 0.017373

run [2250]:
Style Loss : 0.111527 Content Loss: 0.017371

run [2300]:
Style Loss : 0.111313 Content Loss: 0.017368

run [2350]:
Style Loss : 0.111103 Content Loss: 0.017367

run [2400]:
Style Loss : 0.110874 Content Loss: 0.017367

run [2450]:
Style Loss : 0.110657 Content Loss: 0.017369

run [2500]:
Style Loss : 0.110439 Content Loss: 0.017372

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.671305 Content Loss: 0.001819

run [100]:
Style Loss : 1.008904 Content Loss: 0.004261

run [150]:
Style Loss : 0.773079 Content Loss: 0.006333

run [200]:
Style Loss : 0.668042 Content Loss: 0.007480

run [250]:
Style Loss : 0.604899 Content Loss: 0.008378

run [300]:
Style Loss : 0.556154 Content Loss: 0.009140

run [350]:
Style Loss : 0.517386 Content Loss: 0.009744

run [400]:
Style Loss : 0.487585 Content Loss: 0.010247

run [450]:
Style Loss : 0.464904 Content Loss: 0.010659

run [500]:
Style Loss : 0.446308 Content Loss: 0.011066

run [550]:
Style Loss : 0.433058 Content Loss: 0.011407

run [600]:
Style Loss : 0.422264 Content Loss: 0.011735

run [650]:
Style Loss : 0.412873 Content Loss: 0.012048

run [700]:
Style Loss : 0.404087 Content Loss: 0.012336

run [750]:
Style Loss : 0.395827 Content Loss: 0.012638

run [800]:
Style Loss : 0.388188 Content Loss: 0.012920

run [850]:
Style Loss : 0.381341 Content Loss: 0.013219

run [900]:
Style Loss : 0.374637 Content Loss: 0.013502

run [950]:
Style Loss : 0.367967 Content Loss: 0.013800

run [1000]:
Style Loss : 0.361148 Content Loss: 0.014075

run [1050]:
Style Loss : 0.354276 Content Loss: 0.014335

run [1100]:
Style Loss : 0.347292 Content Loss: 0.014658

run [1150]:
Style Loss : 0.340804 Content Loss: 0.014945

run [1200]:
Style Loss : 0.334196 Content Loss: 0.015259

run [1250]:
Style Loss : 0.327228 Content Loss: 0.015575

run [1300]:
Style Loss : 0.320710 Content Loss: 0.015877

run [1350]:
Style Loss : 0.314653 Content Loss: 0.016191

run [1400]:
Style Loss : 0.309233 Content Loss: 0.016483

run [1450]:
Style Loss : 0.304394 Content Loss: 0.016754

run [1500]:
Style Loss : 0.299667 Content Loss: 0.017056

run [1550]:
Style Loss : 0.295333 Content Loss: 0.017337

run [1600]:
Style Loss : 0.291105 Content Loss: 0.017614

run [1650]:
Style Loss : 0.287053 Content Loss: 0.017860

run [1700]:
Style Loss : 0.282976 Content Loss: 0.018138

run [1750]:
Style Loss : 0.279521 Content Loss: 0.018347

run [1800]:
Style Loss : 0.276507 Content Loss: 0.018543

run [1850]:
Style Loss : 0.273684 Content Loss: 0.018725

run [1900]:
Style Loss : 0.271205 Content Loss: 0.018890

run [1950]:
Style Loss : 0.269047 Content Loss: 0.019040

run [2000]:
Style Loss : 0.267142 Content Loss: 0.019165

run [2050]:
Style Loss : 0.265505 Content Loss: 0.019283

run [2100]:
Style Loss : 0.264071 Content Loss: 0.019386

run [2150]:
Style Loss : 0.262825 Content Loss: 0.019481

run [2200]:
Style Loss : 0.261634 Content Loss: 0.019572

run [2250]:
Style Loss : 0.260576 Content Loss: 0.019663

run [2300]:
Style Loss : 0.259613 Content Loss: 0.019743

run [2350]:
Style Loss : 0.258733 Content Loss: 0.019818

run [2400]:
Style Loss : 0.257952 Content Loss: 0.019889

run [2450]:
Style Loss : 0.257263 Content Loss: 0.019949

run [2500]:
Style Loss : 0.256639 Content Loss: 0.020009

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.348364 Content Loss: 0.002719

run [100]:
Style Loss : 0.904416 Content Loss: 0.003103

run [150]:
Style Loss : 0.699437 Content Loss: 0.003663

run [200]:
Style Loss : 0.583655 Content Loss: 0.004364

run [250]:
Style Loss : 0.508630 Content Loss: 0.005090

run [300]:
Style Loss : 0.457708 Content Loss: 0.005775

run [350]:
Style Loss : 0.420198 Content Loss: 0.006565

run [400]:
Style Loss : 0.388482 Content Loss: 0.007375

run [450]:
Style Loss : 0.363745 Content Loss: 0.008151

run [500]:
Style Loss : 0.345136 Content Loss: 0.008850

run [550]:
Style Loss : 0.330716 Content Loss: 0.009452

run [600]:
Style Loss : 0.319255 Content Loss: 0.009920

run [650]:
Style Loss : 0.310623 Content Loss: 0.010306

run [700]:
Style Loss : 0.303509 Content Loss: 0.010587

run [750]:
Style Loss : 0.297331 Content Loss: 0.010861

run [800]:
Style Loss : 0.291820 Content Loss: 0.011047

run [850]:
Style Loss : 0.287087 Content Loss: 0.011217

run [900]:
Style Loss : 0.282742 Content Loss: 0.011365

run [950]:
Style Loss : 0.278731 Content Loss: 0.011528

run [1000]:
Style Loss : 0.275297 Content Loss: 0.011666

run [1050]:
Style Loss : 0.272221 Content Loss: 0.011788

run [1100]:
Style Loss : 0.269308 Content Loss: 0.011917

run [1150]:
Style Loss : 0.266362 Content Loss: 0.012021

run [1200]:
Style Loss : 0.263619 Content Loss: 0.012132

run [1250]:
Style Loss : 0.261035 Content Loss: 0.012245

run [1300]:
Style Loss : 0.258598 Content Loss: 0.012348

run [1350]:
Style Loss : 0.256117 Content Loss: 0.012468

run [1400]:
Style Loss : 0.253763 Content Loss: 0.012584

run [1450]:
Style Loss : 0.251605 Content Loss: 0.012689

run [1500]:
Style Loss : 0.249623 Content Loss: 0.012788

run [1550]:
Style Loss : 0.247674 Content Loss: 0.012902

run [1600]:
Style Loss : 0.245900 Content Loss: 0.013009

run [1650]:
Style Loss : 0.244152 Content Loss: 0.013122

run [1700]:
Style Loss : 0.242436 Content Loss: 0.013219

run [1750]:
Style Loss : 0.240709 Content Loss: 0.013312

run [1800]:
Style Loss : 0.239174 Content Loss: 0.013407

run [1850]:
Style Loss : 0.237638 Content Loss: 0.013511

run [1900]:
Style Loss : 0.236214 Content Loss: 0.013600

run [1950]:
Style Loss : 0.234808 Content Loss: 0.013701

run [2000]:
Style Loss : 0.233523 Content Loss: 0.013786

run [2050]:
Style Loss : 0.232228 Content Loss: 0.013863

run [2100]:
Style Loss : 0.231068 Content Loss: 0.013940

run [2150]:
Style Loss : 0.230049 Content Loss: 0.014004

run [2200]:
Style Loss : 0.229038 Content Loss: 0.014076

run [2250]:
Style Loss : 0.228099 Content Loss: 0.014135

run [2300]:
Style Loss : 0.227264 Content Loss: 0.014193

run [2350]:
Style Loss : 0.226381 Content Loss: 0.014246

run [2400]:
Style Loss : 0.225566 Content Loss: 0.014305

run [2450]:
Style Loss : 0.224796 Content Loss: 0.014353

run [2500]:
Style Loss : 0.224061 Content Loss: 0.014398

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.048798 Content Loss: 0.001841

run [100]:
Style Loss : 0.680933 Content Loss: 0.001729

run [150]:
Style Loss : 0.551124 Content Loss: 0.002164

run [200]:
Style Loss : 0.463748 Content Loss: 0.002662

run [250]:
Style Loss : 0.399698 Content Loss: 0.003284

run [300]:
Style Loss : 0.342417 Content Loss: 0.004045

run [350]:
Style Loss : 0.297568 Content Loss: 0.004882

run [400]:
Style Loss : 0.262976 Content Loss: 0.005741

run [450]:
Style Loss : 0.234872 Content Loss: 0.006688

run [500]:
Style Loss : 0.214019 Content Loss: 0.007568

run [550]:
Style Loss : 0.198745 Content Loss: 0.008301

run [600]:
Style Loss : 0.188340 Content Loss: 0.008858

run [650]:
Style Loss : 0.180812 Content Loss: 0.009292

run [700]:
Style Loss : 0.175322 Content Loss: 0.009547

run [750]:
Style Loss : 0.170876 Content Loss: 0.009750

run [800]:
Style Loss : 0.167020 Content Loss: 0.009904

run [850]:
Style Loss : 0.163628 Content Loss: 0.009995

run [900]:
Style Loss : 0.160526 Content Loss: 0.010080

run [950]:
Style Loss : 0.157865 Content Loss: 0.010156

run [1000]:
Style Loss : 0.155485 Content Loss: 0.010237

run [1050]:
Style Loss : 0.153037 Content Loss: 0.010299

run [1100]:
Style Loss : 0.150879 Content Loss: 0.010362

run [1150]:
Style Loss : 0.148924 Content Loss: 0.010432

run [1200]:
Style Loss : 0.147045 Content Loss: 0.010503

run [1250]:
Style Loss : 0.145331 Content Loss: 0.010552

run [1300]:
Style Loss : 0.143632 Content Loss: 0.010615

run [1350]:
Style Loss : 0.142020 Content Loss: 0.010664

run [1400]:
Style Loss : 0.140617 Content Loss: 0.010720

run [1450]:
Style Loss : 0.139462 Content Loss: 0.010773

run [1500]:
Style Loss : 0.138427 Content Loss: 0.010822

run [1550]:
Style Loss : 0.137466 Content Loss: 0.010872

run [1600]:
Style Loss : 0.136588 Content Loss: 0.010921

run [1650]:
Style Loss : 0.135687 Content Loss: 0.010969

run [1700]:
Style Loss : 0.134888 Content Loss: 0.011028

run [1750]:
Style Loss : 0.134002 Content Loss: 0.011086

run [1800]:
Style Loss : 0.132995 Content Loss: 0.011143

run [1850]:
Style Loss : 0.132060 Content Loss: 0.011193

run [1900]:
Style Loss : 0.131008 Content Loss: 0.011245

run [1950]:
Style Loss : 0.130077 Content Loss: 0.011302

run [2000]:
Style Loss : 0.129231 Content Loss: 0.011349

run [2050]:
Style Loss : 0.128402 Content Loss: 0.011407

run [2100]:
Style Loss : 0.127492 Content Loss: 0.011453

run [2150]:
Style Loss : 0.126658 Content Loss: 0.011493

run [2200]:
Style Loss : 0.125842 Content Loss: 0.011533

run [2250]:
Style Loss : 0.125035 Content Loss: 0.011579

run [2300]:
Style Loss : 0.124183 Content Loss: 0.011611

run [2350]:
Style Loss : 0.123270 Content Loss: 0.011638

run [2400]:
Style Loss : 0.122314 Content Loss: 0.011668

run [2450]:
Style Loss : 0.121282 Content Loss: 0.011689

run [2500]:
Style Loss : 0.120375 Content Loss: 0.011706

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.713539 Content Loss: 0.001540

run [100]:
Style Loss : 1.012247 Content Loss: 0.001703

run [150]:
Style Loss : 0.795830 Content Loss: 0.001820

run [200]:
Style Loss : 0.682465 Content Loss: 0.002034

run [250]:
Style Loss : 0.609559 Content Loss: 0.002281

run [300]:
Style Loss : 0.549843 Content Loss: 0.002547

run [350]:
Style Loss : 0.508383 Content Loss: 0.002763

run [400]:
Style Loss : 0.475385 Content Loss: 0.003010

run [450]:
Style Loss : 0.448966 Content Loss: 0.003255

run [500]:
Style Loss : 0.427406 Content Loss: 0.003540

run [550]:
Style Loss : 0.410812 Content Loss: 0.003814

run [600]:
Style Loss : 0.396706 Content Loss: 0.004104

run [650]:
Style Loss : 0.384175 Content Loss: 0.004406

run [700]:
Style Loss : 0.373418 Content Loss: 0.004659

run [750]:
Style Loss : 0.363976 Content Loss: 0.004915

run [800]:
Style Loss : 0.355951 Content Loss: 0.005150

run [850]:
Style Loss : 0.349468 Content Loss: 0.005375

run [900]:
Style Loss : 0.344113 Content Loss: 0.005565

run [950]:
Style Loss : 0.339690 Content Loss: 0.005729

run [1000]:
Style Loss : 0.335958 Content Loss: 0.005878

run [1050]:
Style Loss : 0.332835 Content Loss: 0.005999

run [1100]:
Style Loss : 0.330337 Content Loss: 0.006093

run [1150]:
Style Loss : 0.328124 Content Loss: 0.006185

run [1200]:
Style Loss : 0.326113 Content Loss: 0.006267

run [1250]:
Style Loss : 0.324187 Content Loss: 0.006335

run [1300]:
Style Loss : 0.322459 Content Loss: 0.006394

run [1350]:
Style Loss : 0.320826 Content Loss: 0.006451

run [1400]:
Style Loss : 0.319291 Content Loss: 0.006499

run [1450]:
Style Loss : 0.317887 Content Loss: 0.006535

run [1500]:
Style Loss : 0.316615 Content Loss: 0.006576

run [1550]:
Style Loss : 0.315376 Content Loss: 0.006607

run [1600]:
Style Loss : 0.314146 Content Loss: 0.006642

run [1650]:
Style Loss : 0.313025 Content Loss: 0.006673

run [1700]:
Style Loss : 0.311901 Content Loss: 0.006695

run [1750]:
Style Loss : 0.310827 Content Loss: 0.006723

run [1800]:
Style Loss : 0.309764 Content Loss: 0.006749

run [1850]:
Style Loss : 0.308741 Content Loss: 0.006772

run [1900]:
Style Loss : 0.307786 Content Loss: 0.006795

run [1950]:
Style Loss : 0.306937 Content Loss: 0.006814

run [2000]:
Style Loss : 0.306101 Content Loss: 0.006833

run [2050]:
Style Loss : 0.305253 Content Loss: 0.006852

run [2100]:
Style Loss : 0.304126 Content Loss: 0.006876

run [2150]:
Style Loss : 0.303008 Content Loss: 0.006894

run [2200]:
Style Loss : 0.302093 Content Loss: 0.006912

run [2250]:
Style Loss : 0.301103 Content Loss: 0.006928

run [2300]:
Style Loss : 0.300125 Content Loss: 0.006942

run [2350]:
Style Loss : 0.299232 Content Loss: 0.006954

run [2400]:
Style Loss : 0.298264 Content Loss: 0.006971

run [2450]:
Style Loss : 0.297250 Content Loss: 0.006986

run [2500]:
Style Loss : 0.296272 Content Loss: 0.006999

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.875275 Content Loss: 0.003294

run [100]:
Style Loss : 0.431746 Content Loss: 0.004642

run [150]:
Style Loss : 0.310585 Content Loss: 0.006271

run [200]:
Style Loss : 0.253239 Content Loss: 0.007783

run [250]:
Style Loss : 0.222781 Content Loss: 0.008836

run [300]:
Style Loss : 0.205445 Content Loss: 0.009589

run [350]:
Style Loss : 0.194442 Content Loss: 0.010106

run [400]:
Style Loss : 0.186360 Content Loss: 0.010440

run [450]:
Style Loss : 0.179798 Content Loss: 0.010738

run [500]:
Style Loss : 0.173929 Content Loss: 0.011041

run [550]:
Style Loss : 0.168723 Content Loss: 0.011313

run [600]:
Style Loss : 0.163642 Content Loss: 0.011570

run [650]:
Style Loss : 0.159345 Content Loss: 0.011826

run [700]:
Style Loss : 0.155456 Content Loss: 0.012074

run [750]:
Style Loss : 0.151958 Content Loss: 0.012275

run [800]:
Style Loss : 0.148790 Content Loss: 0.012469

run [850]:
Style Loss : 0.145924 Content Loss: 0.012636

run [900]:
Style Loss : 0.143367 Content Loss: 0.012817

run [950]:
Style Loss : 0.141150 Content Loss: 0.012957

run [1000]:
Style Loss : 0.139367 Content Loss: 0.013089

run [1050]:
Style Loss : 0.137758 Content Loss: 0.013242

run [1100]:
Style Loss : 0.136260 Content Loss: 0.013388

run [1150]:
Style Loss : 0.134824 Content Loss: 0.013516

run [1200]:
Style Loss : 0.133561 Content Loss: 0.013636

run [1250]:
Style Loss : 0.132442 Content Loss: 0.013749

run [1300]:
Style Loss : 0.131953 Content Loss: 0.013892

run [1350]:
Style Loss : 0.130656 Content Loss: 0.013963

run [1400]:
Style Loss : 0.129837 Content Loss: 0.014051

run [1450]:
Style Loss : 0.128960 Content Loss: 0.014141

run [1500]:
Style Loss : 0.128142 Content Loss: 0.014259

run [1550]:
Style Loss : 0.127414 Content Loss: 0.014357

run [1600]:
Style Loss : 0.126734 Content Loss: 0.014432

run [1650]:
Style Loss : 0.126028 Content Loss: 0.014520

run [1700]:
Style Loss : 0.125907 Content Loss: 0.014685

run [1750]:
Style Loss : 0.124713 Content Loss: 0.014674

run [1800]:
Style Loss : 0.124867 Content Loss: 0.014837

run [1850]:
Style Loss : 0.123755 Content Loss: 0.014848

run [1900]:
Style Loss : 0.123306 Content Loss: 0.014917

run [1950]:
Style Loss : 0.123050 Content Loss: 0.014996

run [2000]:
Style Loss : 0.122292 Content Loss: 0.014988

run [2050]:
Style Loss : 0.121867 Content Loss: 0.015032

run [2100]:
Style Loss : 0.121438 Content Loss: 0.015049

run [2150]:
Style Loss : 0.121086 Content Loss: 0.015088

run [2200]:
Style Loss : 0.120698 Content Loss: 0.015119

run [2250]:
Style Loss : 0.120380 Content Loss: 0.015136

run [2300]:
Style Loss : 0.120318 Content Loss: 0.015170

run [2350]:
Style Loss : 0.119773 Content Loss: 0.015174

run [2400]:
Style Loss : 0.119499 Content Loss: 0.015203

run [2450]:
Style Loss : 0.119820 Content Loss: 0.015288

run [2500]:
Style Loss : 0.120105 Content Loss: 0.015323

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.826890 Content Loss: 0.002792

run [100]:
Style Loss : 0.487697 Content Loss: 0.004944

run [150]:
Style Loss : 0.340568 Content Loss: 0.008448

run [200]:
Style Loss : 0.268811 Content Loss: 0.011976

run [250]:
Style Loss : 0.225832 Content Loss: 0.015001

run [300]:
Style Loss : 0.199322 Content Loss: 0.017398

run [350]:
Style Loss : 0.183642 Content Loss: 0.019056

run [400]:
Style Loss : 0.172536 Content Loss: 0.020087

run [450]:
Style Loss : 0.164367 Content Loss: 0.020828

run [500]:
Style Loss : 0.157882 Content Loss: 0.021164

run [550]:
Style Loss : 0.152190 Content Loss: 0.021353

run [600]:
Style Loss : 0.146927 Content Loss: 0.021552

run [650]:
Style Loss : 0.142492 Content Loss: 0.021692

run [700]:
Style Loss : 0.138642 Content Loss: 0.021793

run [750]:
Style Loss : 0.135592 Content Loss: 0.021924

run [800]:
Style Loss : 0.132963 Content Loss: 0.022012

run [850]:
Style Loss : 0.130629 Content Loss: 0.022100

run [900]:
Style Loss : 0.128434 Content Loss: 0.022225

run [950]:
Style Loss : 0.126281 Content Loss: 0.022348

run [1000]:
Style Loss : 0.124418 Content Loss: 0.022488

run [1050]:
Style Loss : 0.122534 Content Loss: 0.022668

run [1100]:
Style Loss : 0.120652 Content Loss: 0.022809

run [1150]:
Style Loss : 0.119272 Content Loss: 0.022990

run [1200]:
Style Loss : 0.117375 Content Loss: 0.023068

run [1250]:
Style Loss : 0.116082 Content Loss: 0.023220

run [1300]:
Style Loss : 0.114947 Content Loss: 0.023378

run [1350]:
Style Loss : 0.113949 Content Loss: 0.023459

run [1400]:
Style Loss : 0.112888 Content Loss: 0.023532

run [1450]:
Style Loss : 0.112087 Content Loss: 0.023616

run [1500]:
Style Loss : 0.111249 Content Loss: 0.023693

run [1550]:
Style Loss : 0.110560 Content Loss: 0.023762

run [1600]:
Style Loss : 0.109998 Content Loss: 0.023822

run [1650]:
Style Loss : 0.109362 Content Loss: 0.023854

run [1700]:
Style Loss : 0.108816 Content Loss: 0.023902

run [1750]:
Style Loss : 0.108317 Content Loss: 0.023929

run [1800]:
Style Loss : 0.108024 Content Loss: 0.023957

run [1850]:
Style Loss : 0.107360 Content Loss: 0.023998

run [1900]:
Style Loss : 0.106942 Content Loss: 0.024046

run [1950]:
Style Loss : 0.106511 Content Loss: 0.024069

run [2000]:
Style Loss : 0.106153 Content Loss: 0.024091

run [2050]:
Style Loss : 0.105905 Content Loss: 0.024094

run [2100]:
Style Loss : 0.142432 Content Loss: 0.024435

run [2150]:
Style Loss : 0.105855 Content Loss: 0.024154

run [2200]:
Style Loss : 0.104736 Content Loss: 0.024199

run [2250]:
Style Loss : 0.104206 Content Loss: 0.024236

run [2300]:
Style Loss : 0.103939 Content Loss: 0.024256

run [2350]:
Style Loss : 0.103618 Content Loss: 0.024251

run [2400]:
Style Loss : 0.103364 Content Loss: 0.024236

run [2450]:
Style Loss : 0.106063 Content Loss: 0.024224

run [2500]:
Style Loss : 0.102965 Content Loss: 0.024199

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.603385 Content Loss: 0.017004

run [100]:
Style Loss : 1.443276 Content Loss: 0.020706

run [150]:
Style Loss : 1.007509 Content Loss: 0.023830

run [200]:
Style Loss : 0.820754 Content Loss: 0.026422

run [250]:
Style Loss : 0.718615 Content Loss: 0.028303

run [300]:
Style Loss : 0.658777 Content Loss: 0.029462

run [350]:
Style Loss : 0.616525 Content Loss: 0.030370

run [400]:
Style Loss : 0.585184 Content Loss: 0.030976

run [450]:
Style Loss : 0.560168 Content Loss: 0.031555

run [500]:
Style Loss : 0.539437 Content Loss: 0.032015

run [550]:
Style Loss : 0.521350 Content Loss: 0.032347

run [600]:
Style Loss : 0.507615 Content Loss: 0.032639

run [650]:
Style Loss : 0.495348 Content Loss: 0.032926

run [700]:
Style Loss : 0.484814 Content Loss: 0.033193

run [750]:
Style Loss : 0.475811 Content Loss: 0.033514

run [800]:
Style Loss : 0.467678 Content Loss: 0.033752

run [850]:
Style Loss : 0.459971 Content Loss: 0.033944

run [900]:
Style Loss : 0.452280 Content Loss: 0.034202

run [950]:
Style Loss : 0.445615 Content Loss: 0.034344

run [1000]:
Style Loss : 0.439927 Content Loss: 0.034499

run [1050]:
Style Loss : 0.434933 Content Loss: 0.034657

run [1100]:
Style Loss : 0.430514 Content Loss: 0.034765

run [1150]:
Style Loss : 0.426137 Content Loss: 0.034915

run [1200]:
Style Loss : 0.421899 Content Loss: 0.035055

run [1250]:
Style Loss : 0.418358 Content Loss: 0.035193

run [1300]:
Style Loss : 0.414710 Content Loss: 0.035322

run [1350]:
Style Loss : 0.411411 Content Loss: 0.035459

run [1400]:
Style Loss : 0.408294 Content Loss: 0.035544

run [1450]:
Style Loss : 0.405539 Content Loss: 0.035679

run [1500]:
Style Loss : 0.402772 Content Loss: 0.035782

run [1550]:
Style Loss : 0.399851 Content Loss: 0.035861

run [1600]:
Style Loss : 0.397389 Content Loss: 0.035945

run [1650]:
Style Loss : 0.394901 Content Loss: 0.035989

run [1700]:
Style Loss : 0.393103 Content Loss: 0.036097

run [1750]:
Style Loss : 0.391088 Content Loss: 0.036119

run [1800]:
Style Loss : 0.389218 Content Loss: 0.036183

run [1850]:
Style Loss : 0.387566 Content Loss: 0.036225

run [1900]:
Style Loss : 0.385762 Content Loss: 0.036319

run [1950]:
Style Loss : 0.384121 Content Loss: 0.036376

run [2000]:
Style Loss : 0.382668 Content Loss: 0.036401

run [2050]:
Style Loss : 0.381195 Content Loss: 0.036447

run [2100]:
Style Loss : 0.379914 Content Loss: 0.036492

run [2150]:
Style Loss : 0.378735 Content Loss: 0.036541

run [2200]:
Style Loss : 0.377780 Content Loss: 0.036568

run [2250]:
Style Loss : 0.376685 Content Loss: 0.036624

run [2300]:
Style Loss : 0.375909 Content Loss: 0.036655

run [2350]:
Style Loss : 0.374661 Content Loss: 0.036665

run [2400]:
Style Loss : 0.374193 Content Loss: 0.036698

run [2450]:
Style Loss : 0.372979 Content Loss: 0.036736

run [2500]:
Style Loss : 0.372134 Content Loss: 0.036771

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.388306 Content Loss: 0.001465

run [100]:
Style Loss : 0.887984 Content Loss: 0.002042

run [150]:
Style Loss : 0.685854 Content Loss: 0.002616

run [200]:
Style Loss : 0.569151 Content Loss: 0.003330

run [250]:
Style Loss : 0.482118 Content Loss: 0.004389

run [300]:
Style Loss : 0.415381 Content Loss: 0.005597

run [350]:
Style Loss : 0.363802 Content Loss: 0.007116

run [400]:
Style Loss : 0.324420 Content Loss: 0.008559

run [450]:
Style Loss : 0.297113 Content Loss: 0.009725

run [500]:
Style Loss : 0.279431 Content Loss: 0.010636

run [550]:
Style Loss : 0.266070 Content Loss: 0.011194

run [600]:
Style Loss : 0.255732 Content Loss: 0.011556

run [650]:
Style Loss : 0.248344 Content Loss: 0.011763

run [700]:
Style Loss : 0.242672 Content Loss: 0.011940

run [750]:
Style Loss : 0.238058 Content Loss: 0.012066

run [800]:
Style Loss : 0.234142 Content Loss: 0.012181

run [850]:
Style Loss : 0.230195 Content Loss: 0.012299

run [900]:
Style Loss : 0.226452 Content Loss: 0.012387

run [950]:
Style Loss : 0.223362 Content Loss: 0.012471

run [1000]:
Style Loss : 0.220689 Content Loss: 0.012555

run [1050]:
Style Loss : 0.218199 Content Loss: 0.012628

run [1100]:
Style Loss : 0.215957 Content Loss: 0.012681

run [1150]:
Style Loss : 0.213892 Content Loss: 0.012744

run [1200]:
Style Loss : 0.212034 Content Loss: 0.012797

run [1250]:
Style Loss : 0.210321 Content Loss: 0.012864

run [1300]:
Style Loss : 0.208635 Content Loss: 0.012928

run [1350]:
Style Loss : 0.206972 Content Loss: 0.012995

run [1400]:
Style Loss : 0.205364 Content Loss: 0.013057

run [1450]:
Style Loss : 0.203845 Content Loss: 0.013119

run [1500]:
Style Loss : 0.202346 Content Loss: 0.013176

run [1550]:
Style Loss : 0.200926 Content Loss: 0.013234

run [1600]:
Style Loss : 0.199676 Content Loss: 0.013296

run [1650]:
Style Loss : 0.198430 Content Loss: 0.013360

run [1700]:
Style Loss : 0.197278 Content Loss: 0.013424

run [1750]:
Style Loss : 0.196175 Content Loss: 0.013500

run [1800]:
Style Loss : 0.194800 Content Loss: 0.013584

run [1850]:
Style Loss : 0.193464 Content Loss: 0.013648

run [1900]:
Style Loss : 0.192349 Content Loss: 0.013731

run [1950]:
Style Loss : 0.191116 Content Loss: 0.013814

run [2000]:
Style Loss : 0.190079 Content Loss: 0.013894

run [2050]:
Style Loss : 0.190264 Content Loss: 0.014024

run [2100]:
Style Loss : 0.187949 Content Loss: 0.014042

run [2150]:
Style Loss : 0.187061 Content Loss: 0.014133

run [2200]:
Style Loss : 0.186164 Content Loss: 0.014226

run [2250]:
Style Loss : 0.185425 Content Loss: 0.014311

run [2300]:
Style Loss : 0.184317 Content Loss: 0.014363

run [2350]:
Style Loss : 0.183724 Content Loss: 0.014466

run [2400]:
Style Loss : 0.182701 Content Loss: 0.014524

run [2450]:
Style Loss : 0.182201 Content Loss: 0.014639

run [2500]:
Style Loss : 0.183422 Content Loss: 0.014867

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.037939 Content Loss: 0.001972

run [100]:
Style Loss : 0.660870 Content Loss: 0.002741

run [150]:
Style Loss : 0.493037 Content Loss: 0.004066

run [200]:
Style Loss : 0.383339 Content Loss: 0.005760

run [250]:
Style Loss : 0.307773 Content Loss: 0.007854

run [300]:
Style Loss : 0.257371 Content Loss: 0.009765

run [350]:
Style Loss : 0.225514 Content Loss: 0.011104

run [400]:
Style Loss : 0.207919 Content Loss: 0.011710

run [450]:
Style Loss : 0.196929 Content Loss: 0.011946

run [500]:
Style Loss : 0.189483 Content Loss: 0.012085

run [550]:
Style Loss : 0.183602 Content Loss: 0.012160

run [600]:
Style Loss : 0.178877 Content Loss: 0.012261

run [650]:
Style Loss : 0.175080 Content Loss: 0.012350

run [700]:
Style Loss : 0.171400 Content Loss: 0.012416

run [750]:
Style Loss : 0.168514 Content Loss: 0.012464

run [800]:
Style Loss : 0.166047 Content Loss: 0.012496

run [850]:
Style Loss : 0.163729 Content Loss: 0.012532

run [900]:
Style Loss : 0.161411 Content Loss: 0.012581

run [950]:
Style Loss : 0.159042 Content Loss: 0.012632

run [1000]:
Style Loss : 0.157086 Content Loss: 0.012673

run [1050]:
Style Loss : 0.155482 Content Loss: 0.012716

run [1100]:
Style Loss : 0.154092 Content Loss: 0.012756

run [1150]:
Style Loss : 0.152814 Content Loss: 0.012794

run [1200]:
Style Loss : 0.151644 Content Loss: 0.012829

run [1250]:
Style Loss : 0.150581 Content Loss: 0.012869

run [1300]:
Style Loss : 0.149615 Content Loss: 0.012896

run [1350]:
Style Loss : 0.148698 Content Loss: 0.012929

run [1400]:
Style Loss : 0.147636 Content Loss: 0.012959

run [1450]:
Style Loss : 0.146613 Content Loss: 0.012987

run [1500]:
Style Loss : 0.145732 Content Loss: 0.013015

run [1550]:
Style Loss : 0.144949 Content Loss: 0.013040

run [1600]:
Style Loss : 0.143972 Content Loss: 0.013079

run [1650]:
Style Loss : 0.142949 Content Loss: 0.013103

run [1700]:
Style Loss : 0.141930 Content Loss: 0.013130

run [1750]:
Style Loss : 0.141061 Content Loss: 0.013153

run [1800]:
Style Loss : 0.140257 Content Loss: 0.013169

run [1850]:
Style Loss : 0.139515 Content Loss: 0.013183

run [1900]:
Style Loss : 0.138663 Content Loss: 0.013198

run [1950]:
Style Loss : 0.137902 Content Loss: 0.013204

run [2000]:
Style Loss : 0.137182 Content Loss: 0.013212

run [2050]:
Style Loss : 0.136486 Content Loss: 0.013223

run [2100]:
Style Loss : 0.135860 Content Loss: 0.013235

run [2150]:
Style Loss : 0.135216 Content Loss: 0.013248

run [2200]:
Style Loss : 0.134668 Content Loss: 0.013254

run [2250]:
Style Loss : 0.134170 Content Loss: 0.013262

run [2300]:
Style Loss : 0.133712 Content Loss: 0.013269

run [2350]:
Style Loss : 0.133281 Content Loss: 0.013278

run [2400]:
Style Loss : 0.132848 Content Loss: 0.013286

run [2450]:
Style Loss : 0.132411 Content Loss: 0.013298

run [2500]:
Style Loss : 0.131973 Content Loss: 0.013303

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.734115 Content Loss: 0.001153

run [100]:
Style Loss : 0.472895 Content Loss: 0.001248

run [150]:
Style Loss : 0.353804 Content Loss: 0.001636

run [200]:
Style Loss : 0.287875 Content Loss: 0.002173

run [250]:
Style Loss : 0.241745 Content Loss: 0.002923

run [300]:
Style Loss : 0.201534 Content Loss: 0.003991

run [350]:
Style Loss : 0.168013 Content Loss: 0.005150

run [400]:
Style Loss : 0.144382 Content Loss: 0.006349

run [450]:
Style Loss : 0.129549 Content Loss: 0.007287

run [500]:
Style Loss : 0.120765 Content Loss: 0.007888

run [550]:
Style Loss : 0.115124 Content Loss: 0.008214

run [600]:
Style Loss : 0.110834 Content Loss: 0.008360

run [650]:
Style Loss : 0.107496 Content Loss: 0.008440

run [700]:
Style Loss : 0.104657 Content Loss: 0.008496

run [750]:
Style Loss : 0.102272 Content Loss: 0.008539

run [800]:
Style Loss : 0.100096 Content Loss: 0.008605

run [850]:
Style Loss : 0.098215 Content Loss: 0.008646

run [900]:
Style Loss : 0.096496 Content Loss: 0.008708

run [950]:
Style Loss : 0.094917 Content Loss: 0.008773

run [1000]:
Style Loss : 0.093335 Content Loss: 0.008833

run [1050]:
Style Loss : 0.091772 Content Loss: 0.008892

run [1100]:
Style Loss : 0.090391 Content Loss: 0.008946

run [1150]:
Style Loss : 0.089135 Content Loss: 0.009001

run [1200]:
Style Loss : 0.087913 Content Loss: 0.009061

run [1250]:
Style Loss : 0.086665 Content Loss: 0.009130

run [1300]:
Style Loss : 0.085459 Content Loss: 0.009189

run [1350]:
Style Loss : 0.084318 Content Loss: 0.009250

run [1400]:
Style Loss : 0.083188 Content Loss: 0.009314

run [1450]:
Style Loss : 0.082094 Content Loss: 0.009370

run [1500]:
Style Loss : 0.081098 Content Loss: 0.009428

run [1550]:
Style Loss : 0.080162 Content Loss: 0.009488

run [1600]:
Style Loss : 0.079228 Content Loss: 0.009555

run [1650]:
Style Loss : 0.078351 Content Loss: 0.009624

run [1700]:
Style Loss : 0.077557 Content Loss: 0.009702

run [1750]:
Style Loss : 0.076785 Content Loss: 0.009780

run [1800]:
Style Loss : 0.076038 Content Loss: 0.009866

run [1850]:
Style Loss : 0.075279 Content Loss: 0.009953

run [1900]:
Style Loss : 0.074555 Content Loss: 0.010040

run [1950]:
Style Loss : 0.073807 Content Loss: 0.010129

run [2000]:
Style Loss : 0.073137 Content Loss: 0.010212

run [2050]:
Style Loss : 0.072494 Content Loss: 0.010294

run [2100]:
Style Loss : 0.071920 Content Loss: 0.010387

run [2150]:
Style Loss : 0.071364 Content Loss: 0.010446

run [2200]:
Style Loss : 0.070880 Content Loss: 0.010552

run [2250]:
Style Loss : 0.070300 Content Loss: 0.010625

run [2300]:
Style Loss : 0.069849 Content Loss: 0.010722

run [2350]:
Style Loss : 0.069350 Content Loss: 0.010800

run [2400]:
Style Loss : 0.068858 Content Loss: 0.010892

run [2450]:
Style Loss : 0.068500 Content Loss: 0.010983

run [2500]:
Style Loss : 0.068083 Content Loss: 0.011091

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.936691 Content Loss: 0.005347

run [100]:
Style Loss : 1.319932 Content Loss: 0.006957

run [150]:
Style Loss : 0.879535 Content Loss: 0.010663

run [200]:
Style Loss : 0.592385 Content Loss: 0.016428

run [250]:
Style Loss : 0.443396 Content Loss: 0.022450

run [300]:
Style Loss : 0.382574 Content Loss: 0.025499

run [350]:
Style Loss : 0.352629 Content Loss: 0.026615

run [400]:
Style Loss : 0.332958 Content Loss: 0.027247

run [450]:
Style Loss : 0.316670 Content Loss: 0.027687

run [500]:
Style Loss : 0.304309 Content Loss: 0.028060

run [550]:
Style Loss : 0.294595 Content Loss: 0.028497

run [600]:
Style Loss : 0.286957 Content Loss: 0.028863

run [650]:
Style Loss : 0.280113 Content Loss: 0.029266

run [700]:
Style Loss : 0.274131 Content Loss: 0.029596

run [750]:
Style Loss : 0.268814 Content Loss: 0.029810

run [800]:
Style Loss : 0.263627 Content Loss: 0.030035

run [850]:
Style Loss : 0.258689 Content Loss: 0.030246

run [900]:
Style Loss : 0.254544 Content Loss: 0.030394

run [950]:
Style Loss : 0.251148 Content Loss: 0.030543

run [1000]:
Style Loss : 0.248247 Content Loss: 0.030673

run [1050]:
Style Loss : 0.245883 Content Loss: 0.030790

run [1100]:
Style Loss : 0.243779 Content Loss: 0.030899

run [1150]:
Style Loss : 0.241903 Content Loss: 0.031012

run [1200]:
Style Loss : 0.240118 Content Loss: 0.031121

run [1250]:
Style Loss : 0.238412 Content Loss: 0.031223

run [1300]:
Style Loss : 0.236774 Content Loss: 0.031335

run [1350]:
Style Loss : 0.235388 Content Loss: 0.031406

run [1400]:
Style Loss : 0.234134 Content Loss: 0.031488

run [1450]:
Style Loss : 0.232924 Content Loss: 0.031545

run [1500]:
Style Loss : 0.231886 Content Loss: 0.031623

run [1550]:
Style Loss : 0.230658 Content Loss: 0.031659

run [1600]:
Style Loss : 0.229633 Content Loss: 0.031717

run [1650]:
Style Loss : 0.228775 Content Loss: 0.031765

run [1700]:
Style Loss : 0.227760 Content Loss: 0.031799

run [1750]:
Style Loss : 0.226931 Content Loss: 0.031847

run [1800]:
Style Loss : 0.226121 Content Loss: 0.031905

run [1850]:
Style Loss : 0.225344 Content Loss: 0.031972

run [1900]:
Style Loss : 0.224400 Content Loss: 0.032011

run [1950]:
Style Loss : 0.223584 Content Loss: 0.032041

run [2000]:
Style Loss : 0.222835 Content Loss: 0.032099

run [2050]:
Style Loss : 0.222272 Content Loss: 0.032140

run [2100]:
Style Loss : 0.221534 Content Loss: 0.032162

run [2150]:
Style Loss : 0.221023 Content Loss: 0.032180

run [2200]:
Style Loss : 0.220239 Content Loss: 0.032217

run [2250]:
Style Loss : 0.219682 Content Loss: 0.032299

run [2300]:
Style Loss : 0.218852 Content Loss: 0.032289

run [2350]:
Style Loss : 0.218519 Content Loss: 0.032335

run [2400]:
Style Loss : 0.217630 Content Loss: 0.032334

run [2450]:
Style Loss : 0.217152 Content Loss: 0.032343

run [2500]:
Style Loss : 0.216839 Content Loss: 0.032364

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.481934 Content Loss: 0.007040

run [100]:
Style Loss : 0.711291 Content Loss: 0.011662

run [150]:
Style Loss : 0.450346 Content Loss: 0.017049

run [200]:
Style Loss : 0.324160 Content Loss: 0.020727

run [250]:
Style Loss : 0.263566 Content Loss: 0.022460

run [300]:
Style Loss : 0.231851 Content Loss: 0.023410

run [350]:
Style Loss : 0.211899 Content Loss: 0.023973

run [400]:
Style Loss : 0.198115 Content Loss: 0.024243

run [450]:
Style Loss : 0.187739 Content Loss: 0.024533

run [500]:
Style Loss : 0.179923 Content Loss: 0.024821

run [550]:
Style Loss : 0.173699 Content Loss: 0.025032

run [600]:
Style Loss : 0.168572 Content Loss: 0.025216

run [650]:
Style Loss : 0.164227 Content Loss: 0.025394

run [700]:
Style Loss : 0.160662 Content Loss: 0.025497

run [750]:
Style Loss : 0.157404 Content Loss: 0.025578

run [800]:
Style Loss : 0.154447 Content Loss: 0.025629

run [850]:
Style Loss : 0.151889 Content Loss: 0.025666

run [900]:
Style Loss : 0.149665 Content Loss: 0.025694

run [950]:
Style Loss : 0.147767 Content Loss: 0.025733

run [1000]:
Style Loss : 0.145944 Content Loss: 0.025760

run [1050]:
Style Loss : 0.144439 Content Loss: 0.025785

run [1100]:
Style Loss : 0.143033 Content Loss: 0.025790

run [1150]:
Style Loss : 0.141694 Content Loss: 0.025796

run [1200]:
Style Loss : 0.140474 Content Loss: 0.025795

run [1250]:
Style Loss : 0.139208 Content Loss: 0.025782

run [1300]:
Style Loss : 0.137212 Content Loss: 0.025771

run [1350]:
Style Loss : 0.135504 Content Loss: 0.025766

run [1400]:
Style Loss : 0.134078 Content Loss: 0.025760

run [1450]:
Style Loss : 0.132714 Content Loss: 0.025772

run [1500]:
Style Loss : 0.131519 Content Loss: 0.025773

run [1550]:
Style Loss : 0.130411 Content Loss: 0.025783

run [1600]:
Style Loss : 0.129327 Content Loss: 0.025788

run [1650]:
Style Loss : 0.128432 Content Loss: 0.025794

run [1700]:
Style Loss : 0.127606 Content Loss: 0.025812

run [1750]:
Style Loss : 0.126687 Content Loss: 0.025815

run [1800]:
Style Loss : 0.125822 Content Loss: 0.025817

run [1850]:
Style Loss : 0.124549 Content Loss: 0.025827

run [1900]:
Style Loss : 0.123610 Content Loss: 0.025828

run [1950]:
Style Loss : 0.122778 Content Loss: 0.025837

run [2000]:
Style Loss : 0.121976 Content Loss: 0.025828

run [2050]:
Style Loss : 0.121244 Content Loss: 0.025831

run [2100]:
Style Loss : 0.120602 Content Loss: 0.025839

run [2150]:
Style Loss : 0.119992 Content Loss: 0.025844

run [2200]:
Style Loss : 0.119438 Content Loss: 0.025846

run [2250]:
Style Loss : 0.118921 Content Loss: 0.025846

run [2300]:
Style Loss : 0.118405 Content Loss: 0.025846

run [2350]:
Style Loss : 0.117954 Content Loss: 0.025840

run [2400]:
Style Loss : 0.117545 Content Loss: 0.025838

run [2450]:
Style Loss : 0.117127 Content Loss: 0.025832

run [2500]:
Style Loss : 0.116716 Content Loss: 0.025834

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.324158 Content Loss: 0.003810

run [100]:
Style Loss : 1.452408 Content Loss: 0.004169

run [150]:
Style Loss : 1.120802 Content Loss: 0.004877

run [200]:
Style Loss : 0.942275 Content Loss: 0.005784

run [250]:
Style Loss : 0.808799 Content Loss: 0.006836

run [300]:
Style Loss : 0.707131 Content Loss: 0.008134

run [350]:
Style Loss : 0.615946 Content Loss: 0.009605

run [400]:
Style Loss : 0.550223 Content Loss: 0.010854

run [450]:
Style Loss : 0.501574 Content Loss: 0.012077

run [500]:
Style Loss : 0.466772 Content Loss: 0.013242

run [550]:
Style Loss : 0.443507 Content Loss: 0.014132

run [600]:
Style Loss : 0.425987 Content Loss: 0.014827

run [650]:
Style Loss : 0.413324 Content Loss: 0.015339

run [700]:
Style Loss : 0.403161 Content Loss: 0.015785

run [750]:
Style Loss : 0.394796 Content Loss: 0.016111

run [800]:
Style Loss : 0.387671 Content Loss: 0.016313

run [850]:
Style Loss : 0.381434 Content Loss: 0.016512

run [900]:
Style Loss : 0.375955 Content Loss: 0.016656

run [950]:
Style Loss : 0.371321 Content Loss: 0.016773

run [1000]:
Style Loss : 0.367168 Content Loss: 0.016874

run [1050]:
Style Loss : 0.363453 Content Loss: 0.016963

run [1100]:
Style Loss : 0.360225 Content Loss: 0.017049

run [1150]:
Style Loss : 0.357174 Content Loss: 0.017123

run [1200]:
Style Loss : 0.354326 Content Loss: 0.017195

run [1250]:
Style Loss : 0.351725 Content Loss: 0.017267

run [1300]:
Style Loss : 0.349244 Content Loss: 0.017324

run [1350]:
Style Loss : 0.347116 Content Loss: 0.017368

run [1400]:
Style Loss : 0.344912 Content Loss: 0.017429

run [1450]:
Style Loss : 0.342909 Content Loss: 0.017487

run [1500]:
Style Loss : 0.341037 Content Loss: 0.017542

run [1550]:
Style Loss : 0.339364 Content Loss: 0.017596

run [1600]:
Style Loss : 0.337682 Content Loss: 0.017651

run [1650]:
Style Loss : 0.336090 Content Loss: 0.017705

run [1700]:
Style Loss : 0.334505 Content Loss: 0.017752

run [1750]:
Style Loss : 0.332928 Content Loss: 0.017807

run [1800]:
Style Loss : 0.331417 Content Loss: 0.017862

run [1850]:
Style Loss : 0.329918 Content Loss: 0.017917

run [1900]:
Style Loss : 0.328506 Content Loss: 0.017968

run [1950]:
Style Loss : 0.327200 Content Loss: 0.018021

run [2000]:
Style Loss : 0.325990 Content Loss: 0.018059

run [2050]:
Style Loss : 0.324775 Content Loss: 0.018101

run [2100]:
Style Loss : 0.323640 Content Loss: 0.018139

run [2150]:
Style Loss : 0.322582 Content Loss: 0.018181

run [2200]:
Style Loss : 0.321524 Content Loss: 0.018227

run [2250]:
Style Loss : 0.320453 Content Loss: 0.018273

run [2300]:
Style Loss : 0.319427 Content Loss: 0.018314

run [2350]:
Style Loss : 0.318462 Content Loss: 0.018361

run [2400]:
Style Loss : 0.317531 Content Loss: 0.018405

run [2450]:
Style Loss : 0.316673 Content Loss: 0.018438

run [2500]:
Style Loss : 0.315791 Content Loss: 0.018481

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.807333 Content Loss: 0.003428

run [100]:
Style Loss : 0.961958 Content Loss: 0.002895

run [150]:
Style Loss : 0.697936 Content Loss: 0.002983

run [200]:
Style Loss : 0.574810 Content Loss: 0.003238

run [250]:
Style Loss : 0.495032 Content Loss: 0.003699

run [300]:
Style Loss : 0.430557 Content Loss: 0.004285

run [350]:
Style Loss : 0.379143 Content Loss: 0.005032

run [400]:
Style Loss : 0.333796 Content Loss: 0.005954

run [450]:
Style Loss : 0.294232 Content Loss: 0.007033

run [500]:
Style Loss : 0.262560 Content Loss: 0.008090

run [550]:
Style Loss : 0.239628 Content Loss: 0.008943

run [600]:
Style Loss : 0.223428 Content Loss: 0.009725

run [650]:
Style Loss : 0.212229 Content Loss: 0.010285

run [700]:
Style Loss : 0.204146 Content Loss: 0.010608

run [750]:
Style Loss : 0.198074 Content Loss: 0.010848

run [800]:
Style Loss : 0.193412 Content Loss: 0.010953

run [850]:
Style Loss : 0.189585 Content Loss: 0.011057

run [900]:
Style Loss : 0.186326 Content Loss: 0.011114

run [950]:
Style Loss : 0.183432 Content Loss: 0.011145

run [1000]:
Style Loss : 0.180684 Content Loss: 0.011172

run [1050]:
Style Loss : 0.178028 Content Loss: 0.011211

run [1100]:
Style Loss : 0.175663 Content Loss: 0.011237

run [1150]:
Style Loss : 0.173429 Content Loss: 0.011257

run [1200]:
Style Loss : 0.171427 Content Loss: 0.011286

run [1250]:
Style Loss : 0.169554 Content Loss: 0.011312

run [1300]:
Style Loss : 0.167539 Content Loss: 0.011336

run [1350]:
Style Loss : 0.165680 Content Loss: 0.011357

run [1400]:
Style Loss : 0.163916 Content Loss: 0.011377

run [1450]:
Style Loss : 0.162305 Content Loss: 0.011403

run [1500]:
Style Loss : 0.160769 Content Loss: 0.011425

run [1550]:
Style Loss : 0.159328 Content Loss: 0.011450

run [1600]:
Style Loss : 0.157998 Content Loss: 0.011482

run [1650]:
Style Loss : 0.156741 Content Loss: 0.011511

run [1700]:
Style Loss : 0.155573 Content Loss: 0.011536

run [1750]:
Style Loss : 0.154414 Content Loss: 0.011562

run [1800]:
Style Loss : 0.153243 Content Loss: 0.011594

run [1850]:
Style Loss : 0.151946 Content Loss: 0.011629

run [1900]:
Style Loss : 0.150824 Content Loss: 0.011661

run [1950]:
Style Loss : 0.149750 Content Loss: 0.011695

run [2000]:
Style Loss : 0.148824 Content Loss: 0.011723

run [2050]:
Style Loss : 0.147795 Content Loss: 0.011759

run [2100]:
Style Loss : 0.146833 Content Loss: 0.011784

run [2150]:
Style Loss : 0.145927 Content Loss: 0.011814

run [2200]:
Style Loss : 0.145042 Content Loss: 0.011834

run [2250]:
Style Loss : 0.144216 Content Loss: 0.011863

run [2300]:
Style Loss : 0.143398 Content Loss: 0.011891

run [2350]:
Style Loss : 0.142560 Content Loss: 0.011920

run [2400]:
Style Loss : 0.141765 Content Loss: 0.011945

run [2450]:
Style Loss : 0.141011 Content Loss: 0.011975

run [2500]:
Style Loss : 0.140233 Content Loss: 0.012001

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.782415 Content Loss: 0.004363

run [100]:
Style Loss : 1.085014 Content Loss: 0.004670

run [150]:
Style Loss : 0.832577 Content Loss: 0.005500

run [200]:
Style Loss : 0.681956 Content Loss: 0.006382

run [250]:
Style Loss : 0.578561 Content Loss: 0.007313

run [300]:
Style Loss : 0.501521 Content Loss: 0.008230

run [350]:
Style Loss : 0.440344 Content Loss: 0.009202

run [400]:
Style Loss : 0.393483 Content Loss: 0.010105

run [450]:
Style Loss : 0.360860 Content Loss: 0.010781

run [500]:
Style Loss : 0.337362 Content Loss: 0.011424

run [550]:
Style Loss : 0.316675 Content Loss: 0.011934

run [600]:
Style Loss : 0.300069 Content Loss: 0.012330

run [650]:
Style Loss : 0.287399 Content Loss: 0.012682

run [700]:
Style Loss : 0.277452 Content Loss: 0.012935

run [750]:
Style Loss : 0.267352 Content Loss: 0.013185

run [800]:
Style Loss : 0.258255 Content Loss: 0.013359

run [850]:
Style Loss : 0.251225 Content Loss: 0.013566

run [900]:
Style Loss : 0.245312 Content Loss: 0.013727

run [950]:
Style Loss : 0.240022 Content Loss: 0.013888

run [1000]:
Style Loss : 0.235190 Content Loss: 0.014013

run [1050]:
Style Loss : 0.230538 Content Loss: 0.014136

run [1100]:
Style Loss : 0.226607 Content Loss: 0.014287

run [1150]:
Style Loss : 0.223201 Content Loss: 0.014389

run [1200]:
Style Loss : 0.220073 Content Loss: 0.014503

run [1250]:
Style Loss : 0.217406 Content Loss: 0.014614

run [1300]:
Style Loss : 0.215028 Content Loss: 0.014716

run [1350]:
Style Loss : 0.212899 Content Loss: 0.014805

run [1400]:
Style Loss : 0.211118 Content Loss: 0.014891

run [1450]:
Style Loss : 0.209438 Content Loss: 0.014981

run [1500]:
Style Loss : 0.207578 Content Loss: 0.015079

run [1550]:
Style Loss : 0.205818 Content Loss: 0.015145

run [1600]:
Style Loss : 0.204335 Content Loss: 0.015213

run [1650]:
Style Loss : 0.202956 Content Loss: 0.015271

run [1700]:
Style Loss : 0.201615 Content Loss: 0.015338

run [1750]:
Style Loss : 0.200392 Content Loss: 0.015391

run [1800]:
Style Loss : 0.199259 Content Loss: 0.015452

run [1850]:
Style Loss : 0.198178 Content Loss: 0.015513

run [1900]:
Style Loss : 0.196943 Content Loss: 0.015565

run [1950]:
Style Loss : 0.195892 Content Loss: 0.015632

run [2000]:
Style Loss : 0.194912 Content Loss: 0.015664

run [2050]:
Style Loss : 0.194012 Content Loss: 0.015708

run [2100]:
Style Loss : 0.193194 Content Loss: 0.015753

run [2150]:
Style Loss : 0.192486 Content Loss: 0.015809

run [2200]:
Style Loss : 0.191639 Content Loss: 0.015833

run [2250]:
Style Loss : 0.190975 Content Loss: 0.015888

run [2300]:
Style Loss : 0.190353 Content Loss: 0.015921

run [2350]:
Style Loss : 0.189562 Content Loss: 0.015946

run [2400]:
Style Loss : 0.188812 Content Loss: 0.015982

run [2450]:
Style Loss : 0.188334 Content Loss: 0.016061

run [2500]:
Style Loss : 0.187183 Content Loss: 0.016059

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.995342 Content Loss: 0.002122

run [100]:
Style Loss : 1.145771 Content Loss: 0.002039

run [150]:
Style Loss : 0.878066 Content Loss: 0.002165

run [200]:
Style Loss : 0.759784 Content Loss: 0.002367

run [250]:
Style Loss : 0.683997 Content Loss: 0.002669

run [300]:
Style Loss : 0.631227 Content Loss: 0.003048

run [350]:
Style Loss : 0.591054 Content Loss: 0.003383

run [400]:
Style Loss : 0.556877 Content Loss: 0.003790

run [450]:
Style Loss : 0.527182 Content Loss: 0.004177

run [500]:
Style Loss : 0.500039 Content Loss: 0.004521

run [550]:
Style Loss : 0.478195 Content Loss: 0.004837

run [600]:
Style Loss : 0.459339 Content Loss: 0.005106

run [650]:
Style Loss : 0.442631 Content Loss: 0.005360

run [700]:
Style Loss : 0.428110 Content Loss: 0.005574

run [750]:
Style Loss : 0.415883 Content Loss: 0.005803

run [800]:
Style Loss : 0.406204 Content Loss: 0.006005

run [850]:
Style Loss : 0.397903 Content Loss: 0.006222

run [900]:
Style Loss : 0.390755 Content Loss: 0.006421

run [950]:
Style Loss : 0.384591 Content Loss: 0.006617

run [1000]:
Style Loss : 0.379167 Content Loss: 0.006772

run [1050]:
Style Loss : 0.373273 Content Loss: 0.006934

run [1100]:
Style Loss : 0.368445 Content Loss: 0.007068

run [1150]:
Style Loss : 0.364346 Content Loss: 0.007194

run [1200]:
Style Loss : 0.360614 Content Loss: 0.007305

run [1250]:
Style Loss : 0.357329 Content Loss: 0.007401

run [1300]:
Style Loss : 0.354323 Content Loss: 0.007490

run [1350]:
Style Loss : 0.351769 Content Loss: 0.007569

run [1400]:
Style Loss : 0.349372 Content Loss: 0.007648

run [1450]:
Style Loss : 0.347019 Content Loss: 0.007712

run [1500]:
Style Loss : 0.344990 Content Loss: 0.007768

run [1550]:
Style Loss : 0.343101 Content Loss: 0.007821

run [1600]:
Style Loss : 0.341344 Content Loss: 0.007871

run [1650]:
Style Loss : 0.339631 Content Loss: 0.007916

run [1700]:
Style Loss : 0.337974 Content Loss: 0.007954

run [1750]:
Style Loss : 0.336422 Content Loss: 0.007990

run [1800]:
Style Loss : 0.334928 Content Loss: 0.008025

run [1850]:
Style Loss : 0.333480 Content Loss: 0.008059

run [1900]:
Style Loss : 0.332026 Content Loss: 0.008093

run [1950]:
Style Loss : 0.330565 Content Loss: 0.008120

run [2000]:
Style Loss : 0.329244 Content Loss: 0.008144

run [2050]:
Style Loss : 0.327938 Content Loss: 0.008173

run [2100]:
Style Loss : 0.326661 Content Loss: 0.008200

run [2150]:
Style Loss : 0.325339 Content Loss: 0.008225

run [2200]:
Style Loss : 0.324153 Content Loss: 0.008243

run [2250]:
Style Loss : 0.322940 Content Loss: 0.008265

run [2300]:
Style Loss : 0.321902 Content Loss: 0.008278

run [2350]:
Style Loss : 0.320818 Content Loss: 0.008299

run [2400]:
Style Loss : 0.319810 Content Loss: 0.008320

run [2450]:
Style Loss : 0.318802 Content Loss: 0.008342

run [2500]:
Style Loss : 0.317861 Content Loss: 0.008363

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.558941 Content Loss: 0.004158

run [100]:
Style Loss : 1.471413 Content Loss: 0.003627

run [150]:
Style Loss : 1.142274 Content Loss: 0.004019

run [200]:
Style Loss : 0.959716 Content Loss: 0.004574

run [250]:
Style Loss : 0.837298 Content Loss: 0.005129

run [300]:
Style Loss : 0.757373 Content Loss: 0.005671

run [350]:
Style Loss : 0.701669 Content Loss: 0.006147

run [400]:
Style Loss : 0.662485 Content Loss: 0.006623

run [450]:
Style Loss : 0.626412 Content Loss: 0.007101

run [500]:
Style Loss : 0.595864 Content Loss: 0.007492

run [550]:
Style Loss : 0.571908 Content Loss: 0.007766

run [600]:
Style Loss : 0.552283 Content Loss: 0.008015

run [650]:
Style Loss : 0.536291 Content Loss: 0.008279

run [700]:
Style Loss : 0.522544 Content Loss: 0.008519

run [750]:
Style Loss : 0.511234 Content Loss: 0.008723

run [800]:
Style Loss : 0.502265 Content Loss: 0.008923

run [850]:
Style Loss : 0.494540 Content Loss: 0.009107

run [900]:
Style Loss : 0.487808 Content Loss: 0.009272

run [950]:
Style Loss : 0.482512 Content Loss: 0.009403

run [1000]:
Style Loss : 0.478152 Content Loss: 0.009522

run [1050]:
Style Loss : 0.473947 Content Loss: 0.009655

run [1100]:
Style Loss : 0.469785 Content Loss: 0.009771

run [1150]:
Style Loss : 0.465895 Content Loss: 0.009864

run [1200]:
Style Loss : 0.462087 Content Loss: 0.009952

run [1250]:
Style Loss : 0.458855 Content Loss: 0.010024

run [1300]:
Style Loss : 0.456149 Content Loss: 0.010078

run [1350]:
Style Loss : 0.453718 Content Loss: 0.010127

run [1400]:
Style Loss : 0.451500 Content Loss: 0.010185

run [1450]:
Style Loss : 0.449522 Content Loss: 0.010229

run [1500]:
Style Loss : 0.447630 Content Loss: 0.010277

run [1550]:
Style Loss : 0.445676 Content Loss: 0.010323

run [1600]:
Style Loss : 0.443934 Content Loss: 0.010349

run [1650]:
Style Loss : 0.442469 Content Loss: 0.010378

run [1700]:
Style Loss : 0.440946 Content Loss: 0.010412

run [1750]:
Style Loss : 0.439541 Content Loss: 0.010440

run [1800]:
Style Loss : 0.438185 Content Loss: 0.010470

run [1850]:
Style Loss : 0.436843 Content Loss: 0.010502

run [1900]:
Style Loss : 0.435563 Content Loss: 0.010533

run [1950]:
Style Loss : 0.434447 Content Loss: 0.010562

run [2000]:
Style Loss : 0.433378 Content Loss: 0.010592

run [2050]:
Style Loss : 0.432317 Content Loss: 0.010616

run [2100]:
Style Loss : 0.431278 Content Loss: 0.010640

run [2150]:
Style Loss : 0.430274 Content Loss: 0.010663

run [2200]:
Style Loss : 0.429340 Content Loss: 0.010683

run [2250]:
Style Loss : 0.428423 Content Loss: 0.010706

run [2300]:
Style Loss : 0.427509 Content Loss: 0.010728

run [2350]:
Style Loss : 0.426577 Content Loss: 0.010751

run [2400]:
Style Loss : 0.425660 Content Loss: 0.010778

run [2450]:
Style Loss : 0.424833 Content Loss: 0.010798

run [2500]:
Style Loss : 0.424110 Content Loss: 0.010817

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.032999 Content Loss: 0.006052

run [100]:
Style Loss : 2.553036 Content Loss: 0.006364

run [150]:
Style Loss : 2.005448 Content Loss: 0.006929

run [200]:
Style Loss : 1.672392 Content Loss: 0.007664

run [250]:
Style Loss : 1.471399 Content Loss: 0.008341

run [300]:
Style Loss : 1.335972 Content Loss: 0.009063

run [350]:
Style Loss : 1.244462 Content Loss: 0.009873

run [400]:
Style Loss : 1.171614 Content Loss: 0.010618

run [450]:
Style Loss : 1.109955 Content Loss: 0.011165

run [500]:
Style Loss : 1.059932 Content Loss: 0.011682

run [550]:
Style Loss : 1.021803 Content Loss: 0.012061

run [600]:
Style Loss : 0.989234 Content Loss: 0.012542

run [650]:
Style Loss : 0.961524 Content Loss: 0.012853

run [700]:
Style Loss : 0.940715 Content Loss: 0.013149

run [750]:
Style Loss : 0.922155 Content Loss: 0.013431

run [800]:
Style Loss : 0.906784 Content Loss: 0.013673

run [850]:
Style Loss : 0.893447 Content Loss: 0.013921

run [900]:
Style Loss : 0.882811 Content Loss: 0.014092

run [950]:
Style Loss : 0.874147 Content Loss: 0.014272

run [1000]:
Style Loss : 0.866495 Content Loss: 0.014416

run [1050]:
Style Loss : 0.859671 Content Loss: 0.014580

run [1100]:
Style Loss : 0.853611 Content Loss: 0.014706

run [1150]:
Style Loss : 0.847704 Content Loss: 0.014836

run [1200]:
Style Loss : 0.842560 Content Loss: 0.014959

run [1250]:
Style Loss : 0.837885 Content Loss: 0.015058

run [1300]:
Style Loss : 0.833445 Content Loss: 0.015141

run [1350]:
Style Loss : 0.829359 Content Loss: 0.015209

run [1400]:
Style Loss : 0.825759 Content Loss: 0.015271

run [1450]:
Style Loss : 0.822356 Content Loss: 0.015328

run [1500]:
Style Loss : 0.819127 Content Loss: 0.015375

run [1550]:
Style Loss : 0.816067 Content Loss: 0.015446

run [1600]:
Style Loss : 0.813181 Content Loss: 0.015490

run [1650]:
Style Loss : 0.810451 Content Loss: 0.015540

run [1700]:
Style Loss : 0.807645 Content Loss: 0.015579

run [1750]:
Style Loss : 0.805166 Content Loss: 0.015611

run [1800]:
Style Loss : 0.802979 Content Loss: 0.015649

run [1850]:
Style Loss : 0.800836 Content Loss: 0.015681

run [1900]:
Style Loss : 0.798767 Content Loss: 0.015716

run [1950]:
Style Loss : 0.796910 Content Loss: 0.015745

run [2000]:
Style Loss : 0.795174 Content Loss: 0.015770

run [2050]:
Style Loss : 0.793456 Content Loss: 0.015795

run [2100]:
Style Loss : 0.791827 Content Loss: 0.015826

run [2150]:
Style Loss : 0.790122 Content Loss: 0.015862

run [2200]:
Style Loss : 0.788599 Content Loss: 0.015886

run [2250]:
Style Loss : 0.787181 Content Loss: 0.015910

run [2300]:
Style Loss : 0.785778 Content Loss: 0.015934

run [2350]:
Style Loss : 0.784419 Content Loss: 0.015957

run [2400]:
Style Loss : 0.783215 Content Loss: 0.015980

run [2450]:
Style Loss : 0.782126 Content Loss: 0.016002

run [2500]:
Style Loss : 0.780992 Content Loss: 0.016025

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.635294 Content Loss: 0.005219

run [100]:
Style Loss : 1.313922 Content Loss: 0.005175

run [150]:
Style Loss : 0.945866 Content Loss: 0.005675

run [200]:
Style Loss : 0.732782 Content Loss: 0.006447

run [250]:
Style Loss : 0.604001 Content Loss: 0.007333

run [300]:
Style Loss : 0.502428 Content Loss: 0.008336

run [350]:
Style Loss : 0.420599 Content Loss: 0.009399

run [400]:
Style Loss : 0.359066 Content Loss: 0.010316

run [450]:
Style Loss : 0.312390 Content Loss: 0.011189

run [500]:
Style Loss : 0.277467 Content Loss: 0.011929

run [550]:
Style Loss : 0.251455 Content Loss: 0.012651

run [600]:
Style Loss : 0.233231 Content Loss: 0.013177

run [650]:
Style Loss : 0.220297 Content Loss: 0.013654

run [700]:
Style Loss : 0.210536 Content Loss: 0.013938

run [750]:
Style Loss : 0.202932 Content Loss: 0.014110

run [800]:
Style Loss : 0.196334 Content Loss: 0.014264

run [850]:
Style Loss : 0.190536 Content Loss: 0.014348

run [900]:
Style Loss : 0.185599 Content Loss: 0.014418

run [950]:
Style Loss : 0.181073 Content Loss: 0.014486

run [1000]:
Style Loss : 0.176880 Content Loss: 0.014501

run [1050]:
Style Loss : 0.173303 Content Loss: 0.014527

run [1100]:
Style Loss : 0.170152 Content Loss: 0.014538

run [1150]:
Style Loss : 0.167190 Content Loss: 0.014556

run [1200]:
Style Loss : 0.164587 Content Loss: 0.014592

run [1250]:
Style Loss : 0.162048 Content Loss: 0.014616

run [1300]:
Style Loss : 0.159475 Content Loss: 0.014633

run [1350]:
Style Loss : 0.156912 Content Loss: 0.014662

run [1400]:
Style Loss : 0.154700 Content Loss: 0.014700

run [1450]:
Style Loss : 0.152583 Content Loss: 0.014744

run [1500]:
Style Loss : 0.150698 Content Loss: 0.014779

run [1550]:
Style Loss : 0.148834 Content Loss: 0.014811

run [1600]:
Style Loss : 0.146894 Content Loss: 0.014852

run [1650]:
Style Loss : 0.145116 Content Loss: 0.014886

run [1700]:
Style Loss : 0.143469 Content Loss: 0.014926

run [1750]:
Style Loss : 0.141980 Content Loss: 0.014968

run [1800]:
Style Loss : 0.140639 Content Loss: 0.014999

run [1850]:
Style Loss : 0.139346 Content Loss: 0.015035

run [1900]:
Style Loss : 0.138109 Content Loss: 0.015078

run [1950]:
Style Loss : 0.136994 Content Loss: 0.015104

run [2000]:
Style Loss : 0.135930 Content Loss: 0.015139

run [2050]:
Style Loss : 0.134767 Content Loss: 0.015173

run [2100]:
Style Loss : 0.133821 Content Loss: 0.015199

run [2150]:
Style Loss : 0.132938 Content Loss: 0.015223

run [2200]:
Style Loss : 0.132129 Content Loss: 0.015240

run [2250]:
Style Loss : 0.131269 Content Loss: 0.015266

run [2300]:
Style Loss : 0.130592 Content Loss: 0.015301

run [2350]:
Style Loss : 0.129843 Content Loss: 0.015314

run [2400]:
Style Loss : 0.129185 Content Loss: 0.015318

run [2450]:
Style Loss : 0.128809 Content Loss: 0.015339

run [2500]:
Style Loss : 0.127801 Content Loss: 0.015362

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.522053 Content Loss: 0.002625

run [100]:
Style Loss : 0.886073 Content Loss: 0.003043

run [150]:
Style Loss : 0.699001 Content Loss: 0.003990

run [200]:
Style Loss : 0.601393 Content Loss: 0.005186

run [250]:
Style Loss : 0.540593 Content Loss: 0.006202

run [300]:
Style Loss : 0.491597 Content Loss: 0.007147

run [350]:
Style Loss : 0.454460 Content Loss: 0.007791

run [400]:
Style Loss : 0.425795 Content Loss: 0.008437

run [450]:
Style Loss : 0.402240 Content Loss: 0.008904

run [500]:
Style Loss : 0.384850 Content Loss: 0.009322

run [550]:
Style Loss : 0.371880 Content Loss: 0.009699

run [600]:
Style Loss : 0.361904 Content Loss: 0.010015

run [650]:
Style Loss : 0.354063 Content Loss: 0.010291

run [700]:
Style Loss : 0.347887 Content Loss: 0.010497

run [750]:
Style Loss : 0.342789 Content Loss: 0.010659

run [800]:
Style Loss : 0.338372 Content Loss: 0.010812

run [850]:
Style Loss : 0.334382 Content Loss: 0.010950

run [900]:
Style Loss : 0.330816 Content Loss: 0.011068

run [950]:
Style Loss : 0.327498 Content Loss: 0.011172

run [1000]:
Style Loss : 0.324284 Content Loss: 0.011278

run [1050]:
Style Loss : 0.321609 Content Loss: 0.011370

run [1100]:
Style Loss : 0.319177 Content Loss: 0.011444

run [1150]:
Style Loss : 0.317027 Content Loss: 0.011504

run [1200]:
Style Loss : 0.315192 Content Loss: 0.011562

run [1250]:
Style Loss : 0.313443 Content Loss: 0.011614

run [1300]:
Style Loss : 0.311815 Content Loss: 0.011674

run [1350]:
Style Loss : 0.310326 Content Loss: 0.011720

run [1400]:
Style Loss : 0.309059 Content Loss: 0.011755

run [1450]:
Style Loss : 0.307863 Content Loss: 0.011793

run [1500]:
Style Loss : 0.306796 Content Loss: 0.011818

run [1550]:
Style Loss : 0.305812 Content Loss: 0.011848

run [1600]:
Style Loss : 0.304679 Content Loss: 0.011883

run [1650]:
Style Loss : 0.303728 Content Loss: 0.011915

run [1700]:
Style Loss : 0.302790 Content Loss: 0.011945

run [1750]:
Style Loss : 0.301957 Content Loss: 0.011970

run [1800]:
Style Loss : 0.301063 Content Loss: 0.011993

run [1850]:
Style Loss : 0.300153 Content Loss: 0.012022

run [1900]:
Style Loss : 0.299282 Content Loss: 0.012045

run [1950]:
Style Loss : 0.298452 Content Loss: 0.012071

run [2000]:
Style Loss : 0.297662 Content Loss: 0.012095

run [2050]:
Style Loss : 0.296990 Content Loss: 0.012112

run [2100]:
Style Loss : 0.296359 Content Loss: 0.012131

run [2150]:
Style Loss : 0.295778 Content Loss: 0.012152

run [2200]:
Style Loss : 0.295224 Content Loss: 0.012168

run [2250]:
Style Loss : 0.294657 Content Loss: 0.012191

run [2300]:
Style Loss : 0.294063 Content Loss: 0.012214

run [2350]:
Style Loss : 0.293429 Content Loss: 0.012239

run [2400]:
Style Loss : 0.292842 Content Loss: 0.012264

run [2450]:
Style Loss : 0.292283 Content Loss: 0.012277

run [2500]:
Style Loss : 0.291653 Content Loss: 0.012303

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.039543 Content Loss: 0.001674

run [100]:
Style Loss : 0.591977 Content Loss: 0.001950

run [150]:
Style Loss : 0.455829 Content Loss: 0.002184

run [200]:
Style Loss : 0.390650 Content Loss: 0.002511

run [250]:
Style Loss : 0.350494 Content Loss: 0.002855

run [300]:
Style Loss : 0.321975 Content Loss: 0.003248

run [350]:
Style Loss : 0.301665 Content Loss: 0.003531

run [400]:
Style Loss : 0.284650 Content Loss: 0.003806

run [450]:
Style Loss : 0.271629 Content Loss: 0.004004

run [500]:
Style Loss : 0.261114 Content Loss: 0.004207

run [550]:
Style Loss : 0.251801 Content Loss: 0.004413

run [600]:
Style Loss : 0.244620 Content Loss: 0.004578

run [650]:
Style Loss : 0.238417 Content Loss: 0.004731

run [700]:
Style Loss : 0.233323 Content Loss: 0.004884

run [750]:
Style Loss : 0.229154 Content Loss: 0.005012

run [800]:
Style Loss : 0.224977 Content Loss: 0.005157

run [850]:
Style Loss : 0.221250 Content Loss: 0.005276

run [900]:
Style Loss : 0.217317 Content Loss: 0.005391

run [950]:
Style Loss : 0.212733 Content Loss: 0.005508

run [1000]:
Style Loss : 0.208593 Content Loss: 0.005619

run [1050]:
Style Loss : 0.204744 Content Loss: 0.005728

run [1100]:
Style Loss : 0.201153 Content Loss: 0.005831

run [1150]:
Style Loss : 0.198140 Content Loss: 0.005933

run [1200]:
Style Loss : 0.195638 Content Loss: 0.006018

run [1250]:
Style Loss : 0.193445 Content Loss: 0.006104

run [1300]:
Style Loss : 0.191137 Content Loss: 0.006184

run [1350]:
Style Loss : 0.188285 Content Loss: 0.006252

run [1400]:
Style Loss : 0.186250 Content Loss: 0.006328

run [1450]:
Style Loss : 0.184116 Content Loss: 0.006394

run [1500]:
Style Loss : 0.181958 Content Loss: 0.006456

run [1550]:
Style Loss : 0.180021 Content Loss: 0.006523

run [1600]:
Style Loss : 0.178351 Content Loss: 0.006578

run [1650]:
Style Loss : 0.176887 Content Loss: 0.006632

run [1700]:
Style Loss : 0.175591 Content Loss: 0.006693

run [1750]:
Style Loss : 0.174440 Content Loss: 0.006749

run [1800]:
Style Loss : 0.173395 Content Loss: 0.006796

run [1850]:
Style Loss : 0.172459 Content Loss: 0.006840

run [1900]:
Style Loss : 0.171638 Content Loss: 0.006879

run [1950]:
Style Loss : 0.170860 Content Loss: 0.006922

run [2000]:
Style Loss : 0.170040 Content Loss: 0.006963

run [2050]:
Style Loss : 0.168798 Content Loss: 0.007002

run [2100]:
Style Loss : 0.167798 Content Loss: 0.007042

run [2150]:
Style Loss : 0.166995 Content Loss: 0.007076

run [2200]:
Style Loss : 0.166266 Content Loss: 0.007108

run [2250]:
Style Loss : 0.165569 Content Loss: 0.007139

run [2300]:
Style Loss : 0.164947 Content Loss: 0.007168

run [2350]:
Style Loss : 0.164368 Content Loss: 0.007196

run [2400]:
Style Loss : 0.163756 Content Loss: 0.007229

run [2450]:
Style Loss : 0.163196 Content Loss: 0.007253

run [2500]:
Style Loss : 0.162667 Content Loss: 0.007284

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.878482 Content Loss: 0.002575

run [100]:
Style Loss : 0.533370 Content Loss: 0.003501

run [150]:
Style Loss : 0.395655 Content Loss: 0.004696

run [200]:
Style Loss : 0.317816 Content Loss: 0.006059

run [250]:
Style Loss : 0.269387 Content Loss: 0.007342

run [300]:
Style Loss : 0.237848 Content Loss: 0.008415

run [350]:
Style Loss : 0.216968 Content Loss: 0.009368

run [400]:
Style Loss : 0.201974 Content Loss: 0.010159

run [450]:
Style Loss : 0.190829 Content Loss: 0.010751

run [500]:
Style Loss : 0.182334 Content Loss: 0.011127

run [550]:
Style Loss : 0.175392 Content Loss: 0.011526

run [600]:
Style Loss : 0.169022 Content Loss: 0.011860

run [650]:
Style Loss : 0.163292 Content Loss: 0.012181

run [700]:
Style Loss : 0.157907 Content Loss: 0.012433

run [750]:
Style Loss : 0.152920 Content Loss: 0.012679

run [800]:
Style Loss : 0.148721 Content Loss: 0.012921

run [850]:
Style Loss : 0.144615 Content Loss: 0.013175

run [900]:
Style Loss : 0.140566 Content Loss: 0.013448

run [950]:
Style Loss : 0.136868 Content Loss: 0.013691

run [1000]:
Style Loss : 0.133255 Content Loss: 0.013939

run [1050]:
Style Loss : 0.130043 Content Loss: 0.014177

run [1100]:
Style Loss : 0.126951 Content Loss: 0.014420

run [1150]:
Style Loss : 0.124046 Content Loss: 0.014653

run [1200]:
Style Loss : 0.121183 Content Loss: 0.014887

run [1250]:
Style Loss : 0.118715 Content Loss: 0.015104

run [1300]:
Style Loss : 0.116332 Content Loss: 0.015307

run [1350]:
Style Loss : 0.114464 Content Loss: 0.015550

run [1400]:
Style Loss : 0.112769 Content Loss: 0.015840

run [1450]:
Style Loss : 0.111024 Content Loss: 0.016040

run [1500]:
Style Loss : 0.109950 Content Loss: 0.016347

run [1550]:
Style Loss : 0.108429 Content Loss: 0.016626

run [1600]:
Style Loss : 0.109230 Content Loss: 0.016926

run [1650]:
Style Loss : 0.107312 Content Loss: 0.017235

run [1700]:
Style Loss : 0.105957 Content Loss: 0.017477

run [1750]:
Style Loss : 0.138066 Content Loss: 0.018599

run [1800]:
Style Loss : 0.104753 Content Loss: 0.018256

run [1850]:
Style Loss : 0.103845 Content Loss: 0.018477

run [1900]:
Style Loss : 0.126820 Content Loss: 0.019324

run [1950]:
Style Loss : 0.100157 Content Loss: 0.019066

run [2000]:
Style Loss : 0.098961 Content Loss: 0.019442

run [2050]:
Style Loss : 0.097261 Content Loss: 0.019660

run [2100]:
Style Loss : 0.095002 Content Loss: 0.019811

run [2150]:
Style Loss : 0.094514 Content Loss: 0.020026

run [2200]:
Style Loss : 0.093791 Content Loss: 0.020139

run [2250]:
Style Loss : 0.102040 Content Loss: 0.020412

run [2300]:
Style Loss : 0.091179 Content Loss: 0.020250

run [2350]:
Style Loss : 0.090673 Content Loss: 0.020267

run [2400]:
Style Loss : 0.089672 Content Loss: 0.020279

run [2450]:
Style Loss : 0.088638 Content Loss: 0.020235

run [2500]:
Style Loss : 0.087972 Content Loss: 0.020182

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.769356 Content Loss: 0.001207

run [100]:
Style Loss : 0.494557 Content Loss: 0.001541

run [150]:
Style Loss : 0.387446 Content Loss: 0.001938

run [200]:
Style Loss : 0.334125 Content Loss: 0.002370

run [250]:
Style Loss : 0.297850 Content Loss: 0.002868

run [300]:
Style Loss : 0.269105 Content Loss: 0.003263

run [350]:
Style Loss : 0.246884 Content Loss: 0.003649

run [400]:
Style Loss : 0.229046 Content Loss: 0.003979

run [450]:
Style Loss : 0.215998 Content Loss: 0.004271

run [500]:
Style Loss : 0.206033 Content Loss: 0.004523

run [550]:
Style Loss : 0.197805 Content Loss: 0.004773

run [600]:
Style Loss : 0.191235 Content Loss: 0.004990

run [650]:
Style Loss : 0.185681 Content Loss: 0.005217

run [700]:
Style Loss : 0.178602 Content Loss: 0.005413

run [750]:
Style Loss : 0.173270 Content Loss: 0.005565

run [800]:
Style Loss : 0.169129 Content Loss: 0.005724

run [850]:
Style Loss : 0.165283 Content Loss: 0.005871

run [900]:
Style Loss : 0.161107 Content Loss: 0.006026

run [950]:
Style Loss : 0.157393 Content Loss: 0.006155

run [1000]:
Style Loss : 0.154225 Content Loss: 0.006287

run [1050]:
Style Loss : 0.151583 Content Loss: 0.006406

run [1100]:
Style Loss : 0.149476 Content Loss: 0.006512

run [1150]:
Style Loss : 0.147542 Content Loss: 0.006613

run [1200]:
Style Loss : 0.145711 Content Loss: 0.006711

run [1250]:
Style Loss : 0.144124 Content Loss: 0.006785

run [1300]:
Style Loss : 0.142450 Content Loss: 0.006868

run [1350]:
Style Loss : 0.140968 Content Loss: 0.006930

run [1400]:
Style Loss : 0.139505 Content Loss: 0.006983

run [1450]:
Style Loss : 0.138173 Content Loss: 0.007051

run [1500]:
Style Loss : 0.136909 Content Loss: 0.007116

run [1550]:
Style Loss : 0.135761 Content Loss: 0.007179

run [1600]:
Style Loss : 0.134574 Content Loss: 0.007241

run [1650]:
Style Loss : 0.133395 Content Loss: 0.007289

run [1700]:
Style Loss : 0.132221 Content Loss: 0.007355

run [1750]:
Style Loss : 0.131126 Content Loss: 0.007402

run [1800]:
Style Loss : 0.130067 Content Loss: 0.007452

run [1850]:
Style Loss : 0.129035 Content Loss: 0.007502

run [1900]:
Style Loss : 0.128074 Content Loss: 0.007550

run [1950]:
Style Loss : 0.126168 Content Loss: 0.007602

run [2000]:
Style Loss : 0.123581 Content Loss: 0.007628

run [2050]:
Style Loss : 0.122271 Content Loss: 0.007650

run [2100]:
Style Loss : 0.121295 Content Loss: 0.007672

run [2150]:
Style Loss : 0.120382 Content Loss: 0.007700

run [2200]:
Style Loss : 0.119537 Content Loss: 0.007725

run [2250]:
Style Loss : 0.118676 Content Loss: 0.007759

run [2300]:
Style Loss : 0.117774 Content Loss: 0.007787

run [2350]:
Style Loss : 0.116924 Content Loss: 0.007811

run [2400]:
Style Loss : 0.116170 Content Loss: 0.007829

run [2450]:
Style Loss : 0.115414 Content Loss: 0.007847

run [2500]:
Style Loss : 0.114706 Content Loss: 0.007863

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.384610 Content Loss: 0.002357

run [100]:
Style Loss : 1.507775 Content Loss: 0.002373

run [150]:
Style Loss : 1.181063 Content Loss: 0.002494

run [200]:
Style Loss : 0.999066 Content Loss: 0.002658

run [250]:
Style Loss : 0.886783 Content Loss: 0.002872

run [300]:
Style Loss : 0.797679 Content Loss: 0.003151

run [350]:
Style Loss : 0.730797 Content Loss: 0.003417

run [400]:
Style Loss : 0.678949 Content Loss: 0.003717

run [450]:
Style Loss : 0.636394 Content Loss: 0.003985

run [500]:
Style Loss : 0.601020 Content Loss: 0.004312

run [550]:
Style Loss : 0.569540 Content Loss: 0.004595

run [600]:
Style Loss : 0.544254 Content Loss: 0.004862

run [650]:
Style Loss : 0.524005 Content Loss: 0.005143

run [700]:
Style Loss : 0.505546 Content Loss: 0.005423

run [750]:
Style Loss : 0.489801 Content Loss: 0.005641

run [800]:
Style Loss : 0.475735 Content Loss: 0.005891

run [850]:
Style Loss : 0.463600 Content Loss: 0.006112

run [900]:
Style Loss : 0.453086 Content Loss: 0.006331

run [950]:
Style Loss : 0.443384 Content Loss: 0.006512

run [1000]:
Style Loss : 0.435118 Content Loss: 0.006664

run [1050]:
Style Loss : 0.427634 Content Loss: 0.006815

run [1100]:
Style Loss : 0.420999 Content Loss: 0.006947

run [1150]:
Style Loss : 0.415448 Content Loss: 0.007060

run [1200]:
Style Loss : 0.410495 Content Loss: 0.007173

run [1250]:
Style Loss : 0.406204 Content Loss: 0.007262

run [1300]:
Style Loss : 0.402167 Content Loss: 0.007350

run [1350]:
Style Loss : 0.398324 Content Loss: 0.007418

run [1400]:
Style Loss : 0.394870 Content Loss: 0.007492

run [1450]:
Style Loss : 0.391761 Content Loss: 0.007555

run [1500]:
Style Loss : 0.389243 Content Loss: 0.007614

run [1550]:
Style Loss : 0.386608 Content Loss: 0.007672

run [1600]:
Style Loss : 0.384008 Content Loss: 0.007726

run [1650]:
Style Loss : 0.381402 Content Loss: 0.007781

run [1700]:
Style Loss : 0.379034 Content Loss: 0.007828

run [1750]:
Style Loss : 0.376677 Content Loss: 0.007873

run [1800]:
Style Loss : 0.374232 Content Loss: 0.007925

run [1850]:
Style Loss : 0.371918 Content Loss: 0.007969

run [1900]:
Style Loss : 0.369695 Content Loss: 0.008009

run [1950]:
Style Loss : 0.367737 Content Loss: 0.008049

run [2000]:
Style Loss : 0.365682 Content Loss: 0.008091

run [2050]:
Style Loss : 0.363480 Content Loss: 0.008126

run [2100]:
Style Loss : 0.361418 Content Loss: 0.008159

run [2150]:
Style Loss : 0.359639 Content Loss: 0.008184

run [2200]:
Style Loss : 0.357991 Content Loss: 0.008216

run [2250]:
Style Loss : 0.356156 Content Loss: 0.008246

run [2300]:
Style Loss : 0.354376 Content Loss: 0.008276

run [2350]:
Style Loss : 0.352629 Content Loss: 0.008306

run [2400]:
Style Loss : 0.350999 Content Loss: 0.008332

run [2450]:
Style Loss : 0.349343 Content Loss: 0.008367

run [2500]:
Style Loss : 0.347766 Content Loss: 0.008398

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.770194 Content Loss: 0.001849

run [100]:
Style Loss : 0.485638 Content Loss: 0.002536

run [150]:
Style Loss : 0.349379 Content Loss: 0.003316

run [200]:
Style Loss : 0.280075 Content Loss: 0.004199

run [250]:
Style Loss : 0.237479 Content Loss: 0.005003

run [300]:
Style Loss : 0.208959 Content Loss: 0.005830

run [350]:
Style Loss : 0.189556 Content Loss: 0.006448

run [400]:
Style Loss : 0.175381 Content Loss: 0.006908

run [450]:
Style Loss : 0.164908 Content Loss: 0.007248

run [500]:
Style Loss : 0.156196 Content Loss: 0.007475

run [550]:
Style Loss : 0.149679 Content Loss: 0.007631

run [600]:
Style Loss : 0.143959 Content Loss: 0.007808

run [650]:
Style Loss : 0.139368 Content Loss: 0.007929

run [700]:
Style Loss : 0.135402 Content Loss: 0.008036

run [750]:
Style Loss : 0.131785 Content Loss: 0.008169

run [800]:
Style Loss : 0.128233 Content Loss: 0.008271

run [850]:
Style Loss : 0.125222 Content Loss: 0.008362

run [900]:
Style Loss : 0.122477 Content Loss: 0.008444

run [950]:
Style Loss : 0.120123 Content Loss: 0.008522

run [1000]:
Style Loss : 0.118005 Content Loss: 0.008605

run [1050]:
Style Loss : 0.116149 Content Loss: 0.008682

run [1100]:
Style Loss : 0.114481 Content Loss: 0.008754

run [1150]:
Style Loss : 0.113027 Content Loss: 0.008825

run [1200]:
Style Loss : 0.111612 Content Loss: 0.008876

run [1250]:
Style Loss : 0.110336 Content Loss: 0.008940

run [1300]:
Style Loss : 0.109257 Content Loss: 0.008984

run [1350]:
Style Loss : 0.108199 Content Loss: 0.009031

run [1400]:
Style Loss : 0.107175 Content Loss: 0.009081

run [1450]:
Style Loss : 0.106348 Content Loss: 0.009114

run [1500]:
Style Loss : 0.105513 Content Loss: 0.009156

run [1550]:
Style Loss : 0.104699 Content Loss: 0.009187

run [1600]:
Style Loss : 0.103938 Content Loss: 0.009224

run [1650]:
Style Loss : 0.103215 Content Loss: 0.009253

run [1700]:
Style Loss : 0.102569 Content Loss: 0.009279

run [1750]:
Style Loss : 0.101940 Content Loss: 0.009307

run [1800]:
Style Loss : 0.101359 Content Loss: 0.009333

run [1850]:
Style Loss : 0.100820 Content Loss: 0.009356

run [1900]:
Style Loss : 0.100303 Content Loss: 0.009380

run [1950]:
Style Loss : 0.099767 Content Loss: 0.009399

run [2000]:
Style Loss : 0.099253 Content Loss: 0.009417

run [2050]:
Style Loss : 0.098747 Content Loss: 0.009435

run [2100]:
Style Loss : 0.098272 Content Loss: 0.009450

run [2150]:
Style Loss : 0.097801 Content Loss: 0.009467

run [2200]:
Style Loss : 0.097334 Content Loss: 0.009476

run [2250]:
Style Loss : 0.096928 Content Loss: 0.009490

run [2300]:
Style Loss : 0.096551 Content Loss: 0.009500

run [2350]:
Style Loss : 0.096174 Content Loss: 0.009514

run [2400]:
Style Loss : 0.095766 Content Loss: 0.009524

run [2450]:
Style Loss : 0.095397 Content Loss: 0.009534

run [2500]:
Style Loss : 0.095010 Content Loss: 0.009550

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.584637 Content Loss: 0.002468

run [100]:
Style Loss : 0.960387 Content Loss: 0.002823

run [150]:
Style Loss : 0.723821 Content Loss: 0.003369

run [200]:
Style Loss : 0.590982 Content Loss: 0.004118

run [250]:
Style Loss : 0.501355 Content Loss: 0.005098

run [300]:
Style Loss : 0.438650 Content Loss: 0.006175

run [350]:
Style Loss : 0.393117 Content Loss: 0.007363

run [400]:
Style Loss : 0.358154 Content Loss: 0.008426

run [450]:
Style Loss : 0.334644 Content Loss: 0.009371

run [500]:
Style Loss : 0.318215 Content Loss: 0.010191

run [550]:
Style Loss : 0.306470 Content Loss: 0.010743

run [600]:
Style Loss : 0.297939 Content Loss: 0.011162

run [650]:
Style Loss : 0.291131 Content Loss: 0.011446

run [700]:
Style Loss : 0.285335 Content Loss: 0.011673

run [750]:
Style Loss : 0.280446 Content Loss: 0.011862

run [800]:
Style Loss : 0.276068 Content Loss: 0.011991

run [850]:
Style Loss : 0.272144 Content Loss: 0.012116

run [900]:
Style Loss : 0.268853 Content Loss: 0.012228

run [950]:
Style Loss : 0.266018 Content Loss: 0.012318

run [1000]:
Style Loss : 0.263562 Content Loss: 0.012404

run [1050]:
Style Loss : 0.261396 Content Loss: 0.012480

run [1100]:
Style Loss : 0.259428 Content Loss: 0.012563

run [1150]:
Style Loss : 0.257702 Content Loss: 0.012630

run [1200]:
Style Loss : 0.256070 Content Loss: 0.012693

run [1250]:
Style Loss : 0.254476 Content Loss: 0.012758

run [1300]:
Style Loss : 0.253022 Content Loss: 0.012815

run [1350]:
Style Loss : 0.251721 Content Loss: 0.012880

run [1400]:
Style Loss : 0.250425 Content Loss: 0.012950

run [1450]:
Style Loss : 0.249111 Content Loss: 0.013029

run [1500]:
Style Loss : 0.247699 Content Loss: 0.013103

run [1550]:
Style Loss : 0.246174 Content Loss: 0.013173

run [1600]:
Style Loss : 0.244864 Content Loss: 0.013246

run [1650]:
Style Loss : 0.243637 Content Loss: 0.013301

run [1700]:
Style Loss : 0.242446 Content Loss: 0.013371

run [1750]:
Style Loss : 0.241326 Content Loss: 0.013443

run [1800]:
Style Loss : 0.240238 Content Loss: 0.013511

run [1850]:
Style Loss : 0.239240 Content Loss: 0.013572

run [1900]:
Style Loss : 0.238302 Content Loss: 0.013630

run [1950]:
Style Loss : 0.237414 Content Loss: 0.013691

run [2000]:
Style Loss : 0.236568 Content Loss: 0.013747

run [2050]:
Style Loss : 0.235741 Content Loss: 0.013811

run [2100]:
Style Loss : 0.234899 Content Loss: 0.013867

run [2150]:
Style Loss : 0.234118 Content Loss: 0.013921

run [2200]:
Style Loss : 0.233431 Content Loss: 0.013967

run [2250]:
Style Loss : 0.232767 Content Loss: 0.014016

run [2300]:
Style Loss : 0.232100 Content Loss: 0.014063

run [2350]:
Style Loss : 0.231518 Content Loss: 0.014099

run [2400]:
Style Loss : 0.230951 Content Loss: 0.014140

run [2450]:
Style Loss : 0.230400 Content Loss: 0.014172

run [2500]:
Style Loss : 0.229863 Content Loss: 0.014210

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.603516 Content Loss: 0.004448

run [100]:
Style Loss : 0.908286 Content Loss: 0.008302

run [150]:
Style Loss : 0.654706 Content Loss: 0.010661

run [200]:
Style Loss : 0.532699 Content Loss: 0.012334

run [250]:
Style Loss : 0.461522 Content Loss: 0.013610

run [300]:
Style Loss : 0.417601 Content Loss: 0.014333

run [350]:
Style Loss : 0.385770 Content Loss: 0.015064

run [400]:
Style Loss : 0.361459 Content Loss: 0.015538

run [450]:
Style Loss : 0.344066 Content Loss: 0.015920

run [500]:
Style Loss : 0.329562 Content Loss: 0.016169

run [550]:
Style Loss : 0.317961 Content Loss: 0.016342

run [600]:
Style Loss : 0.308233 Content Loss: 0.016510

run [650]:
Style Loss : 0.300194 Content Loss: 0.016672

run [700]:
Style Loss : 0.293639 Content Loss: 0.016828

run [750]:
Style Loss : 0.288047 Content Loss: 0.017006

run [800]:
Style Loss : 0.282901 Content Loss: 0.017205

run [850]:
Style Loss : 0.278144 Content Loss: 0.017389

run [900]:
Style Loss : 0.273900 Content Loss: 0.017565

run [950]:
Style Loss : 0.269967 Content Loss: 0.017736

run [1000]:
Style Loss : 0.266647 Content Loss: 0.017885

run [1050]:
Style Loss : 0.263288 Content Loss: 0.018030

run [1100]:
Style Loss : 0.259802 Content Loss: 0.018192

run [1150]:
Style Loss : 0.256972 Content Loss: 0.018335

run [1200]:
Style Loss : 0.254337 Content Loss: 0.018466

run [1250]:
Style Loss : 0.251465 Content Loss: 0.018599

run [1300]:
Style Loss : 0.248402 Content Loss: 0.018739

run [1350]:
Style Loss : 0.245730 Content Loss: 0.018861

run [1400]:
Style Loss : 0.243219 Content Loss: 0.018993

run [1450]:
Style Loss : 0.241022 Content Loss: 0.019114

run [1500]:
Style Loss : 0.238931 Content Loss: 0.019244

run [1550]:
Style Loss : 0.236948 Content Loss: 0.019365

run [1600]:
Style Loss : 0.234907 Content Loss: 0.019495

run [1650]:
Style Loss : 0.233046 Content Loss: 0.019600

run [1700]:
Style Loss : 0.231311 Content Loss: 0.019702

run [1750]:
Style Loss : 0.229689 Content Loss: 0.019802

run [1800]:
Style Loss : 0.228248 Content Loss: 0.019885

run [1850]:
Style Loss : 0.226890 Content Loss: 0.019980

run [1900]:
Style Loss : 0.225563 Content Loss: 0.020072

run [1950]:
Style Loss : 0.224220 Content Loss: 0.020158

run [2000]:
Style Loss : 0.222881 Content Loss: 0.020244

run [2050]:
Style Loss : 0.221609 Content Loss: 0.020324

run [2100]:
Style Loss : 0.220421 Content Loss: 0.020411

run [2150]:
Style Loss : 0.219359 Content Loss: 0.020478

run [2200]:
Style Loss : 0.218247 Content Loss: 0.020556

run [2250]:
Style Loss : 0.217171 Content Loss: 0.020636

run [2300]:
Style Loss : 0.216226 Content Loss: 0.020702

run [2350]:
Style Loss : 0.215362 Content Loss: 0.020766

run [2400]:
Style Loss : 0.214558 Content Loss: 0.020827

run [2450]:
Style Loss : 0.213788 Content Loss: 0.020887

run [2500]:
Style Loss : 0.213069 Content Loss: 0.020939

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.654014 Content Loss: 0.004518

run [100]:
Style Loss : 0.821996 Content Loss: 0.008540

run [150]:
Style Loss : 0.569958 Content Loss: 0.011113

run [200]:
Style Loss : 0.451605 Content Loss: 0.012924

run [250]:
Style Loss : 0.384830 Content Loss: 0.014182

run [300]:
Style Loss : 0.344081 Content Loss: 0.015049

run [350]:
Style Loss : 0.314705 Content Loss: 0.015771

run [400]:
Style Loss : 0.293958 Content Loss: 0.016258

run [450]:
Style Loss : 0.278354 Content Loss: 0.016651

run [500]:
Style Loss : 0.266331 Content Loss: 0.016942

run [550]:
Style Loss : 0.256700 Content Loss: 0.017166

run [600]:
Style Loss : 0.248464 Content Loss: 0.017355

run [650]:
Style Loss : 0.241958 Content Loss: 0.017524

run [700]:
Style Loss : 0.236458 Content Loss: 0.017704

run [750]:
Style Loss : 0.231619 Content Loss: 0.017867

run [800]:
Style Loss : 0.226977 Content Loss: 0.018020

run [850]:
Style Loss : 0.222805 Content Loss: 0.018153

run [900]:
Style Loss : 0.218994 Content Loss: 0.018269

run [950]:
Style Loss : 0.215263 Content Loss: 0.018403

run [1000]:
Style Loss : 0.211045 Content Loss: 0.018531

run [1050]:
Style Loss : 0.207564 Content Loss: 0.018639

run [1100]:
Style Loss : 0.204693 Content Loss: 0.018739

run [1150]:
Style Loss : 0.201762 Content Loss: 0.018831

run [1200]:
Style Loss : 0.199156 Content Loss: 0.018918

run [1250]:
Style Loss : 0.196610 Content Loss: 0.018978

run [1300]:
Style Loss : 0.194160 Content Loss: 0.019027

run [1350]:
Style Loss : 0.191699 Content Loss: 0.019094

run [1400]:
Style Loss : 0.189552 Content Loss: 0.019144

run [1450]:
Style Loss : 0.187507 Content Loss: 0.019212

run [1500]:
Style Loss : 0.185392 Content Loss: 0.019299

run [1550]:
Style Loss : 0.183292 Content Loss: 0.019373

run [1600]:
Style Loss : 0.181180 Content Loss: 0.019446

run [1650]:
Style Loss : 0.179096 Content Loss: 0.019519

run [1700]:
Style Loss : 0.177172 Content Loss: 0.019563

run [1750]:
Style Loss : 0.174944 Content Loss: 0.019629

run [1800]:
Style Loss : 0.172910 Content Loss: 0.019660

run [1850]:
Style Loss : 0.171242 Content Loss: 0.019703

run [1900]:
Style Loss : 0.169808 Content Loss: 0.019745

run [1950]:
Style Loss : 0.168427 Content Loss: 0.019784

run [2000]:
Style Loss : 0.167094 Content Loss: 0.019827

run [2050]:
Style Loss : 0.165996 Content Loss: 0.019863

run [2100]:
Style Loss : 0.164973 Content Loss: 0.019898

run [2150]:
Style Loss : 0.164054 Content Loss: 0.019928

run [2200]:
Style Loss : 0.163180 Content Loss: 0.019951

run [2250]:
Style Loss : 0.162346 Content Loss: 0.019967

run [2300]:
Style Loss : 0.161565 Content Loss: 0.019982

run [2350]:
Style Loss : 0.160818 Content Loss: 0.020002

run [2400]:
Style Loss : 0.160187 Content Loss: 0.020018

run [2450]:
Style Loss : 0.159555 Content Loss: 0.020037

run [2500]:
Style Loss : 0.158950 Content Loss: 0.020055

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.505601 Content Loss: 0.005409

run [100]:
Style Loss : 1.186634 Content Loss: 0.009617

run [150]:
Style Loss : 0.808812 Content Loss: 0.012423

run [200]:
Style Loss : 0.654949 Content Loss: 0.014294

run [250]:
Style Loss : 0.560875 Content Loss: 0.015703

run [300]:
Style Loss : 0.490212 Content Loss: 0.016763

run [350]:
Style Loss : 0.437223 Content Loss: 0.017591

run [400]:
Style Loss : 0.399383 Content Loss: 0.018214

run [450]:
Style Loss : 0.372646 Content Loss: 0.018669

run [500]:
Style Loss : 0.350570 Content Loss: 0.019077

run [550]:
Style Loss : 0.333725 Content Loss: 0.019429

run [600]:
Style Loss : 0.319386 Content Loss: 0.019662

run [650]:
Style Loss : 0.307788 Content Loss: 0.019856

run [700]:
Style Loss : 0.298616 Content Loss: 0.020029

run [750]:
Style Loss : 0.290532 Content Loss: 0.020159

run [800]:
Style Loss : 0.283263 Content Loss: 0.020273

run [850]:
Style Loss : 0.277142 Content Loss: 0.020370

run [900]:
Style Loss : 0.272192 Content Loss: 0.020450

run [950]:
Style Loss : 0.267683 Content Loss: 0.020521

run [1000]:
Style Loss : 0.262700 Content Loss: 0.020613

run [1050]:
Style Loss : 0.258159 Content Loss: 0.020678

run [1100]:
Style Loss : 0.253947 Content Loss: 0.020747

run [1150]:
Style Loss : 0.249915 Content Loss: 0.020810

run [1200]:
Style Loss : 0.245745 Content Loss: 0.020878

run [1250]:
Style Loss : 0.242332 Content Loss: 0.020936

run [1300]:
Style Loss : 0.238894 Content Loss: 0.020998

run [1350]:
Style Loss : 0.235992 Content Loss: 0.021048

run [1400]:
Style Loss : 0.233212 Content Loss: 0.021115

run [1450]:
Style Loss : 0.230780 Content Loss: 0.021168

run [1500]:
Style Loss : 0.228377 Content Loss: 0.021227

run [1550]:
Style Loss : 0.226172 Content Loss: 0.021281

run [1600]:
Style Loss : 0.224092 Content Loss: 0.021336

run [1650]:
Style Loss : 0.222164 Content Loss: 0.021385

run [1700]:
Style Loss : 0.220557 Content Loss: 0.021423

run [1750]:
Style Loss : 0.219080 Content Loss: 0.021450

run [1800]:
Style Loss : 0.217703 Content Loss: 0.021479

run [1850]:
Style Loss : 0.216440 Content Loss: 0.021509

run [1900]:
Style Loss : 0.215343 Content Loss: 0.021528

run [1950]:
Style Loss : 0.214213 Content Loss: 0.021554

run [2000]:
Style Loss : 0.213069 Content Loss: 0.021588

run [2050]:
Style Loss : 0.211955 Content Loss: 0.021624

run [2100]:
Style Loss : 0.210923 Content Loss: 0.021658

run [2150]:
Style Loss : 0.209974 Content Loss: 0.021690

run [2200]:
Style Loss : 0.209048 Content Loss: 0.021721

run [2250]:
Style Loss : 0.208163 Content Loss: 0.021754

run [2300]:
Style Loss : 0.207271 Content Loss: 0.021789

run [2350]:
Style Loss : 0.206356 Content Loss: 0.021822

run [2400]:
Style Loss : 0.205443 Content Loss: 0.021856

run [2450]:
Style Loss : 0.204578 Content Loss: 0.021888

run [2500]:
Style Loss : 0.203763 Content Loss: 0.021920

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.782806 Content Loss: 0.007901

run [100]:
Style Loss : 0.366519 Content Loss: 0.010994

run [150]:
Style Loss : 0.286918 Content Loss: 0.012861

run [200]:
Style Loss : 0.249730 Content Loss: 0.013788

run [250]:
Style Loss : 0.225968 Content Loss: 0.014534

run [300]:
Style Loss : 0.211179 Content Loss: 0.015001

run [350]:
Style Loss : 0.192251 Content Loss: 0.015178

run [400]:
Style Loss : 0.182478 Content Loss: 0.015415

run [450]:
Style Loss : 0.175096 Content Loss: 0.015670

run [500]:
Style Loss : 0.169047 Content Loss: 0.015882

run [550]:
Style Loss : 0.163861 Content Loss: 0.016091

run [600]:
Style Loss : 0.159790 Content Loss: 0.016312

run [650]:
Style Loss : 0.156027 Content Loss: 0.016502

run [700]:
Style Loss : 0.152480 Content Loss: 0.016720

run [750]:
Style Loss : 0.149526 Content Loss: 0.016905

run [800]:
Style Loss : 0.146652 Content Loss: 0.017060

run [850]:
Style Loss : 0.144051 Content Loss: 0.017210

run [900]:
Style Loss : 0.141696 Content Loss: 0.017372

run [950]:
Style Loss : 0.139582 Content Loss: 0.017501

run [1000]:
Style Loss : 0.137476 Content Loss: 0.017651

run [1050]:
Style Loss : 0.135145 Content Loss: 0.017808

run [1100]:
Style Loss : 0.133392 Content Loss: 0.017917

run [1150]:
Style Loss : 0.131860 Content Loss: 0.018038

run [1200]:
Style Loss : 0.130585 Content Loss: 0.018166

run [1250]:
Style Loss : 0.129365 Content Loss: 0.018285

run [1300]:
Style Loss : 0.128240 Content Loss: 0.018382

run [1350]:
Style Loss : 0.127174 Content Loss: 0.018496

run [1400]:
Style Loss : 0.126315 Content Loss: 0.018564

run [1450]:
Style Loss : 0.125527 Content Loss: 0.018620

run [1500]:
Style Loss : 0.124794 Content Loss: 0.018671

run [1550]:
Style Loss : 0.124069 Content Loss: 0.018731

run [1600]:
Style Loss : 0.123407 Content Loss: 0.018796

run [1650]:
Style Loss : 0.122773 Content Loss: 0.018851

run [1700]:
Style Loss : 0.122170 Content Loss: 0.018909

run [1750]:
Style Loss : 0.121676 Content Loss: 0.018945

run [1800]:
Style Loss : 0.121227 Content Loss: 0.019015

run [1850]:
Style Loss : 0.120633 Content Loss: 0.019029

run [1900]:
Style Loss : 0.120197 Content Loss: 0.019061

run [1950]:
Style Loss : 0.119787 Content Loss: 0.019091

run [2000]:
Style Loss : 0.119413 Content Loss: 0.019113

run [2050]:
Style Loss : 0.119085 Content Loss: 0.019138

run [2100]:
Style Loss : 0.118810 Content Loss: 0.019159

run [2150]:
Style Loss : 0.118574 Content Loss: 0.019188

run [2200]:
Style Loss : 0.118258 Content Loss: 0.019212

run [2250]:
Style Loss : 0.117982 Content Loss: 0.019225

run [2300]:
Style Loss : 0.117726 Content Loss: 0.019230

run [2350]:
Style Loss : 0.117497 Content Loss: 0.019251

run [2400]:
Style Loss : 0.117271 Content Loss: 0.019281

run [2450]:
Style Loss : 0.116950 Content Loss: 0.019295

run [2500]:
Style Loss : 0.116672 Content Loss: 0.019327

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.656913 Content Loss: 0.010245

run [100]:
Style Loss : 0.382081 Content Loss: 0.015405

run [150]:
Style Loss : 0.292130 Content Loss: 0.018159

run [200]:
Style Loss : 0.245822 Content Loss: 0.020520

run [250]:
Style Loss : 0.218406 Content Loss: 0.022539

run [300]:
Style Loss : 0.202062 Content Loss: 0.023770

run [350]:
Style Loss : 0.190191 Content Loss: 0.024605

run [400]:
Style Loss : 0.181324 Content Loss: 0.025135

run [450]:
Style Loss : 0.174578 Content Loss: 0.025478

run [500]:
Style Loss : 0.169066 Content Loss: 0.025721

run [550]:
Style Loss : 0.163687 Content Loss: 0.025956

run [600]:
Style Loss : 0.159332 Content Loss: 0.026215

run [650]:
Style Loss : 0.155999 Content Loss: 0.026459

run [700]:
Style Loss : 0.153175 Content Loss: 0.026707

run [750]:
Style Loss : 0.150711 Content Loss: 0.026944

run [800]:
Style Loss : 0.148559 Content Loss: 0.027153

run [850]:
Style Loss : 0.146618 Content Loss: 0.027347

run [900]:
Style Loss : 0.144892 Content Loss: 0.027497

run [950]:
Style Loss : 0.143407 Content Loss: 0.027647

run [1000]:
Style Loss : 0.142218 Content Loss: 0.027785

run [1050]:
Style Loss : 0.141089 Content Loss: 0.027907

run [1100]:
Style Loss : 0.140036 Content Loss: 0.028016

run [1150]:
Style Loss : 0.139091 Content Loss: 0.028143

run [1200]:
Style Loss : 0.138235 Content Loss: 0.028218

run [1250]:
Style Loss : 0.137488 Content Loss: 0.028305

run [1300]:
Style Loss : 0.136834 Content Loss: 0.028370

run [1350]:
Style Loss : 0.136249 Content Loss: 0.028429

run [1400]:
Style Loss : 0.135668 Content Loss: 0.028493

run [1450]:
Style Loss : 0.135106 Content Loss: 0.028545

run [1500]:
Style Loss : 0.134580 Content Loss: 0.028607

run [1550]:
Style Loss : 0.134061 Content Loss: 0.028647

run [1600]:
Style Loss : 0.133428 Content Loss: 0.028690

run [1650]:
Style Loss : 0.132865 Content Loss: 0.028735

run [1700]:
Style Loss : 0.132341 Content Loss: 0.028759

run [1750]:
Style Loss : 0.131832 Content Loss: 0.028785

run [1800]:
Style Loss : 0.131472 Content Loss: 0.028800

run [1850]:
Style Loss : 0.131093 Content Loss: 0.028806

run [1900]:
Style Loss : 0.130407 Content Loss: 0.028804

run [1950]:
Style Loss : 0.129757 Content Loss: 0.028819

run [2000]:
Style Loss : 0.129295 Content Loss: 0.028828

run [2050]:
Style Loss : 0.128795 Content Loss: 0.028831

run [2100]:
Style Loss : 0.128450 Content Loss: 0.028834

run [2150]:
Style Loss : 0.128188 Content Loss: 0.028834

run [2200]:
Style Loss : 0.127931 Content Loss: 0.028835

run [2250]:
Style Loss : 0.127699 Content Loss: 0.028841

run [2300]:
Style Loss : 0.127496 Content Loss: 0.028840

run [2350]:
Style Loss : 0.127323 Content Loss: 0.028835

run [2400]:
Style Loss : 0.127146 Content Loss: 0.028830

run [2450]:
Style Loss : 0.126991 Content Loss: 0.028823

run [2500]:
Style Loss : 0.126851 Content Loss: 0.028816

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.682301 Content Loss: 0.007510

run [100]:
Style Loss : 0.980758 Content Loss: 0.009989

run [150]:
Style Loss : 0.757250 Content Loss: 0.011886

run [200]:
Style Loss : 0.654180 Content Loss: 0.012980

run [250]:
Style Loss : 0.592061 Content Loss: 0.014054

run [300]:
Style Loss : 0.553548 Content Loss: 0.014916

run [350]:
Style Loss : 0.526037 Content Loss: 0.015737

run [400]:
Style Loss : 0.504635 Content Loss: 0.016545

run [450]:
Style Loss : 0.486542 Content Loss: 0.017157

run [500]:
Style Loss : 0.472347 Content Loss: 0.017756

run [550]:
Style Loss : 0.460464 Content Loss: 0.018217

run [600]:
Style Loss : 0.449517 Content Loss: 0.018666

run [650]:
Style Loss : 0.438609 Content Loss: 0.019058

run [700]:
Style Loss : 0.429002 Content Loss: 0.019485

run [750]:
Style Loss : 0.420443 Content Loss: 0.019853

run [800]:
Style Loss : 0.413524 Content Loss: 0.020193

run [850]:
Style Loss : 0.406809 Content Loss: 0.020526

run [900]:
Style Loss : 0.400084 Content Loss: 0.020845

run [950]:
Style Loss : 0.393241 Content Loss: 0.021105

run [1000]:
Style Loss : 0.387656 Content Loss: 0.021344

run [1050]:
Style Loss : 0.382461 Content Loss: 0.021542

run [1100]:
Style Loss : 0.377757 Content Loss: 0.021769

run [1150]:
Style Loss : 0.372936 Content Loss: 0.021949

run [1200]:
Style Loss : 0.368784 Content Loss: 0.022108

run [1250]:
Style Loss : 0.363928 Content Loss: 0.022287

run [1300]:
Style Loss : 0.359618 Content Loss: 0.022463

run [1350]:
Style Loss : 0.355986 Content Loss: 0.022634

run [1400]:
Style Loss : 0.352821 Content Loss: 0.022753

run [1450]:
Style Loss : 0.349887 Content Loss: 0.022903

run [1500]:
Style Loss : 0.347321 Content Loss: 0.023027

run [1550]:
Style Loss : 0.345113 Content Loss: 0.023131

run [1600]:
Style Loss : 0.343165 Content Loss: 0.023212

run [1650]:
Style Loss : 0.341421 Content Loss: 0.023302

run [1700]:
Style Loss : 0.339859 Content Loss: 0.023384

run [1750]:
Style Loss : 0.338362 Content Loss: 0.023437

run [1800]:
Style Loss : 0.336971 Content Loss: 0.023497

run [1850]:
Style Loss : 0.335584 Content Loss: 0.023544

run [1900]:
Style Loss : 0.334447 Content Loss: 0.023588

run [1950]:
Style Loss : 0.333236 Content Loss: 0.023645

run [2000]:
Style Loss : 0.332205 Content Loss: 0.023701

run [2050]:
Style Loss : 0.331252 Content Loss: 0.023740

run [2100]:
Style Loss : 0.330253 Content Loss: 0.023792

run [2150]:
Style Loss : 0.329202 Content Loss: 0.023838

run [2200]:
Style Loss : 0.328242 Content Loss: 0.023881

run [2250]:
Style Loss : 0.327358 Content Loss: 0.023914

run [2300]:
Style Loss : 0.326526 Content Loss: 0.023956

run [2350]:
Style Loss : 0.325710 Content Loss: 0.023978

run [2400]:
Style Loss : 0.325013 Content Loss: 0.024009

run [2450]:
Style Loss : 0.324326 Content Loss: 0.024031

run [2500]:
Style Loss : 0.323633 Content Loss: 0.024062

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.334160 Content Loss: 0.005582

run [100]:
Style Loss : 0.643893 Content Loss: 0.010525

run [150]:
Style Loss : 0.439195 Content Loss: 0.012921

run [200]:
Style Loss : 0.359078 Content Loss: 0.014462

run [250]:
Style Loss : 0.316132 Content Loss: 0.015561

run [300]:
Style Loss : 0.289586 Content Loss: 0.016220

run [350]:
Style Loss : 0.269138 Content Loss: 0.016586

run [400]:
Style Loss : 0.253749 Content Loss: 0.016856

run [450]:
Style Loss : 0.242003 Content Loss: 0.017144

run [500]:
Style Loss : 0.232932 Content Loss: 0.017353

run [550]:
Style Loss : 0.225169 Content Loss: 0.017555

run [600]:
Style Loss : 0.218811 Content Loss: 0.017756

run [650]:
Style Loss : 0.213025 Content Loss: 0.017937

run [700]:
Style Loss : 0.208383 Content Loss: 0.018076

run [750]:
Style Loss : 0.204304 Content Loss: 0.018207

run [800]:
Style Loss : 0.200855 Content Loss: 0.018341

run [850]:
Style Loss : 0.197698 Content Loss: 0.018477

run [900]:
Style Loss : 0.194718 Content Loss: 0.018581

run [950]:
Style Loss : 0.192338 Content Loss: 0.018637

run [1000]:
Style Loss : 0.190153 Content Loss: 0.018718

run [1050]:
Style Loss : 0.188200 Content Loss: 0.018787

run [1100]:
Style Loss : 0.186256 Content Loss: 0.018861

run [1150]:
Style Loss : 0.184440 Content Loss: 0.018943

run [1200]:
Style Loss : 0.182562 Content Loss: 0.019042

run [1250]:
Style Loss : 0.180705 Content Loss: 0.019140

run [1300]:
Style Loss : 0.178819 Content Loss: 0.019251

run [1350]:
Style Loss : 0.177116 Content Loss: 0.019355

run [1400]:
Style Loss : 0.175460 Content Loss: 0.019454

run [1450]:
Style Loss : 0.173838 Content Loss: 0.019555

run [1500]:
Style Loss : 0.172264 Content Loss: 0.019640

run [1550]:
Style Loss : 0.170953 Content Loss: 0.019708

run [1600]:
Style Loss : 0.169665 Content Loss: 0.019789

run [1650]:
Style Loss : 0.168406 Content Loss: 0.019870

run [1700]:
Style Loss : 0.167230 Content Loss: 0.019962

run [1750]:
Style Loss : 0.166051 Content Loss: 0.020041

run [1800]:
Style Loss : 0.164978 Content Loss: 0.020116

run [1850]:
Style Loss : 0.163982 Content Loss: 0.020199

run [1900]:
Style Loss : 0.162977 Content Loss: 0.020293

run [1950]:
Style Loss : 0.162051 Content Loss: 0.020368

run [2000]:
Style Loss : 0.161099 Content Loss: 0.020460

run [2050]:
Style Loss : 0.160178 Content Loss: 0.020534

run [2100]:
Style Loss : 0.159383 Content Loss: 0.020637

run [2150]:
Style Loss : 0.158390 Content Loss: 0.020717

run [2200]:
Style Loss : 0.157554 Content Loss: 0.020805

run [2250]:
Style Loss : 0.156589 Content Loss: 0.020920

run [2300]:
Style Loss : 0.155469 Content Loss: 0.020999

run [2350]:
Style Loss : 0.154427 Content Loss: 0.021115

run [2400]:
Style Loss : 0.153497 Content Loss: 0.021197

run [2450]:
Style Loss : 0.152702 Content Loss: 0.021297

run [2500]:
Style Loss : 0.151586 Content Loss: 0.021363

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.177137 Content Loss: 0.007279

run [100]:
Style Loss : 0.612958 Content Loss: 0.012850

run [150]:
Style Loss : 0.444395 Content Loss: 0.016186

run [200]:
Style Loss : 0.369926 Content Loss: 0.018029

run [250]:
Style Loss : 0.329772 Content Loss: 0.019216

run [300]:
Style Loss : 0.305798 Content Loss: 0.019887

run [350]:
Style Loss : 0.290262 Content Loss: 0.020149

run [400]:
Style Loss : 0.276488 Content Loss: 0.020419

run [450]:
Style Loss : 0.265984 Content Loss: 0.020550

run [500]:
Style Loss : 0.257356 Content Loss: 0.020755

run [550]:
Style Loss : 0.249616 Content Loss: 0.020899

run [600]:
Style Loss : 0.243422 Content Loss: 0.020992

run [650]:
Style Loss : 0.237788 Content Loss: 0.021097

run [700]:
Style Loss : 0.233162 Content Loss: 0.021208

run [750]:
Style Loss : 0.227964 Content Loss: 0.021322

run [800]:
Style Loss : 0.223242 Content Loss: 0.021437

run [850]:
Style Loss : 0.218183 Content Loss: 0.021561

run [900]:
Style Loss : 0.213364 Content Loss: 0.021679

run [950]:
Style Loss : 0.208904 Content Loss: 0.021769

run [1000]:
Style Loss : 0.204476 Content Loss: 0.021874

run [1050]:
Style Loss : 0.200408 Content Loss: 0.021963

run [1100]:
Style Loss : 0.196839 Content Loss: 0.022028

run [1150]:
Style Loss : 0.194061 Content Loss: 0.022098

run [1200]:
Style Loss : 0.191806 Content Loss: 0.022151

run [1250]:
Style Loss : 0.189521 Content Loss: 0.022198

run [1300]:
Style Loss : 0.187714 Content Loss: 0.022244

run [1350]:
Style Loss : 0.185735 Content Loss: 0.022300

run [1400]:
Style Loss : 0.183696 Content Loss: 0.022349

run [1450]:
Style Loss : 0.181692 Content Loss: 0.022400

run [1500]:
Style Loss : 0.179711 Content Loss: 0.022436

run [1550]:
Style Loss : 0.177186 Content Loss: 0.022494

run [1600]:
Style Loss : 0.174316 Content Loss: 0.022551

run [1650]:
Style Loss : 0.172274 Content Loss: 0.022608

run [1700]:
Style Loss : 0.170597 Content Loss: 0.022662

run [1750]:
Style Loss : 0.169127 Content Loss: 0.022708

run [1800]:
Style Loss : 0.167232 Content Loss: 0.022765

run [1850]:
Style Loss : 0.165485 Content Loss: 0.022805

run [1900]:
Style Loss : 0.164193 Content Loss: 0.022835

run [1950]:
Style Loss : 0.163030 Content Loss: 0.022854

run [2000]:
Style Loss : 0.161946 Content Loss: 0.022870

run [2050]:
Style Loss : 0.160954 Content Loss: 0.022883

run [2100]:
Style Loss : 0.159880 Content Loss: 0.022909

run [2150]:
Style Loss : 0.158923 Content Loss: 0.022937

run [2200]:
Style Loss : 0.158041 Content Loss: 0.022960

run [2250]:
Style Loss : 0.157202 Content Loss: 0.022974

run [2300]:
Style Loss : 0.156480 Content Loss: 0.022988

run [2350]:
Style Loss : 0.155844 Content Loss: 0.022993

run [2400]:
Style Loss : 0.155230 Content Loss: 0.022999

run [2450]:
Style Loss : 0.154609 Content Loss: 0.023013

run [2500]:
Style Loss : 0.153973 Content Loss: 0.023027

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.109621 Content Loss: 0.006868

run [100]:
Style Loss : 0.477965 Content Loss: 0.011326

run [150]:
Style Loss : 0.314316 Content Loss: 0.014018

run [200]:
Style Loss : 0.248549 Content Loss: 0.015462

run [250]:
Style Loss : 0.211163 Content Loss: 0.016317

run [300]:
Style Loss : 0.187643 Content Loss: 0.016955

run [350]:
Style Loss : 0.167570 Content Loss: 0.017321

run [400]:
Style Loss : 0.147152 Content Loss: 0.017599

run [450]:
Style Loss : 0.136127 Content Loss: 0.017726

run [500]:
Style Loss : 0.127989 Content Loss: 0.017810

run [550]:
Style Loss : 0.121790 Content Loss: 0.017922

run [600]:
Style Loss : 0.116606 Content Loss: 0.018051

run [650]:
Style Loss : 0.112279 Content Loss: 0.018172

run [700]:
Style Loss : 0.108474 Content Loss: 0.018269

run [750]:
Style Loss : 0.104998 Content Loss: 0.018386

run [800]:
Style Loss : 0.102081 Content Loss: 0.018469

run [850]:
Style Loss : 0.099653 Content Loss: 0.018539

run [900]:
Style Loss : 0.097573 Content Loss: 0.018590

run [950]:
Style Loss : 0.095766 Content Loss: 0.018644

run [1000]:
Style Loss : 0.094080 Content Loss: 0.018696

run [1050]:
Style Loss : 0.092494 Content Loss: 0.018761

run [1100]:
Style Loss : 0.090997 Content Loss: 0.018819

run [1150]:
Style Loss : 0.089438 Content Loss: 0.018895

run [1200]:
Style Loss : 0.087907 Content Loss: 0.018983

run [1250]:
Style Loss : 0.086454 Content Loss: 0.019052

run [1300]:
Style Loss : 0.085080 Content Loss: 0.019133

run [1350]:
Style Loss : 0.083730 Content Loss: 0.019211

run [1400]:
Style Loss : 0.082344 Content Loss: 0.019287

run [1450]:
Style Loss : 0.081141 Content Loss: 0.019355

run [1500]:
Style Loss : 0.079961 Content Loss: 0.019438

run [1550]:
Style Loss : 0.078962 Content Loss: 0.019514

run [1600]:
Style Loss : 0.078076 Content Loss: 0.019575

run [1650]:
Style Loss : 0.077049 Content Loss: 0.019644

run [1700]:
Style Loss : 0.075805 Content Loss: 0.019759

run [1750]:
Style Loss : 0.074669 Content Loss: 0.019781

run [1800]:
Style Loss : 0.073877 Content Loss: 0.019828

run [1850]:
Style Loss : 0.073183 Content Loss: 0.019872

run [1900]:
Style Loss : 0.072517 Content Loss: 0.019930

run [1950]:
Style Loss : 0.071921 Content Loss: 0.019980

run [2000]:
Style Loss : 0.071381 Content Loss: 0.020016

run [2050]:
Style Loss : 0.070904 Content Loss: 0.020055

run [2100]:
Style Loss : 0.070451 Content Loss: 0.020095

run [2150]:
Style Loss : 0.070010 Content Loss: 0.020134

run [2200]:
Style Loss : 0.069594 Content Loss: 0.020174

run [2250]:
Style Loss : 0.069229 Content Loss: 0.020239

run [2300]:
Style Loss : 0.068895 Content Loss: 0.020285

run [2350]:
Style Loss : 0.068572 Content Loss: 0.020333

run [2400]:
Style Loss : 0.068269 Content Loss: 0.020405

run [2450]:
Style Loss : 0.067924 Content Loss: 0.020411

run [2500]:
Style Loss : 0.067702 Content Loss: 0.020459

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.215180 Content Loss: 0.006614

run [100]:
Style Loss : 0.733013 Content Loss: 0.011523

run [150]:
Style Loss : 0.548022 Content Loss: 0.015285

run [200]:
Style Loss : 0.457669 Content Loss: 0.017549

run [250]:
Style Loss : 0.407990 Content Loss: 0.019164

run [300]:
Style Loss : 0.377896 Content Loss: 0.019836

run [350]:
Style Loss : 0.358577 Content Loss: 0.020354

run [400]:
Style Loss : 0.341382 Content Loss: 0.020811

run [450]:
Style Loss : 0.328723 Content Loss: 0.021163

run [500]:
Style Loss : 0.319257 Content Loss: 0.021531

run [550]:
Style Loss : 0.310551 Content Loss: 0.021866

run [600]:
Style Loss : 0.303586 Content Loss: 0.022155

run [650]:
Style Loss : 0.297265 Content Loss: 0.022507

run [700]:
Style Loss : 0.292057 Content Loss: 0.022815

run [750]:
Style Loss : 0.287786 Content Loss: 0.023098

run [800]:
Style Loss : 0.283808 Content Loss: 0.023369

run [850]:
Style Loss : 0.280401 Content Loss: 0.023592

run [900]:
Style Loss : 0.277408 Content Loss: 0.023783

run [950]:
Style Loss : 0.274604 Content Loss: 0.023974

run [1000]:
Style Loss : 0.271827 Content Loss: 0.024129

run [1050]:
Style Loss : 0.269573 Content Loss: 0.024241

run [1100]:
Style Loss : 0.267731 Content Loss: 0.024349

run [1150]:
Style Loss : 0.265895 Content Loss: 0.024465

run [1200]:
Style Loss : 0.263876 Content Loss: 0.024572

run [1250]:
Style Loss : 0.262084 Content Loss: 0.024694

run [1300]:
Style Loss : 0.260414 Content Loss: 0.024797

run [1350]:
Style Loss : 0.258906 Content Loss: 0.024875

run [1400]:
Style Loss : 0.257578 Content Loss: 0.024956

run [1450]:
Style Loss : 0.256248 Content Loss: 0.025043

run [1500]:
Style Loss : 0.255203 Content Loss: 0.025103

run [1550]:
Style Loss : 0.254088 Content Loss: 0.025172

run [1600]:
Style Loss : 0.253133 Content Loss: 0.025249

run [1650]:
Style Loss : 0.252234 Content Loss: 0.025332

run [1700]:
Style Loss : 0.251319 Content Loss: 0.025393

run [1750]:
Style Loss : 0.250469 Content Loss: 0.025500

run [1800]:
Style Loss : 0.249533 Content Loss: 0.025560

run [1850]:
Style Loss : 0.248598 Content Loss: 0.025641

run [1900]:
Style Loss : 0.247639 Content Loss: 0.025729

run [1950]:
Style Loss : 0.246573 Content Loss: 0.025808

run [2000]:
Style Loss : 0.245684 Content Loss: 0.025849

run [2050]:
Style Loss : 0.244896 Content Loss: 0.025899

run [2100]:
Style Loss : 0.244307 Content Loss: 0.025957

run [2150]:
Style Loss : 0.243508 Content Loss: 0.026000

run [2200]:
Style Loss : 0.242908 Content Loss: 0.026038

run [2250]:
Style Loss : 0.242216 Content Loss: 0.026061

run [2300]:
Style Loss : 0.241600 Content Loss: 0.026088

run [2350]:
Style Loss : 0.240782 Content Loss: 0.026107

run [2400]:
Style Loss : 0.240250 Content Loss: 0.026167

run [2450]:
Style Loss : 0.239547 Content Loss: 0.026185

run [2500]:
Style Loss : 0.238899 Content Loss: 0.026206

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.709062 Content Loss: 0.008449

run [100]:
Style Loss : 0.321136 Content Loss: 0.012593

run [150]:
Style Loss : 0.225178 Content Loss: 0.014638

run [200]:
Style Loss : 0.186372 Content Loss: 0.015572

run [250]:
Style Loss : 0.165418 Content Loss: 0.016132

run [300]:
Style Loss : 0.152377 Content Loss: 0.016570

run [350]:
Style Loss : 0.143000 Content Loss: 0.016820

run [400]:
Style Loss : 0.136218 Content Loss: 0.017026

run [450]:
Style Loss : 0.130907 Content Loss: 0.017203

run [500]:
Style Loss : 0.126849 Content Loss: 0.017336

run [550]:
Style Loss : 0.123308 Content Loss: 0.017415

run [600]:
Style Loss : 0.120516 Content Loss: 0.017487

run [650]:
Style Loss : 0.118026 Content Loss: 0.017527

run [700]:
Style Loss : 0.115721 Content Loss: 0.017552

run [750]:
Style Loss : 0.113689 Content Loss: 0.017611

run [800]:
Style Loss : 0.110845 Content Loss: 0.017691

run [850]:
Style Loss : 0.108014 Content Loss: 0.017766

run [900]:
Style Loss : 0.105361 Content Loss: 0.017847

run [950]:
Style Loss : 0.096031 Content Loss: 0.017939

run [1000]:
Style Loss : 0.091446 Content Loss: 0.018017

run [1050]:
Style Loss : 0.089091 Content Loss: 0.018058

run [1100]:
Style Loss : 0.087225 Content Loss: 0.018080

run [1150]:
Style Loss : 0.085659 Content Loss: 0.018096

run [1200]:
Style Loss : 0.084386 Content Loss: 0.018095

run [1250]:
Style Loss : 0.083400 Content Loss: 0.018070

run [1300]:
Style Loss : 0.082462 Content Loss: 0.018036

run [1350]:
Style Loss : 0.081523 Content Loss: 0.018010

run [1400]:
Style Loss : 0.080679 Content Loss: 0.018000

run [1450]:
Style Loss : 0.079931 Content Loss: 0.017989

run [1500]:
Style Loss : 0.079278 Content Loss: 0.017987

run [1550]:
Style Loss : 0.078656 Content Loss: 0.017995

run [1600]:
Style Loss : 0.078118 Content Loss: 0.017998

run [1650]:
Style Loss : 0.077635 Content Loss: 0.018006

run [1700]:
Style Loss : 0.077180 Content Loss: 0.018004

run [1750]:
Style Loss : 0.076720 Content Loss: 0.018010

run [1800]:
Style Loss : 0.076289 Content Loss: 0.018019

run [1850]:
Style Loss : 0.075897 Content Loss: 0.018016

run [1900]:
Style Loss : 0.075498 Content Loss: 0.018022

run [1950]:
Style Loss : 0.075151 Content Loss: 0.018033

run [2000]:
Style Loss : 0.074856 Content Loss: 0.018034

run [2050]:
Style Loss : 0.074554 Content Loss: 0.018031

run [2100]:
Style Loss : 0.074299 Content Loss: 0.018020

run [2150]:
Style Loss : 0.074030 Content Loss: 0.018016

run [2200]:
Style Loss : 0.073766 Content Loss: 0.018018

run [2250]:
Style Loss : 0.073528 Content Loss: 0.018014

run [2300]:
Style Loss : 0.073305 Content Loss: 0.018017

run [2350]:
Style Loss : 0.073101 Content Loss: 0.018013

run [2400]:
Style Loss : 0.072916 Content Loss: 0.018010

run [2450]:
Style Loss : 0.072737 Content Loss: 0.018007

run [2500]:
Style Loss : 0.072557 Content Loss: 0.018009

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.054995 Content Loss: 0.004267

run [100]:
Style Loss : 1.207452 Content Loss: 0.007458

run [150]:
Style Loss : 0.876734 Content Loss: 0.009839

run [200]:
Style Loss : 0.704809 Content Loss: 0.011440

run [250]:
Style Loss : 0.609169 Content Loss: 0.012484

run [300]:
Style Loss : 0.550459 Content Loss: 0.013429

run [350]:
Style Loss : 0.508812 Content Loss: 0.014161

run [400]:
Style Loss : 0.477522 Content Loss: 0.014676

run [450]:
Style Loss : 0.449234 Content Loss: 0.015275

run [500]:
Style Loss : 0.426670 Content Loss: 0.015741

run [550]:
Style Loss : 0.406760 Content Loss: 0.016175

run [600]:
Style Loss : 0.387360 Content Loss: 0.016561

run [650]:
Style Loss : 0.369311 Content Loss: 0.016936

run [700]:
Style Loss : 0.355565 Content Loss: 0.017255

run [750]:
Style Loss : 0.344532 Content Loss: 0.017495

run [800]:
Style Loss : 0.335145 Content Loss: 0.017712

run [850]:
Style Loss : 0.326664 Content Loss: 0.017926

run [900]:
Style Loss : 0.318868 Content Loss: 0.018111

run [950]:
Style Loss : 0.311951 Content Loss: 0.018269

run [1000]:
Style Loss : 0.302777 Content Loss: 0.018448

run [1050]:
Style Loss : 0.294934 Content Loss: 0.018605

run [1100]:
Style Loss : 0.289026 Content Loss: 0.018746

run [1150]:
Style Loss : 0.283844 Content Loss: 0.018877

run [1200]:
Style Loss : 0.279531 Content Loss: 0.019021

run [1250]:
Style Loss : 0.275672 Content Loss: 0.019138

run [1300]:
Style Loss : 0.272358 Content Loss: 0.019257

run [1350]:
Style Loss : 0.269404 Content Loss: 0.019351

run [1400]:
Style Loss : 0.266729 Content Loss: 0.019442

run [1450]:
Style Loss : 0.264258 Content Loss: 0.019517

run [1500]:
Style Loss : 0.261910 Content Loss: 0.019601

run [1550]:
Style Loss : 0.259713 Content Loss: 0.019677

run [1600]:
Style Loss : 0.257633 Content Loss: 0.019754

run [1650]:
Style Loss : 0.255585 Content Loss: 0.019839

run [1700]:
Style Loss : 0.253548 Content Loss: 0.019928

run [1750]:
Style Loss : 0.251637 Content Loss: 0.020011

run [1800]:
Style Loss : 0.249689 Content Loss: 0.020110

run [1850]:
Style Loss : 0.247667 Content Loss: 0.020198

run [1900]:
Style Loss : 0.245624 Content Loss: 0.020301

run [1950]:
Style Loss : 0.242554 Content Loss: 0.020410

run [2000]:
Style Loss : 0.239684 Content Loss: 0.020520

run [2050]:
Style Loss : 0.237384 Content Loss: 0.020611

run [2100]:
Style Loss : 0.235490 Content Loss: 0.020690

run [2150]:
Style Loss : 0.233656 Content Loss: 0.020775

run [2200]:
Style Loss : 0.231951 Content Loss: 0.020852

run [2250]:
Style Loss : 0.230344 Content Loss: 0.020917

run [2300]:
Style Loss : 0.228694 Content Loss: 0.020983

run [2350]:
Style Loss : 0.227177 Content Loss: 0.021043

run [2400]:
Style Loss : 0.225827 Content Loss: 0.021096

run [2450]:
Style Loss : 0.224537 Content Loss: 0.021151

run [2500]:
Style Loss : 0.223382 Content Loss: 0.021196

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.520975 Content Loss: 0.003425

run [100]:
Style Loss : 1.108054 Content Loss: 0.006621

run [150]:
Style Loss : 0.708789 Content Loss: 0.009654

run [200]:
Style Loss : 0.536332 Content Loss: 0.011712

run [250]:
Style Loss : 0.445044 Content Loss: 0.013089

run [300]:
Style Loss : 0.388844 Content Loss: 0.014044

run [350]:
Style Loss : 0.350292 Content Loss: 0.014859

run [400]:
Style Loss : 0.320424 Content Loss: 0.015529

run [450]:
Style Loss : 0.298360 Content Loss: 0.016012

run [500]:
Style Loss : 0.279135 Content Loss: 0.016418

run [550]:
Style Loss : 0.262486 Content Loss: 0.016729

run [600]:
Style Loss : 0.249896 Content Loss: 0.017002

run [650]:
Style Loss : 0.239866 Content Loss: 0.017217

run [700]:
Style Loss : 0.231997 Content Loss: 0.017335

run [750]:
Style Loss : 0.225275 Content Loss: 0.017501

run [800]:
Style Loss : 0.219390 Content Loss: 0.017626

run [850]:
Style Loss : 0.214034 Content Loss: 0.017751

run [900]:
Style Loss : 0.209086 Content Loss: 0.017861

run [950]:
Style Loss : 0.204944 Content Loss: 0.017955

run [1000]:
Style Loss : 0.201094 Content Loss: 0.018049

run [1050]:
Style Loss : 0.197417 Content Loss: 0.018133

run [1100]:
Style Loss : 0.194108 Content Loss: 0.018189

run [1150]:
Style Loss : 0.191248 Content Loss: 0.018235

run [1200]:
Style Loss : 0.188618 Content Loss: 0.018281

run [1250]:
Style Loss : 0.186152 Content Loss: 0.018337

run [1300]:
Style Loss : 0.183888 Content Loss: 0.018389

run [1350]:
Style Loss : 0.181758 Content Loss: 0.018433

run [1400]:
Style Loss : 0.179705 Content Loss: 0.018477

run [1450]:
Style Loss : 0.177757 Content Loss: 0.018512

run [1500]:
Style Loss : 0.176017 Content Loss: 0.018542

run [1550]:
Style Loss : 0.174307 Content Loss: 0.018579

run [1600]:
Style Loss : 0.172665 Content Loss: 0.018613

run [1650]:
Style Loss : 0.171184 Content Loss: 0.018643

run [1700]:
Style Loss : 0.169801 Content Loss: 0.018671

run [1750]:
Style Loss : 0.168541 Content Loss: 0.018694

run [1800]:
Style Loss : 0.167430 Content Loss: 0.018714

run [1850]:
Style Loss : 0.166335 Content Loss: 0.018739

run [1900]:
Style Loss : 0.165307 Content Loss: 0.018760

run [1950]:
Style Loss : 0.164342 Content Loss: 0.018785

run [2000]:
Style Loss : 0.163366 Content Loss: 0.018809

run [2050]:
Style Loss : 0.162425 Content Loss: 0.018834

run [2100]:
Style Loss : 0.161432 Content Loss: 0.018864

run [2150]:
Style Loss : 0.160336 Content Loss: 0.018892

run [2200]:
Style Loss : 0.159369 Content Loss: 0.018916

run [2250]:
Style Loss : 0.158391 Content Loss: 0.018943

run [2300]:
Style Loss : 0.157412 Content Loss: 0.018971

run [2350]:
Style Loss : 0.156411 Content Loss: 0.018999

run [2400]:
Style Loss : 0.155443 Content Loss: 0.019023

run [2450]:
Style Loss : 0.154577 Content Loss: 0.019047

run [2500]:
Style Loss : 0.153807 Content Loss: 0.019074

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.870341 Content Loss: 0.005239

run [100]:
Style Loss : 1.028501 Content Loss: 0.009597

run [150]:
Style Loss : 0.730591 Content Loss: 0.012909

run [200]:
Style Loss : 0.577361 Content Loss: 0.014917

run [250]:
Style Loss : 0.493370 Content Loss: 0.016338

run [300]:
Style Loss : 0.441009 Content Loss: 0.017332

run [350]:
Style Loss : 0.403979 Content Loss: 0.018008

run [400]:
Style Loss : 0.375764 Content Loss: 0.018553

run [450]:
Style Loss : 0.352738 Content Loss: 0.019009

run [500]:
Style Loss : 0.336075 Content Loss: 0.019339

run [550]:
Style Loss : 0.322603 Content Loss: 0.019655

run [600]:
Style Loss : 0.310594 Content Loss: 0.019985

run [650]:
Style Loss : 0.300287 Content Loss: 0.020273

run [700]:
Style Loss : 0.290853 Content Loss: 0.020522

run [750]:
Style Loss : 0.283248 Content Loss: 0.020770

run [800]:
Style Loss : 0.277395 Content Loss: 0.020952

run [850]:
Style Loss : 0.271994 Content Loss: 0.021115

run [900]:
Style Loss : 0.266400 Content Loss: 0.021288

run [950]:
Style Loss : 0.261117 Content Loss: 0.021438

run [1000]:
Style Loss : 0.256526 Content Loss: 0.021562

run [1050]:
Style Loss : 0.252853 Content Loss: 0.021672

run [1100]:
Style Loss : 0.249409 Content Loss: 0.021783

run [1150]:
Style Loss : 0.246155 Content Loss: 0.021877

run [1200]:
Style Loss : 0.243033 Content Loss: 0.021999

run [1250]:
Style Loss : 0.240412 Content Loss: 0.022068

run [1300]:
Style Loss : 0.238250 Content Loss: 0.022136

run [1350]:
Style Loss : 0.236314 Content Loss: 0.022206

run [1400]:
Style Loss : 0.234478 Content Loss: 0.022266

run [1450]:
Style Loss : 0.232510 Content Loss: 0.022338

run [1500]:
Style Loss : 0.230641 Content Loss: 0.022398

run [1550]:
Style Loss : 0.228873 Content Loss: 0.022448

run [1600]:
Style Loss : 0.227208 Content Loss: 0.022523

run [1650]:
Style Loss : 0.225568 Content Loss: 0.022581

run [1700]:
Style Loss : 0.224099 Content Loss: 0.022639

run [1750]:
Style Loss : 0.222556 Content Loss: 0.022694

run [1800]:
Style Loss : 0.221192 Content Loss: 0.022743

run [1850]:
Style Loss : 0.220033 Content Loss: 0.022794

run [1900]:
Style Loss : 0.218952 Content Loss: 0.022843

run [1950]:
Style Loss : 0.218001 Content Loss: 0.022889

run [2000]:
Style Loss : 0.216916 Content Loss: 0.022930

run [2050]:
Style Loss : 0.215887 Content Loss: 0.022971

run [2100]:
Style Loss : 0.214937 Content Loss: 0.023009

run [2150]:
Style Loss : 0.214122 Content Loss: 0.023047

run [2200]:
Style Loss : 0.213245 Content Loss: 0.023090

run [2250]:
Style Loss : 0.212499 Content Loss: 0.023121

run [2300]:
Style Loss : 0.211796 Content Loss: 0.023155

run [2350]:
Style Loss : 0.211141 Content Loss: 0.023184

run [2400]:
Style Loss : 0.210483 Content Loss: 0.023213

run [2450]:
Style Loss : 0.209892 Content Loss: 0.023244

run [2500]:
Style Loss : 0.209338 Content Loss: 0.023280

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.855307 Content Loss: 0.003541

run [100]:
Style Loss : 2.168963 Content Loss: 0.006906

run [150]:
Style Loss : 1.543135 Content Loss: 0.009536

run [200]:
Style Loss : 1.258834 Content Loss: 0.011543

run [250]:
Style Loss : 1.072927 Content Loss: 0.012981

run [300]:
Style Loss : 0.935120 Content Loss: 0.013901

run [350]:
Style Loss : 0.822466 Content Loss: 0.014727

run [400]:
Style Loss : 0.743257 Content Loss: 0.015332

run [450]:
Style Loss : 0.677532 Content Loss: 0.015812

run [500]:
Style Loss : 0.628837 Content Loss: 0.016276

run [550]:
Style Loss : 0.590002 Content Loss: 0.016612

run [600]:
Style Loss : 0.556981 Content Loss: 0.016932

run [650]:
Style Loss : 0.529262 Content Loss: 0.017216

run [700]:
Style Loss : 0.506133 Content Loss: 0.017516

run [750]:
Style Loss : 0.485263 Content Loss: 0.017723

run [800]:
Style Loss : 0.466220 Content Loss: 0.017945

run [850]:
Style Loss : 0.449353 Content Loss: 0.018120

run [900]:
Style Loss : 0.436106 Content Loss: 0.018222

run [950]:
Style Loss : 0.424711 Content Loss: 0.018332

run [1000]:
Style Loss : 0.413781 Content Loss: 0.018445

run [1050]:
Style Loss : 0.400665 Content Loss: 0.018601

run [1100]:
Style Loss : 0.390379 Content Loss: 0.018722

run [1150]:
Style Loss : 0.382012 Content Loss: 0.018806

run [1200]:
Style Loss : 0.374573 Content Loss: 0.018861

run [1250]:
Style Loss : 0.368099 Content Loss: 0.018939

run [1300]:
Style Loss : 0.361125 Content Loss: 0.019008

run [1350]:
Style Loss : 0.354470 Content Loss: 0.019084

run [1400]:
Style Loss : 0.348941 Content Loss: 0.019149

run [1450]:
Style Loss : 0.344033 Content Loss: 0.019217

run [1500]:
Style Loss : 0.339403 Content Loss: 0.019259

run [1550]:
Style Loss : 0.334751 Content Loss: 0.019324

run [1600]:
Style Loss : 0.330539 Content Loss: 0.019379

run [1650]:
Style Loss : 0.326700 Content Loss: 0.019431

run [1700]:
Style Loss : 0.323418 Content Loss: 0.019465

run [1750]:
Style Loss : 0.320433 Content Loss: 0.019503

run [1800]:
Style Loss : 0.317899 Content Loss: 0.019531

run [1850]:
Style Loss : 0.315586 Content Loss: 0.019561

run [1900]:
Style Loss : 0.313442 Content Loss: 0.019589

run [1950]:
Style Loss : 0.311494 Content Loss: 0.019608

run [2000]:
Style Loss : 0.309815 Content Loss: 0.019622

run [2050]:
Style Loss : 0.308137 Content Loss: 0.019635

run [2100]:
Style Loss : 0.306602 Content Loss: 0.019651

run [2150]:
Style Loss : 0.305186 Content Loss: 0.019666

run [2200]:
Style Loss : 0.303627 Content Loss: 0.019682

run [2250]:
Style Loss : 0.302198 Content Loss: 0.019698

run [2300]:
Style Loss : 0.300780 Content Loss: 0.019719

run [2350]:
Style Loss : 0.299362 Content Loss: 0.019742

run [2400]:
Style Loss : 0.297829 Content Loss: 0.019764

run [2450]:
Style Loss : 0.296603 Content Loss: 0.019789

run [2500]:
Style Loss : 0.295453 Content Loss: 0.019806

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.368872 Content Loss: 0.004623

run [100]:
Style Loss : 1.856046 Content Loss: 0.007613

run [150]:
Style Loss : 1.411814 Content Loss: 0.010019

run [200]:
Style Loss : 1.175587 Content Loss: 0.011723

run [250]:
Style Loss : 1.019321 Content Loss: 0.013125

run [300]:
Style Loss : 0.903929 Content Loss: 0.014020

run [350]:
Style Loss : 0.821770 Content Loss: 0.014790

run [400]:
Style Loss : 0.761104 Content Loss: 0.015411

run [450]:
Style Loss : 0.715165 Content Loss: 0.015934

run [500]:
Style Loss : 0.681567 Content Loss: 0.016294

run [550]:
Style Loss : 0.657154 Content Loss: 0.016665

run [600]:
Style Loss : 0.638293 Content Loss: 0.016999

run [650]:
Style Loss : 0.622048 Content Loss: 0.017270

run [700]:
Style Loss : 0.607372 Content Loss: 0.017500

run [750]:
Style Loss : 0.594772 Content Loss: 0.017702

run [800]:
Style Loss : 0.584054 Content Loss: 0.017864

run [850]:
Style Loss : 0.575628 Content Loss: 0.018035

run [900]:
Style Loss : 0.567262 Content Loss: 0.018206

run [950]:
Style Loss : 0.559151 Content Loss: 0.018345

run [1000]:
Style Loss : 0.551613 Content Loss: 0.018460

run [1050]:
Style Loss : 0.544541 Content Loss: 0.018598

run [1100]:
Style Loss : 0.537812 Content Loss: 0.018726

run [1150]:
Style Loss : 0.530921 Content Loss: 0.018824

run [1200]:
Style Loss : 0.525142 Content Loss: 0.018921

run [1250]:
Style Loss : 0.520680 Content Loss: 0.018999

run [1300]:
Style Loss : 0.516588 Content Loss: 0.019077

run [1350]:
Style Loss : 0.512843 Content Loss: 0.019156

run [1400]:
Style Loss : 0.509415 Content Loss: 0.019233

run [1450]:
Style Loss : 0.505799 Content Loss: 0.019318

run [1500]:
Style Loss : 0.502616 Content Loss: 0.019393

run [1550]:
Style Loss : 0.499959 Content Loss: 0.019455

run [1600]:
Style Loss : 0.497458 Content Loss: 0.019513

run [1650]:
Style Loss : 0.495234 Content Loss: 0.019565

run [1700]:
Style Loss : 0.493219 Content Loss: 0.019617

run [1750]:
Style Loss : 0.491215 Content Loss: 0.019656

run [1800]:
Style Loss : 0.489421 Content Loss: 0.019697

run [1850]:
Style Loss : 0.487746 Content Loss: 0.019735

run [1900]:
Style Loss : 0.486177 Content Loss: 0.019769

run [1950]:
Style Loss : 0.484731 Content Loss: 0.019798

run [2000]:
Style Loss : 0.483440 Content Loss: 0.019827

run [2050]:
Style Loss : 0.482254 Content Loss: 0.019854

run [2100]:
Style Loss : 0.481065 Content Loss: 0.019888

run [2150]:
Style Loss : 0.480010 Content Loss: 0.019912

run [2200]:
Style Loss : 0.479010 Content Loss: 0.019936

run [2250]:
Style Loss : 0.478028 Content Loss: 0.019962

run [2300]:
Style Loss : 0.477169 Content Loss: 0.019981

run [2350]:
Style Loss : 0.476294 Content Loss: 0.020003

run [2400]:
Style Loss : 0.475443 Content Loss: 0.020027

run [2450]:
Style Loss : 0.474630 Content Loss: 0.020041

run [2500]:
Style Loss : 0.473833 Content Loss: 0.020062

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.793001 Content Loss: 0.004270

run [100]:
Style Loss : 2.276725 Content Loss: 0.006398

run [150]:
Style Loss : 1.759566 Content Loss: 0.008561

run [200]:
Style Loss : 1.507194 Content Loss: 0.010229

run [250]:
Style Loss : 1.355416 Content Loss: 0.011455

run [300]:
Style Loss : 1.259053 Content Loss: 0.012400

run [350]:
Style Loss : 1.188684 Content Loss: 0.013345

run [400]:
Style Loss : 1.130860 Content Loss: 0.014116

run [450]:
Style Loss : 1.082874 Content Loss: 0.014650

run [500]:
Style Loss : 1.044408 Content Loss: 0.015147

run [550]:
Style Loss : 1.009067 Content Loss: 0.015619

run [600]:
Style Loss : 0.981554 Content Loss: 0.015996

run [650]:
Style Loss : 0.957919 Content Loss: 0.016339

run [700]:
Style Loss : 0.938008 Content Loss: 0.016670

run [750]:
Style Loss : 0.921269 Content Loss: 0.016929

run [800]:
Style Loss : 0.905797 Content Loss: 0.017189

run [850]:
Style Loss : 0.891308 Content Loss: 0.017451

run [900]:
Style Loss : 0.879905 Content Loss: 0.017636

run [950]:
Style Loss : 0.868630 Content Loss: 0.017860

run [1000]:
Style Loss : 0.856451 Content Loss: 0.018073

run [1050]:
Style Loss : 0.846412 Content Loss: 0.018245

run [1100]:
Style Loss : 0.837355 Content Loss: 0.018440

run [1150]:
Style Loss : 0.829242 Content Loss: 0.018587

run [1200]:
Style Loss : 0.821847 Content Loss: 0.018734

run [1250]:
Style Loss : 0.814922 Content Loss: 0.018861

run [1300]:
Style Loss : 0.808508 Content Loss: 0.018971

run [1350]:
Style Loss : 0.802406 Content Loss: 0.019099

run [1400]:
Style Loss : 0.795899 Content Loss: 0.019216

run [1450]:
Style Loss : 0.789746 Content Loss: 0.019312

run [1500]:
Style Loss : 0.784476 Content Loss: 0.019394

run [1550]:
Style Loss : 0.779504 Content Loss: 0.019501

run [1600]:
Style Loss : 0.773448 Content Loss: 0.019593

run [1650]:
Style Loss : 0.768774 Content Loss: 0.019688

run [1700]:
Style Loss : 0.764783 Content Loss: 0.019763

run [1750]:
Style Loss : 0.761377 Content Loss: 0.019828

run [1800]:
Style Loss : 0.758473 Content Loss: 0.019906

run [1850]:
Style Loss : 0.755616 Content Loss: 0.019977

run [1900]:
Style Loss : 0.753150 Content Loss: 0.020039

run [1950]:
Style Loss : 0.750687 Content Loss: 0.020110

run [2000]:
Style Loss : 0.748267 Content Loss: 0.020177

run [2050]:
Style Loss : 0.745814 Content Loss: 0.020259

run [2100]:
Style Loss : 0.743659 Content Loss: 0.020320

run [2150]:
Style Loss : 0.741505 Content Loss: 0.020374

run [2200]:
Style Loss : 0.739664 Content Loss: 0.020427

run [2250]:
Style Loss : 0.737654 Content Loss: 0.020487

run [2300]:
Style Loss : 0.735948 Content Loss: 0.020528

run [2350]:
Style Loss : 0.734304 Content Loss: 0.020574

run [2400]:
Style Loss : 0.732674 Content Loss: 0.020617

run [2450]:
Style Loss : 0.731042 Content Loss: 0.020657

run [2500]:
Style Loss : 0.729516 Content Loss: 0.020702

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.610400 Content Loss: 0.005390

run [100]:
Style Loss : 1.171337 Content Loss: 0.007454

run [150]:
Style Loss : 0.811053 Content Loss: 0.009343

run [200]:
Style Loss : 0.644872 Content Loss: 0.011082

run [250]:
Style Loss : 0.552716 Content Loss: 0.012129

run [300]:
Style Loss : 0.496197 Content Loss: 0.012864

run [350]:
Style Loss : 0.457574 Content Loss: 0.013364

run [400]:
Style Loss : 0.427595 Content Loss: 0.013920

run [450]:
Style Loss : 0.404273 Content Loss: 0.014381

run [500]:
Style Loss : 0.386628 Content Loss: 0.014717

run [550]:
Style Loss : 0.372819 Content Loss: 0.014921

run [600]:
Style Loss : 0.360795 Content Loss: 0.015171

run [650]:
Style Loss : 0.350789 Content Loss: 0.015391

run [700]:
Style Loss : 0.342852 Content Loss: 0.015593

run [750]:
Style Loss : 0.336108 Content Loss: 0.015754

run [800]:
Style Loss : 0.329709 Content Loss: 0.015927

run [850]:
Style Loss : 0.323925 Content Loss: 0.016049

run [900]:
Style Loss : 0.318776 Content Loss: 0.016188

run [950]:
Style Loss : 0.314145 Content Loss: 0.016300

run [1000]:
Style Loss : 0.309731 Content Loss: 0.016416

run [1050]:
Style Loss : 0.305996 Content Loss: 0.016527

run [1100]:
Style Loss : 0.302485 Content Loss: 0.016628

run [1150]:
Style Loss : 0.298462 Content Loss: 0.016743

run [1200]:
Style Loss : 0.295022 Content Loss: 0.016841

run [1250]:
Style Loss : 0.291920 Content Loss: 0.016919

run [1300]:
Style Loss : 0.289117 Content Loss: 0.016997

run [1350]:
Style Loss : 0.286524 Content Loss: 0.017074

run [1400]:
Style Loss : 0.284115 Content Loss: 0.017147

run [1450]:
Style Loss : 0.281923 Content Loss: 0.017227

run [1500]:
Style Loss : 0.279722 Content Loss: 0.017284

run [1550]:
Style Loss : 0.277368 Content Loss: 0.017356

run [1600]:
Style Loss : 0.275261 Content Loss: 0.017417

run [1650]:
Style Loss : 0.273431 Content Loss: 0.017465

run [1700]:
Style Loss : 0.271597 Content Loss: 0.017508

run [1750]:
Style Loss : 0.269814 Content Loss: 0.017560

run [1800]:
Style Loss : 0.268115 Content Loss: 0.017606

run [1850]:
Style Loss : 0.266414 Content Loss: 0.017639

run [1900]:
Style Loss : 0.264892 Content Loss: 0.017673

run [1950]:
Style Loss : 0.263426 Content Loss: 0.017705

run [2000]:
Style Loss : 0.262147 Content Loss: 0.017734

run [2050]:
Style Loss : 0.260944 Content Loss: 0.017752

run [2100]:
Style Loss : 0.259874 Content Loss: 0.017759

run [2150]:
Style Loss : 0.258842 Content Loss: 0.017764

run [2200]:
Style Loss : 0.257853 Content Loss: 0.017782

run [2250]:
Style Loss : 0.256910 Content Loss: 0.017798

run [2300]:
Style Loss : 0.255948 Content Loss: 0.017818

run [2350]:
Style Loss : 0.255070 Content Loss: 0.017834

run [2400]:
Style Loss : 0.254189 Content Loss: 0.017853

run [2450]:
Style Loss : 0.253366 Content Loss: 0.017869

run [2500]:
Style Loss : 0.252631 Content Loss: 0.017886

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.584274 Content Loss: 0.004242

run [100]:
Style Loss : 0.860738 Content Loss: 0.008263

run [150]:
Style Loss : 0.646064 Content Loss: 0.010864

run [200]:
Style Loss : 0.546599 Content Loss: 0.012663

run [250]:
Style Loss : 0.479839 Content Loss: 0.013870

run [300]:
Style Loss : 0.434299 Content Loss: 0.014814

run [350]:
Style Loss : 0.405611 Content Loss: 0.015641

run [400]:
Style Loss : 0.386984 Content Loss: 0.016202

run [450]:
Style Loss : 0.373988 Content Loss: 0.016659

run [500]:
Style Loss : 0.364852 Content Loss: 0.017002

run [550]:
Style Loss : 0.356936 Content Loss: 0.017312

run [600]:
Style Loss : 0.350087 Content Loss: 0.017560

run [650]:
Style Loss : 0.344695 Content Loss: 0.017762

run [700]:
Style Loss : 0.340204 Content Loss: 0.017975

run [750]:
Style Loss : 0.336078 Content Loss: 0.018163

run [800]:
Style Loss : 0.332148 Content Loss: 0.018308

run [850]:
Style Loss : 0.328440 Content Loss: 0.018463

run [900]:
Style Loss : 0.325389 Content Loss: 0.018592

run [950]:
Style Loss : 0.322776 Content Loss: 0.018707

run [1000]:
Style Loss : 0.320433 Content Loss: 0.018831

run [1050]:
Style Loss : 0.318376 Content Loss: 0.018931

run [1100]:
Style Loss : 0.316634 Content Loss: 0.019012

run [1150]:
Style Loss : 0.315191 Content Loss: 0.019095

run [1200]:
Style Loss : 0.313721 Content Loss: 0.019172

run [1250]:
Style Loss : 0.312396 Content Loss: 0.019244

run [1300]:
Style Loss : 0.311300 Content Loss: 0.019296

run [1350]:
Style Loss : 0.310333 Content Loss: 0.019362

run [1400]:
Style Loss : 0.309301 Content Loss: 0.019421

run [1450]:
Style Loss : 0.308322 Content Loss: 0.019483

run [1500]:
Style Loss : 0.307472 Content Loss: 0.019519

run [1550]:
Style Loss : 0.306552 Content Loss: 0.019574

run [1600]:
Style Loss : 0.305569 Content Loss: 0.019633

run [1650]:
Style Loss : 0.304617 Content Loss: 0.019674

run [1700]:
Style Loss : 0.303617 Content Loss: 0.019725

run [1750]:
Style Loss : 0.302719 Content Loss: 0.019763

run [1800]:
Style Loss : 0.301961 Content Loss: 0.019807

run [1850]:
Style Loss : 0.301159 Content Loss: 0.019837

run [1900]:
Style Loss : 0.300379 Content Loss: 0.019873

run [1950]:
Style Loss : 0.299683 Content Loss: 0.019904

run [2000]:
Style Loss : 0.299106 Content Loss: 0.019932

run [2050]:
Style Loss : 0.298542 Content Loss: 0.019957

run [2100]:
Style Loss : 0.297997 Content Loss: 0.019980

run [2150]:
Style Loss : 0.297480 Content Loss: 0.020009

run [2200]:
Style Loss : 0.296986 Content Loss: 0.020038

run [2250]:
Style Loss : 0.296448 Content Loss: 0.020075

run [2300]:
Style Loss : 0.295976 Content Loss: 0.020103

run [2350]:
Style Loss : 0.295491 Content Loss: 0.020130

run [2400]:
Style Loss : 0.295011 Content Loss: 0.020151

run [2450]:
Style Loss : 0.294514 Content Loss: 0.020186

run [2500]:
Style Loss : 0.294052 Content Loss: 0.020210

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.141116 Content Loss: 0.006292

run [100]:
Style Loss : 0.630076 Content Loss: 0.010460

run [150]:
Style Loss : 0.482480 Content Loss: 0.012401

run [200]:
Style Loss : 0.404993 Content Loss: 0.013968

run [250]:
Style Loss : 0.362465 Content Loss: 0.015084

run [300]:
Style Loss : 0.336490 Content Loss: 0.015874

run [350]:
Style Loss : 0.319373 Content Loss: 0.016444

run [400]:
Style Loss : 0.307530 Content Loss: 0.016858

run [450]:
Style Loss : 0.298884 Content Loss: 0.017130

run [500]:
Style Loss : 0.292283 Content Loss: 0.017334

run [550]:
Style Loss : 0.287090 Content Loss: 0.017504

run [600]:
Style Loss : 0.282348 Content Loss: 0.017620

run [650]:
Style Loss : 0.278342 Content Loss: 0.017699

run [700]:
Style Loss : 0.274947 Content Loss: 0.017788

run [750]:
Style Loss : 0.271602 Content Loss: 0.017871

run [800]:
Style Loss : 0.268778 Content Loss: 0.017941

run [850]:
Style Loss : 0.265944 Content Loss: 0.018014

run [900]:
Style Loss : 0.263483 Content Loss: 0.018081

run [950]:
Style Loss : 0.261144 Content Loss: 0.018153

run [1000]:
Style Loss : 0.259085 Content Loss: 0.018208

run [1050]:
Style Loss : 0.257362 Content Loss: 0.018260

run [1100]:
Style Loss : 0.255894 Content Loss: 0.018311

run [1150]:
Style Loss : 0.254583 Content Loss: 0.018359

run [1200]:
Style Loss : 0.253425 Content Loss: 0.018391

run [1250]:
Style Loss : 0.252171 Content Loss: 0.018431

run [1300]:
Style Loss : 0.251033 Content Loss: 0.018471

run [1350]:
Style Loss : 0.250000 Content Loss: 0.018508

run [1400]:
Style Loss : 0.249158 Content Loss: 0.018536

run [1450]:
Style Loss : 0.248331 Content Loss: 0.018567

run [1500]:
Style Loss : 0.247610 Content Loss: 0.018591

run [1550]:
Style Loss : 0.246933 Content Loss: 0.018614

run [1600]:
Style Loss : 0.246297 Content Loss: 0.018639

run [1650]:
Style Loss : 0.245681 Content Loss: 0.018668

run [1700]:
Style Loss : 0.245142 Content Loss: 0.018693

run [1750]:
Style Loss : 0.244617 Content Loss: 0.018718

run [1800]:
Style Loss : 0.244121 Content Loss: 0.018741

run [1850]:
Style Loss : 0.243643 Content Loss: 0.018764

run [1900]:
Style Loss : 0.243175 Content Loss: 0.018787

run [1950]:
Style Loss : 0.242720 Content Loss: 0.018813

run [2000]:
Style Loss : 0.242306 Content Loss: 0.018838

run [2050]:
Style Loss : 0.241900 Content Loss: 0.018863

run [2100]:
Style Loss : 0.241517 Content Loss: 0.018885

run [2150]:
Style Loss : 0.241124 Content Loss: 0.018910

run [2200]:
Style Loss : 0.240686 Content Loss: 0.018938

run [2250]:
Style Loss : 0.240254 Content Loss: 0.018965

run [2300]:
Style Loss : 0.239835 Content Loss: 0.018989

run [2350]:
Style Loss : 0.239430 Content Loss: 0.019017

run [2400]:
Style Loss : 0.239014 Content Loss: 0.019047

run [2450]:
Style Loss : 0.238534 Content Loss: 0.019076

run [2500]:
Style Loss : 0.238080 Content Loss: 0.019105

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.651348 Content Loss: 0.007164

run [100]:
Style Loss : 0.413250 Content Loss: 0.010109

run [150]:
Style Loss : 0.337277 Content Loss: 0.011546

run [200]:
Style Loss : 0.298152 Content Loss: 0.012470

run [250]:
Style Loss : 0.274329 Content Loss: 0.013054

run [300]:
Style Loss : 0.256668 Content Loss: 0.013574

run [350]:
Style Loss : 0.243609 Content Loss: 0.013899

run [400]:
Style Loss : 0.233925 Content Loss: 0.014247

run [450]:
Style Loss : 0.225012 Content Loss: 0.014599

run [500]:
Style Loss : 0.216892 Content Loss: 0.014934

run [550]:
Style Loss : 0.209248 Content Loss: 0.015210

run [600]:
Style Loss : 0.202551 Content Loss: 0.015517

run [650]:
Style Loss : 0.196775 Content Loss: 0.015799

run [700]:
Style Loss : 0.192167 Content Loss: 0.016093

run [750]:
Style Loss : 0.187699 Content Loss: 0.016427

run [800]:
Style Loss : 0.183328 Content Loss: 0.016764

run [850]:
Style Loss : 0.179342 Content Loss: 0.017054

run [900]:
Style Loss : 0.175902 Content Loss: 0.017318

run [950]:
Style Loss : 0.172819 Content Loss: 0.017605

run [1000]:
Style Loss : 0.169767 Content Loss: 0.017877

run [1050]:
Style Loss : 0.166836 Content Loss: 0.018174

run [1100]:
Style Loss : 0.164153 Content Loss: 0.018554

run [1150]:
Style Loss : 0.161454 Content Loss: 0.018934

run [1200]:
Style Loss : 0.158159 Content Loss: 0.019369

run [1250]:
Style Loss : 0.154160 Content Loss: 0.019854

run [1300]:
Style Loss : 0.150956 Content Loss: 0.020383

run [1350]:
Style Loss : 0.148454 Content Loss: 0.021002

run [1400]:
Style Loss : 0.146108 Content Loss: 0.021530

run [1450]:
Style Loss : 0.143723 Content Loss: 0.022125

run [1500]:
Style Loss : 0.141914 Content Loss: 0.022908

run [1550]:
Style Loss : 0.140598 Content Loss: 0.023837

run [1600]:
Style Loss : 0.138790 Content Loss: 0.024640

run [1650]:
Style Loss : 0.197253 Content Loss: 0.028100

run [1700]:
Style Loss : 0.138122 Content Loss: 0.027340

run [1750]:
Style Loss : 0.137421 Content Loss: 0.027567

run [1800]:
Style Loss : 0.131876 Content Loss: 0.027739

run [1850]:
Style Loss : 0.130066 Content Loss: 0.027945

run [1900]:
Style Loss : 0.129411 Content Loss: 0.028353

run [1950]:
Style Loss : 0.127523 Content Loss: 0.028487

run [2000]:
Style Loss : 0.126065 Content Loss: 0.028591

run [2050]:
Style Loss : 0.125914 Content Loss: 0.028655

run [2100]:
Style Loss : 0.123846 Content Loss: 0.028744

run [2150]:
Style Loss : 0.130878 Content Loss: 0.028995

run [2200]:
Style Loss : 0.121832 Content Loss: 0.028799

run [2250]:
Style Loss : 0.120969 Content Loss: 0.028725

run [2300]:
Style Loss : 0.120325 Content Loss: 0.028620

run [2350]:
Style Loss : 0.121187 Content Loss: 0.028493

run [2400]:
Style Loss : 0.122060 Content Loss: 0.028358

run [2450]:
Style Loss : 0.119446 Content Loss: 0.028234

run [2500]:
Style Loss : 0.117574 Content Loss: 0.028129

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.026641 Content Loss: 0.005745

run [100]:
Style Loss : 0.531247 Content Loss: 0.009537

run [150]:
Style Loss : 0.385495 Content Loss: 0.011473

run [200]:
Style Loss : 0.321215 Content Loss: 0.012495

run [250]:
Style Loss : 0.279302 Content Loss: 0.013483

run [300]:
Style Loss : 0.247080 Content Loss: 0.014122

run [350]:
Style Loss : 0.227225 Content Loss: 0.014748

run [400]:
Style Loss : 0.212537 Content Loss: 0.015256

run [450]:
Style Loss : 0.201855 Content Loss: 0.015611

run [500]:
Style Loss : 0.194226 Content Loss: 0.015871

run [550]:
Style Loss : 0.187869 Content Loss: 0.016108

run [600]:
Style Loss : 0.182961 Content Loss: 0.016290

run [650]:
Style Loss : 0.179070 Content Loss: 0.016414

run [700]:
Style Loss : 0.175682 Content Loss: 0.016519

run [750]:
Style Loss : 0.172877 Content Loss: 0.016587

run [800]:
Style Loss : 0.170317 Content Loss: 0.016653

run [850]:
Style Loss : 0.168186 Content Loss: 0.016698

run [900]:
Style Loss : 0.166360 Content Loss: 0.016753

run [950]:
Style Loss : 0.164684 Content Loss: 0.016809

run [1000]:
Style Loss : 0.162826 Content Loss: 0.016863

run [1050]:
Style Loss : 0.161351 Content Loss: 0.016905

run [1100]:
Style Loss : 0.159889 Content Loss: 0.016947

run [1150]:
Style Loss : 0.158416 Content Loss: 0.016996

run [1200]:
Style Loss : 0.157114 Content Loss: 0.017047

run [1250]:
Style Loss : 0.155997 Content Loss: 0.017091

run [1300]:
Style Loss : 0.155126 Content Loss: 0.017124

run [1350]:
Style Loss : 0.154263 Content Loss: 0.017156

run [1400]:
Style Loss : 0.153456 Content Loss: 0.017184

run [1450]:
Style Loss : 0.152687 Content Loss: 0.017211

run [1500]:
Style Loss : 0.151829 Content Loss: 0.017244

run [1550]:
Style Loss : 0.151042 Content Loss: 0.017272

run [1600]:
Style Loss : 0.150288 Content Loss: 0.017300

run [1650]:
Style Loss : 0.149638 Content Loss: 0.017325

run [1700]:
Style Loss : 0.149044 Content Loss: 0.017349

run [1750]:
Style Loss : 0.148488 Content Loss: 0.017372

run [1800]:
Style Loss : 0.147711 Content Loss: 0.017400

run [1850]:
Style Loss : 0.147083 Content Loss: 0.017425

run [1900]:
Style Loss : 0.146479 Content Loss: 0.017451

run [1950]:
Style Loss : 0.145913 Content Loss: 0.017478

run [2000]:
Style Loss : 0.145366 Content Loss: 0.017507

run [2050]:
Style Loss : 0.144906 Content Loss: 0.017532

run [2100]:
Style Loss : 0.144480 Content Loss: 0.017558

run [2150]:
Style Loss : 0.144072 Content Loss: 0.017583

run [2200]:
Style Loss : 0.143640 Content Loss: 0.017607

run [2250]:
Style Loss : 0.143246 Content Loss: 0.017630

run [2300]:
Style Loss : 0.142867 Content Loss: 0.017653

run [2350]:
Style Loss : 0.142543 Content Loss: 0.017671

run [2400]:
Style Loss : 0.142200 Content Loss: 0.017691

run [2450]:
Style Loss : 0.141881 Content Loss: 0.017709

run [2500]:
Style Loss : 0.141579 Content Loss: 0.017729

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.820496 Content Loss: 0.003739

run [100]:
Style Loss : 1.834809 Content Loss: 0.007593

run [150]:
Style Loss : 1.228984 Content Loss: 0.010258

run [200]:
Style Loss : 0.954545 Content Loss: 0.011964

run [250]:
Style Loss : 0.811096 Content Loss: 0.013284

run [300]:
Style Loss : 0.720788 Content Loss: 0.014231

run [350]:
Style Loss : 0.657053 Content Loss: 0.015028

run [400]:
Style Loss : 0.610461 Content Loss: 0.015719

run [450]:
Style Loss : 0.576805 Content Loss: 0.016120

run [500]:
Style Loss : 0.551379 Content Loss: 0.016552

run [550]:
Style Loss : 0.529903 Content Loss: 0.016902

run [600]:
Style Loss : 0.511564 Content Loss: 0.017202

run [650]:
Style Loss : 0.495189 Content Loss: 0.017469

run [700]:
Style Loss : 0.480285 Content Loss: 0.017661

run [750]:
Style Loss : 0.467099 Content Loss: 0.017868

run [800]:
Style Loss : 0.454429 Content Loss: 0.018039

run [850]:
Style Loss : 0.443797 Content Loss: 0.018168

run [900]:
Style Loss : 0.434456 Content Loss: 0.018268

run [950]:
Style Loss : 0.426373 Content Loss: 0.018355

run [1000]:
Style Loss : 0.419004 Content Loss: 0.018443

run [1050]:
Style Loss : 0.412596 Content Loss: 0.018519

run [1100]:
Style Loss : 0.407066 Content Loss: 0.018593

run [1150]:
Style Loss : 0.402470 Content Loss: 0.018650

run [1200]:
Style Loss : 0.398319 Content Loss: 0.018714

run [1250]:
Style Loss : 0.394648 Content Loss: 0.018759

run [1300]:
Style Loss : 0.391393 Content Loss: 0.018802

run [1350]:
Style Loss : 0.388111 Content Loss: 0.018850

run [1400]:
Style Loss : 0.385173 Content Loss: 0.018900

run [1450]:
Style Loss : 0.382307 Content Loss: 0.018953

run [1500]:
Style Loss : 0.379377 Content Loss: 0.019020

run [1550]:
Style Loss : 0.376395 Content Loss: 0.019085

run [1600]:
Style Loss : 0.373434 Content Loss: 0.019153

run [1650]:
Style Loss : 0.370440 Content Loss: 0.019211

run [1700]:
Style Loss : 0.367394 Content Loss: 0.019289

run [1750]:
Style Loss : 0.364405 Content Loss: 0.019358

run [1800]:
Style Loss : 0.361629 Content Loss: 0.019429

run [1850]:
Style Loss : 0.358683 Content Loss: 0.019512

run [1900]:
Style Loss : 0.355571 Content Loss: 0.019578

run [1950]:
Style Loss : 0.352754 Content Loss: 0.019644

run [2000]:
Style Loss : 0.350197 Content Loss: 0.019704

run [2050]:
Style Loss : 0.347624 Content Loss: 0.019773

run [2100]:
Style Loss : 0.345008 Content Loss: 0.019833

run [2150]:
Style Loss : 0.342654 Content Loss: 0.019897

run [2200]:
Style Loss : 0.340288 Content Loss: 0.019979

run [2250]:
Style Loss : 0.338072 Content Loss: 0.020063

run [2300]:
Style Loss : 0.336006 Content Loss: 0.020142

run [2350]:
Style Loss : 0.333952 Content Loss: 0.020223

run [2400]:
Style Loss : 0.331910 Content Loss: 0.020299

run [2450]:
Style Loss : 0.329753 Content Loss: 0.020379

run [2500]:
Style Loss : 0.327533 Content Loss: 0.020458

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.697182 Content Loss: 0.007580

run [100]:
Style Loss : 0.328034 Content Loss: 0.012021

run [150]:
Style Loss : 0.236860 Content Loss: 0.013964

run [200]:
Style Loss : 0.196555 Content Loss: 0.014918

run [250]:
Style Loss : 0.173917 Content Loss: 0.015478

run [300]:
Style Loss : 0.159529 Content Loss: 0.015937

run [350]:
Style Loss : 0.148672 Content Loss: 0.016200

run [400]:
Style Loss : 0.138667 Content Loss: 0.016436

run [450]:
Style Loss : 0.127802 Content Loss: 0.016621

run [500]:
Style Loss : 0.120211 Content Loss: 0.016777

run [550]:
Style Loss : 0.114698 Content Loss: 0.016913

run [600]:
Style Loss : 0.110177 Content Loss: 0.017015

run [650]:
Style Loss : 0.106181 Content Loss: 0.017121

run [700]:
Style Loss : 0.103018 Content Loss: 0.017182

run [750]:
Style Loss : 0.100111 Content Loss: 0.017254

run [800]:
Style Loss : 0.097382 Content Loss: 0.017316

run [850]:
Style Loss : 0.094980 Content Loss: 0.017383

run [900]:
Style Loss : 0.092904 Content Loss: 0.017440

run [950]:
Style Loss : 0.091087 Content Loss: 0.017487

run [1000]:
Style Loss : 0.089323 Content Loss: 0.017535

run [1050]:
Style Loss : 0.087716 Content Loss: 0.017593

run [1100]:
Style Loss : 0.086104 Content Loss: 0.017654

run [1150]:
Style Loss : 0.084622 Content Loss: 0.017689

run [1200]:
Style Loss : 0.083261 Content Loss: 0.017726

run [1250]:
Style Loss : 0.081857 Content Loss: 0.017767

run [1300]:
Style Loss : 0.080469 Content Loss: 0.017805

run [1350]:
Style Loss : 0.079295 Content Loss: 0.017830

run [1400]:
Style Loss : 0.078291 Content Loss: 0.017840

run [1450]:
Style Loss : 0.077262 Content Loss: 0.017859

run [1500]:
Style Loss : 0.076437 Content Loss: 0.017858

run [1550]:
Style Loss : 0.075700 Content Loss: 0.017853

run [1600]:
Style Loss : 0.074968 Content Loss: 0.017855

run [1650]:
Style Loss : 0.074314 Content Loss: 0.017859

run [1700]:
Style Loss : 0.073689 Content Loss: 0.017864

run [1750]:
Style Loss : 0.073128 Content Loss: 0.017867

run [1800]:
Style Loss : 0.072547 Content Loss: 0.017874

run [1850]:
Style Loss : 0.071973 Content Loss: 0.017884

run [1900]:
Style Loss : 0.071464 Content Loss: 0.017896

run [1950]:
Style Loss : 0.070961 Content Loss: 0.017903

run [2000]:
Style Loss : 0.070405 Content Loss: 0.017912

run [2050]:
Style Loss : 0.069818 Content Loss: 0.017932

run [2100]:
Style Loss : 0.069298 Content Loss: 0.017946

run [2150]:
Style Loss : 0.068770 Content Loss: 0.017957

run [2200]:
Style Loss : 0.068270 Content Loss: 0.017958

run [2250]:
Style Loss : 0.067768 Content Loss: 0.017967

run [2300]:
Style Loss : 0.067327 Content Loss: 0.017966

run [2350]:
Style Loss : 0.066931 Content Loss: 0.017966

run [2400]:
Style Loss : 0.066543 Content Loss: 0.017969

run [2450]:
Style Loss : 0.066167 Content Loss: 0.017974

run [2500]:
Style Loss : 0.065841 Content Loss: 0.017981

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.864284 Content Loss: 0.004152

run [100]:
Style Loss : 1.037868 Content Loss: 0.008431

run [150]:
Style Loss : 0.754580 Content Loss: 0.010969

run [200]:
Style Loss : 0.589708 Content Loss: 0.012545

run [250]:
Style Loss : 0.495199 Content Loss: 0.013647

run [300]:
Style Loss : 0.442802 Content Loss: 0.014457

run [350]:
Style Loss : 0.407336 Content Loss: 0.014974

run [400]:
Style Loss : 0.382184 Content Loss: 0.015371

run [450]:
Style Loss : 0.361875 Content Loss: 0.015700

run [500]:
Style Loss : 0.346931 Content Loss: 0.015962

run [550]:
Style Loss : 0.335169 Content Loss: 0.016195

run [600]:
Style Loss : 0.325074 Content Loss: 0.016420

run [650]:
Style Loss : 0.316735 Content Loss: 0.016640

run [700]:
Style Loss : 0.309812 Content Loss: 0.016831

run [750]:
Style Loss : 0.303778 Content Loss: 0.017002

run [800]:
Style Loss : 0.298899 Content Loss: 0.017134

run [850]:
Style Loss : 0.293979 Content Loss: 0.017277

run [900]:
Style Loss : 0.289650 Content Loss: 0.017381

run [950]:
Style Loss : 0.285949 Content Loss: 0.017484

run [1000]:
Style Loss : 0.282248 Content Loss: 0.017584

run [1050]:
Style Loss : 0.278913 Content Loss: 0.017677

run [1100]:
Style Loss : 0.275968 Content Loss: 0.017761

run [1150]:
Style Loss : 0.273068 Content Loss: 0.017850

run [1200]:
Style Loss : 0.270542 Content Loss: 0.017927

run [1250]:
Style Loss : 0.268123 Content Loss: 0.017987

run [1300]:
Style Loss : 0.265677 Content Loss: 0.018042

run [1350]:
Style Loss : 0.263365 Content Loss: 0.018096

run [1400]:
Style Loss : 0.261410 Content Loss: 0.018136

run [1450]:
Style Loss : 0.259539 Content Loss: 0.018192

run [1500]:
Style Loss : 0.257862 Content Loss: 0.018253

run [1550]:
Style Loss : 0.256393 Content Loss: 0.018312

run [1600]:
Style Loss : 0.254997 Content Loss: 0.018373

run [1650]:
Style Loss : 0.253614 Content Loss: 0.018432

run [1700]:
Style Loss : 0.252328 Content Loss: 0.018480

run [1750]:
Style Loss : 0.251108 Content Loss: 0.018523

run [1800]:
Style Loss : 0.249974 Content Loss: 0.018567

run [1850]:
Style Loss : 0.248902 Content Loss: 0.018604

run [1900]:
Style Loss : 0.247863 Content Loss: 0.018645

run [1950]:
Style Loss : 0.246888 Content Loss: 0.018685

run [2000]:
Style Loss : 0.245916 Content Loss: 0.018715

run [2050]:
Style Loss : 0.245124 Content Loss: 0.018743

run [2100]:
Style Loss : 0.244307 Content Loss: 0.018779

run [2150]:
Style Loss : 0.243496 Content Loss: 0.018810

run [2200]:
Style Loss : 0.242794 Content Loss: 0.018837

run [2250]:
Style Loss : 0.242134 Content Loss: 0.018857

run [2300]:
Style Loss : 0.241505 Content Loss: 0.018880

run [2350]:
Style Loss : 0.240895 Content Loss: 0.018901

run [2400]:
Style Loss : 0.240315 Content Loss: 0.018918

run [2450]:
Style Loss : 0.239800 Content Loss: 0.018931

run [2500]:
Style Loss : 0.239237 Content Loss: 0.018952

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.542676 Content Loss: 0.006020

run [100]:
Style Loss : 0.855971 Content Loss: 0.011301

run [150]:
Style Loss : 0.650254 Content Loss: 0.014525

run [200]:
Style Loss : 0.547275 Content Loss: 0.016238

run [250]:
Style Loss : 0.488646 Content Loss: 0.017476

run [300]:
Style Loss : 0.446680 Content Loss: 0.018213

run [350]:
Style Loss : 0.416653 Content Loss: 0.018761

run [400]:
Style Loss : 0.392631 Content Loss: 0.019154

run [450]:
Style Loss : 0.371629 Content Loss: 0.019601

run [500]:
Style Loss : 0.354565 Content Loss: 0.020009

run [550]:
Style Loss : 0.339930 Content Loss: 0.020310

run [600]:
Style Loss : 0.327310 Content Loss: 0.020555

run [650]:
Style Loss : 0.316664 Content Loss: 0.020767

run [700]:
Style Loss : 0.307919 Content Loss: 0.020982

run [750]:
Style Loss : 0.300227 Content Loss: 0.021203

run [800]:
Style Loss : 0.293347 Content Loss: 0.021425

run [850]:
Style Loss : 0.287329 Content Loss: 0.021631

run [900]:
Style Loss : 0.282005 Content Loss: 0.021807

run [950]:
Style Loss : 0.276810 Content Loss: 0.022023

run [1000]:
Style Loss : 0.272130 Content Loss: 0.022196

run [1050]:
Style Loss : 0.267853 Content Loss: 0.022356

run [1100]:
Style Loss : 0.263643 Content Loss: 0.022507

run [1150]:
Style Loss : 0.259707 Content Loss: 0.022644

run [1200]:
Style Loss : 0.256160 Content Loss: 0.022778

run [1250]:
Style Loss : 0.252910 Content Loss: 0.022916

run [1300]:
Style Loss : 0.249995 Content Loss: 0.023058

run [1350]:
Style Loss : 0.247080 Content Loss: 0.023193

run [1400]:
Style Loss : 0.244538 Content Loss: 0.023323

run [1450]:
Style Loss : 0.242144 Content Loss: 0.023445

run [1500]:
Style Loss : 0.240048 Content Loss: 0.023551

run [1550]:
Style Loss : 0.237998 Content Loss: 0.023677

run [1600]:
Style Loss : 0.236020 Content Loss: 0.023806

run [1650]:
Style Loss : 0.234131 Content Loss: 0.023938

run [1700]:
Style Loss : 0.232332 Content Loss: 0.024064

run [1750]:
Style Loss : 0.230600 Content Loss: 0.024190

run [1800]:
Style Loss : 0.228972 Content Loss: 0.024302

run [1850]:
Style Loss : 0.227362 Content Loss: 0.024402

run [1900]:
Style Loss : 0.225759 Content Loss: 0.024507

run [1950]:
Style Loss : 0.224207 Content Loss: 0.024601

run [2000]:
Style Loss : 0.222777 Content Loss: 0.024687

run [2050]:
Style Loss : 0.221386 Content Loss: 0.024779

run [2100]:
Style Loss : 0.220092 Content Loss: 0.024859

run [2150]:
Style Loss : 0.218894 Content Loss: 0.024947

run [2200]:
Style Loss : 0.217747 Content Loss: 0.025014

run [2250]:
Style Loss : 0.216601 Content Loss: 0.025092

run [2300]:
Style Loss : 0.215450 Content Loss: 0.025157

run [2350]:
Style Loss : 0.214409 Content Loss: 0.025214

run [2400]:
Style Loss : 0.213388 Content Loss: 0.025276

run [2450]:
Style Loss : 0.212408 Content Loss: 0.025338

run [2500]:
Style Loss : 0.211467 Content Loss: 0.025398

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.190947 Content Loss: 0.005306

run [100]:
Style Loss : 0.883553 Content Loss: 0.011418

run [150]:
Style Loss : 0.559852 Content Loss: 0.014815

run [200]:
Style Loss : 0.426259 Content Loss: 0.016869

run [250]:
Style Loss : 0.356365 Content Loss: 0.018295

run [300]:
Style Loss : 0.313632 Content Loss: 0.019177

run [350]:
Style Loss : 0.283284 Content Loss: 0.019814

run [400]:
Style Loss : 0.261525 Content Loss: 0.020272

run [450]:
Style Loss : 0.245373 Content Loss: 0.020611

run [500]:
Style Loss : 0.233758 Content Loss: 0.020855

run [550]:
Style Loss : 0.225117 Content Loss: 0.021014

run [600]:
Style Loss : 0.217657 Content Loss: 0.021161

run [650]:
Style Loss : 0.211815 Content Loss: 0.021299

run [700]:
Style Loss : 0.207268 Content Loss: 0.021405

run [750]:
Style Loss : 0.203125 Content Loss: 0.021513

run [800]:
Style Loss : 0.199468 Content Loss: 0.021602

run [850]:
Style Loss : 0.196146 Content Loss: 0.021692

run [900]:
Style Loss : 0.193197 Content Loss: 0.021776

run [950]:
Style Loss : 0.190742 Content Loss: 0.021853

run [1000]:
Style Loss : 0.188379 Content Loss: 0.021949

run [1050]:
Style Loss : 0.186307 Content Loss: 0.022026

run [1100]:
Style Loss : 0.184405 Content Loss: 0.022110

run [1150]:
Style Loss : 0.180478 Content Loss: 0.022181

run [1200]:
Style Loss : 0.177656 Content Loss: 0.022252

run [1250]:
Style Loss : 0.175448 Content Loss: 0.022317

run [1300]:
Style Loss : 0.173359 Content Loss: 0.022372

run [1350]:
Style Loss : 0.171184 Content Loss: 0.022432

run [1400]:
Style Loss : 0.168820 Content Loss: 0.022513

run [1450]:
Style Loss : 0.166854 Content Loss: 0.022558

run [1500]:
Style Loss : 0.165122 Content Loss: 0.022599

run [1550]:
Style Loss : 0.163545 Content Loss: 0.022639

run [1600]:
Style Loss : 0.162178 Content Loss: 0.022679

run [1650]:
Style Loss : 0.160921 Content Loss: 0.022713

run [1700]:
Style Loss : 0.159745 Content Loss: 0.022750

run [1750]:
Style Loss : 0.158747 Content Loss: 0.022781

run [1800]:
Style Loss : 0.157866 Content Loss: 0.022810

run [1850]:
Style Loss : 0.156985 Content Loss: 0.022840

run [1900]:
Style Loss : 0.156094 Content Loss: 0.022880

run [1950]:
Style Loss : 0.155250 Content Loss: 0.022906

run [2000]:
Style Loss : 0.154517 Content Loss: 0.022931

run [2050]:
Style Loss : 0.153832 Content Loss: 0.022951

run [2100]:
Style Loss : 0.153074 Content Loss: 0.022975

run [2150]:
Style Loss : 0.152389 Content Loss: 0.022998

run [2200]:
Style Loss : 0.151772 Content Loss: 0.023016

run [2250]:
Style Loss : 0.151156 Content Loss: 0.023039

run [2300]:
Style Loss : 0.150598 Content Loss: 0.023063

run [2350]:
Style Loss : 0.150067 Content Loss: 0.023084

run [2400]:
Style Loss : 0.149541 Content Loss: 0.023103

run [2450]:
Style Loss : 0.149022 Content Loss: 0.023130

run [2500]:
Style Loss : 0.148537 Content Loss: 0.023151

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.987496 Content Loss: 0.006110

run [100]:
Style Loss : 1.524298 Content Loss: 0.012700

run [150]:
Style Loss : 1.018309 Content Loss: 0.016138

run [200]:
Style Loss : 0.792400 Content Loss: 0.018315

run [250]:
Style Loss : 0.667612 Content Loss: 0.019754

run [300]:
Style Loss : 0.587738 Content Loss: 0.020959

run [350]:
Style Loss : 0.533725 Content Loss: 0.021919

run [400]:
Style Loss : 0.496059 Content Loss: 0.022662

run [450]:
Style Loss : 0.469411 Content Loss: 0.023275

run [500]:
Style Loss : 0.446696 Content Loss: 0.023755

run [550]:
Style Loss : 0.428889 Content Loss: 0.024105

run [600]:
Style Loss : 0.415321 Content Loss: 0.024409

run [650]:
Style Loss : 0.404855 Content Loss: 0.024592

run [700]:
Style Loss : 0.396495 Content Loss: 0.024773

run [750]:
Style Loss : 0.389692 Content Loss: 0.024930

run [800]:
Style Loss : 0.382966 Content Loss: 0.025068

run [850]:
Style Loss : 0.376829 Content Loss: 0.025196

run [900]:
Style Loss : 0.371729 Content Loss: 0.025306

run [950]:
Style Loss : 0.367030 Content Loss: 0.025407

run [1000]:
Style Loss : 0.362662 Content Loss: 0.025500

run [1050]:
Style Loss : 0.358759 Content Loss: 0.025576

run [1100]:
Style Loss : 0.355545 Content Loss: 0.025657

run [1150]:
Style Loss : 0.352704 Content Loss: 0.025716

run [1200]:
Style Loss : 0.350275 Content Loss: 0.025766

run [1250]:
Style Loss : 0.348047 Content Loss: 0.025825

run [1300]:
Style Loss : 0.345931 Content Loss: 0.025869

run [1350]:
Style Loss : 0.343920 Content Loss: 0.025908

run [1400]:
Style Loss : 0.341946 Content Loss: 0.025941

run [1450]:
Style Loss : 0.340161 Content Loss: 0.025972

run [1500]:
Style Loss : 0.338464 Content Loss: 0.026012

run [1550]:
Style Loss : 0.336819 Content Loss: 0.026047

run [1600]:
Style Loss : 0.335270 Content Loss: 0.026078

run [1650]:
Style Loss : 0.333831 Content Loss: 0.026109

run [1700]:
Style Loss : 0.332552 Content Loss: 0.026141

run [1750]:
Style Loss : 0.331470 Content Loss: 0.026163

run [1800]:
Style Loss : 0.330455 Content Loss: 0.026188

run [1850]:
Style Loss : 0.329334 Content Loss: 0.026214

run [1900]:
Style Loss : 0.328253 Content Loss: 0.026237

run [1950]:
Style Loss : 0.327281 Content Loss: 0.026256

run [2000]:
Style Loss : 0.326428 Content Loss: 0.026277

run [2050]:
Style Loss : 0.325558 Content Loss: 0.026298

run [2100]:
Style Loss : 0.324696 Content Loss: 0.026322

run [2150]:
Style Loss : 0.323819 Content Loss: 0.026350

run [2200]:
Style Loss : 0.323001 Content Loss: 0.026377

run [2250]:
Style Loss : 0.322157 Content Loss: 0.026406

run [2300]:
Style Loss : 0.321381 Content Loss: 0.026430

run [2350]:
Style Loss : 0.320591 Content Loss: 0.026452

run [2400]:
Style Loss : 0.319823 Content Loss: 0.026474

run [2450]:
Style Loss : 0.319125 Content Loss: 0.026495

run [2500]:
Style Loss : 0.318433 Content Loss: 0.026520

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.942761 Content Loss: 0.009237

run [100]:
Style Loss : 0.577770 Content Loss: 0.013824

run [150]:
Style Loss : 0.444335 Content Loss: 0.015826

run [200]:
Style Loss : 0.376364 Content Loss: 0.016974

run [250]:
Style Loss : 0.337801 Content Loss: 0.017822

run [300]:
Style Loss : 0.312893 Content Loss: 0.018557

run [350]:
Style Loss : 0.296577 Content Loss: 0.019096

run [400]:
Style Loss : 0.283905 Content Loss: 0.019404

run [450]:
Style Loss : 0.273676 Content Loss: 0.019654

run [500]:
Style Loss : 0.264949 Content Loss: 0.019946

run [550]:
Style Loss : 0.258233 Content Loss: 0.020210

run [600]:
Style Loss : 0.252399 Content Loss: 0.020393

run [650]:
Style Loss : 0.247158 Content Loss: 0.020577

run [700]:
Style Loss : 0.242515 Content Loss: 0.020739

run [750]:
Style Loss : 0.238286 Content Loss: 0.020903

run [800]:
Style Loss : 0.233887 Content Loss: 0.021096

run [850]:
Style Loss : 0.229799 Content Loss: 0.021263

run [900]:
Style Loss : 0.226417 Content Loss: 0.021437

run [950]:
Style Loss : 0.223341 Content Loss: 0.021557

run [1000]:
Style Loss : 0.220389 Content Loss: 0.021702

run [1050]:
Style Loss : 0.217784 Content Loss: 0.021838

run [1100]:
Style Loss : 0.215321 Content Loss: 0.021976

run [1150]:
Style Loss : 0.213218 Content Loss: 0.022087

run [1200]:
Style Loss : 0.211160 Content Loss: 0.022211

run [1250]:
Style Loss : 0.209302 Content Loss: 0.022316

run [1300]:
Style Loss : 0.207568 Content Loss: 0.022447

run [1350]:
Style Loss : 0.205996 Content Loss: 0.022576

run [1400]:
Style Loss : 0.204562 Content Loss: 0.022677

run [1450]:
Style Loss : 0.203319 Content Loss: 0.022783

run [1500]:
Style Loss : 0.202100 Content Loss: 0.022877

run [1550]:
Style Loss : 0.200987 Content Loss: 0.022966

run [1600]:
Style Loss : 0.199898 Content Loss: 0.023071

run [1650]:
Style Loss : 0.198853 Content Loss: 0.023141

run [1700]:
Style Loss : 0.197944 Content Loss: 0.023223

run [1750]:
Style Loss : 0.197005 Content Loss: 0.023308

run [1800]:
Style Loss : 0.196051 Content Loss: 0.023383

run [1850]:
Style Loss : 0.195213 Content Loss: 0.023428

run [1900]:
Style Loss : 0.194349 Content Loss: 0.023484

run [1950]:
Style Loss : 0.193527 Content Loss: 0.023530

run [2000]:
Style Loss : 0.192721 Content Loss: 0.023594

run [2050]:
Style Loss : 0.191914 Content Loss: 0.023640

run [2100]:
Style Loss : 0.191151 Content Loss: 0.023677

run [2150]:
Style Loss : 0.190477 Content Loss: 0.023738

run [2200]:
Style Loss : 0.189837 Content Loss: 0.023782

run [2250]:
Style Loss : 0.189286 Content Loss: 0.023830

run [2300]:
Style Loss : 0.188760 Content Loss: 0.023870

run [2350]:
Style Loss : 0.188288 Content Loss: 0.023908

run [2400]:
Style Loss : 0.187855 Content Loss: 0.023938

run [2450]:
Style Loss : 0.187457 Content Loss: 0.023969

run [2500]:
Style Loss : 0.187132 Content Loss: 0.023988

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.904001 Content Loss: 0.012795

run [100]:
Style Loss : 0.540510 Content Loss: 0.017848

run [150]:
Style Loss : 0.414072 Content Loss: 0.020719

run [200]:
Style Loss : 0.349579 Content Loss: 0.022816

run [250]:
Style Loss : 0.300484 Content Loss: 0.024571

run [300]:
Style Loss : 0.264954 Content Loss: 0.026028

run [350]:
Style Loss : 0.241463 Content Loss: 0.027306

run [400]:
Style Loss : 0.224881 Content Loss: 0.028458

run [450]:
Style Loss : 0.212540 Content Loss: 0.029396

run [500]:
Style Loss : 0.204067 Content Loss: 0.029977

run [550]:
Style Loss : 0.197982 Content Loss: 0.030405

run [600]:
Style Loss : 0.192621 Content Loss: 0.030759

run [650]:
Style Loss : 0.188074 Content Loss: 0.031004

run [700]:
Style Loss : 0.183439 Content Loss: 0.031200

run [750]:
Style Loss : 0.178579 Content Loss: 0.031413

run [800]:
Style Loss : 0.173848 Content Loss: 0.031631

run [850]:
Style Loss : 0.169700 Content Loss: 0.031862

run [900]:
Style Loss : 0.166565 Content Loss: 0.032066

run [950]:
Style Loss : 0.163483 Content Loss: 0.032291

run [1000]:
Style Loss : 0.160658 Content Loss: 0.032455

run [1050]:
Style Loss : 0.157955 Content Loss: 0.032690

run [1100]:
Style Loss : 0.155384 Content Loss: 0.032903

run [1150]:
Style Loss : 0.153175 Content Loss: 0.033074

run [1200]:
Style Loss : 0.151349 Content Loss: 0.033227

run [1250]:
Style Loss : 0.149830 Content Loss: 0.033396

run [1300]:
Style Loss : 0.148571 Content Loss: 0.033532

run [1350]:
Style Loss : 0.147338 Content Loss: 0.033664

run [1400]:
Style Loss : 0.146222 Content Loss: 0.033792

run [1450]:
Style Loss : 0.145209 Content Loss: 0.033915

run [1500]:
Style Loss : 0.144318 Content Loss: 0.034021

run [1550]:
Style Loss : 0.143354 Content Loss: 0.034144

run [1600]:
Style Loss : 0.142476 Content Loss: 0.034262

run [1650]:
Style Loss : 0.141697 Content Loss: 0.034356

run [1700]:
Style Loss : 0.140982 Content Loss: 0.034423

run [1750]:
Style Loss : 0.140360 Content Loss: 0.034492

run [1800]:
Style Loss : 0.139762 Content Loss: 0.034562

run [1850]:
Style Loss : 0.139241 Content Loss: 0.034612

run [1900]:
Style Loss : 0.138726 Content Loss: 0.034656

run [1950]:
Style Loss : 0.138232 Content Loss: 0.034693

run [2000]:
Style Loss : 0.137785 Content Loss: 0.034732

run [2050]:
Style Loss : 0.137378 Content Loss: 0.034780

run [2100]:
Style Loss : 0.136995 Content Loss: 0.034804

run [2150]:
Style Loss : 0.136622 Content Loss: 0.034831

run [2200]:
Style Loss : 0.136303 Content Loss: 0.034853

run [2250]:
Style Loss : 0.135949 Content Loss: 0.034890

run [2300]:
Style Loss : 0.135534 Content Loss: 0.034916

run [2350]:
Style Loss : 0.135217 Content Loss: 0.034929

run [2400]:
Style Loss : 0.134930 Content Loss: 0.034947

run [2450]:
Style Loss : 0.134660 Content Loss: 0.034969

run [2500]:
Style Loss : 0.134416 Content Loss: 0.034984

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.563187 Content Loss: 0.007011

run [100]:
Style Loss : 0.943768 Content Loss: 0.009634

run [150]:
Style Loss : 0.744651 Content Loss: 0.011735

run [200]:
Style Loss : 0.649897 Content Loss: 0.013313

run [250]:
Style Loss : 0.591462 Content Loss: 0.014565

run [300]:
Style Loss : 0.550826 Content Loss: 0.015817

run [350]:
Style Loss : 0.518613 Content Loss: 0.016987

run [400]:
Style Loss : 0.495136 Content Loss: 0.017937

run [450]:
Style Loss : 0.476966 Content Loss: 0.018826

run [500]:
Style Loss : 0.461509 Content Loss: 0.019597

run [550]:
Style Loss : 0.447301 Content Loss: 0.020267

run [600]:
Style Loss : 0.435010 Content Loss: 0.020898

run [650]:
Style Loss : 0.424338 Content Loss: 0.021424

run [700]:
Style Loss : 0.414564 Content Loss: 0.021922

run [750]:
Style Loss : 0.405520 Content Loss: 0.022424

run [800]:
Style Loss : 0.398055 Content Loss: 0.022809

run [850]:
Style Loss : 0.392034 Content Loss: 0.023162

run [900]:
Style Loss : 0.386491 Content Loss: 0.023523

run [950]:
Style Loss : 0.381473 Content Loss: 0.023827

run [1000]:
Style Loss : 0.376417 Content Loss: 0.024175

run [1050]:
Style Loss : 0.371985 Content Loss: 0.024429

run [1100]:
Style Loss : 0.368188 Content Loss: 0.024617

run [1150]:
Style Loss : 0.364791 Content Loss: 0.024820

run [1200]:
Style Loss : 0.361757 Content Loss: 0.025032

run [1250]:
Style Loss : 0.358890 Content Loss: 0.025203

run [1300]:
Style Loss : 0.356212 Content Loss: 0.025364

run [1350]:
Style Loss : 0.353566 Content Loss: 0.025522

run [1400]:
Style Loss : 0.350862 Content Loss: 0.025641

run [1450]:
Style Loss : 0.348482 Content Loss: 0.025752

run [1500]:
Style Loss : 0.346196 Content Loss: 0.025890

run [1550]:
Style Loss : 0.344122 Content Loss: 0.025997

run [1600]:
Style Loss : 0.342334 Content Loss: 0.026117

run [1650]:
Style Loss : 0.340562 Content Loss: 0.026193

run [1700]:
Style Loss : 0.338915 Content Loss: 0.026300

run [1750]:
Style Loss : 0.337310 Content Loss: 0.026375

run [1800]:
Style Loss : 0.335790 Content Loss: 0.026453

run [1850]:
Style Loss : 0.334213 Content Loss: 0.026506

run [1900]:
Style Loss : 0.332856 Content Loss: 0.026566

run [1950]:
Style Loss : 0.331798 Content Loss: 0.026623

run [2000]:
Style Loss : 0.330638 Content Loss: 0.026642

run [2050]:
Style Loss : 0.329575 Content Loss: 0.026689

run [2100]:
Style Loss : 0.328603 Content Loss: 0.026741

run [2150]:
Style Loss : 0.327514 Content Loss: 0.026801

run [2200]:
Style Loss : 0.326533 Content Loss: 0.026864

run [2250]:
Style Loss : 0.325501 Content Loss: 0.026948

run [2300]:
Style Loss : 0.324544 Content Loss: 0.027004

run [2350]:
Style Loss : 0.323632 Content Loss: 0.027067

run [2400]:
Style Loss : 0.322694 Content Loss: 0.027109

run [2450]:
Style Loss : 0.321837 Content Loss: 0.027188

run [2500]:
Style Loss : 0.321062 Content Loss: 0.027230

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.698298 Content Loss: 0.006275

run [100]:
Style Loss : 0.747510 Content Loss: 0.012980

run [150]:
Style Loss : 0.509366 Content Loss: 0.016122

run [200]:
Style Loss : 0.406543 Content Loss: 0.017875

run [250]:
Style Loss : 0.348005 Content Loss: 0.018813

run [300]:
Style Loss : 0.310889 Content Loss: 0.019607

run [350]:
Style Loss : 0.286828 Content Loss: 0.020028

run [400]:
Style Loss : 0.267953 Content Loss: 0.020420

run [450]:
Style Loss : 0.253074 Content Loss: 0.020779

run [500]:
Style Loss : 0.241281 Content Loss: 0.021068

run [550]:
Style Loss : 0.230556 Content Loss: 0.021313

run [600]:
Style Loss : 0.221577 Content Loss: 0.021551

run [650]:
Style Loss : 0.213902 Content Loss: 0.021734

run [700]:
Style Loss : 0.207280 Content Loss: 0.021888

run [750]:
Style Loss : 0.202182 Content Loss: 0.022058

run [800]:
Style Loss : 0.197404 Content Loss: 0.022204

run [850]:
Style Loss : 0.193186 Content Loss: 0.022358

run [900]:
Style Loss : 0.189417 Content Loss: 0.022503

run [950]:
Style Loss : 0.185726 Content Loss: 0.022641

run [1000]:
Style Loss : 0.182090 Content Loss: 0.022781

run [1050]:
Style Loss : 0.178810 Content Loss: 0.022915

run [1100]:
Style Loss : 0.175955 Content Loss: 0.023042

run [1150]:
Style Loss : 0.173407 Content Loss: 0.023176

run [1200]:
Style Loss : 0.171050 Content Loss: 0.023305

run [1250]:
Style Loss : 0.168546 Content Loss: 0.023433

run [1300]:
Style Loss : 0.166258 Content Loss: 0.023564

run [1350]:
Style Loss : 0.164170 Content Loss: 0.023694

run [1400]:
Style Loss : 0.162170 Content Loss: 0.023823

run [1450]:
Style Loss : 0.160305 Content Loss: 0.023953

run [1500]:
Style Loss : 0.158543 Content Loss: 0.024076

run [1550]:
Style Loss : 0.156935 Content Loss: 0.024186

run [1600]:
Style Loss : 0.155306 Content Loss: 0.024311

run [1650]:
Style Loss : 0.153758 Content Loss: 0.024421

run [1700]:
Style Loss : 0.152271 Content Loss: 0.024526

run [1750]:
Style Loss : 0.150911 Content Loss: 0.024639

run [1800]:
Style Loss : 0.149617 Content Loss: 0.024748

run [1850]:
Style Loss : 0.148449 Content Loss: 0.024831

run [1900]:
Style Loss : 0.147345 Content Loss: 0.024914

run [1950]:
Style Loss : 0.146294 Content Loss: 0.025010

run [2000]:
Style Loss : 0.145289 Content Loss: 0.025099

run [2050]:
Style Loss : 0.144333 Content Loss: 0.025175

run [2100]:
Style Loss : 0.143451 Content Loss: 0.025263

run [2150]:
Style Loss : 0.142602 Content Loss: 0.025338

run [2200]:
Style Loss : 0.141794 Content Loss: 0.025413

run [2250]:
Style Loss : 0.141036 Content Loss: 0.025485

run [2300]:
Style Loss : 0.140255 Content Loss: 0.025571

run [2350]:
Style Loss : 0.139463 Content Loss: 0.025648

run [2400]:
Style Loss : 0.138748 Content Loss: 0.025717

run [2450]:
Style Loss : 0.138054 Content Loss: 0.025804

run [2500]:
Style Loss : 0.137575 Content Loss: 0.025927

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.291777 Content Loss: 0.009284

run [100]:
Style Loss : 0.665533 Content Loss: 0.015876

run [150]:
Style Loss : 0.453837 Content Loss: 0.019400

run [200]:
Style Loss : 0.354077 Content Loss: 0.021574

run [250]:
Style Loss : 0.299289 Content Loss: 0.022742

run [300]:
Style Loss : 0.266407 Content Loss: 0.023454

run [350]:
Style Loss : 0.243040 Content Loss: 0.023905

run [400]:
Style Loss : 0.226424 Content Loss: 0.024102

run [450]:
Style Loss : 0.214083 Content Loss: 0.024292

run [500]:
Style Loss : 0.205058 Content Loss: 0.024469

run [550]:
Style Loss : 0.197656 Content Loss: 0.024599

run [600]:
Style Loss : 0.191749 Content Loss: 0.024724

run [650]:
Style Loss : 0.186745 Content Loss: 0.024829

run [700]:
Style Loss : 0.181929 Content Loss: 0.024910

run [750]:
Style Loss : 0.178011 Content Loss: 0.024965

run [800]:
Style Loss : 0.174405 Content Loss: 0.025003

run [850]:
Style Loss : 0.171143 Content Loss: 0.025049

run [900]:
Style Loss : 0.167945 Content Loss: 0.025110

run [950]:
Style Loss : 0.164910 Content Loss: 0.025171

run [1000]:
Style Loss : 0.162082 Content Loss: 0.025217

run [1050]:
Style Loss : 0.159853 Content Loss: 0.025241

run [1100]:
Style Loss : 0.157923 Content Loss: 0.025274

run [1150]:
Style Loss : 0.156243 Content Loss: 0.025304

run [1200]:
Style Loss : 0.154829 Content Loss: 0.025329

run [1250]:
Style Loss : 0.153521 Content Loss: 0.025356

run [1300]:
Style Loss : 0.152290 Content Loss: 0.025384

run [1350]:
Style Loss : 0.151199 Content Loss: 0.025404

run [1400]:
Style Loss : 0.150226 Content Loss: 0.025421

run [1450]:
Style Loss : 0.149332 Content Loss: 0.025433

run [1500]:
Style Loss : 0.148521 Content Loss: 0.025454

run [1550]:
Style Loss : 0.147798 Content Loss: 0.025473

run [1600]:
Style Loss : 0.147159 Content Loss: 0.025489

run [1650]:
Style Loss : 0.146474 Content Loss: 0.025510

run [1700]:
Style Loss : 0.145884 Content Loss: 0.025529

run [1750]:
Style Loss : 0.145346 Content Loss: 0.025554

run [1800]:
Style Loss : 0.144843 Content Loss: 0.025572

run [1850]:
Style Loss : 0.144361 Content Loss: 0.025589

run [1900]:
Style Loss : 0.143903 Content Loss: 0.025598

run [1950]:
Style Loss : 0.143503 Content Loss: 0.025608

run [2000]:
Style Loss : 0.143109 Content Loss: 0.025620

run [2050]:
Style Loss : 0.142735 Content Loss: 0.025630

run [2100]:
Style Loss : 0.142321 Content Loss: 0.025647

run [2150]:
Style Loss : 0.141946 Content Loss: 0.025667

run [2200]:
Style Loss : 0.141575 Content Loss: 0.025684

run [2250]:
Style Loss : 0.141190 Content Loss: 0.025702

run [2300]:
Style Loss : 0.140699 Content Loss: 0.025716

run [2350]:
Style Loss : 0.140237 Content Loss: 0.025732

run [2400]:
Style Loss : 0.139836 Content Loss: 0.025741

run [2450]:
Style Loss : 0.139439 Content Loss: 0.025757

run [2500]:
Style Loss : 0.139101 Content Loss: 0.025767

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.557671 Content Loss: 0.007684

run [100]:
Style Loss : 0.650455 Content Loss: 0.014063

run [150]:
Style Loss : 0.417571 Content Loss: 0.017496

run [200]:
Style Loss : 0.309536 Content Loss: 0.019415

run [250]:
Style Loss : 0.256614 Content Loss: 0.020432

run [300]:
Style Loss : 0.226016 Content Loss: 0.021290

run [350]:
Style Loss : 0.205825 Content Loss: 0.021635

run [400]:
Style Loss : 0.191904 Content Loss: 0.021835

run [450]:
Style Loss : 0.181388 Content Loss: 0.022054

run [500]:
Style Loss : 0.173205 Content Loss: 0.022170

run [550]:
Style Loss : 0.165878 Content Loss: 0.022309

run [600]:
Style Loss : 0.160016 Content Loss: 0.022410

run [650]:
Style Loss : 0.154620 Content Loss: 0.022553

run [700]:
Style Loss : 0.149551 Content Loss: 0.022694

run [750]:
Style Loss : 0.145522 Content Loss: 0.022792

run [800]:
Style Loss : 0.142257 Content Loss: 0.022882

run [850]:
Style Loss : 0.139214 Content Loss: 0.022968

run [900]:
Style Loss : 0.136075 Content Loss: 0.023055

run [950]:
Style Loss : 0.133160 Content Loss: 0.023141

run [1000]:
Style Loss : 0.130497 Content Loss: 0.023217

run [1050]:
Style Loss : 0.127857 Content Loss: 0.023287

run [1100]:
Style Loss : 0.125650 Content Loss: 0.023345

run [1150]:
Style Loss : 0.123275 Content Loss: 0.023424

run [1200]:
Style Loss : 0.120694 Content Loss: 0.023489

run [1250]:
Style Loss : 0.118332 Content Loss: 0.023560

run [1300]:
Style Loss : 0.116195 Content Loss: 0.023637

run [1350]:
Style Loss : 0.114399 Content Loss: 0.023723

run [1400]:
Style Loss : 0.112870 Content Loss: 0.023796

run [1450]:
Style Loss : 0.111387 Content Loss: 0.023878

run [1500]:
Style Loss : 0.110064 Content Loss: 0.023951

run [1550]:
Style Loss : 0.108775 Content Loss: 0.024024

run [1600]:
Style Loss : 0.107683 Content Loss: 0.024085

run [1650]:
Style Loss : 0.106739 Content Loss: 0.024142

run [1700]:
Style Loss : 0.105799 Content Loss: 0.024201

run [1750]:
Style Loss : 0.104941 Content Loss: 0.024263

run [1800]:
Style Loss : 0.104150 Content Loss: 0.024321

run [1850]:
Style Loss : 0.103414 Content Loss: 0.024380

run [1900]:
Style Loss : 0.102632 Content Loss: 0.024435

run [1950]:
Style Loss : 0.101955 Content Loss: 0.024491

run [2000]:
Style Loss : 0.101353 Content Loss: 0.024549

run [2050]:
Style Loss : 0.100791 Content Loss: 0.024601

run [2100]:
Style Loss : 0.100270 Content Loss: 0.024651

run [2150]:
Style Loss : 0.099747 Content Loss: 0.024708

run [2200]:
Style Loss : 0.099071 Content Loss: 0.024761

run [2250]:
Style Loss : 0.098488 Content Loss: 0.024818

run [2300]:
Style Loss : 0.097966 Content Loss: 0.024870

run [2350]:
Style Loss : 0.096852 Content Loss: 0.024942

run [2400]:
Style Loss : 377.902954 Content Loss: 0.315734

run [2450]:
Style Loss : 435.863464 Content Loss: 0.327754

run [2500]:
Style Loss : 649.156067 Content Loss: 0.404896

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.382129 Content Loss: 0.008343

run [100]:
Style Loss : 0.704570 Content Loss: 0.012937

run [150]:
Style Loss : 0.510543 Content Loss: 0.016195

run [200]:
Style Loss : 0.417294 Content Loss: 0.019091

run [250]:
Style Loss : 0.362539 Content Loss: 0.020834

run [300]:
Style Loss : 0.330909 Content Loss: 0.022000

run [350]:
Style Loss : 0.310949 Content Loss: 0.022587

run [400]:
Style Loss : 0.294272 Content Loss: 0.023013

run [450]:
Style Loss : 0.282213 Content Loss: 0.023436

run [500]:
Style Loss : 0.272525 Content Loss: 0.023840

run [550]:
Style Loss : 0.264329 Content Loss: 0.024293

run [600]:
Style Loss : 0.257571 Content Loss: 0.024745

run [650]:
Style Loss : 0.251283 Content Loss: 0.025106

run [700]:
Style Loss : 0.245787 Content Loss: 0.025454

run [750]:
Style Loss : 0.240646 Content Loss: 0.025683

run [800]:
Style Loss : 0.236494 Content Loss: 0.025938

run [850]:
Style Loss : 0.233021 Content Loss: 0.026184

run [900]:
Style Loss : 0.229711 Content Loss: 0.026437

run [950]:
Style Loss : 0.226925 Content Loss: 0.026586

run [1000]:
Style Loss : 0.224487 Content Loss: 0.026727

run [1050]:
Style Loss : 0.222315 Content Loss: 0.026843

run [1100]:
Style Loss : 0.220322 Content Loss: 0.026940

run [1150]:
Style Loss : 0.218449 Content Loss: 0.027064

run [1200]:
Style Loss : 0.216895 Content Loss: 0.027149

run [1250]:
Style Loss : 0.215440 Content Loss: 0.027243

run [1300]:
Style Loss : 0.214014 Content Loss: 0.027327

run [1350]:
Style Loss : 0.212770 Content Loss: 0.027404

run [1400]:
Style Loss : 0.211561 Content Loss: 0.027473

run [1450]:
Style Loss : 0.210452 Content Loss: 0.027525

run [1500]:
Style Loss : 0.209282 Content Loss: 0.027578

run [1550]:
Style Loss : 0.208300 Content Loss: 0.027652

run [1600]:
Style Loss : 0.207313 Content Loss: 0.027751

run [1650]:
Style Loss : 0.206437 Content Loss: 0.027835

run [1700]:
Style Loss : 0.205790 Content Loss: 0.027920

run [1750]:
Style Loss : 0.204972 Content Loss: 0.027972

run [1800]:
Style Loss : 0.204243 Content Loss: 0.028051

run [1850]:
Style Loss : 0.203565 Content Loss: 0.028130

run [1900]:
Style Loss : 0.202842 Content Loss: 0.028217

run [1950]:
Style Loss : 0.202234 Content Loss: 0.028288

run [2000]:
Style Loss : 0.201627 Content Loss: 0.028337

run [2050]:
Style Loss : 0.201226 Content Loss: 0.028425

run [2100]:
Style Loss : 0.200634 Content Loss: 0.028473

run [2150]:
Style Loss : 0.200124 Content Loss: 0.028505

run [2200]:
Style Loss : 0.199414 Content Loss: 0.028562

run [2250]:
Style Loss : 0.199398 Content Loss: 0.028636

run [2300]:
Style Loss : 0.198453 Content Loss: 0.028671

run [2350]:
Style Loss : 0.198030 Content Loss: 0.028740

run [2400]:
Style Loss : 0.197520 Content Loss: 0.028803

run [2450]:
Style Loss : 0.197016 Content Loss: 0.028867

run [2500]:
Style Loss : 0.197409 Content Loss: 0.028942

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.720878 Content Loss: 0.010726

run [100]:
Style Loss : 0.376061 Content Loss: 0.015349

run [150]:
Style Loss : 0.284493 Content Loss: 0.017727

run [200]:
Style Loss : 0.237681 Content Loss: 0.018893

run [250]:
Style Loss : 0.209402 Content Loss: 0.019416

run [300]:
Style Loss : 0.191698 Content Loss: 0.019893

run [350]:
Style Loss : 0.178741 Content Loss: 0.020259

run [400]:
Style Loss : 0.167815 Content Loss: 0.020587

run [450]:
Style Loss : 0.159066 Content Loss: 0.020879

run [500]:
Style Loss : 0.152197 Content Loss: 0.021186

run [550]:
Style Loss : 0.146691 Content Loss: 0.021372

run [600]:
Style Loss : 0.141889 Content Loss: 0.021494

run [650]:
Style Loss : 0.138183 Content Loss: 0.021584

run [700]:
Style Loss : 0.134805 Content Loss: 0.021671

run [750]:
Style Loss : 0.130997 Content Loss: 0.021784

run [800]:
Style Loss : 0.126187 Content Loss: 0.021912

run [850]:
Style Loss : 0.114161 Content Loss: 0.022039

run [900]:
Style Loss : 0.109360 Content Loss: 0.022176

run [950]:
Style Loss : 0.105430 Content Loss: 0.022252

run [1000]:
Style Loss : 0.102451 Content Loss: 0.022276

run [1050]:
Style Loss : 0.099989 Content Loss: 0.022328

run [1100]:
Style Loss : 0.097941 Content Loss: 0.022364

run [1150]:
Style Loss : 0.096242 Content Loss: 0.022373

run [1200]:
Style Loss : 0.094751 Content Loss: 0.022390

run [1250]:
Style Loss : 0.093402 Content Loss: 0.022365

run [1300]:
Style Loss : 0.091882 Content Loss: 0.022340

run [1350]:
Style Loss : 0.090604 Content Loss: 0.022310

run [1400]:
Style Loss : 0.089547 Content Loss: 0.022277

run [1450]:
Style Loss : 0.088573 Content Loss: 0.022240

run [1500]:
Style Loss : 0.087735 Content Loss: 0.022201

run [1550]:
Style Loss : 0.086875 Content Loss: 0.022170

run [1600]:
Style Loss : 0.086023 Content Loss: 0.022136

run [1650]:
Style Loss : 0.085260 Content Loss: 0.022094

run [1700]:
Style Loss : 0.084437 Content Loss: 0.022081

run [1750]:
Style Loss : 0.083820 Content Loss: 0.022060

run [1800]:
Style Loss : 0.083191 Content Loss: 0.022031

run [1850]:
Style Loss : 0.082672 Content Loss: 0.022005

run [1900]:
Style Loss : 0.082114 Content Loss: 0.021977

run [1950]:
Style Loss : 0.081519 Content Loss: 0.021959

run [2000]:
Style Loss : 0.080973 Content Loss: 0.021951

run [2050]:
Style Loss : 0.080514 Content Loss: 0.021938

run [2100]:
Style Loss : 0.080091 Content Loss: 0.021916

run [2150]:
Style Loss : 0.079721 Content Loss: 0.021903

run [2200]:
Style Loss : 0.079334 Content Loss: 0.021889

run [2250]:
Style Loss : 0.078946 Content Loss: 0.021879

run [2300]:
Style Loss : 0.078604 Content Loss: 0.021865

run [2350]:
Style Loss : 0.078270 Content Loss: 0.021853

run [2400]:
Style Loss : 0.077828 Content Loss: 0.021854

run [2450]:
Style Loss : 0.077457 Content Loss: 0.021843

run [2500]:
Style Loss : 0.077147 Content Loss: 0.021833

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.377094 Content Loss: 0.004364

run [100]:
Style Loss : 1.267555 Content Loss: 0.009236

run [150]:
Style Loss : 0.922726 Content Loss: 0.011691

run [200]:
Style Loss : 0.771328 Content Loss: 0.013498

run [250]:
Style Loss : 0.690227 Content Loss: 0.014841

run [300]:
Style Loss : 0.635208 Content Loss: 0.015898

run [350]:
Style Loss : 0.595845 Content Loss: 0.016748

run [400]:
Style Loss : 0.564644 Content Loss: 0.017340

run [450]:
Style Loss : 0.539460 Content Loss: 0.017955

run [500]:
Style Loss : 0.517103 Content Loss: 0.018550

run [550]:
Style Loss : 0.500051 Content Loss: 0.019035

run [600]:
Style Loss : 0.485940 Content Loss: 0.019451

run [650]:
Style Loss : 0.473581 Content Loss: 0.019779

run [700]:
Style Loss : 0.462667 Content Loss: 0.020098

run [750]:
Style Loss : 0.453320 Content Loss: 0.020396

run [800]:
Style Loss : 0.445252 Content Loss: 0.020625

run [850]:
Style Loss : 0.438731 Content Loss: 0.020860

run [900]:
Style Loss : 0.432405 Content Loss: 0.021089

run [950]:
Style Loss : 0.426692 Content Loss: 0.021306

run [1000]:
Style Loss : 0.421406 Content Loss: 0.021511

run [1050]:
Style Loss : 0.416541 Content Loss: 0.021693

run [1100]:
Style Loss : 0.412295 Content Loss: 0.021835

run [1150]:
Style Loss : 0.408225 Content Loss: 0.021982

run [1200]:
Style Loss : 0.404037 Content Loss: 0.022146

run [1250]:
Style Loss : 0.400382 Content Loss: 0.022280

run [1300]:
Style Loss : 0.397250 Content Loss: 0.022396

run [1350]:
Style Loss : 0.393985 Content Loss: 0.022537

run [1400]:
Style Loss : 0.390878 Content Loss: 0.022672

run [1450]:
Style Loss : 0.387877 Content Loss: 0.022803

run [1500]:
Style Loss : 0.385108 Content Loss: 0.022931

run [1550]:
Style Loss : 0.382179 Content Loss: 0.023056

run [1600]:
Style Loss : 0.379489 Content Loss: 0.023155

run [1650]:
Style Loss : 0.376994 Content Loss: 0.023260

run [1700]:
Style Loss : 0.374123 Content Loss: 0.023366

run [1750]:
Style Loss : 0.371739 Content Loss: 0.023463

run [1800]:
Style Loss : 0.369518 Content Loss: 0.023548

run [1850]:
Style Loss : 0.367389 Content Loss: 0.023644

run [1900]:
Style Loss : 0.365240 Content Loss: 0.023748

run [1950]:
Style Loss : 0.363116 Content Loss: 0.023848

run [2000]:
Style Loss : 0.360974 Content Loss: 0.023952

run [2050]:
Style Loss : 0.359009 Content Loss: 0.024051

run [2100]:
Style Loss : 0.357068 Content Loss: 0.024161

run [2150]:
Style Loss : 0.355166 Content Loss: 0.024263

run [2200]:
Style Loss : 0.353233 Content Loss: 0.024375

run [2250]:
Style Loss : 0.351395 Content Loss: 0.024458

run [2300]:
Style Loss : 0.349636 Content Loss: 0.024543

run [2350]:
Style Loss : 0.347968 Content Loss: 0.024633

run [2400]:
Style Loss : 0.346408 Content Loss: 0.024705

run [2450]:
Style Loss : 0.344838 Content Loss: 0.024792

run [2500]:
Style Loss : 0.343376 Content Loss: 0.024868

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.093041 Content Loss: 0.003768

run [100]:
Style Loss : 1.401217 Content Loss: 0.009336

run [150]:
Style Loss : 0.889141 Content Loss: 0.012729

run [200]:
Style Loss : 0.648068 Content Loss: 0.015195

run [250]:
Style Loss : 0.513257 Content Loss: 0.017016

run [300]:
Style Loss : 0.428984 Content Loss: 0.018145

run [350]:
Style Loss : 0.366735 Content Loss: 0.019092

run [400]:
Style Loss : 0.321785 Content Loss: 0.019785

run [450]:
Style Loss : 0.289985 Content Loss: 0.020384

run [500]:
Style Loss : 0.267214 Content Loss: 0.020715

run [550]:
Style Loss : 0.249024 Content Loss: 0.021141

run [600]:
Style Loss : 0.235547 Content Loss: 0.021366

run [650]:
Style Loss : 0.224285 Content Loss: 0.021567

run [700]:
Style Loss : 0.214778 Content Loss: 0.021753

run [750]:
Style Loss : 0.206461 Content Loss: 0.021880

run [800]:
Style Loss : 0.199085 Content Loss: 0.022001

run [850]:
Style Loss : 0.192672 Content Loss: 0.022082

run [900]:
Style Loss : 0.187223 Content Loss: 0.022194

run [950]:
Style Loss : 0.182466 Content Loss: 0.022277

run [1000]:
Style Loss : 0.178545 Content Loss: 0.022347

run [1050]:
Style Loss : 0.175213 Content Loss: 0.022411

run [1100]:
Style Loss : 0.172118 Content Loss: 0.022442

run [1150]:
Style Loss : 0.169252 Content Loss: 0.022489

run [1200]:
Style Loss : 0.166341 Content Loss: 0.022536

run [1250]:
Style Loss : 0.163594 Content Loss: 0.022573

run [1300]:
Style Loss : 0.161144 Content Loss: 0.022611

run [1350]:
Style Loss : 0.157940 Content Loss: 0.022639

run [1400]:
Style Loss : 0.155469 Content Loss: 0.022655

run [1450]:
Style Loss : 0.153460 Content Loss: 0.022667

run [1500]:
Style Loss : 0.151539 Content Loss: 0.022687

run [1550]:
Style Loss : 0.149860 Content Loss: 0.022708

run [1600]:
Style Loss : 0.148298 Content Loss: 0.022743

run [1650]:
Style Loss : 0.146805 Content Loss: 0.022784

run [1700]:
Style Loss : 0.145197 Content Loss: 0.022820

run [1750]:
Style Loss : 0.143393 Content Loss: 0.022858

run [1800]:
Style Loss : 0.141668 Content Loss: 0.022897

run [1850]:
Style Loss : 0.140125 Content Loss: 0.022929

run [1900]:
Style Loss : 0.138627 Content Loss: 0.022964

run [1950]:
Style Loss : 0.137108 Content Loss: 0.023001

run [2000]:
Style Loss : 0.135639 Content Loss: 0.023031

run [2050]:
Style Loss : 0.134111 Content Loss: 0.023069

run [2100]:
Style Loss : 0.132623 Content Loss: 0.023104

run [2150]:
Style Loss : 0.131221 Content Loss: 0.023130

run [2200]:
Style Loss : 0.130059 Content Loss: 0.023150

run [2250]:
Style Loss : 0.128919 Content Loss: 0.023173

run [2300]:
Style Loss : 0.127926 Content Loss: 0.023181

run [2350]:
Style Loss : 0.126997 Content Loss: 0.023185

run [2400]:
Style Loss : 0.126158 Content Loss: 0.023192

run [2450]:
Style Loss : 0.125369 Content Loss: 0.023199

run [2500]:
Style Loss : 0.124623 Content Loss: 0.023206

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.254459 Content Loss: 0.005266

run [100]:
Style Loss : 1.216963 Content Loss: 0.010263

run [150]:
Style Loss : 0.900455 Content Loss: 0.013917

run [200]:
Style Loss : 0.740207 Content Loss: 0.016311

run [250]:
Style Loss : 0.645874 Content Loss: 0.017947

run [300]:
Style Loss : 0.580114 Content Loss: 0.019066

run [350]:
Style Loss : 0.529530 Content Loss: 0.019844

run [400]:
Style Loss : 0.488991 Content Loss: 0.020418

run [450]:
Style Loss : 0.450787 Content Loss: 0.020924

run [500]:
Style Loss : 0.421053 Content Loss: 0.021303

run [550]:
Style Loss : 0.393493 Content Loss: 0.021697

run [600]:
Style Loss : 0.371291 Content Loss: 0.021944

run [650]:
Style Loss : 0.354280 Content Loss: 0.022158

run [700]:
Style Loss : 0.339691 Content Loss: 0.022413

run [750]:
Style Loss : 0.326596 Content Loss: 0.022622

run [800]:
Style Loss : 0.316649 Content Loss: 0.022840

run [850]:
Style Loss : 0.307906 Content Loss: 0.023009

run [900]:
Style Loss : 0.300305 Content Loss: 0.023151

run [950]:
Style Loss : 0.294286 Content Loss: 0.023268

run [1000]:
Style Loss : 0.289066 Content Loss: 0.023397

run [1050]:
Style Loss : 0.284423 Content Loss: 0.023506

run [1100]:
Style Loss : 0.280286 Content Loss: 0.023627

run [1150]:
Style Loss : 0.276389 Content Loss: 0.023737

run [1200]:
Style Loss : 0.273082 Content Loss: 0.023832

run [1250]:
Style Loss : 0.270083 Content Loss: 0.023933

run [1300]:
Style Loss : 0.266603 Content Loss: 0.024033

run [1350]:
Style Loss : 0.263784 Content Loss: 0.024129

run [1400]:
Style Loss : 0.261070 Content Loss: 0.024210

run [1450]:
Style Loss : 0.258880 Content Loss: 0.024296

run [1500]:
Style Loss : 0.256881 Content Loss: 0.024372

run [1550]:
Style Loss : 0.255071 Content Loss: 0.024447

run [1600]:
Style Loss : 0.253462 Content Loss: 0.024524

run [1650]:
Style Loss : 0.252084 Content Loss: 0.024576

run [1700]:
Style Loss : 0.250832 Content Loss: 0.024619

run [1750]:
Style Loss : 0.249633 Content Loss: 0.024660

run [1800]:
Style Loss : 0.248565 Content Loss: 0.024682

run [1850]:
Style Loss : 0.247539 Content Loss: 0.024714

run [1900]:
Style Loss : 0.246579 Content Loss: 0.024737

run [1950]:
Style Loss : 0.245649 Content Loss: 0.024763

run [2000]:
Style Loss : 0.244796 Content Loss: 0.024784

run [2050]:
Style Loss : 0.243977 Content Loss: 0.024806

run [2100]:
Style Loss : 0.243104 Content Loss: 0.024820

run [2150]:
Style Loss : 0.242097 Content Loss: 0.024845

run [2200]:
Style Loss : 0.241281 Content Loss: 0.024866

run [2250]:
Style Loss : 0.240545 Content Loss: 0.024885

run [2300]:
Style Loss : 0.239893 Content Loss: 0.024905

run [2350]:
Style Loss : 0.239323 Content Loss: 0.024922

run [2400]:
Style Loss : 0.238709 Content Loss: 0.024946

run [2450]:
Style Loss : 0.238092 Content Loss: 0.024963

run [2500]:
Style Loss : 0.237531 Content Loss: 0.024976

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.251674 Content Loss: 0.003136

run [100]:
Style Loss : 2.180187 Content Loss: 0.007575

run [150]:
Style Loss : 1.429096 Content Loss: 0.011009

run [200]:
Style Loss : 1.075035 Content Loss: 0.013630

run [250]:
Style Loss : 0.884543 Content Loss: 0.015474

run [300]:
Style Loss : 0.761839 Content Loss: 0.016920

run [350]:
Style Loss : 0.681406 Content Loss: 0.017949

run [400]:
Style Loss : 0.625947 Content Loss: 0.018824

run [450]:
Style Loss : 0.585522 Content Loss: 0.019507

run [500]:
Style Loss : 0.554100 Content Loss: 0.020047

run [550]:
Style Loss : 0.527605 Content Loss: 0.020450

run [600]:
Style Loss : 0.506547 Content Loss: 0.020798

run [650]:
Style Loss : 0.489894 Content Loss: 0.021110

run [700]:
Style Loss : 0.476361 Content Loss: 0.021365

run [750]:
Style Loss : 0.463515 Content Loss: 0.021605

run [800]:
Style Loss : 0.450686 Content Loss: 0.021773

run [850]:
Style Loss : 0.440305 Content Loss: 0.021920

run [900]:
Style Loss : 0.432150 Content Loss: 0.022057

run [950]:
Style Loss : 0.424598 Content Loss: 0.022177

run [1000]:
Style Loss : 0.418091 Content Loss: 0.022288

run [1050]:
Style Loss : 0.412164 Content Loss: 0.022381

run [1100]:
Style Loss : 0.406819 Content Loss: 0.022464

run [1150]:
Style Loss : 0.401653 Content Loss: 0.022539

run [1200]:
Style Loss : 0.397010 Content Loss: 0.022610

run [1250]:
Style Loss : 0.392873 Content Loss: 0.022655

run [1300]:
Style Loss : 0.388582 Content Loss: 0.022703

run [1350]:
Style Loss : 0.385021 Content Loss: 0.022739

run [1400]:
Style Loss : 0.381819 Content Loss: 0.022794

run [1450]:
Style Loss : 0.378904 Content Loss: 0.022833

run [1500]:
Style Loss : 0.376215 Content Loss: 0.022878

run [1550]:
Style Loss : 0.373921 Content Loss: 0.022911

run [1600]:
Style Loss : 0.371735 Content Loss: 0.022947

run [1650]:
Style Loss : 0.369456 Content Loss: 0.022992

run [1700]:
Style Loss : 0.367480 Content Loss: 0.023026

run [1750]:
Style Loss : 0.365545 Content Loss: 0.023065

run [1800]:
Style Loss : 0.363800 Content Loss: 0.023096

run [1850]:
Style Loss : 0.362066 Content Loss: 0.023125

run [1900]:
Style Loss : 0.360440 Content Loss: 0.023154

run [1950]:
Style Loss : 0.358775 Content Loss: 0.023182

run [2000]:
Style Loss : 0.357211 Content Loss: 0.023206

run [2050]:
Style Loss : 0.355539 Content Loss: 0.023235

run [2100]:
Style Loss : 0.353881 Content Loss: 0.023262

run [2150]:
Style Loss : 0.352372 Content Loss: 0.023287

run [2200]:
Style Loss : 0.350718 Content Loss: 0.023322

run [2250]:
Style Loss : 0.349099 Content Loss: 0.023344

run [2300]:
Style Loss : 0.347558 Content Loss: 0.023357

run [2350]:
Style Loss : 0.345968 Content Loss: 0.023377

run [2400]:
Style Loss : 0.344314 Content Loss: 0.023399

run [2450]:
Style Loss : 0.342675 Content Loss: 0.023425

run [2500]:
Style Loss : 0.341117 Content Loss: 0.023450

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.215199 Content Loss: 0.005394

run [100]:
Style Loss : 2.069678 Content Loss: 0.009764

run [150]:
Style Loss : 1.414284 Content Loss: 0.012906

run [200]:
Style Loss : 1.112286 Content Loss: 0.015069

run [250]:
Style Loss : 0.939532 Content Loss: 0.016585

run [300]:
Style Loss : 0.831351 Content Loss: 0.017828

run [350]:
Style Loss : 0.760776 Content Loss: 0.018608

run [400]:
Style Loss : 0.712177 Content Loss: 0.019311

run [450]:
Style Loss : 0.676540 Content Loss: 0.019939

run [500]:
Style Loss : 0.651346 Content Loss: 0.020411

run [550]:
Style Loss : 0.630073 Content Loss: 0.020851

run [600]:
Style Loss : 0.611487 Content Loss: 0.021188

run [650]:
Style Loss : 0.594331 Content Loss: 0.021453

run [700]:
Style Loss : 0.578664 Content Loss: 0.021680

run [750]:
Style Loss : 0.565106 Content Loss: 0.021904

run [800]:
Style Loss : 0.553904 Content Loss: 0.022086

run [850]:
Style Loss : 0.544228 Content Loss: 0.022289

run [900]:
Style Loss : 0.534842 Content Loss: 0.022462

run [950]:
Style Loss : 0.526275 Content Loss: 0.022619

run [1000]:
Style Loss : 0.518574 Content Loss: 0.022728

run [1050]:
Style Loss : 0.511371 Content Loss: 0.022845

run [1100]:
Style Loss : 0.504906 Content Loss: 0.022963

run [1150]:
Style Loss : 0.498789 Content Loss: 0.023065

run [1200]:
Style Loss : 0.493508 Content Loss: 0.023132

run [1250]:
Style Loss : 0.488583 Content Loss: 0.023207

run [1300]:
Style Loss : 0.484211 Content Loss: 0.023276

run [1350]:
Style Loss : 0.480356 Content Loss: 0.023340

run [1400]:
Style Loss : 0.476808 Content Loss: 0.023402

run [1450]:
Style Loss : 0.473621 Content Loss: 0.023458

run [1500]:
Style Loss : 0.470602 Content Loss: 0.023509

run [1550]:
Style Loss : 0.467831 Content Loss: 0.023552

run [1600]:
Style Loss : 0.465115 Content Loss: 0.023594

run [1650]:
Style Loss : 0.462771 Content Loss: 0.023619

run [1700]:
Style Loss : 0.460614 Content Loss: 0.023654

run [1750]:
Style Loss : 0.458553 Content Loss: 0.023688

run [1800]:
Style Loss : 0.456582 Content Loss: 0.023722

run [1850]:
Style Loss : 0.454738 Content Loss: 0.023760

run [1900]:
Style Loss : 0.453077 Content Loss: 0.023796

run [1950]:
Style Loss : 0.451524 Content Loss: 0.023834

run [2000]:
Style Loss : 0.450169 Content Loss: 0.023867

run [2050]:
Style Loss : 0.448830 Content Loss: 0.023900

run [2100]:
Style Loss : 0.447531 Content Loss: 0.023930

run [2150]:
Style Loss : 0.446321 Content Loss: 0.023959

run [2200]:
Style Loss : 0.445222 Content Loss: 0.023987

run [2250]:
Style Loss : 0.444132 Content Loss: 0.024012

run [2300]:
Style Loss : 0.443089 Content Loss: 0.024032

run [2350]:
Style Loss : 0.442139 Content Loss: 0.024055

run [2400]:
Style Loss : 0.441221 Content Loss: 0.024079

run [2450]:
Style Loss : 0.440334 Content Loss: 0.024104

run [2500]:
Style Loss : 0.439353 Content Loss: 0.024132

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.005589 Content Loss: 0.004356

run [100]:
Style Loss : 2.213042 Content Loss: 0.007095

run [150]:
Style Loss : 1.597046 Content Loss: 0.009976

run [200]:
Style Loss : 1.329260 Content Loss: 0.012037

run [250]:
Style Loss : 1.179755 Content Loss: 0.013517

run [300]:
Style Loss : 1.078871 Content Loss: 0.014584

run [350]:
Style Loss : 0.997994 Content Loss: 0.015470

run [400]:
Style Loss : 0.936145 Content Loss: 0.016221

run [450]:
Style Loss : 0.891486 Content Loss: 0.016904

run [500]:
Style Loss : 0.855927 Content Loss: 0.017510

run [550]:
Style Loss : 0.824726 Content Loss: 0.018145

run [600]:
Style Loss : 0.801416 Content Loss: 0.018609

run [650]:
Style Loss : 0.782588 Content Loss: 0.019040

run [700]:
Style Loss : 0.767232 Content Loss: 0.019394

run [750]:
Style Loss : 0.754028 Content Loss: 0.019719

run [800]:
Style Loss : 0.742656 Content Loss: 0.020033

run [850]:
Style Loss : 0.733023 Content Loss: 0.020274

run [900]:
Style Loss : 0.724396 Content Loss: 0.020479

run [950]:
Style Loss : 0.716477 Content Loss: 0.020685

run [1000]:
Style Loss : 0.707950 Content Loss: 0.020898

run [1050]:
Style Loss : 0.699834 Content Loss: 0.021078

run [1100]:
Style Loss : 0.693104 Content Loss: 0.021250

run [1150]:
Style Loss : 0.686741 Content Loss: 0.021422

run [1200]:
Style Loss : 0.680569 Content Loss: 0.021578

run [1250]:
Style Loss : 0.674774 Content Loss: 0.021738

run [1300]:
Style Loss : 0.669215 Content Loss: 0.021876

run [1350]:
Style Loss : 0.664235 Content Loss: 0.021999

run [1400]:
Style Loss : 0.659538 Content Loss: 0.022124

run [1450]:
Style Loss : 0.655361 Content Loss: 0.022231

run [1500]:
Style Loss : 0.651696 Content Loss: 0.022320

run [1550]:
Style Loss : 0.647545 Content Loss: 0.022419

run [1600]:
Style Loss : 0.643686 Content Loss: 0.022500

run [1650]:
Style Loss : 0.640646 Content Loss: 0.022556

run [1700]:
Style Loss : 0.637897 Content Loss: 0.022615

run [1750]:
Style Loss : 0.635341 Content Loss: 0.022656

run [1800]:
Style Loss : 0.633030 Content Loss: 0.022707

run [1850]:
Style Loss : 0.631002 Content Loss: 0.022760

run [1900]:
Style Loss : 0.629123 Content Loss: 0.022805

run [1950]:
Style Loss : 0.627484 Content Loss: 0.022847

run [2000]:
Style Loss : 0.625956 Content Loss: 0.022906

run [2050]:
Style Loss : 0.624328 Content Loss: 0.022952

run [2100]:
Style Loss : 0.622909 Content Loss: 0.022999

run [2150]:
Style Loss : 0.621275 Content Loss: 0.023050

run [2200]:
Style Loss : 0.619945 Content Loss: 0.023093

run [2250]:
Style Loss : 0.618650 Content Loss: 0.023134

run [2300]:
Style Loss : 0.617410 Content Loss: 0.023179

run [2350]:
Style Loss : 0.616284 Content Loss: 0.023219

run [2400]:
Style Loss : 0.615290 Content Loss: 0.023251

run [2450]:
Style Loss : 0.614330 Content Loss: 0.023282

run [2500]:
Style Loss : 0.613475 Content Loss: 0.023310

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.322462 Content Loss: 0.005070

run [100]:
Style Loss : 1.775471 Content Loss: 0.007957

run [150]:
Style Loss : 1.103866 Content Loss: 0.010782

run [200]:
Style Loss : 0.839938 Content Loss: 0.012807

run [250]:
Style Loss : 0.700811 Content Loss: 0.014810

run [300]:
Style Loss : 0.616541 Content Loss: 0.015972

run [350]:
Style Loss : 0.552544 Content Loss: 0.016734

run [400]:
Style Loss : 0.510411 Content Loss: 0.017188

run [450]:
Style Loss : 0.477554 Content Loss: 0.017827

run [500]:
Style Loss : 0.452638 Content Loss: 0.018368

run [550]:
Style Loss : 0.429897 Content Loss: 0.018749

run [600]:
Style Loss : 0.407521 Content Loss: 0.019211

run [650]:
Style Loss : 0.387123 Content Loss: 0.019527

run [700]:
Style Loss : 0.368707 Content Loss: 0.019798

run [750]:
Style Loss : 0.353358 Content Loss: 0.019988

run [800]:
Style Loss : 0.341024 Content Loss: 0.020223

run [850]:
Style Loss : 0.330044 Content Loss: 0.020420

run [900]:
Style Loss : 0.320523 Content Loss: 0.020615

run [950]:
Style Loss : 0.312386 Content Loss: 0.020774

run [1000]:
Style Loss : 0.305725 Content Loss: 0.020905

run [1050]:
Style Loss : 0.299737 Content Loss: 0.021016

run [1100]:
Style Loss : 0.294229 Content Loss: 0.021128

run [1150]:
Style Loss : 0.289274 Content Loss: 0.021245

run [1200]:
Style Loss : 0.284238 Content Loss: 0.021350

run [1250]:
Style Loss : 0.279728 Content Loss: 0.021436

run [1300]:
Style Loss : 0.275058 Content Loss: 0.021529

run [1350]:
Style Loss : 0.270659 Content Loss: 0.021577

run [1400]:
Style Loss : 0.266578 Content Loss: 0.021649

run [1450]:
Style Loss : 0.263155 Content Loss: 0.021690

run [1500]:
Style Loss : 0.259735 Content Loss: 0.021742

run [1550]:
Style Loss : 0.256794 Content Loss: 0.021784

run [1600]:
Style Loss : 0.254100 Content Loss: 0.021837

run [1650]:
Style Loss : 0.251542 Content Loss: 0.021878

run [1700]:
Style Loss : 0.249029 Content Loss: 0.021933

run [1750]:
Style Loss : 0.246656 Content Loss: 0.021981

run [1800]:
Style Loss : 0.244400 Content Loss: 0.022040

run [1850]:
Style Loss : 0.242256 Content Loss: 0.022089

run [1900]:
Style Loss : 0.240163 Content Loss: 0.022111

run [1950]:
Style Loss : 0.238303 Content Loss: 0.022139

run [2000]:
Style Loss : 0.236407 Content Loss: 0.022180

run [2050]:
Style Loss : 0.234505 Content Loss: 0.022227

run [2100]:
Style Loss : 0.232720 Content Loss: 0.022248

run [2150]:
Style Loss : 0.231131 Content Loss: 0.022269

run [2200]:
Style Loss : 0.229729 Content Loss: 0.022277

run [2250]:
Style Loss : 0.228339 Content Loss: 0.022295

run [2300]:
Style Loss : 0.227044 Content Loss: 0.022306

run [2350]:
Style Loss : 0.225685 Content Loss: 0.022302

run [2400]:
Style Loss : 0.224432 Content Loss: 0.022303

run [2450]:
Style Loss : 0.223306 Content Loss: 0.022312

run [2500]:
Style Loss : 0.222296 Content Loss: 0.022301

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.828230 Content Loss: 0.004918

run [100]:
Style Loss : 1.045841 Content Loss: 0.009850

run [150]:
Style Loss : 0.770267 Content Loss: 0.012971

run [200]:
Style Loss : 0.631585 Content Loss: 0.014912

run [250]:
Style Loss : 0.547594 Content Loss: 0.016350

run [300]:
Style Loss : 0.498225 Content Loss: 0.017391

run [350]:
Style Loss : 0.465574 Content Loss: 0.018232

run [400]:
Style Loss : 0.441218 Content Loss: 0.018720

run [450]:
Style Loss : 0.422608 Content Loss: 0.019188

run [500]:
Style Loss : 0.409888 Content Loss: 0.019539

run [550]:
Style Loss : 0.400112 Content Loss: 0.019786

run [600]:
Style Loss : 0.392189 Content Loss: 0.020007

run [650]:
Style Loss : 0.385629 Content Loss: 0.020197

run [700]:
Style Loss : 0.380456 Content Loss: 0.020360

run [750]:
Style Loss : 0.376144 Content Loss: 0.020495

run [800]:
Style Loss : 0.372312 Content Loss: 0.020618

run [850]:
Style Loss : 0.369021 Content Loss: 0.020728

run [900]:
Style Loss : 0.366424 Content Loss: 0.020819

run [950]:
Style Loss : 0.363446 Content Loss: 0.020927

run [1000]:
Style Loss : 0.360920 Content Loss: 0.021005

run [1050]:
Style Loss : 0.358227 Content Loss: 0.021108

run [1100]:
Style Loss : 0.356112 Content Loss: 0.021181

run [1150]:
Style Loss : 0.354176 Content Loss: 0.021266

run [1200]:
Style Loss : 0.352420 Content Loss: 0.021339

run [1250]:
Style Loss : 0.349567 Content Loss: 0.021433

run [1300]:
Style Loss : 0.347587 Content Loss: 0.021510

run [1350]:
Style Loss : 0.346035 Content Loss: 0.021572

run [1400]:
Style Loss : 0.344486 Content Loss: 0.021633

run [1450]:
Style Loss : 0.343181 Content Loss: 0.021700

run [1500]:
Style Loss : 0.342006 Content Loss: 0.021750

run [1550]:
Style Loss : 0.340845 Content Loss: 0.021804

run [1600]:
Style Loss : 0.339366 Content Loss: 0.021866

run [1650]:
Style Loss : 0.338224 Content Loss: 0.021913

run [1700]:
Style Loss : 0.337207 Content Loss: 0.021959

run [1750]:
Style Loss : 0.336182 Content Loss: 0.022009

run [1800]:
Style Loss : 0.335241 Content Loss: 0.022063

run [1850]:
Style Loss : 0.334269 Content Loss: 0.022113

run [1900]:
Style Loss : 0.333357 Content Loss: 0.022160

run [1950]:
Style Loss : 0.332414 Content Loss: 0.022203

run [2000]:
Style Loss : 0.331637 Content Loss: 0.022227

run [2050]:
Style Loss : 0.330937 Content Loss: 0.022252

run [2100]:
Style Loss : 0.330291 Content Loss: 0.022283

run [2150]:
Style Loss : 0.329667 Content Loss: 0.022314

run [2200]:
Style Loss : 0.329040 Content Loss: 0.022343

run [2250]:
Style Loss : 0.328499 Content Loss: 0.022377

run [2300]:
Style Loss : 0.327628 Content Loss: 0.022414

run [2350]:
Style Loss : 0.326529 Content Loss: 0.022463

run [2400]:
Style Loss : 0.325818 Content Loss: 0.022501

run [2450]:
Style Loss : 0.325215 Content Loss: 0.022529

run [2500]:
Style Loss : 0.324445 Content Loss: 0.022559

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.508990 Content Loss: 0.007436

run [100]:
Style Loss : 0.814854 Content Loss: 0.012652

run [150]:
Style Loss : 0.573532 Content Loss: 0.015213

run [200]:
Style Loss : 0.464652 Content Loss: 0.016953

run [250]:
Style Loss : 0.388824 Content Loss: 0.018531

run [300]:
Style Loss : 0.337967 Content Loss: 0.019485

run [350]:
Style Loss : 0.306999 Content Loss: 0.020183

run [400]:
Style Loss : 0.286266 Content Loss: 0.020682

run [450]:
Style Loss : 0.271801 Content Loss: 0.021009

run [500]:
Style Loss : 0.260886 Content Loss: 0.021277

run [550]:
Style Loss : 0.252671 Content Loss: 0.021503

run [600]:
Style Loss : 0.246325 Content Loss: 0.021662

run [650]:
Style Loss : 0.241173 Content Loss: 0.021763

run [700]:
Style Loss : 0.236957 Content Loss: 0.021844

run [750]:
Style Loss : 0.233089 Content Loss: 0.021897

run [800]:
Style Loss : 0.229692 Content Loss: 0.021961

run [850]:
Style Loss : 0.226386 Content Loss: 0.022030

run [900]:
Style Loss : 0.223571 Content Loss: 0.022095

run [950]:
Style Loss : 0.221030 Content Loss: 0.022144

run [1000]:
Style Loss : 0.218704 Content Loss: 0.022189

run [1050]:
Style Loss : 0.216393 Content Loss: 0.022237

run [1100]:
Style Loss : 0.214081 Content Loss: 0.022291

run [1150]:
Style Loss : 0.211705 Content Loss: 0.022339

run [1200]:
Style Loss : 0.209761 Content Loss: 0.022378

run [1250]:
Style Loss : 0.208044 Content Loss: 0.022409

run [1300]:
Style Loss : 0.206372 Content Loss: 0.022453

run [1350]:
Style Loss : 0.204953 Content Loss: 0.022483

run [1400]:
Style Loss : 0.203271 Content Loss: 0.022519

run [1450]:
Style Loss : 0.196742 Content Loss: 0.022550

run [1500]:
Style Loss : 0.193576 Content Loss: 0.022567

run [1550]:
Style Loss : 0.191467 Content Loss: 0.022600

run [1600]:
Style Loss : 0.189717 Content Loss: 0.022628

run [1650]:
Style Loss : 0.188285 Content Loss: 0.022657

run [1700]:
Style Loss : 0.187060 Content Loss: 0.022686

run [1750]:
Style Loss : 0.185933 Content Loss: 0.022714

run [1800]:
Style Loss : 0.184959 Content Loss: 0.022742

run [1850]:
Style Loss : 0.184017 Content Loss: 0.022769

run [1900]:
Style Loss : 0.183121 Content Loss: 0.022789

run [1950]:
Style Loss : 0.182173 Content Loss: 0.022815

run [2000]:
Style Loss : 0.181348 Content Loss: 0.022837

run [2050]:
Style Loss : 0.180653 Content Loss: 0.022860

run [2100]:
Style Loss : 0.179986 Content Loss: 0.022879

run [2150]:
Style Loss : 0.179429 Content Loss: 0.022895

run [2200]:
Style Loss : 0.178886 Content Loss: 0.022914

run [2250]:
Style Loss : 0.178321 Content Loss: 0.022931

run [2300]:
Style Loss : 0.176187 Content Loss: 0.022969

run [2350]:
Style Loss : 0.175191 Content Loss: 0.023002

run [2400]:
Style Loss : 0.174447 Content Loss: 0.023034

run [2450]:
Style Loss : 0.173773 Content Loss: 0.023061

run [2500]:
Style Loss : 0.173161 Content Loss: 0.023088

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.843197 Content Loss: 0.008538

run [100]:
Style Loss : 0.461959 Content Loss: 0.012129

run [150]:
Style Loss : 0.344593 Content Loss: 0.014060

run [200]:
Style Loss : 0.291400 Content Loss: 0.015183

run [250]:
Style Loss : 0.258985 Content Loss: 0.015900

run [300]:
Style Loss : 0.237194 Content Loss: 0.016443

run [350]:
Style Loss : 0.219873 Content Loss: 0.016934

run [400]:
Style Loss : 0.206643 Content Loss: 0.017372

run [450]:
Style Loss : 0.195458 Content Loss: 0.017817

run [500]:
Style Loss : 0.186589 Content Loss: 0.018281

run [550]:
Style Loss : 0.179409 Content Loss: 0.018702

run [600]:
Style Loss : 0.172762 Content Loss: 0.019143

run [650]:
Style Loss : 0.166460 Content Loss: 0.019642

run [700]:
Style Loss : 0.160805 Content Loss: 0.020146

run [750]:
Style Loss : 0.155693 Content Loss: 0.020628

run [800]:
Style Loss : 0.150723 Content Loss: 0.021125

run [850]:
Style Loss : 0.146447 Content Loss: 0.021584

run [900]:
Style Loss : 0.142640 Content Loss: 0.022030

run [950]:
Style Loss : 0.139052 Content Loss: 0.022494

run [1000]:
Style Loss : 0.136050 Content Loss: 0.022894

run [1050]:
Style Loss : 0.133453 Content Loss: 0.023249

run [1100]:
Style Loss : 0.131165 Content Loss: 0.023623

run [1150]:
Style Loss : 0.129351 Content Loss: 0.023971

run [1200]:
Style Loss : 0.127747 Content Loss: 0.024184

run [1250]:
Style Loss : 0.126401 Content Loss: 0.024418

run [1300]:
Style Loss : 0.125315 Content Loss: 0.024645

run [1350]:
Style Loss : 0.124238 Content Loss: 0.024797

run [1400]:
Style Loss : 0.123472 Content Loss: 0.024932

run [1450]:
Style Loss : 0.122702 Content Loss: 0.025025

run [1500]:
Style Loss : 0.122021 Content Loss: 0.025138

run [1550]:
Style Loss : 0.121338 Content Loss: 0.025240

run [1600]:
Style Loss : 0.120937 Content Loss: 0.025389

run [1650]:
Style Loss : 0.120271 Content Loss: 0.025477

run [1700]:
Style Loss : 0.119746 Content Loss: 0.025587

run [1750]:
Style Loss : 0.119691 Content Loss: 0.025813

run [1800]:
Style Loss : 0.118635 Content Loss: 0.025813

run [1850]:
Style Loss : 0.118487 Content Loss: 0.025966

run [1900]:
Style Loss : 0.118925 Content Loss: 0.026127

run [1950]:
Style Loss : 0.117107 Content Loss: 0.026065

run [2000]:
Style Loss : 0.116679 Content Loss: 0.026085

run [2050]:
Style Loss : 0.116427 Content Loss: 0.026180

run [2100]:
Style Loss : 0.115886 Content Loss: 0.026192

run [2150]:
Style Loss : 0.115603 Content Loss: 0.026266

run [2200]:
Style Loss : 0.115358 Content Loss: 0.026365

run [2250]:
Style Loss : 0.114728 Content Loss: 0.026387

run [2300]:
Style Loss : 0.114264 Content Loss: 0.026428

run [2350]:
Style Loss : 0.113987 Content Loss: 0.026508

run [2400]:
Style Loss : 0.113640 Content Loss: 0.026552

run [2450]:
Style Loss : 0.112568 Content Loss: 0.026609

run [2500]:
Style Loss : 0.112313 Content Loss: 0.026659

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.144635 Content Loss: 0.006838

run [100]:
Style Loss : 0.537375 Content Loss: 0.012449

run [150]:
Style Loss : 0.382673 Content Loss: 0.014739

run [200]:
Style Loss : 0.308931 Content Loss: 0.016216

run [250]:
Style Loss : 0.263732 Content Loss: 0.017283

run [300]:
Style Loss : 0.233008 Content Loss: 0.017990

run [350]:
Style Loss : 0.211125 Content Loss: 0.018533

run [400]:
Style Loss : 0.198140 Content Loss: 0.018904

run [450]:
Style Loss : 0.189727 Content Loss: 0.019153

run [500]:
Style Loss : 0.184067 Content Loss: 0.019306

run [550]:
Style Loss : 0.179367 Content Loss: 0.019447

run [600]:
Style Loss : 0.175678 Content Loss: 0.019530

run [650]:
Style Loss : 0.172708 Content Loss: 0.019603

run [700]:
Style Loss : 0.170204 Content Loss: 0.019687

run [750]:
Style Loss : 0.168111 Content Loss: 0.019742

run [800]:
Style Loss : 0.165951 Content Loss: 0.019814

run [850]:
Style Loss : 0.163534 Content Loss: 0.019871

run [900]:
Style Loss : 0.161815 Content Loss: 0.019924

run [950]:
Style Loss : 0.160305 Content Loss: 0.019969

run [1000]:
Style Loss : 0.158971 Content Loss: 0.020002

run [1050]:
Style Loss : 0.157881 Content Loss: 0.020036

run [1100]:
Style Loss : 0.156868 Content Loss: 0.020067

run [1150]:
Style Loss : 0.155760 Content Loss: 0.020101

run [1200]:
Style Loss : 0.154742 Content Loss: 0.020128

run [1250]:
Style Loss : 0.153826 Content Loss: 0.020158

run [1300]:
Style Loss : 0.152961 Content Loss: 0.020192

run [1350]:
Style Loss : 0.152144 Content Loss: 0.020221

run [1400]:
Style Loss : 0.151326 Content Loss: 0.020248

run [1450]:
Style Loss : 0.150633 Content Loss: 0.020274

run [1500]:
Style Loss : 0.149925 Content Loss: 0.020302

run [1550]:
Style Loss : 0.149271 Content Loss: 0.020333

run [1600]:
Style Loss : 0.148673 Content Loss: 0.020364

run [1650]:
Style Loss : 0.148162 Content Loss: 0.020391

run [1700]:
Style Loss : 0.147722 Content Loss: 0.020414

run [1750]:
Style Loss : 0.147293 Content Loss: 0.020434

run [1800]:
Style Loss : 0.146875 Content Loss: 0.020461

run [1850]:
Style Loss : 0.146446 Content Loss: 0.020485

run [1900]:
Style Loss : 0.146024 Content Loss: 0.020510

run [1950]:
Style Loss : 0.145652 Content Loss: 0.020530

run [2000]:
Style Loss : 0.145253 Content Loss: 0.020551

run [2050]:
Style Loss : 0.144880 Content Loss: 0.020570

run [2100]:
Style Loss : 0.144549 Content Loss: 0.020591

run [2150]:
Style Loss : 0.144223 Content Loss: 0.020608

run [2200]:
Style Loss : 0.143926 Content Loss: 0.020625

run [2250]:
Style Loss : 0.143655 Content Loss: 0.020641

run [2300]:
Style Loss : 0.143392 Content Loss: 0.020656

run [2350]:
Style Loss : 0.143149 Content Loss: 0.020671

run [2400]:
Style Loss : 0.142906 Content Loss: 0.020689

run [2450]:
Style Loss : 0.142658 Content Loss: 0.020704

run [2500]:
Style Loss : 0.142408 Content Loss: 0.020719

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.639037 Content Loss: 0.005432

run [100]:
Style Loss : 0.375552 Content Loss: 0.006436

run [150]:
Style Loss : 0.268425 Content Loss: 0.007732

run [200]:
Style Loss : 0.210432 Content Loss: 0.009014

run [250]:
Style Loss : 0.176381 Content Loss: 0.010219

run [300]:
Style Loss : 0.155690 Content Loss: 0.011288

run [350]:
Style Loss : 0.141535 Content Loss: 0.012163

run [400]:
Style Loss : 0.131504 Content Loss: 0.012711

run [450]:
Style Loss : 0.123428 Content Loss: 0.013246

run [500]:
Style Loss : 0.116821 Content Loss: 0.013617

run [550]:
Style Loss : 0.111153 Content Loss: 0.013946

run [600]:
Style Loss : 0.106216 Content Loss: 0.014221

run [650]:
Style Loss : 0.102114 Content Loss: 0.014460

run [700]:
Style Loss : 0.098727 Content Loss: 0.014675

run [750]:
Style Loss : 0.095543 Content Loss: 0.014853

run [800]:
Style Loss : 0.092864 Content Loss: 0.015045

run [850]:
Style Loss : 0.090503 Content Loss: 0.015189

run [900]:
Style Loss : 0.088430 Content Loss: 0.015302

run [950]:
Style Loss : 0.086480 Content Loss: 0.015364

run [1000]:
Style Loss : 0.084761 Content Loss: 0.015444

run [1050]:
Style Loss : 0.083233 Content Loss: 0.015517

run [1100]:
Style Loss : 0.081793 Content Loss: 0.015600

run [1150]:
Style Loss : 0.080497 Content Loss: 0.015662

run [1200]:
Style Loss : 0.079353 Content Loss: 0.015715

run [1250]:
Style Loss : 0.078354 Content Loss: 0.015755

run [1300]:
Style Loss : 0.077339 Content Loss: 0.015794

run [1350]:
Style Loss : 0.076378 Content Loss: 0.015818

run [1400]:
Style Loss : 0.075467 Content Loss: 0.015845

run [1450]:
Style Loss : 0.074617 Content Loss: 0.015869

run [1500]:
Style Loss : 0.073932 Content Loss: 0.015877

run [1550]:
Style Loss : 0.073328 Content Loss: 0.015878

run [1600]:
Style Loss : 0.072756 Content Loss: 0.015874

run [1650]:
Style Loss : 0.072216 Content Loss: 0.015866

run [1700]:
Style Loss : 0.071803 Content Loss: 0.015850

run [1750]:
Style Loss : 0.071332 Content Loss: 0.015843

run [1800]:
Style Loss : 0.070943 Content Loss: 0.015833

run [1850]:
Style Loss : 0.070569 Content Loss: 0.015821

run [1900]:
Style Loss : 0.070232 Content Loss: 0.015803

run [1950]:
Style Loss : 0.069869 Content Loss: 0.015782

run [2000]:
Style Loss : 0.069509 Content Loss: 0.015764

run [2050]:
Style Loss : 0.069181 Content Loss: 0.015753

run [2100]:
Style Loss : 0.068857 Content Loss: 0.015740

run [2150]:
Style Loss : 0.068566 Content Loss: 0.015724

run [2200]:
Style Loss : 0.068294 Content Loss: 0.015708

run [2250]:
Style Loss : 0.068024 Content Loss: 0.015702

run [2300]:
Style Loss : 0.067752 Content Loss: 0.015693

run [2350]:
Style Loss : 0.067461 Content Loss: 0.015693

run [2400]:
Style Loss : 0.067213 Content Loss: 0.015686

run [2450]:
Style Loss : 0.066988 Content Loss: 0.015676

run [2500]:
Style Loss : 0.066768 Content Loss: 0.015668

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.128155 Content Loss: 0.002615

run [100]:
Style Loss : 0.672486 Content Loss: 0.005073

run [150]:
Style Loss : 0.470531 Content Loss: 0.007766

run [200]:
Style Loss : 0.366118 Content Loss: 0.009746

run [250]:
Style Loss : 0.304038 Content Loss: 0.010943

run [300]:
Style Loss : 0.260456 Content Loss: 0.011552

run [350]:
Style Loss : 0.231457 Content Loss: 0.011946

run [400]:
Style Loss : 0.212592 Content Loss: 0.012308

run [450]:
Style Loss : 0.199786 Content Loss: 0.012636

run [500]:
Style Loss : 0.190293 Content Loss: 0.012906

run [550]:
Style Loss : 0.182900 Content Loss: 0.013188

run [600]:
Style Loss : 0.176540 Content Loss: 0.013378

run [650]:
Style Loss : 0.171061 Content Loss: 0.013579

run [700]:
Style Loss : 0.166006 Content Loss: 0.013756

run [750]:
Style Loss : 0.161436 Content Loss: 0.013884

run [800]:
Style Loss : 0.156531 Content Loss: 0.014002

run [850]:
Style Loss : 0.151427 Content Loss: 0.014116

run [900]:
Style Loss : 0.146585 Content Loss: 0.014187

run [950]:
Style Loss : 0.142737 Content Loss: 0.014242

run [1000]:
Style Loss : 0.139398 Content Loss: 0.014321

run [1050]:
Style Loss : 0.136508 Content Loss: 0.014384

run [1100]:
Style Loss : 0.133823 Content Loss: 0.014451

run [1150]:
Style Loss : 0.131659 Content Loss: 0.014500

run [1200]:
Style Loss : 0.129813 Content Loss: 0.014544

run [1250]:
Style Loss : 0.128166 Content Loss: 0.014589

run [1300]:
Style Loss : 0.126749 Content Loss: 0.014626

run [1350]:
Style Loss : 0.125447 Content Loss: 0.014654

run [1400]:
Style Loss : 0.124249 Content Loss: 0.014683

run [1450]:
Style Loss : 0.123207 Content Loss: 0.014703

run [1500]:
Style Loss : 0.122346 Content Loss: 0.014724

run [1550]:
Style Loss : 0.121562 Content Loss: 0.014742

run [1600]:
Style Loss : 0.120781 Content Loss: 0.014759

run [1650]:
Style Loss : 0.120036 Content Loss: 0.014771

run [1700]:
Style Loss : 0.119387 Content Loss: 0.014789

run [1750]:
Style Loss : 0.118786 Content Loss: 0.014806

run [1800]:
Style Loss : 0.118207 Content Loss: 0.014810

run [1850]:
Style Loss : 0.117564 Content Loss: 0.014820

run [1900]:
Style Loss : 0.117006 Content Loss: 0.014828

run [1950]:
Style Loss : 0.116542 Content Loss: 0.014833

run [2000]:
Style Loss : 0.116073 Content Loss: 0.014839

run [2050]:
Style Loss : 0.115608 Content Loss: 0.014847

run [2100]:
Style Loss : 0.115209 Content Loss: 0.014853

run [2150]:
Style Loss : 0.114862 Content Loss: 0.014860

run [2200]:
Style Loss : 0.114535 Content Loss: 0.014867

run [2250]:
Style Loss : 0.114197 Content Loss: 0.014880

run [2300]:
Style Loss : 0.113906 Content Loss: 0.014887

run [2350]:
Style Loss : 0.113638 Content Loss: 0.014890

run [2400]:
Style Loss : 0.113381 Content Loss: 0.014896

run [2450]:
Style Loss : 0.113134 Content Loss: 0.014897

run [2500]:
Style Loss : 0.112903 Content Loss: 0.014896

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.998240 Content Loss: 0.001808

run [100]:
Style Loss : 0.541222 Content Loss: 0.003964

run [150]:
Style Loss : 0.387742 Content Loss: 0.006068

run [200]:
Style Loss : 0.306834 Content Loss: 0.008042

run [250]:
Style Loss : 0.250694 Content Loss: 0.009995

run [300]:
Style Loss : 0.212226 Content Loss: 0.011791

run [350]:
Style Loss : 0.182863 Content Loss: 0.013387

run [400]:
Style Loss : 0.159657 Content Loss: 0.014881

run [450]:
Style Loss : 0.142424 Content Loss: 0.016081

run [500]:
Style Loss : 0.129605 Content Loss: 0.017016

run [550]:
Style Loss : 0.119827 Content Loss: 0.017812

run [600]:
Style Loss : 0.112893 Content Loss: 0.018414

run [650]:
Style Loss : 0.107524 Content Loss: 0.018928

run [700]:
Style Loss : 0.103390 Content Loss: 0.019250

run [750]:
Style Loss : 0.100191 Content Loss: 0.019465

run [800]:
Style Loss : 0.097264 Content Loss: 0.019721

run [850]:
Style Loss : 0.094765 Content Loss: 0.019881

run [900]:
Style Loss : 0.092681 Content Loss: 0.020006

run [950]:
Style Loss : 0.090679 Content Loss: 0.020153

run [1000]:
Style Loss : 0.088813 Content Loss: 0.020260

run [1050]:
Style Loss : 0.087204 Content Loss: 0.020342

run [1100]:
Style Loss : 0.085670 Content Loss: 0.020433

run [1150]:
Style Loss : 0.084199 Content Loss: 0.020516

run [1200]:
Style Loss : 0.082824 Content Loss: 0.020587

run [1250]:
Style Loss : 0.081495 Content Loss: 0.020667

run [1300]:
Style Loss : 0.080164 Content Loss: 0.020741

run [1350]:
Style Loss : 0.078877 Content Loss: 0.020814

run [1400]:
Style Loss : 0.077603 Content Loss: 0.020898

run [1450]:
Style Loss : 0.076303 Content Loss: 0.020980

run [1500]:
Style Loss : 0.075035 Content Loss: 0.021069

run [1550]:
Style Loss : 0.073792 Content Loss: 0.021166

run [1600]:
Style Loss : 0.072554 Content Loss: 0.021265

run [1650]:
Style Loss : 0.071196 Content Loss: 0.021369

run [1700]:
Style Loss : 0.069860 Content Loss: 0.021478

run [1750]:
Style Loss : 0.068608 Content Loss: 0.021589

run [1800]:
Style Loss : 0.067414 Content Loss: 0.021707

run [1850]:
Style Loss : 0.066263 Content Loss: 0.021821

run [1900]:
Style Loss : 0.065089 Content Loss: 0.021939

run [1950]:
Style Loss : 0.063921 Content Loss: 0.022068

run [2000]:
Style Loss : 0.062671 Content Loss: 0.022200

run [2050]:
Style Loss : 0.061418 Content Loss: 0.022327

run [2100]:
Style Loss : 0.060228 Content Loss: 0.022463

run [2150]:
Style Loss : 0.059104 Content Loss: 0.022590

run [2200]:
Style Loss : 0.058069 Content Loss: 0.022728

run [2250]:
Style Loss : 0.057054 Content Loss: 0.022862

run [2300]:
Style Loss : 0.056083 Content Loss: 0.023010

run [2350]:
Style Loss : 0.055194 Content Loss: 0.023153

run [2400]:
Style Loss : 0.054366 Content Loss: 0.023285

run [2450]:
Style Loss : 0.053582 Content Loss: 0.023416

run [2500]:
Style Loss : 0.052848 Content Loss: 0.023550

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.792404 Content Loss: 0.004538

run [100]:
Style Loss : 0.437173 Content Loss: 0.006786

run [150]:
Style Loss : 0.279122 Content Loss: 0.009642

run [200]:
Style Loss : 0.189025 Content Loss: 0.012424

run [250]:
Style Loss : 0.141465 Content Loss: 0.014776

run [300]:
Style Loss : 0.116481 Content Loss: 0.016781

run [350]:
Style Loss : 0.103254 Content Loss: 0.017759

run [400]:
Style Loss : 0.094082 Content Loss: 0.018374

run [450]:
Style Loss : 0.087286 Content Loss: 0.018913

run [500]:
Style Loss : 0.081759 Content Loss: 0.019521

run [550]:
Style Loss : 0.077481 Content Loss: 0.019890

run [600]:
Style Loss : 0.073922 Content Loss: 0.020255

run [650]:
Style Loss : 0.070861 Content Loss: 0.020617

run [700]:
Style Loss : 0.068346 Content Loss: 0.020905

run [750]:
Style Loss : 0.066221 Content Loss: 0.021189

run [800]:
Style Loss : 0.064261 Content Loss: 0.021451

run [850]:
Style Loss : 0.062599 Content Loss: 0.021703

run [900]:
Style Loss : 0.061093 Content Loss: 0.021964

run [950]:
Style Loss : 0.059799 Content Loss: 0.022179

run [1000]:
Style Loss : 0.058637 Content Loss: 0.022372

run [1050]:
Style Loss : 0.057635 Content Loss: 0.022548

run [1100]:
Style Loss : 0.056718 Content Loss: 0.022711

run [1150]:
Style Loss : 0.055944 Content Loss: 0.022838

run [1200]:
Style Loss : 0.055267 Content Loss: 0.022950

run [1250]:
Style Loss : 0.054648 Content Loss: 0.023040

run [1300]:
Style Loss : 0.054076 Content Loss: 0.023123

run [1350]:
Style Loss : 0.053554 Content Loss: 0.023198

run [1400]:
Style Loss : 0.053079 Content Loss: 0.023262

run [1450]:
Style Loss : 0.052637 Content Loss: 0.023308

run [1500]:
Style Loss : 0.052229 Content Loss: 0.023344

run [1550]:
Style Loss : 0.051849 Content Loss: 0.023379

run [1600]:
Style Loss : 0.051504 Content Loss: 0.023413

run [1650]:
Style Loss : 0.051185 Content Loss: 0.023431

run [1700]:
Style Loss : 0.050886 Content Loss: 0.023467

run [1750]:
Style Loss : 0.050596 Content Loss: 0.023494

run [1800]:
Style Loss : 0.050301 Content Loss: 0.023498

run [1850]:
Style Loss : 0.050026 Content Loss: 0.023514

run [1900]:
Style Loss : 0.049723 Content Loss: 0.023524

run [1950]:
Style Loss : 0.049473 Content Loss: 0.023529

run [2000]:
Style Loss : 0.049215 Content Loss: 0.023549

run [2050]:
Style Loss : 0.048953 Content Loss: 0.023571

run [2100]:
Style Loss : 0.048730 Content Loss: 0.023596

run [2150]:
Style Loss : 0.048499 Content Loss: 0.023618

run [2200]:
Style Loss : 0.048318 Content Loss: 0.023644

run [2250]:
Style Loss : 0.048090 Content Loss: 0.023670

run [2300]:
Style Loss : 0.047892 Content Loss: 0.023689

run [2350]:
Style Loss : 0.047659 Content Loss: 0.023713

run [2400]:
Style Loss : 0.047559 Content Loss: 0.023745

run [2450]:
Style Loss : 0.047329 Content Loss: 0.023761

run [2500]:
Style Loss : 0.047136 Content Loss: 0.023781

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.665160 Content Loss: 0.001931

run [100]:
Style Loss : 0.390523 Content Loss: 0.003239

run [150]:
Style Loss : 0.273429 Content Loss: 0.004811

run [200]:
Style Loss : 0.209306 Content Loss: 0.006321

run [250]:
Style Loss : 0.171988 Content Loss: 0.007522

run [300]:
Style Loss : 0.148669 Content Loss: 0.008296

run [350]:
Style Loss : 0.131948 Content Loss: 0.008936

run [400]:
Style Loss : 0.120127 Content Loss: 0.009535

run [450]:
Style Loss : 0.111236 Content Loss: 0.010026

run [500]:
Style Loss : 0.104744 Content Loss: 0.010421

run [550]:
Style Loss : 0.099709 Content Loss: 0.010745

run [600]:
Style Loss : 0.096033 Content Loss: 0.010978

run [650]:
Style Loss : 0.093051 Content Loss: 0.011113

run [700]:
Style Loss : 0.090570 Content Loss: 0.011205

run [750]:
Style Loss : 0.088489 Content Loss: 0.011303

run [800]:
Style Loss : 0.086751 Content Loss: 0.011377

run [850]:
Style Loss : 0.085261 Content Loss: 0.011440

run [900]:
Style Loss : 0.084006 Content Loss: 0.011489

run [950]:
Style Loss : 0.082859 Content Loss: 0.011528

run [1000]:
Style Loss : 0.081844 Content Loss: 0.011552

run [1050]:
Style Loss : 0.080863 Content Loss: 0.011599

run [1100]:
Style Loss : 0.079999 Content Loss: 0.011633

run [1150]:
Style Loss : 0.079162 Content Loss: 0.011673

run [1200]:
Style Loss : 0.078461 Content Loss: 0.011698

run [1250]:
Style Loss : 0.077846 Content Loss: 0.011714

run [1300]:
Style Loss : 0.077275 Content Loss: 0.011728

run [1350]:
Style Loss : 0.076763 Content Loss: 0.011741

run [1400]:
Style Loss : 0.076291 Content Loss: 0.011751

run [1450]:
Style Loss : 0.075870 Content Loss: 0.011759

run [1500]:
Style Loss : 0.075460 Content Loss: 0.011766

run [1550]:
Style Loss : 0.075093 Content Loss: 0.011769

run [1600]:
Style Loss : 0.074747 Content Loss: 0.011775

run [1650]:
Style Loss : 0.074444 Content Loss: 0.011780

run [1700]:
Style Loss : 0.074130 Content Loss: 0.011788

run [1750]:
Style Loss : 0.073805 Content Loss: 0.011794

run [1800]:
Style Loss : 0.073417 Content Loss: 0.011798

run [1850]:
Style Loss : 0.073099 Content Loss: 0.011806

run [1900]:
Style Loss : 0.072819 Content Loss: 0.011807

run [1950]:
Style Loss : 0.072568 Content Loss: 0.011813

run [2000]:
Style Loss : 0.072344 Content Loss: 0.011816

run [2050]:
Style Loss : 0.072111 Content Loss: 0.011826

run [2100]:
Style Loss : 0.071907 Content Loss: 0.011834

run [2150]:
Style Loss : 0.071704 Content Loss: 0.011839

run [2200]:
Style Loss : 0.071501 Content Loss: 0.011844

run [2250]:
Style Loss : 0.071300 Content Loss: 0.011851

run [2300]:
Style Loss : 0.071117 Content Loss: 0.011858

run [2350]:
Style Loss : 0.070968 Content Loss: 0.011861

run [2400]:
Style Loss : 0.070817 Content Loss: 0.011866

run [2450]:
Style Loss : 0.070673 Content Loss: 0.011871

run [2500]:
Style Loss : 0.070548 Content Loss: 0.011871

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.876079 Content Loss: 0.000886

run [100]:
Style Loss : 0.554554 Content Loss: 0.001647

run [150]:
Style Loss : 0.411999 Content Loss: 0.002740

run [200]:
Style Loss : 0.319702 Content Loss: 0.004157

run [250]:
Style Loss : 0.254601 Content Loss: 0.005931

run [300]:
Style Loss : 0.203614 Content Loss: 0.008016

run [350]:
Style Loss : 0.162609 Content Loss: 0.010142

run [400]:
Style Loss : 0.132530 Content Loss: 0.012187

run [450]:
Style Loss : 0.110777 Content Loss: 0.013893

run [500]:
Style Loss : 0.095984 Content Loss: 0.015269

run [550]:
Style Loss : 0.085293 Content Loss: 0.016353

run [600]:
Style Loss : 0.078065 Content Loss: 0.016979

run [650]:
Style Loss : 0.073088 Content Loss: 0.017355

run [700]:
Style Loss : 0.069142 Content Loss: 0.017619

run [750]:
Style Loss : 0.066034 Content Loss: 0.017757

run [800]:
Style Loss : 0.063570 Content Loss: 0.017816

run [850]:
Style Loss : 0.061600 Content Loss: 0.017854

run [900]:
Style Loss : 0.060029 Content Loss: 0.017896

run [950]:
Style Loss : 0.058678 Content Loss: 0.017949

run [1000]:
Style Loss : 0.057512 Content Loss: 0.017970

run [1050]:
Style Loss : 0.056510 Content Loss: 0.017974

run [1100]:
Style Loss : 0.055603 Content Loss: 0.017982

run [1150]:
Style Loss : 0.054735 Content Loss: 0.017984

run [1200]:
Style Loss : 0.053996 Content Loss: 0.017988

run [1250]:
Style Loss : 0.053287 Content Loss: 0.017993

run [1300]:
Style Loss : 0.052685 Content Loss: 0.017997

run [1350]:
Style Loss : 0.052177 Content Loss: 0.018000

run [1400]:
Style Loss : 0.051733 Content Loss: 0.018007

run [1450]:
Style Loss : 0.051290 Content Loss: 0.018016

run [1500]:
Style Loss : 0.050844 Content Loss: 0.018025

run [1550]:
Style Loss : 0.050418 Content Loss: 0.018037

run [1600]:
Style Loss : 0.049960 Content Loss: 0.018051

run [1650]:
Style Loss : 0.049499 Content Loss: 0.018066

run [1700]:
Style Loss : 0.049051 Content Loss: 0.018081

run [1750]:
Style Loss : 0.048654 Content Loss: 0.018094

run [1800]:
Style Loss : 0.048255 Content Loss: 0.018112

run [1850]:
Style Loss : 0.047829 Content Loss: 0.018135

run [1900]:
Style Loss : 0.047419 Content Loss: 0.018159

run [1950]:
Style Loss : 0.046997 Content Loss: 0.018181

run [2000]:
Style Loss : 0.046625 Content Loss: 0.018206

run [2050]:
Style Loss : 0.046272 Content Loss: 0.018227

run [2100]:
Style Loss : 0.045932 Content Loss: 0.018244

run [2150]:
Style Loss : 0.045597 Content Loss: 0.018271

run [2200]:
Style Loss : 0.045256 Content Loss: 0.018289

run [2250]:
Style Loss : 0.044946 Content Loss: 0.018309

run [2300]:
Style Loss : 0.044644 Content Loss: 0.018328

run [2350]:
Style Loss : 0.044386 Content Loss: 0.018347

run [2400]:
Style Loss : 0.044111 Content Loss: 0.018360

run [2450]:
Style Loss : 0.043842 Content Loss: 0.018374

run [2500]:
Style Loss : 0.043578 Content Loss: 0.018386

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.976927 Content Loss: 0.005859

run [100]:
Style Loss : 0.531589 Content Loss: 0.009350

run [150]:
Style Loss : 0.301906 Content Loss: 0.013989

run [200]:
Style Loss : 0.194373 Content Loss: 0.018190

run [250]:
Style Loss : 0.149745 Content Loss: 0.020748

run [300]:
Style Loss : 0.125792 Content Loss: 0.021895

run [350]:
Style Loss : 0.111127 Content Loss: 0.022561

run [400]:
Style Loss : 0.100983 Content Loss: 0.023204

run [450]:
Style Loss : 0.093624 Content Loss: 0.023717

run [500]:
Style Loss : 0.087544 Content Loss: 0.024229

run [550]:
Style Loss : 0.082650 Content Loss: 0.024717

run [600]:
Style Loss : 0.078396 Content Loss: 0.025176

run [650]:
Style Loss : 0.074873 Content Loss: 0.025564

run [700]:
Style Loss : 0.071565 Content Loss: 0.025954

run [750]:
Style Loss : 0.068708 Content Loss: 0.026230

run [800]:
Style Loss : 0.066420 Content Loss: 0.026510

run [850]:
Style Loss : 0.064455 Content Loss: 0.026705

run [900]:
Style Loss : 0.062863 Content Loss: 0.026842

run [950]:
Style Loss : 0.061436 Content Loss: 0.026993

run [1000]:
Style Loss : 0.060137 Content Loss: 0.027092

run [1050]:
Style Loss : 0.059013 Content Loss: 0.027125

run [1100]:
Style Loss : 0.058023 Content Loss: 0.027130

run [1150]:
Style Loss : 0.057089 Content Loss: 0.027169

run [1200]:
Style Loss : 0.056301 Content Loss: 0.027191

run [1250]:
Style Loss : 0.055520 Content Loss: 0.027208

run [1300]:
Style Loss : 0.054897 Content Loss: 0.027216

run [1350]:
Style Loss : 0.054279 Content Loss: 0.027229

run [1400]:
Style Loss : 0.053764 Content Loss: 0.027228

run [1450]:
Style Loss : 0.053398 Content Loss: 0.027230

run [1500]:
Style Loss : 0.052801 Content Loss: 0.027269

run [1550]:
Style Loss : 0.052338 Content Loss: 0.027297

run [1600]:
Style Loss : 0.052016 Content Loss: 0.027344

run [1650]:
Style Loss : 0.051685 Content Loss: 0.027382

run [1700]:
Style Loss : 0.051342 Content Loss: 0.027423

run [1750]:
Style Loss : 0.051079 Content Loss: 0.027446

run [1800]:
Style Loss : 0.050769 Content Loss: 0.027474

run [1850]:
Style Loss : 0.050581 Content Loss: 0.027527

run [1900]:
Style Loss : 0.050268 Content Loss: 0.027559

run [1950]:
Style Loss : 0.050363 Content Loss: 0.027620

run [2000]:
Style Loss : 0.049677 Content Loss: 0.027617

run [2050]:
Style Loss : 0.049477 Content Loss: 0.027674

run [2100]:
Style Loss : 0.049213 Content Loss: 0.027728

run [2150]:
Style Loss : 0.049077 Content Loss: 0.027753

run [2200]:
Style Loss : 0.048845 Content Loss: 0.027812

run [2250]:
Style Loss : 0.050335 Content Loss: 0.027889

run [2300]:
Style Loss : 0.048228 Content Loss: 0.027893

run [2350]:
Style Loss : 0.048021 Content Loss: 0.027915

run [2400]:
Style Loss : 0.047763 Content Loss: 0.027911

run [2450]:
Style Loss : 0.047501 Content Loss: 0.027931

run [2500]:
Style Loss : 0.047277 Content Loss: 0.027922

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.734951 Content Loss: 0.002241

run [100]:
Style Loss : 0.463688 Content Loss: 0.002910

run [150]:
Style Loss : 0.343537 Content Loss: 0.003923

run [200]:
Style Loss : 0.274416 Content Loss: 0.005072

run [250]:
Style Loss : 0.230222 Content Loss: 0.006122

run [300]:
Style Loss : 0.200214 Content Loss: 0.006987

run [350]:
Style Loss : 0.178196 Content Loss: 0.007750

run [400]:
Style Loss : 0.162465 Content Loss: 0.008368

run [450]:
Style Loss : 0.150830 Content Loss: 0.008877

run [500]:
Style Loss : 0.142646 Content Loss: 0.009282

run [550]:
Style Loss : 0.136231 Content Loss: 0.009601

run [600]:
Style Loss : 0.131017 Content Loss: 0.009834

run [650]:
Style Loss : 0.126738 Content Loss: 0.010023

run [700]:
Style Loss : 0.123144 Content Loss: 0.010191

run [750]:
Style Loss : 0.119893 Content Loss: 0.010345

run [800]:
Style Loss : 0.117245 Content Loss: 0.010484

run [850]:
Style Loss : 0.114926 Content Loss: 0.010607

run [900]:
Style Loss : 0.112699 Content Loss: 0.010749

run [950]:
Style Loss : 0.110750 Content Loss: 0.010885

run [1000]:
Style Loss : 0.108996 Content Loss: 0.010992

run [1050]:
Style Loss : 0.107346 Content Loss: 0.011101

run [1100]:
Style Loss : 0.105698 Content Loss: 0.011226

run [1150]:
Style Loss : 0.104181 Content Loss: 0.011327

run [1200]:
Style Loss : 0.102706 Content Loss: 0.011431

run [1250]:
Style Loss : 0.101382 Content Loss: 0.011537

run [1300]:
Style Loss : 0.100077 Content Loss: 0.011633

run [1350]:
Style Loss : 0.098942 Content Loss: 0.011718

run [1400]:
Style Loss : 0.097834 Content Loss: 0.011827

run [1450]:
Style Loss : 0.096804 Content Loss: 0.011916

run [1500]:
Style Loss : 0.095827 Content Loss: 0.011993

run [1550]:
Style Loss : 0.094939 Content Loss: 0.012066

run [1600]:
Style Loss : 0.094055 Content Loss: 0.012141

run [1650]:
Style Loss : 0.093253 Content Loss: 0.012199

run [1700]:
Style Loss : 0.092554 Content Loss: 0.012247

run [1750]:
Style Loss : 0.091893 Content Loss: 0.012293

run [1800]:
Style Loss : 0.091269 Content Loss: 0.012338

run [1850]:
Style Loss : 0.090736 Content Loss: 0.012377

run [1900]:
Style Loss : 0.090188 Content Loss: 0.012403

run [1950]:
Style Loss : 0.089717 Content Loss: 0.012415

run [2000]:
Style Loss : 0.089246 Content Loss: 0.012446

run [2050]:
Style Loss : 0.088794 Content Loss: 0.012464

run [2100]:
Style Loss : 0.088358 Content Loss: 0.012497

run [2150]:
Style Loss : 0.087952 Content Loss: 0.012507

run [2200]:
Style Loss : 0.087574 Content Loss: 0.012528

run [2250]:
Style Loss : 0.087230 Content Loss: 0.012550

run [2300]:
Style Loss : 0.086906 Content Loss: 0.012572

run [2350]:
Style Loss : 0.086576 Content Loss: 0.012575

run [2400]:
Style Loss : 0.086260 Content Loss: 0.012593

run [2450]:
Style Loss : 0.085934 Content Loss: 0.012606

run [2500]:
Style Loss : 0.085635 Content Loss: 0.012625

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.369894 Content Loss: 0.002126

run [100]:
Style Loss : 1.424920 Content Loss: 0.002753

run [150]:
Style Loss : 1.056034 Content Loss: 0.003383

run [200]:
Style Loss : 0.833676 Content Loss: 0.004111

run [250]:
Style Loss : 0.695978 Content Loss: 0.004933

run [300]:
Style Loss : 0.605626 Content Loss: 0.005788

run [350]:
Style Loss : 0.542983 Content Loss: 0.006650

run [400]:
Style Loss : 0.497604 Content Loss: 0.007487

run [450]:
Style Loss : 0.464744 Content Loss: 0.008178

run [500]:
Style Loss : 0.440782 Content Loss: 0.008869

run [550]:
Style Loss : 0.420341 Content Loss: 0.009531

run [600]:
Style Loss : 0.403504 Content Loss: 0.009949

run [650]:
Style Loss : 0.389151 Content Loss: 0.010269

run [700]:
Style Loss : 0.378500 Content Loss: 0.010586

run [750]:
Style Loss : 0.369789 Content Loss: 0.010864

run [800]:
Style Loss : 0.362410 Content Loss: 0.011101

run [850]:
Style Loss : 0.356199 Content Loss: 0.011313

run [900]:
Style Loss : 0.350647 Content Loss: 0.011501

run [950]:
Style Loss : 0.345928 Content Loss: 0.011661

run [1000]:
Style Loss : 0.341561 Content Loss: 0.011820

run [1050]:
Style Loss : 0.337451 Content Loss: 0.011934

run [1100]:
Style Loss : 0.333458 Content Loss: 0.012058

run [1150]:
Style Loss : 0.329802 Content Loss: 0.012159

run [1200]:
Style Loss : 0.326561 Content Loss: 0.012261

run [1250]:
Style Loss : 0.323363 Content Loss: 0.012359

run [1300]:
Style Loss : 0.320702 Content Loss: 0.012456

run [1350]:
Style Loss : 0.318492 Content Loss: 0.012548

run [1400]:
Style Loss : 0.316183 Content Loss: 0.012643

run [1450]:
Style Loss : 0.314023 Content Loss: 0.012725

run [1500]:
Style Loss : 0.312058 Content Loss: 0.012797

run [1550]:
Style Loss : 0.310258 Content Loss: 0.012880

run [1600]:
Style Loss : 0.308537 Content Loss: 0.012941

run [1650]:
Style Loss : 0.306810 Content Loss: 0.013020

run [1700]:
Style Loss : 0.305183 Content Loss: 0.013096

run [1750]:
Style Loss : 0.303550 Content Loss: 0.013166

run [1800]:
Style Loss : 0.302061 Content Loss: 0.013236

run [1850]:
Style Loss : 0.300665 Content Loss: 0.013298

run [1900]:
Style Loss : 0.299422 Content Loss: 0.013346

run [1950]:
Style Loss : 0.298244 Content Loss: 0.013400

run [2000]:
Style Loss : 0.297137 Content Loss: 0.013455

run [2050]:
Style Loss : 0.296170 Content Loss: 0.013510

run [2100]:
Style Loss : 0.295265 Content Loss: 0.013547

run [2150]:
Style Loss : 0.294385 Content Loss: 0.013583

run [2200]:
Style Loss : 0.293561 Content Loss: 0.013622

run [2250]:
Style Loss : 0.292707 Content Loss: 0.013661

run [2300]:
Style Loss : 0.291874 Content Loss: 0.013687

run [2350]:
Style Loss : 0.291115 Content Loss: 0.013716

run [2400]:
Style Loss : 0.290498 Content Loss: 0.013754

run [2450]:
Style Loss : 0.289864 Content Loss: 0.013782

run [2500]:
Style Loss : 0.289207 Content Loss: 0.013813

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.628244 Content Loss: 0.001583

run [100]:
Style Loss : 1.070224 Content Loss: 0.002088

run [150]:
Style Loss : 0.822009 Content Loss: 0.003083

run [200]:
Style Loss : 0.683913 Content Loss: 0.004865

run [250]:
Style Loss : 0.585531 Content Loss: 0.006928

run [300]:
Style Loss : 0.507625 Content Loss: 0.009320

run [350]:
Style Loss : 0.446799 Content Loss: 0.012097

run [400]:
Style Loss : 0.397001 Content Loss: 0.014387

run [450]:
Style Loss : 0.358123 Content Loss: 0.016501

run [500]:
Style Loss : 0.329256 Content Loss: 0.017941

run [550]:
Style Loss : 0.306191 Content Loss: 0.019144

run [600]:
Style Loss : 0.287958 Content Loss: 0.020136

run [650]:
Style Loss : 0.273055 Content Loss: 0.021011

run [700]:
Style Loss : 0.261154 Content Loss: 0.021698

run [750]:
Style Loss : 0.250766 Content Loss: 0.022392

run [800]:
Style Loss : 0.242099 Content Loss: 0.022938

run [850]:
Style Loss : 0.234783 Content Loss: 0.023440

run [900]:
Style Loss : 0.227946 Content Loss: 0.023747

run [950]:
Style Loss : 0.222328 Content Loss: 0.024063

run [1000]:
Style Loss : 0.217046 Content Loss: 0.024369

run [1050]:
Style Loss : 0.211784 Content Loss: 0.024577

run [1100]:
Style Loss : 0.207470 Content Loss: 0.024846

run [1150]:
Style Loss : 0.202696 Content Loss: 0.025095

run [1200]:
Style Loss : 0.198982 Content Loss: 0.025298

run [1250]:
Style Loss : 0.195666 Content Loss: 0.025460

run [1300]:
Style Loss : 0.192568 Content Loss: 0.025660

run [1350]:
Style Loss : 0.189811 Content Loss: 0.025854

run [1400]:
Style Loss : 0.187293 Content Loss: 0.026028

run [1450]:
Style Loss : 0.184981 Content Loss: 0.026183

run [1500]:
Style Loss : 0.182806 Content Loss: 0.026345

run [1550]:
Style Loss : 0.180852 Content Loss: 0.026470

run [1600]:
Style Loss : 0.179158 Content Loss: 0.026628

run [1650]:
Style Loss : 0.177454 Content Loss: 0.026742

run [1700]:
Style Loss : 0.176050 Content Loss: 0.026892

run [1750]:
Style Loss : 0.174592 Content Loss: 0.027028

run [1800]:
Style Loss : 0.173125 Content Loss: 0.027183

run [1850]:
Style Loss : 0.171778 Content Loss: 0.027312

run [1900]:
Style Loss : 0.170580 Content Loss: 0.027443

run [1950]:
Style Loss : 0.169408 Content Loss: 0.027540

run [2000]:
Style Loss : 0.168309 Content Loss: 0.027646

run [2050]:
Style Loss : 0.167280 Content Loss: 0.027760

run [2100]:
Style Loss : 0.166276 Content Loss: 0.027832

run [2150]:
Style Loss : 0.165300 Content Loss: 0.027903

run [2200]:
Style Loss : 0.164304 Content Loss: 0.027975

run [2250]:
Style Loss : 0.163473 Content Loss: 0.028027

run [2300]:
Style Loss : 0.162792 Content Loss: 0.028101

run [2350]:
Style Loss : 0.162085 Content Loss: 0.028146

run [2400]:
Style Loss : 0.161413 Content Loss: 0.028187

run [2450]:
Style Loss : 0.160841 Content Loss: 0.028236

run [2500]:
Style Loss : 0.160189 Content Loss: 0.028275

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.732307 Content Loss: 0.002934

run [100]:
Style Loss : 0.450680 Content Loss: 0.003361

run [150]:
Style Loss : 0.341687 Content Loss: 0.004018

run [200]:
Style Loss : 0.280170 Content Loss: 0.004677

run [250]:
Style Loss : 0.244138 Content Loss: 0.005232

run [300]:
Style Loss : 0.217193 Content Loss: 0.005686

run [350]:
Style Loss : 0.197534 Content Loss: 0.006108

run [400]:
Style Loss : 0.181261 Content Loss: 0.006492

run [450]:
Style Loss : 0.169073 Content Loss: 0.006851

run [500]:
Style Loss : 0.159159 Content Loss: 0.007161

run [550]:
Style Loss : 0.150863 Content Loss: 0.007467

run [600]:
Style Loss : 0.143813 Content Loss: 0.007731

run [650]:
Style Loss : 0.137524 Content Loss: 0.008005

run [700]:
Style Loss : 0.131484 Content Loss: 0.008262

run [750]:
Style Loss : 0.125782 Content Loss: 0.008499

run [800]:
Style Loss : 0.120438 Content Loss: 0.008739

run [850]:
Style Loss : 0.115360 Content Loss: 0.008986

run [900]:
Style Loss : 0.110574 Content Loss: 0.009181

run [950]:
Style Loss : 0.105929 Content Loss: 0.009421

run [1000]:
Style Loss : 0.101698 Content Loss: 0.009647

run [1050]:
Style Loss : 0.097890 Content Loss: 0.009852

run [1100]:
Style Loss : 0.094239 Content Loss: 0.010067

run [1150]:
Style Loss : 0.090976 Content Loss: 0.010286

run [1200]:
Style Loss : 0.087859 Content Loss: 0.010509

run [1250]:
Style Loss : 0.085045 Content Loss: 0.010710

run [1300]:
Style Loss : 0.082433 Content Loss: 0.010916

run [1350]:
Style Loss : 0.080175 Content Loss: 0.011098

run [1400]:
Style Loss : 0.078158 Content Loss: 0.011262

run [1450]:
Style Loss : 0.076228 Content Loss: 0.011417

run [1500]:
Style Loss : 0.074564 Content Loss: 0.011540

run [1550]:
Style Loss : 0.073181 Content Loss: 0.011661

run [1600]:
Style Loss : 0.071937 Content Loss: 0.011754

run [1650]:
Style Loss : 0.070844 Content Loss: 0.011836

run [1700]:
Style Loss : 0.069897 Content Loss: 0.011896

run [1750]:
Style Loss : 0.069085 Content Loss: 0.011935

run [1800]:
Style Loss : 0.068309 Content Loss: 0.011979

run [1850]:
Style Loss : 0.067619 Content Loss: 0.012022

run [1900]:
Style Loss : 0.066964 Content Loss: 0.012052

run [1950]:
Style Loss : 0.066399 Content Loss: 0.012078

run [2000]:
Style Loss : 0.065859 Content Loss: 0.012094

run [2050]:
Style Loss : 0.065376 Content Loss: 0.012105

run [2100]:
Style Loss : 0.064983 Content Loss: 0.012111

run [2150]:
Style Loss : 0.064656 Content Loss: 0.012109

run [2200]:
Style Loss : 0.064342 Content Loss: 0.012113

run [2250]:
Style Loss : 0.064046 Content Loss: 0.012112

run [2300]:
Style Loss : 0.063785 Content Loss: 0.012111

run [2350]:
Style Loss : 0.063545 Content Loss: 0.012110

run [2400]:
Style Loss : 0.063318 Content Loss: 0.012109

run [2450]:
Style Loss : 0.063101 Content Loss: 0.012107

run [2500]:
Style Loss : 0.062889 Content Loss: 0.012101

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.629126 Content Loss: 0.002685

run [100]:
Style Loss : 1.022619 Content Loss: 0.003384

run [150]:
Style Loss : 0.787126 Content Loss: 0.003941

run [200]:
Style Loss : 0.649330 Content Loss: 0.004549

run [250]:
Style Loss : 0.567668 Content Loss: 0.005214

run [300]:
Style Loss : 0.506588 Content Loss: 0.005854

run [350]:
Style Loss : 0.462907 Content Loss: 0.006351

run [400]:
Style Loss : 0.430020 Content Loss: 0.006821

run [450]:
Style Loss : 0.405448 Content Loss: 0.007245

run [500]:
Style Loss : 0.385025 Content Loss: 0.007633

run [550]:
Style Loss : 0.369521 Content Loss: 0.007912

run [600]:
Style Loss : 0.356816 Content Loss: 0.008250

run [650]:
Style Loss : 0.345815 Content Loss: 0.008496

run [700]:
Style Loss : 0.336961 Content Loss: 0.008738

run [750]:
Style Loss : 0.329215 Content Loss: 0.008943

run [800]:
Style Loss : 0.321958 Content Loss: 0.009149

run [850]:
Style Loss : 0.315247 Content Loss: 0.009293

run [900]:
Style Loss : 0.309089 Content Loss: 0.009444

run [950]:
Style Loss : 0.303517 Content Loss: 0.009596

run [1000]:
Style Loss : 0.298768 Content Loss: 0.009732

run [1050]:
Style Loss : 0.294401 Content Loss: 0.009857

run [1100]:
Style Loss : 0.290420 Content Loss: 0.009962

run [1150]:
Style Loss : 0.286794 Content Loss: 0.010069

run [1200]:
Style Loss : 0.283458 Content Loss: 0.010159

run [1250]:
Style Loss : 0.280411 Content Loss: 0.010237

run [1300]:
Style Loss : 0.277293 Content Loss: 0.010316

run [1350]:
Style Loss : 0.274381 Content Loss: 0.010390

run [1400]:
Style Loss : 0.271358 Content Loss: 0.010464

run [1450]:
Style Loss : 0.268258 Content Loss: 0.010562

run [1500]:
Style Loss : 0.265048 Content Loss: 0.010629

run [1550]:
Style Loss : 0.262226 Content Loss: 0.010691

run [1600]:
Style Loss : 0.259284 Content Loss: 0.010766

run [1650]:
Style Loss : 0.256034 Content Loss: 0.010827

run [1700]:
Style Loss : 0.252684 Content Loss: 0.010894

run [1750]:
Style Loss : 0.249479 Content Loss: 0.010958

run [1800]:
Style Loss : 0.246639 Content Loss: 0.011007

run [1850]:
Style Loss : 0.244047 Content Loss: 0.011070

run [1900]:
Style Loss : 0.241497 Content Loss: 0.011139

run [1950]:
Style Loss : 0.238852 Content Loss: 0.011207

run [2000]:
Style Loss : 0.236078 Content Loss: 0.011273

run [2050]:
Style Loss : 0.233586 Content Loss: 0.011323

run [2100]:
Style Loss : 0.231123 Content Loss: 0.011370

run [2150]:
Style Loss : 0.228790 Content Loss: 0.011411

run [2200]:
Style Loss : 0.226403 Content Loss: 0.011454

run [2250]:
Style Loss : 0.224168 Content Loss: 0.011489

run [2300]:
Style Loss : 0.221864 Content Loss: 0.011534

run [2350]:
Style Loss : 0.219990 Content Loss: 0.011573

run [2400]:
Style Loss : 0.218288 Content Loss: 0.011611

run [2450]:
Style Loss : 0.216635 Content Loss: 0.011647

run [2500]:
Style Loss : 0.215139 Content Loss: 0.011680

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.505357 Content Loss: 0.001720

run [100]:
Style Loss : 0.981561 Content Loss: 0.002129

run [150]:
Style Loss : 0.778291 Content Loss: 0.002828

run [200]:
Style Loss : 0.650130 Content Loss: 0.003846

run [250]:
Style Loss : 0.560778 Content Loss: 0.005321

run [300]:
Style Loss : 0.496126 Content Loss: 0.007144

run [350]:
Style Loss : 0.447409 Content Loss: 0.008970

run [400]:
Style Loss : 0.409669 Content Loss: 0.010711

run [450]:
Style Loss : 0.379167 Content Loss: 0.012133

run [500]:
Style Loss : 0.354619 Content Loss: 0.013118

run [550]:
Style Loss : 0.334748 Content Loss: 0.014049

run [600]:
Style Loss : 0.319317 Content Loss: 0.014748

run [650]:
Style Loss : 0.307312 Content Loss: 0.015438

run [700]:
Style Loss : 0.297395 Content Loss: 0.016004

run [750]:
Style Loss : 0.289454 Content Loss: 0.016548

run [800]:
Style Loss : 0.282714 Content Loss: 0.016972

run [850]:
Style Loss : 0.276984 Content Loss: 0.017383

run [900]:
Style Loss : 0.271750 Content Loss: 0.017683

run [950]:
Style Loss : 0.267018 Content Loss: 0.017945

run [1000]:
Style Loss : 0.262682 Content Loss: 0.018196

run [1050]:
Style Loss : 0.258471 Content Loss: 0.018416

run [1100]:
Style Loss : 0.254571 Content Loss: 0.018599

run [1150]:
Style Loss : 0.250837 Content Loss: 0.018811

run [1200]:
Style Loss : 0.247485 Content Loss: 0.018960

run [1250]:
Style Loss : 0.244194 Content Loss: 0.019130

run [1300]:
Style Loss : 0.241101 Content Loss: 0.019248

run [1350]:
Style Loss : 0.238443 Content Loss: 0.019367

run [1400]:
Style Loss : 0.236057 Content Loss: 0.019500

run [1450]:
Style Loss : 0.233854 Content Loss: 0.019607

run [1500]:
Style Loss : 0.231837 Content Loss: 0.019702

run [1550]:
Style Loss : 0.229595 Content Loss: 0.019807

run [1600]:
Style Loss : 0.227611 Content Loss: 0.019888

run [1650]:
Style Loss : 0.225681 Content Loss: 0.019972

run [1700]:
Style Loss : 0.223916 Content Loss: 0.020048

run [1750]:
Style Loss : 0.222209 Content Loss: 0.020131

run [1800]:
Style Loss : 0.220661 Content Loss: 0.020213

run [1850]:
Style Loss : 0.219123 Content Loss: 0.020291

run [1900]:
Style Loss : 0.217420 Content Loss: 0.020381

run [1950]:
Style Loss : 0.215841 Content Loss: 0.020464

run [2000]:
Style Loss : 0.214273 Content Loss: 0.020538

run [2050]:
Style Loss : 0.212671 Content Loss: 0.020602

run [2100]:
Style Loss : 0.211117 Content Loss: 0.020667

run [2150]:
Style Loss : 0.209666 Content Loss: 0.020730

run [2200]:
Style Loss : 0.208346 Content Loss: 0.020791

run [2250]:
Style Loss : 0.207174 Content Loss: 0.020827

run [2300]:
Style Loss : 0.206031 Content Loss: 0.020876

run [2350]:
Style Loss : 0.204978 Content Loss: 0.020929

run [2400]:
Style Loss : 0.203892 Content Loss: 0.020981

run [2450]:
Style Loss : 0.202944 Content Loss: 0.021023

run [2500]:
Style Loss : 0.202054 Content Loss: 0.021057

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.135231 Content Loss: 0.003464

run [100]:
Style Loss : 0.610207 Content Loss: 0.004241

run [150]:
Style Loss : 0.445992 Content Loss: 0.005244

run [200]:
Style Loss : 0.358430 Content Loss: 0.006157

run [250]:
Style Loss : 0.304937 Content Loss: 0.006866

run [300]:
Style Loss : 0.273641 Content Loss: 0.007436

run [350]:
Style Loss : 0.252067 Content Loss: 0.007834

run [400]:
Style Loss : 0.236083 Content Loss: 0.008142

run [450]:
Style Loss : 0.222878 Content Loss: 0.008376

run [500]:
Style Loss : 0.212339 Content Loss: 0.008558

run [550]:
Style Loss : 0.204022 Content Loss: 0.008770

run [600]:
Style Loss : 0.197144 Content Loss: 0.008963

run [650]:
Style Loss : 0.190947 Content Loss: 0.009147

run [700]:
Style Loss : 0.185369 Content Loss: 0.009316

run [750]:
Style Loss : 0.179945 Content Loss: 0.009475

run [800]:
Style Loss : 0.175140 Content Loss: 0.009629

run [850]:
Style Loss : 0.170809 Content Loss: 0.009754

run [900]:
Style Loss : 0.167039 Content Loss: 0.009874

run [950]:
Style Loss : 0.163554 Content Loss: 0.009990

run [1000]:
Style Loss : 0.160218 Content Loss: 0.010105

run [1050]:
Style Loss : 0.157447 Content Loss: 0.010206

run [1100]:
Style Loss : 0.154597 Content Loss: 0.010316

run [1150]:
Style Loss : 0.152275 Content Loss: 0.010404

run [1200]:
Style Loss : 0.150107 Content Loss: 0.010491

run [1250]:
Style Loss : 0.148023 Content Loss: 0.010577

run [1300]:
Style Loss : 0.146099 Content Loss: 0.010652

run [1350]:
Style Loss : 0.144317 Content Loss: 0.010723

run [1400]:
Style Loss : 0.142721 Content Loss: 0.010794

run [1450]:
Style Loss : 0.141172 Content Loss: 0.010856

run [1500]:
Style Loss : 0.139550 Content Loss: 0.010932

run [1550]:
Style Loss : 0.138019 Content Loss: 0.010985

run [1600]:
Style Loss : 0.136549 Content Loss: 0.011056

run [1650]:
Style Loss : 0.135132 Content Loss: 0.011121

run [1700]:
Style Loss : 0.133823 Content Loss: 0.011183

run [1750]:
Style Loss : 0.132546 Content Loss: 0.011247

run [1800]:
Style Loss : 0.131471 Content Loss: 0.011298

run [1850]:
Style Loss : 0.130378 Content Loss: 0.011349

run [1900]:
Style Loss : 0.129403 Content Loss: 0.011395

run [1950]:
Style Loss : 0.128472 Content Loss: 0.011440

run [2000]:
Style Loss : 0.127586 Content Loss: 0.011490

run [2050]:
Style Loss : 0.126789 Content Loss: 0.011520

run [2100]:
Style Loss : 0.125987 Content Loss: 0.011557

run [2150]:
Style Loss : 0.125227 Content Loss: 0.011594

run [2200]:
Style Loss : 0.124527 Content Loss: 0.011624

run [2250]:
Style Loss : 0.123881 Content Loss: 0.011660

run [2300]:
Style Loss : 0.123285 Content Loss: 0.011699

run [2350]:
Style Loss : 0.122741 Content Loss: 0.011727

run [2400]:
Style Loss : 0.122205 Content Loss: 0.011758

run [2450]:
Style Loss : 0.121731 Content Loss: 0.011791

run [2500]:
Style Loss : 0.121302 Content Loss: 0.011817

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.334230 Content Loss: 0.002659

run [100]:
Style Loss : 1.422155 Content Loss: 0.003028

run [150]:
Style Loss : 1.095810 Content Loss: 0.003249

run [200]:
Style Loss : 0.915075 Content Loss: 0.003672

run [250]:
Style Loss : 0.800443 Content Loss: 0.004158

run [300]:
Style Loss : 0.723658 Content Loss: 0.004632

run [350]:
Style Loss : 0.667689 Content Loss: 0.005232

run [400]:
Style Loss : 0.624413 Content Loss: 0.005809

run [450]:
Style Loss : 0.588052 Content Loss: 0.006308

run [500]:
Style Loss : 0.557351 Content Loss: 0.006807

run [550]:
Style Loss : 0.531572 Content Loss: 0.007296

run [600]:
Style Loss : 0.510172 Content Loss: 0.007744

run [650]:
Style Loss : 0.490165 Content Loss: 0.008174

run [700]:
Style Loss : 0.472028 Content Loss: 0.008572

run [750]:
Style Loss : 0.456379 Content Loss: 0.008899

run [800]:
Style Loss : 0.443536 Content Loss: 0.009182

run [850]:
Style Loss : 0.433106 Content Loss: 0.009450

run [900]:
Style Loss : 0.423975 Content Loss: 0.009714

run [950]:
Style Loss : 0.415559 Content Loss: 0.009969

run [1000]:
Style Loss : 0.407817 Content Loss: 0.010214

run [1050]:
Style Loss : 0.400385 Content Loss: 0.010443

run [1100]:
Style Loss : 0.393222 Content Loss: 0.010656

run [1150]:
Style Loss : 0.386570 Content Loss: 0.010862

run [1200]:
Style Loss : 0.380328 Content Loss: 0.011035

run [1250]:
Style Loss : 0.374070 Content Loss: 0.011229

run [1300]:
Style Loss : 0.366077 Content Loss: 0.011394

run [1350]:
Style Loss : 0.359098 Content Loss: 0.011547

run [1400]:
Style Loss : 0.352707 Content Loss: 0.011693

run [1450]:
Style Loss : 0.347041 Content Loss: 0.011834

run [1500]:
Style Loss : 0.341777 Content Loss: 0.011985

run [1550]:
Style Loss : 0.336228 Content Loss: 0.012151

run [1600]:
Style Loss : 0.331297 Content Loss: 0.012289

run [1650]:
Style Loss : 0.326153 Content Loss: 0.012427

run [1700]:
Style Loss : 0.321118 Content Loss: 0.012558

run [1750]:
Style Loss : 0.316544 Content Loss: 0.012685

run [1800]:
Style Loss : 0.312256 Content Loss: 0.012814

run [1850]:
Style Loss : 0.308037 Content Loss: 0.012942

run [1900]:
Style Loss : 0.303987 Content Loss: 0.013067

run [1950]:
Style Loss : 0.300306 Content Loss: 0.013190

run [2000]:
Style Loss : 0.296628 Content Loss: 0.013323

run [2050]:
Style Loss : 0.293144 Content Loss: 0.013462

run [2100]:
Style Loss : 0.289806 Content Loss: 0.013594

run [2150]:
Style Loss : 0.286506 Content Loss: 0.013731

run [2200]:
Style Loss : 0.283510 Content Loss: 0.013863

run [2250]:
Style Loss : 0.280614 Content Loss: 0.014000

run [2300]:
Style Loss : 0.277853 Content Loss: 0.014149

run [2350]:
Style Loss : 0.275231 Content Loss: 0.014284

run [2400]:
Style Loss : 0.272548 Content Loss: 0.014428

run [2450]:
Style Loss : 0.269982 Content Loss: 0.014574

run [2500]:
Style Loss : 0.267442 Content Loss: 0.014711

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.571136 Content Loss: 0.002299

run [100]:
Style Loss : 0.968254 Content Loss: 0.003620

run [150]:
Style Loss : 0.735427 Content Loss: 0.005043

run [200]:
Style Loss : 0.600272 Content Loss: 0.006436

run [250]:
Style Loss : 0.511844 Content Loss: 0.007945

run [300]:
Style Loss : 0.449095 Content Loss: 0.009273

run [350]:
Style Loss : 0.404779 Content Loss: 0.010573

run [400]:
Style Loss : 0.370930 Content Loss: 0.011723

run [450]:
Style Loss : 0.346643 Content Loss: 0.012630

run [500]:
Style Loss : 0.327363 Content Loss: 0.013370

run [550]:
Style Loss : 0.311707 Content Loss: 0.013976

run [600]:
Style Loss : 0.299504 Content Loss: 0.014473

run [650]:
Style Loss : 0.290142 Content Loss: 0.014915

run [700]:
Style Loss : 0.282602 Content Loss: 0.015297

run [750]:
Style Loss : 0.276382 Content Loss: 0.015658

run [800]:
Style Loss : 0.270681 Content Loss: 0.015952

run [850]:
Style Loss : 0.265304 Content Loss: 0.016237

run [900]:
Style Loss : 0.260911 Content Loss: 0.016477

run [950]:
Style Loss : 0.257127 Content Loss: 0.016724

run [1000]:
Style Loss : 0.253536 Content Loss: 0.017002

run [1050]:
Style Loss : 0.250300 Content Loss: 0.017238

run [1100]:
Style Loss : 0.247271 Content Loss: 0.017509

run [1150]:
Style Loss : 0.244322 Content Loss: 0.017744

run [1200]:
Style Loss : 0.241611 Content Loss: 0.017963

run [1250]:
Style Loss : 0.239088 Content Loss: 0.018193

run [1300]:
Style Loss : 0.236777 Content Loss: 0.018373

run [1350]:
Style Loss : 0.234589 Content Loss: 0.018590

run [1400]:
Style Loss : 0.232507 Content Loss: 0.018787

run [1450]:
Style Loss : 0.230487 Content Loss: 0.018969

run [1500]:
Style Loss : 0.228604 Content Loss: 0.019145

run [1550]:
Style Loss : 0.226875 Content Loss: 0.019306

run [1600]:
Style Loss : 0.225170 Content Loss: 0.019479

run [1650]:
Style Loss : 0.223648 Content Loss: 0.019618

run [1700]:
Style Loss : 0.222066 Content Loss: 0.019778

run [1750]:
Style Loss : 0.220620 Content Loss: 0.019923

run [1800]:
Style Loss : 0.219206 Content Loss: 0.020074

run [1850]:
Style Loss : 0.217930 Content Loss: 0.020211

run [1900]:
Style Loss : 0.216724 Content Loss: 0.020337

run [1950]:
Style Loss : 0.215562 Content Loss: 0.020477

run [2000]:
Style Loss : 0.214451 Content Loss: 0.020599

run [2050]:
Style Loss : 0.213458 Content Loss: 0.020705

run [2100]:
Style Loss : 0.212515 Content Loss: 0.020822

run [2150]:
Style Loss : 0.211656 Content Loss: 0.020926

run [2200]:
Style Loss : 0.210727 Content Loss: 0.021039

run [2250]:
Style Loss : 0.209792 Content Loss: 0.021152

run [2300]:
Style Loss : 0.208888 Content Loss: 0.021262

run [2350]:
Style Loss : 0.207900 Content Loss: 0.021365

run [2400]:
Style Loss : 0.206824 Content Loss: 0.021472

run [2450]:
Style Loss : 0.205834 Content Loss: 0.021571

run [2500]:
Style Loss : 0.204895 Content Loss: 0.021664

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.058627 Content Loss: 0.003598

run [100]:
Style Loss : 0.554523 Content Loss: 0.004917

run [150]:
Style Loss : 0.406051 Content Loss: 0.005981

run [200]:
Style Loss : 0.334092 Content Loss: 0.006855

run [250]:
Style Loss : 0.291179 Content Loss: 0.007632

run [300]:
Style Loss : 0.262319 Content Loss: 0.008267

run [350]:
Style Loss : 0.241269 Content Loss: 0.008801

run [400]:
Style Loss : 0.226850 Content Loss: 0.009291

run [450]:
Style Loss : 0.215656 Content Loss: 0.009662

run [500]:
Style Loss : 0.206992 Content Loss: 0.009973

run [550]:
Style Loss : 0.199412 Content Loss: 0.010248

run [600]:
Style Loss : 0.192819 Content Loss: 0.010469

run [650]:
Style Loss : 0.187022 Content Loss: 0.010701

run [700]:
Style Loss : 0.181703 Content Loss: 0.010887

run [750]:
Style Loss : 0.176984 Content Loss: 0.011031

run [800]:
Style Loss : 0.173048 Content Loss: 0.011165

run [850]:
Style Loss : 0.169738 Content Loss: 0.011284

run [900]:
Style Loss : 0.166754 Content Loss: 0.011397

run [950]:
Style Loss : 0.163929 Content Loss: 0.011504

run [1000]:
Style Loss : 0.161296 Content Loss: 0.011597

run [1050]:
Style Loss : 0.159195 Content Loss: 0.011677

run [1100]:
Style Loss : 0.157298 Content Loss: 0.011746

run [1150]:
Style Loss : 0.155369 Content Loss: 0.011830

run [1200]:
Style Loss : 0.153570 Content Loss: 0.011902

run [1250]:
Style Loss : 0.151967 Content Loss: 0.011956

run [1300]:
Style Loss : 0.150493 Content Loss: 0.012016

run [1350]:
Style Loss : 0.149105 Content Loss: 0.012073

run [1400]:
Style Loss : 0.147832 Content Loss: 0.012134

run [1450]:
Style Loss : 0.146651 Content Loss: 0.012184

run [1500]:
Style Loss : 0.145616 Content Loss: 0.012228

run [1550]:
Style Loss : 0.144672 Content Loss: 0.012274

run [1600]:
Style Loss : 0.143740 Content Loss: 0.012307

run [1650]:
Style Loss : 0.142927 Content Loss: 0.012345

run [1700]:
Style Loss : 0.142164 Content Loss: 0.012381

run [1750]:
Style Loss : 0.141461 Content Loss: 0.012414

run [1800]:
Style Loss : 0.140814 Content Loss: 0.012447

run [1850]:
Style Loss : 0.140198 Content Loss: 0.012474

run [1900]:
Style Loss : 0.139675 Content Loss: 0.012504

run [1950]:
Style Loss : 0.139166 Content Loss: 0.012535

run [2000]:
Style Loss : 0.138719 Content Loss: 0.012563

run [2050]:
Style Loss : 0.138309 Content Loss: 0.012590

run [2100]:
Style Loss : 0.137927 Content Loss: 0.012615

run [2150]:
Style Loss : 0.137564 Content Loss: 0.012637

run [2200]:
Style Loss : 0.137183 Content Loss: 0.012660

run [2250]:
Style Loss : 0.136796 Content Loss: 0.012681

run [2300]:
Style Loss : 0.136443 Content Loss: 0.012703

run [2350]:
Style Loss : 0.136079 Content Loss: 0.012721

run [2400]:
Style Loss : 0.135723 Content Loss: 0.012745

run [2450]:
Style Loss : 0.135352 Content Loss: 0.012771

run [2500]:
Style Loss : 0.134985 Content Loss: 0.012794

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.462463 Content Loss: 0.002859

run [100]:
Style Loss : 1.491241 Content Loss: 0.003524

run [150]:
Style Loss : 1.150841 Content Loss: 0.004213

run [200]:
Style Loss : 0.971477 Content Loss: 0.004877

run [250]:
Style Loss : 0.853201 Content Loss: 0.005593

run [300]:
Style Loss : 0.765925 Content Loss: 0.006152

run [350]:
Style Loss : 0.702119 Content Loss: 0.006702

run [400]:
Style Loss : 0.651002 Content Loss: 0.007232

run [450]:
Style Loss : 0.611687 Content Loss: 0.007689

run [500]:
Style Loss : 0.580449 Content Loss: 0.008195

run [550]:
Style Loss : 0.553062 Content Loss: 0.008632

run [600]:
Style Loss : 0.530869 Content Loss: 0.009042

run [650]:
Style Loss : 0.510521 Content Loss: 0.009449

run [700]:
Style Loss : 0.492975 Content Loss: 0.009805

run [750]:
Style Loss : 0.477944 Content Loss: 0.010103

run [800]:
Style Loss : 0.464859 Content Loss: 0.010392

run [850]:
Style Loss : 0.453850 Content Loss: 0.010658

run [900]:
Style Loss : 0.443778 Content Loss: 0.010902

run [950]:
Style Loss : 0.435195 Content Loss: 0.011129

run [1000]:
Style Loss : 0.427787 Content Loss: 0.011330

run [1050]:
Style Loss : 0.420993 Content Loss: 0.011537

run [1100]:
Style Loss : 0.415363 Content Loss: 0.011709

run [1150]:
Style Loss : 0.410385 Content Loss: 0.011864

run [1200]:
Style Loss : 0.406026 Content Loss: 0.012014

run [1250]:
Style Loss : 0.401944 Content Loss: 0.012164

run [1300]:
Style Loss : 0.398320 Content Loss: 0.012279

run [1350]:
Style Loss : 0.394814 Content Loss: 0.012402

run [1400]:
Style Loss : 0.391366 Content Loss: 0.012514

run [1450]:
Style Loss : 0.388304 Content Loss: 0.012607

run [1500]:
Style Loss : 0.385597 Content Loss: 0.012689

run [1550]:
Style Loss : 0.383177 Content Loss: 0.012759

run [1600]:
Style Loss : 0.381008 Content Loss: 0.012827

run [1650]:
Style Loss : 0.378841 Content Loss: 0.012903

run [1700]:
Style Loss : 0.376799 Content Loss: 0.012979

run [1750]:
Style Loss : 0.374780 Content Loss: 0.013051

run [1800]:
Style Loss : 0.372877 Content Loss: 0.013117

run [1850]:
Style Loss : 0.370962 Content Loss: 0.013192

run [1900]:
Style Loss : 0.368915 Content Loss: 0.013266

run [1950]:
Style Loss : 0.366504 Content Loss: 0.013328

run [2000]:
Style Loss : 0.364580 Content Loss: 0.013376

run [2050]:
Style Loss : 0.362850 Content Loss: 0.013425

run [2100]:
Style Loss : 0.361381 Content Loss: 0.013461

run [2150]:
Style Loss : 0.359977 Content Loss: 0.013503

run [2200]:
Style Loss : 0.358710 Content Loss: 0.013544

run [2250]:
Style Loss : 0.357447 Content Loss: 0.013584

run [2300]:
Style Loss : 0.356195 Content Loss: 0.013625

run [2350]:
Style Loss : 0.354887 Content Loss: 0.013673

run [2400]:
Style Loss : 0.353650 Content Loss: 0.013717

run [2450]:
Style Loss : 0.352528 Content Loss: 0.013755

run [2500]:
Style Loss : 0.351450 Content Loss: 0.013791

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.560475 Content Loss: 0.007829

run [100]:
Style Loss : 0.276777 Content Loss: 0.010235

run [150]:
Style Loss : 0.175938 Content Loss: 0.012127

run [200]:
Style Loss : 0.137954 Content Loss: 0.013139

run [250]:
Style Loss : 0.119967 Content Loss: 0.013513

run [300]:
Style Loss : 0.107992 Content Loss: 0.013736

run [350]:
Style Loss : 0.099655 Content Loss: 0.013943

run [400]:
Style Loss : 0.093804 Content Loss: 0.014091

run [450]:
Style Loss : 0.089219 Content Loss: 0.014178

run [500]:
Style Loss : 0.085599 Content Loss: 0.014272

run [550]:
Style Loss : 0.082850 Content Loss: 0.014290

run [600]:
Style Loss : 0.080506 Content Loss: 0.014319

run [650]:
Style Loss : 0.078333 Content Loss: 0.014356

run [700]:
Style Loss : 0.076351 Content Loss: 0.014388

run [750]:
Style Loss : 0.074754 Content Loss: 0.014397

run [800]:
Style Loss : 0.073339 Content Loss: 0.014407

run [850]:
Style Loss : 0.072077 Content Loss: 0.014429

run [900]:
Style Loss : 0.070974 Content Loss: 0.014442

run [950]:
Style Loss : 0.070084 Content Loss: 0.014446

run [1000]:
Style Loss : 0.069288 Content Loss: 0.014437

run [1050]:
Style Loss : 0.068639 Content Loss: 0.014434

run [1100]:
Style Loss : 0.067992 Content Loss: 0.014425

run [1150]:
Style Loss : 0.067465 Content Loss: 0.014410

run [1200]:
Style Loss : 0.066980 Content Loss: 0.014394

run [1250]:
Style Loss : 0.066503 Content Loss: 0.014387

run [1300]:
Style Loss : 0.066041 Content Loss: 0.014384

run [1350]:
Style Loss : 0.065590 Content Loss: 0.014381

run [1400]:
Style Loss : 0.065127 Content Loss: 0.014374

run [1450]:
Style Loss : 0.064627 Content Loss: 0.014373

run [1500]:
Style Loss : 0.064174 Content Loss: 0.014377

run [1550]:
Style Loss : 0.063738 Content Loss: 0.014378

run [1600]:
Style Loss : 0.063298 Content Loss: 0.014387

run [1650]:
Style Loss : 0.062882 Content Loss: 0.014385

run [1700]:
Style Loss : 0.062503 Content Loss: 0.014385

run [1750]:
Style Loss : 0.062139 Content Loss: 0.014393

run [1800]:
Style Loss : 0.061806 Content Loss: 0.014400

run [1850]:
Style Loss : 0.061482 Content Loss: 0.014405

run [1900]:
Style Loss : 0.061174 Content Loss: 0.014408

run [1950]:
Style Loss : 0.060890 Content Loss: 0.014412

run [2000]:
Style Loss : 0.060640 Content Loss: 0.014408

run [2050]:
Style Loss : 0.060387 Content Loss: 0.014408

run [2100]:
Style Loss : 0.060170 Content Loss: 0.014406

run [2150]:
Style Loss : 0.059955 Content Loss: 0.014410

run [2200]:
Style Loss : 0.059753 Content Loss: 0.014413

run [2250]:
Style Loss : 0.059534 Content Loss: 0.014412

run [2300]:
Style Loss : 0.059323 Content Loss: 0.014413

run [2350]:
Style Loss : 0.059127 Content Loss: 0.014412

run [2400]:
Style Loss : 0.058937 Content Loss: 0.014418

run [2450]:
Style Loss : 0.058770 Content Loss: 0.014422

run [2500]:
Style Loss : 0.058595 Content Loss: 0.014426

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.973490 Content Loss: 0.002892

run [100]:
Style Loss : 0.497537 Content Loss: 0.003523

run [150]:
Style Loss : 0.359489 Content Loss: 0.004322

run [200]:
Style Loss : 0.292649 Content Loss: 0.005092

run [250]:
Style Loss : 0.249879 Content Loss: 0.005749

run [300]:
Style Loss : 0.220959 Content Loss: 0.006343

run [350]:
Style Loss : 0.199634 Content Loss: 0.006843

run [400]:
Style Loss : 0.183530 Content Loss: 0.007260

run [450]:
Style Loss : 0.171674 Content Loss: 0.007627

run [500]:
Style Loss : 0.161701 Content Loss: 0.007868

run [550]:
Style Loss : 0.153948 Content Loss: 0.008081

run [600]:
Style Loss : 0.147571 Content Loss: 0.008258

run [650]:
Style Loss : 0.142124 Content Loss: 0.008414

run [700]:
Style Loss : 0.137669 Content Loss: 0.008558

run [750]:
Style Loss : 0.134022 Content Loss: 0.008677

run [800]:
Style Loss : 0.130920 Content Loss: 0.008800

run [850]:
Style Loss : 0.128263 Content Loss: 0.008885

run [900]:
Style Loss : 0.126077 Content Loss: 0.008973

run [950]:
Style Loss : 0.124198 Content Loss: 0.009043

run [1000]:
Style Loss : 0.122550 Content Loss: 0.009120

run [1050]:
Style Loss : 0.121075 Content Loss: 0.009186

run [1100]:
Style Loss : 0.119645 Content Loss: 0.009263

run [1150]:
Style Loss : 0.118430 Content Loss: 0.009325

run [1200]:
Style Loss : 0.117332 Content Loss: 0.009392

run [1250]:
Style Loss : 0.116354 Content Loss: 0.009447

run [1300]:
Style Loss : 0.115463 Content Loss: 0.009501

run [1350]:
Style Loss : 0.114671 Content Loss: 0.009549

run [1400]:
Style Loss : 0.113855 Content Loss: 0.009614

run [1450]:
Style Loss : 0.113122 Content Loss: 0.009668

run [1500]:
Style Loss : 0.112370 Content Loss: 0.009721

run [1550]:
Style Loss : 0.111617 Content Loss: 0.009772

run [1600]:
Style Loss : 0.110929 Content Loss: 0.009826

run [1650]:
Style Loss : 0.110253 Content Loss: 0.009880

run [1700]:
Style Loss : 0.109626 Content Loss: 0.009926

run [1750]:
Style Loss : 0.109033 Content Loss: 0.009978

run [1800]:
Style Loss : 0.108484 Content Loss: 0.010024

run [1850]:
Style Loss : 0.107959 Content Loss: 0.010061

run [1900]:
Style Loss : 0.107459 Content Loss: 0.010100

run [1950]:
Style Loss : 0.106992 Content Loss: 0.010137

run [2000]:
Style Loss : 0.106582 Content Loss: 0.010171

run [2050]:
Style Loss : 0.106195 Content Loss: 0.010202

run [2100]:
Style Loss : 0.105823 Content Loss: 0.010229

run [2150]:
Style Loss : 0.105450 Content Loss: 0.010260

run [2200]:
Style Loss : 0.105087 Content Loss: 0.010291

run [2250]:
Style Loss : 0.104738 Content Loss: 0.010316

run [2300]:
Style Loss : 0.104398 Content Loss: 0.010349

run [2350]:
Style Loss : 0.104054 Content Loss: 0.010380

run [2400]:
Style Loss : 0.103721 Content Loss: 0.010411

run [2450]:
Style Loss : 0.103428 Content Loss: 0.010445

run [2500]:
Style Loss : 0.103114 Content Loss: 0.010477

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.315359 Content Loss: 0.003335

run [100]:
Style Loss : 1.890417 Content Loss: 0.004305

run [150]:
Style Loss : 1.417989 Content Loss: 0.004784

run [200]:
Style Loss : 1.188368 Content Loss: 0.005784

run [250]:
Style Loss : 1.018933 Content Loss: 0.007023

run [300]:
Style Loss : 0.900473 Content Loss: 0.008386

run [350]:
Style Loss : 0.812245 Content Loss: 0.009919

run [400]:
Style Loss : 0.734904 Content Loss: 0.011259

run [450]:
Style Loss : 0.678524 Content Loss: 0.012191

run [500]:
Style Loss : 0.635546 Content Loss: 0.013094

run [550]:
Style Loss : 0.602003 Content Loss: 0.013889

run [600]:
Style Loss : 0.572316 Content Loss: 0.014670

run [650]:
Style Loss : 0.546637 Content Loss: 0.015300

run [700]:
Style Loss : 0.524214 Content Loss: 0.015873

run [750]:
Style Loss : 0.506808 Content Loss: 0.016366

run [800]:
Style Loss : 0.491906 Content Loss: 0.016824

run [850]:
Style Loss : 0.478761 Content Loss: 0.017251

run [900]:
Style Loss : 0.465475 Content Loss: 0.017706

run [950]:
Style Loss : 0.453767 Content Loss: 0.018115

run [1000]:
Style Loss : 0.443011 Content Loss: 0.018449

run [1050]:
Style Loss : 0.432928 Content Loss: 0.018772

run [1100]:
Style Loss : 0.423784 Content Loss: 0.019077

run [1150]:
Style Loss : 0.415783 Content Loss: 0.019339

run [1200]:
Style Loss : 0.408904 Content Loss: 0.019551

run [1250]:
Style Loss : 0.402456 Content Loss: 0.019775

run [1300]:
Style Loss : 0.396545 Content Loss: 0.019982

run [1350]:
Style Loss : 0.391405 Content Loss: 0.020136

run [1400]:
Style Loss : 0.386589 Content Loss: 0.020296

run [1450]:
Style Loss : 0.381433 Content Loss: 0.020470

run [1500]:
Style Loss : 0.376043 Content Loss: 0.020610

run [1550]:
Style Loss : 0.370868 Content Loss: 0.020749

run [1600]:
Style Loss : 0.365965 Content Loss: 0.020883

run [1650]:
Style Loss : 0.360257 Content Loss: 0.021034

run [1700]:
Style Loss : 0.355624 Content Loss: 0.021133

run [1750]:
Style Loss : 0.351926 Content Loss: 0.021238

run [1800]:
Style Loss : 0.348261 Content Loss: 0.021339

run [1850]:
Style Loss : 0.345254 Content Loss: 0.021412

run [1900]:
Style Loss : 0.342544 Content Loss: 0.021496

run [1950]:
Style Loss : 0.339969 Content Loss: 0.021578

run [2000]:
Style Loss : 0.337423 Content Loss: 0.021645

run [2050]:
Style Loss : 0.334901 Content Loss: 0.021711

run [2100]:
Style Loss : 0.332411 Content Loss: 0.021792

run [2150]:
Style Loss : 0.329960 Content Loss: 0.021845

run [2200]:
Style Loss : 0.327793 Content Loss: 0.021897

run [2250]:
Style Loss : 0.325917 Content Loss: 0.021946

run [2300]:
Style Loss : 0.324407 Content Loss: 0.021991

run [2350]:
Style Loss : 0.322858 Content Loss: 0.022044

run [2400]:
Style Loss : 0.321464 Content Loss: 0.022095

run [2450]:
Style Loss : 0.320108 Content Loss: 0.022141

run [2500]:
Style Loss : 0.318800 Content Loss: 0.022190

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.743118 Content Loss: 0.009348

run [100]:
Style Loss : 0.340291 Content Loss: 0.013109

run [150]:
Style Loss : 0.204367 Content Loss: 0.016894

run [200]:
Style Loss : 0.148805 Content Loss: 0.019208

run [250]:
Style Loss : 0.122502 Content Loss: 0.020363

run [300]:
Style Loss : 0.106288 Content Loss: 0.020982

run [350]:
Style Loss : 0.094373 Content Loss: 0.021380

run [400]:
Style Loss : 0.085070 Content Loss: 0.021755

run [450]:
Style Loss : 0.076736 Content Loss: 0.021932

run [500]:
Style Loss : 0.070891 Content Loss: 0.022069

run [550]:
Style Loss : 0.066418 Content Loss: 0.022146

run [600]:
Style Loss : 0.062764 Content Loss: 0.022197

run [650]:
Style Loss : 0.059576 Content Loss: 0.022200

run [700]:
Style Loss : 0.057053 Content Loss: 0.022198

run [750]:
Style Loss : 0.054717 Content Loss: 0.022190

run [800]:
Style Loss : 0.052786 Content Loss: 0.022190

run [850]:
Style Loss : 0.051112 Content Loss: 0.022175

run [900]:
Style Loss : 0.049656 Content Loss: 0.022124

run [950]:
Style Loss : 0.048458 Content Loss: 0.022049

run [1000]:
Style Loss : 0.047342 Content Loss: 0.021994

run [1050]:
Style Loss : 0.046319 Content Loss: 0.021922

run [1100]:
Style Loss : 0.045389 Content Loss: 0.021857

run [1150]:
Style Loss : 0.044511 Content Loss: 0.021786

run [1200]:
Style Loss : 0.043712 Content Loss: 0.021732

run [1250]:
Style Loss : 0.043010 Content Loss: 0.021673

run [1300]:
Style Loss : 0.042419 Content Loss: 0.021603

run [1350]:
Style Loss : 0.041815 Content Loss: 0.021553

run [1400]:
Style Loss : 0.041284 Content Loss: 0.021494

run [1450]:
Style Loss : 0.040782 Content Loss: 0.021444

run [1500]:
Style Loss : 0.040313 Content Loss: 0.021398

run [1550]:
Style Loss : 0.039886 Content Loss: 0.021346

run [1600]:
Style Loss : 0.039436 Content Loss: 0.021309

run [1650]:
Style Loss : 0.039049 Content Loss: 0.021277

run [1700]:
Style Loss : 0.038689 Content Loss: 0.021249

run [1750]:
Style Loss : 0.038373 Content Loss: 0.021212

run [1800]:
Style Loss : 0.038080 Content Loss: 0.021189

run [1850]:
Style Loss : 0.037797 Content Loss: 0.021158

run [1900]:
Style Loss : 0.037542 Content Loss: 0.021132

run [1950]:
Style Loss : 0.037273 Content Loss: 0.021103

run [2000]:
Style Loss : 0.037047 Content Loss: 0.021084

run [2050]:
Style Loss : 0.036822 Content Loss: 0.021059

run [2100]:
Style Loss : 0.036595 Content Loss: 0.021043

run [2150]:
Style Loss : 0.036406 Content Loss: 0.021033

run [2200]:
Style Loss : 0.036186 Content Loss: 0.021023

run [2250]:
Style Loss : 0.036010 Content Loss: 0.021018

run [2300]:
Style Loss : 0.035817 Content Loss: 0.021000

run [2350]:
Style Loss : 0.035640 Content Loss: 0.020986

run [2400]:
Style Loss : 0.035448 Content Loss: 0.020964

run [2450]:
Style Loss : 0.035251 Content Loss: 0.020958

run [2500]:
Style Loss : 0.035079 Content Loss: 0.020953

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.362951 Content Loss: 0.003646

run [100]:
Style Loss : 0.661287 Content Loss: 0.004490

run [150]:
Style Loss : 0.447069 Content Loss: 0.006346

run [200]:
Style Loss : 0.342452 Content Loss: 0.008387

run [250]:
Style Loss : 0.286771 Content Loss: 0.010242

run [300]:
Style Loss : 0.252787 Content Loss: 0.011535

run [350]:
Style Loss : 0.230945 Content Loss: 0.012506

run [400]:
Style Loss : 0.215736 Content Loss: 0.013202

run [450]:
Style Loss : 0.204169 Content Loss: 0.013843

run [500]:
Style Loss : 0.195824 Content Loss: 0.014261

run [550]:
Style Loss : 0.188909 Content Loss: 0.014678

run [600]:
Style Loss : 0.182433 Content Loss: 0.014980

run [650]:
Style Loss : 0.176455 Content Loss: 0.015251

run [700]:
Style Loss : 0.171610 Content Loss: 0.015449

run [750]:
Style Loss : 0.167707 Content Loss: 0.015625

run [800]:
Style Loss : 0.164390 Content Loss: 0.015770

run [850]:
Style Loss : 0.161334 Content Loss: 0.015892

run [900]:
Style Loss : 0.158577 Content Loss: 0.015995

run [950]:
Style Loss : 0.156312 Content Loss: 0.016077

run [1000]:
Style Loss : 0.154246 Content Loss: 0.016164

run [1050]:
Style Loss : 0.152381 Content Loss: 0.016225

run [1100]:
Style Loss : 0.150606 Content Loss: 0.016294

run [1150]:
Style Loss : 0.148807 Content Loss: 0.016352

run [1200]:
Style Loss : 0.147327 Content Loss: 0.016393

run [1250]:
Style Loss : 0.146073 Content Loss: 0.016433

run [1300]:
Style Loss : 0.144756 Content Loss: 0.016470

run [1350]:
Style Loss : 0.143502 Content Loss: 0.016513

run [1400]:
Style Loss : 0.142449 Content Loss: 0.016545

run [1450]:
Style Loss : 0.141452 Content Loss: 0.016577

run [1500]:
Style Loss : 0.140465 Content Loss: 0.016603

run [1550]:
Style Loss : 0.139492 Content Loss: 0.016627

run [1600]:
Style Loss : 0.138678 Content Loss: 0.016650

run [1650]:
Style Loss : 0.137919 Content Loss: 0.016666

run [1700]:
Style Loss : 0.137225 Content Loss: 0.016683

run [1750]:
Style Loss : 0.136621 Content Loss: 0.016695

run [1800]:
Style Loss : 0.136071 Content Loss: 0.016707

run [1850]:
Style Loss : 0.135543 Content Loss: 0.016721

run [1900]:
Style Loss : 0.135043 Content Loss: 0.016731

run [1950]:
Style Loss : 0.134558 Content Loss: 0.016744

run [2000]:
Style Loss : 0.134091 Content Loss: 0.016757

run [2050]:
Style Loss : 0.133634 Content Loss: 0.016763

run [2100]:
Style Loss : 0.133202 Content Loss: 0.016774

run [2150]:
Style Loss : 0.132726 Content Loss: 0.016787

run [2200]:
Style Loss : 0.132245 Content Loss: 0.016794

run [2250]:
Style Loss : 0.131715 Content Loss: 0.016802

run [2300]:
Style Loss : 0.131270 Content Loss: 0.016811

run [2350]:
Style Loss : 0.130850 Content Loss: 0.016817

run [2400]:
Style Loss : 0.130459 Content Loss: 0.016822

run [2450]:
Style Loss : 0.130124 Content Loss: 0.016829

run [2500]:
Style Loss : 0.129805 Content Loss: 0.016832

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.368317 Content Loss: 0.008286

run [100]:
Style Loss : 1.765790 Content Loss: 0.008708

run [150]:
Style Loss : 1.225935 Content Loss: 0.010392

run [200]:
Style Loss : 0.943479 Content Loss: 0.012119

run [250]:
Style Loss : 0.796765 Content Loss: 0.013806

run [300]:
Style Loss : 0.708133 Content Loss: 0.015484

run [350]:
Style Loss : 0.648936 Content Loss: 0.016853

run [400]:
Style Loss : 0.607347 Content Loss: 0.017949

run [450]:
Style Loss : 0.574660 Content Loss: 0.018713

run [500]:
Style Loss : 0.546045 Content Loss: 0.019492

run [550]:
Style Loss : 0.524172 Content Loss: 0.020084

run [600]:
Style Loss : 0.507675 Content Loss: 0.020685

run [650]:
Style Loss : 0.493844 Content Loss: 0.021195

run [700]:
Style Loss : 0.481602 Content Loss: 0.021667

run [750]:
Style Loss : 0.469091 Content Loss: 0.022137

run [800]:
Style Loss : 0.457682 Content Loss: 0.022548

run [850]:
Style Loss : 0.447447 Content Loss: 0.022821

run [900]:
Style Loss : 0.439727 Content Loss: 0.023107

run [950]:
Style Loss : 0.433136 Content Loss: 0.023345

run [1000]:
Style Loss : 0.426922 Content Loss: 0.023583

run [1050]:
Style Loss : 0.421415 Content Loss: 0.023768

run [1100]:
Style Loss : 0.416611 Content Loss: 0.023925

run [1150]:
Style Loss : 0.412045 Content Loss: 0.024097

run [1200]:
Style Loss : 0.408005 Content Loss: 0.024243

run [1250]:
Style Loss : 0.404596 Content Loss: 0.024388

run [1300]:
Style Loss : 0.401460 Content Loss: 0.024502

run [1350]:
Style Loss : 0.398487 Content Loss: 0.024627

run [1400]:
Style Loss : 0.396048 Content Loss: 0.024730

run [1450]:
Style Loss : 0.393533 Content Loss: 0.024792

run [1500]:
Style Loss : 0.391283 Content Loss: 0.024894

run [1550]:
Style Loss : 0.389117 Content Loss: 0.024985

run [1600]:
Style Loss : 0.387357 Content Loss: 0.025059

run [1650]:
Style Loss : 0.385569 Content Loss: 0.025120

run [1700]:
Style Loss : 0.383849 Content Loss: 0.025176

run [1750]:
Style Loss : 0.382236 Content Loss: 0.025234

run [1800]:
Style Loss : 0.380777 Content Loss: 0.025282

run [1850]:
Style Loss : 0.379163 Content Loss: 0.025343

run [1900]:
Style Loss : 0.377598 Content Loss: 0.025400

run [1950]:
Style Loss : 0.376171 Content Loss: 0.025435

run [2000]:
Style Loss : 0.374804 Content Loss: 0.025488

run [2050]:
Style Loss : 0.373558 Content Loss: 0.025522

run [2100]:
Style Loss : 0.372340 Content Loss: 0.025564

run [2150]:
Style Loss : 0.371084 Content Loss: 0.025621

run [2200]:
Style Loss : 0.369876 Content Loss: 0.025653

run [2250]:
Style Loss : 0.368545 Content Loss: 0.025696

run [2300]:
Style Loss : 0.367290 Content Loss: 0.025737

run [2350]:
Style Loss : 0.365740 Content Loss: 0.025795

run [2400]:
Style Loss : 0.364318 Content Loss: 0.025833

run [2450]:
Style Loss : 0.362900 Content Loss: 0.025885

run [2500]:
Style Loss : 0.361520 Content Loss: 0.025934

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 5.124803 Content Loss: 0.004532

run [100]:
Style Loss : 2.966155 Content Loss: 0.004744

run [150]:
Style Loss : 2.209581 Content Loss: 0.005442

run [200]:
Style Loss : 1.801945 Content Loss: 0.006180

run [250]:
Style Loss : 1.541715 Content Loss: 0.007140

run [300]:
Style Loss : 1.360047 Content Loss: 0.008136

run [350]:
Style Loss : 1.229268 Content Loss: 0.009375

run [400]:
Style Loss : 1.126624 Content Loss: 0.010570

run [450]:
Style Loss : 1.040637 Content Loss: 0.011852

run [500]:
Style Loss : 0.968323 Content Loss: 0.013100

run [550]:
Style Loss : 0.905776 Content Loss: 0.014240

run [600]:
Style Loss : 0.854668 Content Loss: 0.015380

run [650]:
Style Loss : 0.808670 Content Loss: 0.016393

run [700]:
Style Loss : 0.769680 Content Loss: 0.017248

run [750]:
Style Loss : 0.736296 Content Loss: 0.017993

run [800]:
Style Loss : 0.707558 Content Loss: 0.018661

run [850]:
Style Loss : 0.683022 Content Loss: 0.019221

run [900]:
Style Loss : 0.662049 Content Loss: 0.019803

run [950]:
Style Loss : 0.643965 Content Loss: 0.020299

run [1000]:
Style Loss : 0.627520 Content Loss: 0.020767

run [1050]:
Style Loss : 0.612166 Content Loss: 0.021161

run [1100]:
Style Loss : 0.598397 Content Loss: 0.021553

run [1150]:
Style Loss : 0.586345 Content Loss: 0.021883

run [1200]:
Style Loss : 0.577171 Content Loss: 0.022164

run [1250]:
Style Loss : 0.569284 Content Loss: 0.022414

run [1300]:
Style Loss : 0.561508 Content Loss: 0.022669

run [1350]:
Style Loss : 0.554900 Content Loss: 0.022912

run [1400]:
Style Loss : 0.548891 Content Loss: 0.023148

run [1450]:
Style Loss : 0.543009 Content Loss: 0.023379

run [1500]:
Style Loss : 0.537576 Content Loss: 0.023569

run [1550]:
Style Loss : 0.532784 Content Loss: 0.023758

run [1600]:
Style Loss : 0.528421 Content Loss: 0.023951

run [1650]:
Style Loss : 0.524103 Content Loss: 0.024108

run [1700]:
Style Loss : 0.520307 Content Loss: 0.024250

run [1750]:
Style Loss : 0.516756 Content Loss: 0.024385

run [1800]:
Style Loss : 0.513617 Content Loss: 0.024486

run [1850]:
Style Loss : 0.510854 Content Loss: 0.024614

run [1900]:
Style Loss : 0.508308 Content Loss: 0.024724

run [1950]:
Style Loss : 0.506036 Content Loss: 0.024825

run [2000]:
Style Loss : 0.503864 Content Loss: 0.024919

run [2050]:
Style Loss : 0.501751 Content Loss: 0.025022

run [2100]:
Style Loss : 0.499855 Content Loss: 0.025092

run [2150]:
Style Loss : 0.497933 Content Loss: 0.025167

run [2200]:
Style Loss : 0.496186 Content Loss: 0.025227

run [2250]:
Style Loss : 0.494522 Content Loss: 0.025295

run [2300]:
Style Loss : 0.492882 Content Loss: 0.025365

run [2350]:
Style Loss : 0.491182 Content Loss: 0.025438

run [2400]:
Style Loss : 0.489546 Content Loss: 0.025506

run [2450]:
Style Loss : 0.487786 Content Loss: 0.025579

run [2500]:
Style Loss : 0.486148 Content Loss: 0.025638

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.515051 Content Loss: 0.004275

run [100]:
Style Loss : 0.838699 Content Loss: 0.009087

run [150]:
Style Loss : 0.573334 Content Loss: 0.014474

run [200]:
Style Loss : 0.440093 Content Loss: 0.018707

run [250]:
Style Loss : 0.362949 Content Loss: 0.021834

run [300]:
Style Loss : 0.313911 Content Loss: 0.023703

run [350]:
Style Loss : 0.279301 Content Loss: 0.025206

run [400]:
Style Loss : 0.253265 Content Loss: 0.026349

run [450]:
Style Loss : 0.230686 Content Loss: 0.027574

run [500]:
Style Loss : 0.211682 Content Loss: 0.028697

run [550]:
Style Loss : 0.194901 Content Loss: 0.029929

run [600]:
Style Loss : 0.179484 Content Loss: 0.031082

run [650]:
Style Loss : 0.166007 Content Loss: 0.032210

run [700]:
Style Loss : 0.153596 Content Loss: 0.033325

run [750]:
Style Loss : 0.142133 Content Loss: 0.034406

run [800]:
Style Loss : 0.131772 Content Loss: 0.035578

run [850]:
Style Loss : 0.122858 Content Loss: 0.036677

run [900]:
Style Loss : 0.115068 Content Loss: 0.037685

run [950]:
Style Loss : 0.108344 Content Loss: 0.038700

run [1000]:
Style Loss : 0.102562 Content Loss: 0.039582

run [1050]:
Style Loss : 0.097725 Content Loss: 0.040250

run [1100]:
Style Loss : 0.093787 Content Loss: 0.040627

run [1150]:
Style Loss : 0.090607 Content Loss: 0.040872

run [1200]:
Style Loss : 0.088091 Content Loss: 0.040866

run [1250]:
Style Loss : 0.085997 Content Loss: 0.040812

run [1300]:
Style Loss : 0.084134 Content Loss: 0.040668

run [1350]:
Style Loss : 0.082607 Content Loss: 0.040389

run [1400]:
Style Loss : 0.081395 Content Loss: 0.040015

run [1450]:
Style Loss : 0.080206 Content Loss: 0.039674

run [1500]:
Style Loss : 0.079388 Content Loss: 0.039355

run [1550]:
Style Loss : 0.078285 Content Loss: 0.039079

run [1600]:
Style Loss : 0.077491 Content Loss: 0.038781

run [1650]:
Style Loss : 0.076785 Content Loss: 0.038516

run [1700]:
Style Loss : 0.076132 Content Loss: 0.038287

run [1750]:
Style Loss : 0.075454 Content Loss: 0.038061

run [1800]:
Style Loss : 0.074929 Content Loss: 0.037856

run [1850]:
Style Loss : 0.074452 Content Loss: 0.037637

run [1900]:
Style Loss : 0.074015 Content Loss: 0.037424

run [1950]:
Style Loss : 0.073870 Content Loss: 0.037224

run [2000]:
Style Loss : 0.073216 Content Loss: 0.037056

run [2050]:
Style Loss : 0.072874 Content Loss: 0.036877

run [2100]:
Style Loss : 0.072866 Content Loss: 0.036676

run [2150]:
Style Loss : 0.072323 Content Loss: 0.036533

run [2200]:
Style Loss : 0.072136 Content Loss: 0.036372

run [2250]:
Style Loss : 0.072007 Content Loss: 0.036209

run [2300]:
Style Loss : 0.071808 Content Loss: 0.036074

run [2350]:
Style Loss : 0.071603 Content Loss: 0.035935

run [2400]:
Style Loss : 0.071470 Content Loss: 0.035780

run [2450]:
Style Loss : 0.071399 Content Loss: 0.035670

run [2500]:
Style Loss : 0.071304 Content Loss: 0.035529

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.771248 Content Loss: 0.005714

run [100]:
Style Loss : 0.920812 Content Loss: 0.010369

run [150]:
Style Loss : 0.617842 Content Loss: 0.014086

run [200]:
Style Loss : 0.458593 Content Loss: 0.017793

run [250]:
Style Loss : 0.368806 Content Loss: 0.020417

run [300]:
Style Loss : 0.313720 Content Loss: 0.022474

run [350]:
Style Loss : 0.276826 Content Loss: 0.024010

run [400]:
Style Loss : 0.250354 Content Loss: 0.025204

run [450]:
Style Loss : 0.229190 Content Loss: 0.026187

run [500]:
Style Loss : 0.211412 Content Loss: 0.027123

run [550]:
Style Loss : 0.196501 Content Loss: 0.027865

run [600]:
Style Loss : 0.183629 Content Loss: 0.028422

run [650]:
Style Loss : 0.172901 Content Loss: 0.028994

run [700]:
Style Loss : 0.163628 Content Loss: 0.029490

run [750]:
Style Loss : 0.155038 Content Loss: 0.029970

run [800]:
Style Loss : 0.147359 Content Loss: 0.030344

run [850]:
Style Loss : 0.140508 Content Loss: 0.030734

run [900]:
Style Loss : 0.134302 Content Loss: 0.031052

run [950]:
Style Loss : 0.128383 Content Loss: 0.031319

run [1000]:
Style Loss : 0.122846 Content Loss: 0.031548

run [1050]:
Style Loss : 0.117949 Content Loss: 0.031766

run [1100]:
Style Loss : 0.113617 Content Loss: 0.031924

run [1150]:
Style Loss : 0.109703 Content Loss: 0.032087

run [1200]:
Style Loss : 0.106415 Content Loss: 0.032192

run [1250]:
Style Loss : 0.103228 Content Loss: 0.032269

run [1300]:
Style Loss : 0.100347 Content Loss: 0.032324

run [1350]:
Style Loss : 0.097804 Content Loss: 0.032358

run [1400]:
Style Loss : 0.095495 Content Loss: 0.032380

run [1450]:
Style Loss : 0.093520 Content Loss: 0.032368

run [1500]:
Style Loss : 0.091689 Content Loss: 0.032339

run [1550]:
Style Loss : 0.090077 Content Loss: 0.032296

run [1600]:
Style Loss : 0.088582 Content Loss: 0.032243

run [1650]:
Style Loss : 0.087231 Content Loss: 0.032185

run [1700]:
Style Loss : 0.085916 Content Loss: 0.032131

run [1750]:
Style Loss : 0.084831 Content Loss: 0.032067

run [1800]:
Style Loss : 0.083874 Content Loss: 0.031991

run [1850]:
Style Loss : 0.083026 Content Loss: 0.031922

run [1900]:
Style Loss : 0.082197 Content Loss: 0.031852

run [1950]:
Style Loss : 0.081459 Content Loss: 0.031783

run [2000]:
Style Loss : 0.080819 Content Loss: 0.031721

run [2050]:
Style Loss : 0.080222 Content Loss: 0.031659

run [2100]:
Style Loss : 0.079652 Content Loss: 0.031596

run [2150]:
Style Loss : 0.079145 Content Loss: 0.031545

run [2200]:
Style Loss : 0.078689 Content Loss: 0.031490

run [2250]:
Style Loss : 0.078265 Content Loss: 0.031441

run [2300]:
Style Loss : 0.077854 Content Loss: 0.031398

run [2350]:
Style Loss : 0.077481 Content Loss: 0.031352

run [2400]:
Style Loss : 0.077146 Content Loss: 0.031313

run [2450]:
Style Loss : 0.076855 Content Loss: 0.031280

run [2500]:
Style Loss : 0.076550 Content Loss: 0.031247

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.923313 Content Loss: 0.006645

run [100]:
Style Loss : 0.801857 Content Loss: 0.012922

run [150]:
Style Loss : 0.486806 Content Loss: 0.017522

run [200]:
Style Loss : 0.321178 Content Loss: 0.022375

run [250]:
Style Loss : 0.222109 Content Loss: 0.026731

run [300]:
Style Loss : 0.161920 Content Loss: 0.030861

run [350]:
Style Loss : 0.126317 Content Loss: 0.034119

run [400]:
Style Loss : 0.105399 Content Loss: 0.036047

run [450]:
Style Loss : 0.091569 Content Loss: 0.037564

run [500]:
Style Loss : 0.082044 Content Loss: 0.038746

run [550]:
Style Loss : 0.075520 Content Loss: 0.039430

run [600]:
Style Loss : 0.070841 Content Loss: 0.039783

run [650]:
Style Loss : 0.067164 Content Loss: 0.040017

run [700]:
Style Loss : 0.064393 Content Loss: 0.040160

run [750]:
Style Loss : 0.061936 Content Loss: 0.040277

run [800]:
Style Loss : 0.059691 Content Loss: 0.040334

run [850]:
Style Loss : 0.057601 Content Loss: 0.040367

run [900]:
Style Loss : 0.055764 Content Loss: 0.040357

run [950]:
Style Loss : 0.054070 Content Loss: 0.040320

run [1000]:
Style Loss : 0.052267 Content Loss: 0.040271

run [1050]:
Style Loss : 0.050683 Content Loss: 0.040205

run [1100]:
Style Loss : 0.049208 Content Loss: 0.040134

run [1150]:
Style Loss : 0.047905 Content Loss: 0.040058

run [1200]:
Style Loss : 0.046855 Content Loss: 0.039977

run [1250]:
Style Loss : 0.045849 Content Loss: 0.039907

run [1300]:
Style Loss : 0.044928 Content Loss: 0.039835

run [1350]:
Style Loss : 0.043891 Content Loss: 0.039763

run [1400]:
Style Loss : 0.042977 Content Loss: 0.039706

run [1450]:
Style Loss : 0.042149 Content Loss: 0.039641

run [1500]:
Style Loss : 0.041273 Content Loss: 0.039590

run [1550]:
Style Loss : 0.040453 Content Loss: 0.039545

run [1600]:
Style Loss : 0.039707 Content Loss: 0.039499

run [1650]:
Style Loss : 0.038971 Content Loss: 0.039453

run [1700]:
Style Loss : 0.038268 Content Loss: 0.039411

run [1750]:
Style Loss : 0.037611 Content Loss: 0.039378

run [1800]:
Style Loss : 0.037008 Content Loss: 0.039341

run [1850]:
Style Loss : 0.036277 Content Loss: 0.039303

run [1900]:
Style Loss : 0.035603 Content Loss: 0.039265

run [1950]:
Style Loss : 0.035042 Content Loss: 0.039233

run [2000]:
Style Loss : 0.034584 Content Loss: 0.039206

run [2050]:
Style Loss : 0.034132 Content Loss: 0.039189

run [2100]:
Style Loss : 0.033698 Content Loss: 0.039163

run [2150]:
Style Loss : 0.033215 Content Loss: 0.039140

run [2200]:
Style Loss : 0.032794 Content Loss: 0.039121

run [2250]:
Style Loss : 0.032372 Content Loss: 0.039100

run [2300]:
Style Loss : 0.032002 Content Loss: 0.039079

run [2350]:
Style Loss : 0.031678 Content Loss: 0.039062

run [2400]:
Style Loss : 0.031410 Content Loss: 0.039046

run [2450]:
Style Loss : 0.031163 Content Loss: 0.039028

run [2500]:
Style Loss : 0.030937 Content Loss: 0.039007

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.438424 Content Loss: 0.005931

run [100]:
Style Loss : 0.698655 Content Loss: 0.013964

run [150]:
Style Loss : 0.370361 Content Loss: 0.022666

run [200]:
Style Loss : 0.244578 Content Loss: 0.029049

run [250]:
Style Loss : 0.189726 Content Loss: 0.032530

run [300]:
Style Loss : 0.159802 Content Loss: 0.033977

run [350]:
Style Loss : 0.139459 Content Loss: 0.034813

run [400]:
Style Loss : 0.124443 Content Loss: 0.035268

run [450]:
Style Loss : 0.111635 Content Loss: 0.035863

run [500]:
Style Loss : 0.101002 Content Loss: 0.036678

run [550]:
Style Loss : 0.091386 Content Loss: 0.037509

run [600]:
Style Loss : 0.083373 Content Loss: 0.038217

run [650]:
Style Loss : 0.075816 Content Loss: 0.039046

run [700]:
Style Loss : 0.069035 Content Loss: 0.039810

run [750]:
Style Loss : 0.062929 Content Loss: 0.040553

run [800]:
Style Loss : 0.057428 Content Loss: 0.041297

run [850]:
Style Loss : 0.053026 Content Loss: 0.042092

run [900]:
Style Loss : 0.049009 Content Loss: 0.042766

run [950]:
Style Loss : 0.045747 Content Loss: 0.043351

run [1000]:
Style Loss : 0.042981 Content Loss: 0.043863

run [1050]:
Style Loss : 0.040826 Content Loss: 0.044241

run [1100]:
Style Loss : 0.039084 Content Loss: 0.044483

run [1150]:
Style Loss : 0.037670 Content Loss: 0.044548

run [1200]:
Style Loss : 0.036357 Content Loss: 0.044502

run [1250]:
Style Loss : 0.035431 Content Loss: 0.044428

run [1300]:
Style Loss : 0.034473 Content Loss: 0.044216

run [1350]:
Style Loss : 0.033710 Content Loss: 0.044019

run [1400]:
Style Loss : 0.033061 Content Loss: 0.043779

run [1450]:
Style Loss : 0.032550 Content Loss: 0.043532

run [1500]:
Style Loss : 0.032197 Content Loss: 0.043286

run [1550]:
Style Loss : 0.031698 Content Loss: 0.043093

run [1600]:
Style Loss : 0.031363 Content Loss: 0.042922

run [1650]:
Style Loss : 0.030995 Content Loss: 0.042782

run [1700]:
Style Loss : 0.030738 Content Loss: 0.042626

run [1750]:
Style Loss : 0.030422 Content Loss: 0.042495

run [1800]:
Style Loss : 0.030256 Content Loss: 0.042345

run [1850]:
Style Loss : 0.030137 Content Loss: 0.042217

run [1900]:
Style Loss : 0.029881 Content Loss: 0.042080

run [1950]:
Style Loss : 0.029494 Content Loss: 0.041946

run [2000]:
Style Loss : 0.029224 Content Loss: 0.041808

run [2050]:
Style Loss : 0.029076 Content Loss: 0.041647

run [2100]:
Style Loss : 0.028982 Content Loss: 0.041467

run [2150]:
Style Loss : 0.028698 Content Loss: 0.041300

run [2200]:
Style Loss : 0.028861 Content Loss: 0.041115

run [2250]:
Style Loss : 0.028605 Content Loss: 0.040976

run [2300]:
Style Loss : 0.029054 Content Loss: 0.040807

run [2350]:
Style Loss : 0.028582 Content Loss: 0.040673

run [2400]:
Style Loss : 0.028882 Content Loss: 0.040547

run [2450]:
Style Loss : 0.028392 Content Loss: 0.040438

run [2500]:
Style Loss : 0.028328 Content Loss: 0.040334

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.929343 Content Loss: 0.004372

run [100]:
Style Loss : 0.871764 Content Loss: 0.008791

run [150]:
Style Loss : 0.578279 Content Loss: 0.012499

run [200]:
Style Loss : 0.422147 Content Loss: 0.016389

run [250]:
Style Loss : 0.329718 Content Loss: 0.019046

run [300]:
Style Loss : 0.270083 Content Loss: 0.021695

run [350]:
Style Loss : 0.233458 Content Loss: 0.023391

run [400]:
Style Loss : 0.208773 Content Loss: 0.024666

run [450]:
Style Loss : 0.190091 Content Loss: 0.025503

run [500]:
Style Loss : 0.175373 Content Loss: 0.026135

run [550]:
Style Loss : 0.162979 Content Loss: 0.026645

run [600]:
Style Loss : 0.152862 Content Loss: 0.026981

run [650]:
Style Loss : 0.144000 Content Loss: 0.027318

run [700]:
Style Loss : 0.136131 Content Loss: 0.027689

run [750]:
Style Loss : 0.129147 Content Loss: 0.027943

run [800]:
Style Loss : 0.123037 Content Loss: 0.028189

run [850]:
Style Loss : 0.117409 Content Loss: 0.028461

run [900]:
Style Loss : 0.112214 Content Loss: 0.028699

run [950]:
Style Loss : 0.107645 Content Loss: 0.028900

run [1000]:
Style Loss : 0.103585 Content Loss: 0.029090

run [1050]:
Style Loss : 0.099775 Content Loss: 0.029247

run [1100]:
Style Loss : 0.096396 Content Loss: 0.029377

run [1150]:
Style Loss : 0.093346 Content Loss: 0.029506

run [1200]:
Style Loss : 0.090429 Content Loss: 0.029594

run [1250]:
Style Loss : 0.087839 Content Loss: 0.029664

run [1300]:
Style Loss : 0.085466 Content Loss: 0.029751

run [1350]:
Style Loss : 0.083360 Content Loss: 0.029807

run [1400]:
Style Loss : 0.081443 Content Loss: 0.029862

run [1450]:
Style Loss : 0.079736 Content Loss: 0.029902

run [1500]:
Style Loss : 0.078306 Content Loss: 0.029926

run [1550]:
Style Loss : 0.077006 Content Loss: 0.029930

run [1600]:
Style Loss : 0.075897 Content Loss: 0.029917

run [1650]:
Style Loss : 0.074905 Content Loss: 0.029882

run [1700]:
Style Loss : 0.073994 Content Loss: 0.029842

run [1750]:
Style Loss : 0.073233 Content Loss: 0.029786

run [1800]:
Style Loss : 0.072561 Content Loss: 0.029724

run [1850]:
Style Loss : 0.071970 Content Loss: 0.029664

run [1900]:
Style Loss : 0.071478 Content Loss: 0.029604

run [1950]:
Style Loss : 0.071041 Content Loss: 0.029550

run [2000]:
Style Loss : 0.070646 Content Loss: 0.029491

run [2050]:
Style Loss : 0.070300 Content Loss: 0.029431

run [2100]:
Style Loss : 0.069995 Content Loss: 0.029371

run [2150]:
Style Loss : 0.069706 Content Loss: 0.029312

run [2200]:
Style Loss : 0.069359 Content Loss: 0.029254

run [2250]:
Style Loss : 0.069026 Content Loss: 0.029208

run [2300]:
Style Loss : 0.068730 Content Loss: 0.029158

run [2350]:
Style Loss : 0.068480 Content Loss: 0.029108

run [2400]:
Style Loss : 0.068237 Content Loss: 0.029063

run [2450]:
Style Loss : 0.068000 Content Loss: 0.029032

run [2500]:
Style Loss : 0.067783 Content Loss: 0.028997

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.947800 Content Loss: 0.001662

run [100]:
Style Loss : 0.519232 Content Loss: 0.002975

run [150]:
Style Loss : 0.373923 Content Loss: 0.004375

run [200]:
Style Loss : 0.297485 Content Loss: 0.005728

run [250]:
Style Loss : 0.243431 Content Loss: 0.006994

run [300]:
Style Loss : 0.200912 Content Loss: 0.008259

run [350]:
Style Loss : 0.168863 Content Loss: 0.009407

run [400]:
Style Loss : 0.143444 Content Loss: 0.010642

run [450]:
Style Loss : 0.124589 Content Loss: 0.011685

run [500]:
Style Loss : 0.111448 Content Loss: 0.012696

run [550]:
Style Loss : 0.102538 Content Loss: 0.013445

run [600]:
Style Loss : 0.096311 Content Loss: 0.013974

run [650]:
Style Loss : 0.091767 Content Loss: 0.014295

run [700]:
Style Loss : 0.088380 Content Loss: 0.014506

run [750]:
Style Loss : 0.085766 Content Loss: 0.014635

run [800]:
Style Loss : 0.083737 Content Loss: 0.014721

run [850]:
Style Loss : 0.081961 Content Loss: 0.014774

run [900]:
Style Loss : 0.080302 Content Loss: 0.014792

run [950]:
Style Loss : 0.078715 Content Loss: 0.014811

run [1000]:
Style Loss : 0.077310 Content Loss: 0.014821

run [1050]:
Style Loss : 0.075995 Content Loss: 0.014816

run [1100]:
Style Loss : 0.074771 Content Loss: 0.014823

run [1150]:
Style Loss : 0.073631 Content Loss: 0.014844

run [1200]:
Style Loss : 0.072556 Content Loss: 0.014877

run [1250]:
Style Loss : 0.071476 Content Loss: 0.014911

run [1300]:
Style Loss : 0.070436 Content Loss: 0.014943

run [1350]:
Style Loss : 0.069476 Content Loss: 0.014981

run [1400]:
Style Loss : 0.068537 Content Loss: 0.015033

run [1450]:
Style Loss : 0.067523 Content Loss: 0.015097

run [1500]:
Style Loss : 0.066523 Content Loss: 0.015163

run [1550]:
Style Loss : 0.065570 Content Loss: 0.015240

run [1600]:
Style Loss : 0.064650 Content Loss: 0.015326

run [1650]:
Style Loss : 0.063744 Content Loss: 0.015423

run [1700]:
Style Loss : 0.062801 Content Loss: 0.015522

run [1750]:
Style Loss : 0.061995 Content Loss: 0.015615

run [1800]:
Style Loss : 0.061162 Content Loss: 0.015741

run [1850]:
Style Loss : 0.060318 Content Loss: 0.015861

run [1900]:
Style Loss : 0.059525 Content Loss: 0.015978

run [1950]:
Style Loss : 0.058749 Content Loss: 0.016094

run [2000]:
Style Loss : 0.058053 Content Loss: 0.016238

run [2050]:
Style Loss : 0.057315 Content Loss: 0.016348

run [2100]:
Style Loss : 0.056660 Content Loss: 0.016466

run [2150]:
Style Loss : 0.056037 Content Loss: 0.016579

run [2200]:
Style Loss : 0.055446 Content Loss: 0.016694

run [2250]:
Style Loss : 0.054838 Content Loss: 0.016806

run [2300]:
Style Loss : 0.054303 Content Loss: 0.016929

run [2350]:
Style Loss : 0.053762 Content Loss: 0.017029

run [2400]:
Style Loss : 0.053283 Content Loss: 0.017140

run [2450]:
Style Loss : 0.052852 Content Loss: 0.017257

run [2500]:
Style Loss : 0.052380 Content Loss: 0.017348

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.778465 Content Loss: 0.006156

run [100]:
Style Loss : 0.429028 Content Loss: 0.007968

run [150]:
Style Loss : 0.259351 Content Loss: 0.010903

run [200]:
Style Loss : 0.173520 Content Loss: 0.013696

run [250]:
Style Loss : 0.135988 Content Loss: 0.015560

run [300]:
Style Loss : 0.117335 Content Loss: 0.016064

run [350]:
Style Loss : 0.104753 Content Loss: 0.016319

run [400]:
Style Loss : 0.095439 Content Loss: 0.016631

run [450]:
Style Loss : 0.088545 Content Loss: 0.016938

run [500]:
Style Loss : 0.082658 Content Loss: 0.017201

run [550]:
Style Loss : 0.078057 Content Loss: 0.017464

run [600]:
Style Loss : 0.074490 Content Loss: 0.017699

run [650]:
Style Loss : 0.071524 Content Loss: 0.017941

run [700]:
Style Loss : 0.069165 Content Loss: 0.018112

run [750]:
Style Loss : 0.067077 Content Loss: 0.018271

run [800]:
Style Loss : 0.065277 Content Loss: 0.018410

run [850]:
Style Loss : 0.063627 Content Loss: 0.018558

run [900]:
Style Loss : 0.062285 Content Loss: 0.018694

run [950]:
Style Loss : 0.061124 Content Loss: 0.018816

run [1000]:
Style Loss : 0.060020 Content Loss: 0.018926

run [1050]:
Style Loss : 0.059042 Content Loss: 0.019019

run [1100]:
Style Loss : 0.058176 Content Loss: 0.019091

run [1150]:
Style Loss : 0.057335 Content Loss: 0.019145

run [1200]:
Style Loss : 0.056523 Content Loss: 0.019220

run [1250]:
Style Loss : 0.055857 Content Loss: 0.019255

run [1300]:
Style Loss : 0.055252 Content Loss: 0.019299

run [1350]:
Style Loss : 0.054647 Content Loss: 0.019333

run [1400]:
Style Loss : 0.054120 Content Loss: 0.019349

run [1450]:
Style Loss : 0.053642 Content Loss: 0.019362

run [1500]:
Style Loss : 0.053063 Content Loss: 0.019373

run [1550]:
Style Loss : 0.052561 Content Loss: 0.019386

run [1600]:
Style Loss : 0.052078 Content Loss: 0.019395

run [1650]:
Style Loss : 0.051726 Content Loss: 0.019412

run [1700]:
Style Loss : 0.051351 Content Loss: 0.019425

run [1750]:
Style Loss : 0.051022 Content Loss: 0.019447

run [1800]:
Style Loss : 0.050635 Content Loss: 0.019460

run [1850]:
Style Loss : 0.050324 Content Loss: 0.019477

run [1900]:
Style Loss : 0.049994 Content Loss: 0.019486

run [1950]:
Style Loss : 0.049655 Content Loss: 0.019504

run [2000]:
Style Loss : 0.049321 Content Loss: 0.019516

run [2050]:
Style Loss : 0.049068 Content Loss: 0.019509

run [2100]:
Style Loss : 0.048775 Content Loss: 0.019537

run [2150]:
Style Loss : 0.048525 Content Loss: 0.019543

run [2200]:
Style Loss : 0.048238 Content Loss: 0.019565

run [2250]:
Style Loss : 0.048037 Content Loss: 0.019594

run [2300]:
Style Loss : 0.047796 Content Loss: 0.019598

run [2350]:
Style Loss : 0.047587 Content Loss: 0.019616

run [2400]:
Style Loss : 0.047386 Content Loss: 0.019628

run [2450]:
Style Loss : 0.047181 Content Loss: 0.019631

run [2500]:
Style Loss : 0.046994 Content Loss: 0.019630

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.721564 Content Loss: 0.002642

run [100]:
Style Loss : 0.403784 Content Loss: 0.003189

run [150]:
Style Loss : 0.293859 Content Loss: 0.003788

run [200]:
Style Loss : 0.234778 Content Loss: 0.004426

run [250]:
Style Loss : 0.196704 Content Loss: 0.004989

run [300]:
Style Loss : 0.171395 Content Loss: 0.005539

run [350]:
Style Loss : 0.153938 Content Loss: 0.005990

run [400]:
Style Loss : 0.142078 Content Loss: 0.006349

run [450]:
Style Loss : 0.133406 Content Loss: 0.006699

run [500]:
Style Loss : 0.126755 Content Loss: 0.006959

run [550]:
Style Loss : 0.121111 Content Loss: 0.007168

run [600]:
Style Loss : 0.116719 Content Loss: 0.007307

run [650]:
Style Loss : 0.112957 Content Loss: 0.007447

run [700]:
Style Loss : 0.109891 Content Loss: 0.007543

run [750]:
Style Loss : 0.107315 Content Loss: 0.007627

run [800]:
Style Loss : 0.105178 Content Loss: 0.007697

run [850]:
Style Loss : 0.103134 Content Loss: 0.007756

run [900]:
Style Loss : 0.101376 Content Loss: 0.007804

run [950]:
Style Loss : 0.099626 Content Loss: 0.007859

run [1000]:
Style Loss : 0.098006 Content Loss: 0.007913

run [1050]:
Style Loss : 0.096594 Content Loss: 0.007959

run [1100]:
Style Loss : 0.095170 Content Loss: 0.008007

run [1150]:
Style Loss : 0.094055 Content Loss: 0.008031

run [1200]:
Style Loss : 0.093082 Content Loss: 0.008062

run [1250]:
Style Loss : 0.092198 Content Loss: 0.008089

run [1300]:
Style Loss : 0.091327 Content Loss: 0.008116

run [1350]:
Style Loss : 0.090485 Content Loss: 0.008149

run [1400]:
Style Loss : 0.089623 Content Loss: 0.008178

run [1450]:
Style Loss : 0.088890 Content Loss: 0.008199

run [1500]:
Style Loss : 0.088279 Content Loss: 0.008215

run [1550]:
Style Loss : 0.087743 Content Loss: 0.008221

run [1600]:
Style Loss : 0.087214 Content Loss: 0.008237

run [1650]:
Style Loss : 0.086752 Content Loss: 0.008244

run [1700]:
Style Loss : 0.086288 Content Loss: 0.008259

run [1750]:
Style Loss : 0.085826 Content Loss: 0.008272

run [1800]:
Style Loss : 0.085394 Content Loss: 0.008278

run [1850]:
Style Loss : 0.085013 Content Loss: 0.008288

run [1900]:
Style Loss : 0.084644 Content Loss: 0.008294

run [1950]:
Style Loss : 0.084304 Content Loss: 0.008301

run [2000]:
Style Loss : 0.084014 Content Loss: 0.008307

run [2050]:
Style Loss : 0.083732 Content Loss: 0.008313

run [2100]:
Style Loss : 0.083452 Content Loss: 0.008319

run [2150]:
Style Loss : 0.083164 Content Loss: 0.008326

run [2200]:
Style Loss : 0.082900 Content Loss: 0.008332

run [2250]:
Style Loss : 0.082660 Content Loss: 0.008334

run [2300]:
Style Loss : 0.082436 Content Loss: 0.008341

run [2350]:
Style Loss : 0.082221 Content Loss: 0.008343

run [2400]:
Style Loss : 0.081966 Content Loss: 0.008346

run [2450]:
Style Loss : 0.081738 Content Loss: 0.008350

run [2500]:
Style Loss : 0.081520 Content Loss: 0.008356

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.886716 Content Loss: 0.002409

run [100]:
Style Loss : 1.201196 Content Loss: 0.002950

run [150]:
Style Loss : 0.892266 Content Loss: 0.003482

run [200]:
Style Loss : 0.727567 Content Loss: 0.004081

run [250]:
Style Loss : 0.623920 Content Loss: 0.004569

run [300]:
Style Loss : 0.557281 Content Loss: 0.005086

run [350]:
Style Loss : 0.512003 Content Loss: 0.005584

run [400]:
Style Loss : 0.479578 Content Loss: 0.006062

run [450]:
Style Loss : 0.455101 Content Loss: 0.006480

run [500]:
Style Loss : 0.436664 Content Loss: 0.006839

run [550]:
Style Loss : 0.422357 Content Loss: 0.007168

run [600]:
Style Loss : 0.410747 Content Loss: 0.007486

run [650]:
Style Loss : 0.401803 Content Loss: 0.007726

run [700]:
Style Loss : 0.394618 Content Loss: 0.007948

run [750]:
Style Loss : 0.387979 Content Loss: 0.008137

run [800]:
Style Loss : 0.382275 Content Loss: 0.008317

run [850]:
Style Loss : 0.377359 Content Loss: 0.008467

run [900]:
Style Loss : 0.372669 Content Loss: 0.008639

run [950]:
Style Loss : 0.368707 Content Loss: 0.008761

run [1000]:
Style Loss : 0.364993 Content Loss: 0.008871

run [1050]:
Style Loss : 0.361125 Content Loss: 0.009000

run [1100]:
Style Loss : 0.357890 Content Loss: 0.009104

run [1150]:
Style Loss : 0.354676 Content Loss: 0.009194

run [1200]:
Style Loss : 0.351733 Content Loss: 0.009276

run [1250]:
Style Loss : 0.348912 Content Loss: 0.009373

run [1300]:
Style Loss : 0.346036 Content Loss: 0.009465

run [1350]:
Style Loss : 0.343523 Content Loss: 0.009541

run [1400]:
Style Loss : 0.341181 Content Loss: 0.009621

run [1450]:
Style Loss : 0.339001 Content Loss: 0.009695

run [1500]:
Style Loss : 0.337199 Content Loss: 0.009769

run [1550]:
Style Loss : 0.335332 Content Loss: 0.009816

run [1600]:
Style Loss : 0.333792 Content Loss: 0.009863

run [1650]:
Style Loss : 0.331749 Content Loss: 0.009923

run [1700]:
Style Loss : 0.329225 Content Loss: 0.009982

run [1750]:
Style Loss : 0.327094 Content Loss: 0.010043

run [1800]:
Style Loss : 0.325139 Content Loss: 0.010095

run [1850]:
Style Loss : 0.323437 Content Loss: 0.010147

run [1900]:
Style Loss : 0.321890 Content Loss: 0.010200

run [1950]:
Style Loss : 0.320442 Content Loss: 0.010254

run [2000]:
Style Loss : 0.318972 Content Loss: 0.010313

run [2050]:
Style Loss : 0.317545 Content Loss: 0.010365

run [2100]:
Style Loss : 0.316214 Content Loss: 0.010422

run [2150]:
Style Loss : 0.314616 Content Loss: 0.010490

run [2200]:
Style Loss : 0.313164 Content Loss: 0.010538

run [2250]:
Style Loss : 0.311712 Content Loss: 0.010585

run [2300]:
Style Loss : 0.310103 Content Loss: 0.010647

run [2350]:
Style Loss : 0.308881 Content Loss: 0.010691

run [2400]:
Style Loss : 0.307700 Content Loss: 0.010731

run [2450]:
Style Loss : 0.306731 Content Loss: 0.010762

run [2500]:
Style Loss : 0.305792 Content Loss: 0.010806

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.577603 Content Loss: 0.002282

run [100]:
Style Loss : 1.035467 Content Loss: 0.002884

run [150]:
Style Loss : 0.806493 Content Loss: 0.004016

run [200]:
Style Loss : 0.668075 Content Loss: 0.005317

run [250]:
Style Loss : 0.576032 Content Loss: 0.006967

run [300]:
Style Loss : 0.509274 Content Loss: 0.008601

run [350]:
Style Loss : 0.454761 Content Loss: 0.010261

run [400]:
Style Loss : 0.411823 Content Loss: 0.011956

run [450]:
Style Loss : 0.378786 Content Loss: 0.013220

run [500]:
Style Loss : 0.352213 Content Loss: 0.014337

run [550]:
Style Loss : 0.330185 Content Loss: 0.015312

run [600]:
Style Loss : 0.313016 Content Loss: 0.016010

run [650]:
Style Loss : 0.295315 Content Loss: 0.016607

run [700]:
Style Loss : 0.283047 Content Loss: 0.017198

run [750]:
Style Loss : 0.272626 Content Loss: 0.017663

run [800]:
Style Loss : 0.263144 Content Loss: 0.018159

run [850]:
Style Loss : 0.255122 Content Loss: 0.018537

run [900]:
Style Loss : 0.248056 Content Loss: 0.018915

run [950]:
Style Loss : 0.242057 Content Loss: 0.019269

run [1000]:
Style Loss : 0.236664 Content Loss: 0.019565

run [1050]:
Style Loss : 0.232062 Content Loss: 0.019858

run [1100]:
Style Loss : 0.227913 Content Loss: 0.020141

run [1150]:
Style Loss : 0.223902 Content Loss: 0.020417

run [1200]:
Style Loss : 0.219728 Content Loss: 0.020682

run [1250]:
Style Loss : 0.216020 Content Loss: 0.020914

run [1300]:
Style Loss : 0.212800 Content Loss: 0.021107

run [1350]:
Style Loss : 0.209161 Content Loss: 0.021321

run [1400]:
Style Loss : 0.206078 Content Loss: 0.021497

run [1450]:
Style Loss : 0.203261 Content Loss: 0.021653

run [1500]:
Style Loss : 0.200621 Content Loss: 0.021784

run [1550]:
Style Loss : 0.198155 Content Loss: 0.021923

run [1600]:
Style Loss : 0.195965 Content Loss: 0.022030

run [1650]:
Style Loss : 0.193808 Content Loss: 0.022125

run [1700]:
Style Loss : 0.192033 Content Loss: 0.022207

run [1750]:
Style Loss : 0.190278 Content Loss: 0.022300

run [1800]:
Style Loss : 0.188646 Content Loss: 0.022365

run [1850]:
Style Loss : 0.186971 Content Loss: 0.022451

run [1900]:
Style Loss : 0.185458 Content Loss: 0.022521

run [1950]:
Style Loss : 0.184078 Content Loss: 0.022590

run [2000]:
Style Loss : 0.182850 Content Loss: 0.022665

run [2050]:
Style Loss : 0.181677 Content Loss: 0.022735

run [2100]:
Style Loss : 0.180644 Content Loss: 0.022798

run [2150]:
Style Loss : 0.179716 Content Loss: 0.022860

run [2200]:
Style Loss : 0.178839 Content Loss: 0.022903

run [2250]:
Style Loss : 0.178035 Content Loss: 0.022960

run [2300]:
Style Loss : 0.177225 Content Loss: 0.023015

run [2350]:
Style Loss : 0.176447 Content Loss: 0.023067

run [2400]:
Style Loss : 0.175724 Content Loss: 0.023114

run [2450]:
Style Loss : 0.175048 Content Loss: 0.023158

run [2500]:
Style Loss : 0.174418 Content Loss: 0.023200

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.858883 Content Loss: 0.001766

run [100]:
Style Loss : 0.493935 Content Loss: 0.003553

run [150]:
Style Loss : 0.350204 Content Loss: 0.005444

run [200]:
Style Loss : 0.269207 Content Loss: 0.006999

run [250]:
Style Loss : 0.217765 Content Loss: 0.008441

run [300]:
Style Loss : 0.183759 Content Loss: 0.009604

run [350]:
Style Loss : 0.160739 Content Loss: 0.010445

run [400]:
Style Loss : 0.145141 Content Loss: 0.011008

run [450]:
Style Loss : 0.134020 Content Loss: 0.011340

run [500]:
Style Loss : 0.125198 Content Loss: 0.011524

run [550]:
Style Loss : 0.118501 Content Loss: 0.011559

run [600]:
Style Loss : 0.113216 Content Loss: 0.011634

run [650]:
Style Loss : 0.108960 Content Loss: 0.011675

run [700]:
Style Loss : 0.105722 Content Loss: 0.011711

run [750]:
Style Loss : 0.102808 Content Loss: 0.011763

run [800]:
Style Loss : 0.100242 Content Loss: 0.011798

run [850]:
Style Loss : 0.097998 Content Loss: 0.011841

run [900]:
Style Loss : 0.095846 Content Loss: 0.011882

run [950]:
Style Loss : 0.093909 Content Loss: 0.011921

run [1000]:
Style Loss : 0.091931 Content Loss: 0.011940

run [1050]:
Style Loss : 0.090209 Content Loss: 0.011961

run [1100]:
Style Loss : 0.088650 Content Loss: 0.011976

run [1150]:
Style Loss : 0.087118 Content Loss: 0.011988

run [1200]:
Style Loss : 0.085709 Content Loss: 0.011996

run [1250]:
Style Loss : 0.084425 Content Loss: 0.012002

run [1300]:
Style Loss : 0.083260 Content Loss: 0.012007

run [1350]:
Style Loss : 0.082119 Content Loss: 0.012012

run [1400]:
Style Loss : 0.080931 Content Loss: 0.012024

run [1450]:
Style Loss : 0.079784 Content Loss: 0.012035

run [1500]:
Style Loss : 0.078696 Content Loss: 0.012046

run [1550]:
Style Loss : 0.077780 Content Loss: 0.012048

run [1600]:
Style Loss : 0.076940 Content Loss: 0.012049

run [1650]:
Style Loss : 0.076191 Content Loss: 0.012052

run [1700]:
Style Loss : 0.075544 Content Loss: 0.012050

run [1750]:
Style Loss : 0.074946 Content Loss: 0.012047

run [1800]:
Style Loss : 0.074294 Content Loss: 0.012045

run [1850]:
Style Loss : 0.073749 Content Loss: 0.012046

run [1900]:
Style Loss : 0.073222 Content Loss: 0.012044

run [1950]:
Style Loss : 0.072729 Content Loss: 0.012040

run [2000]:
Style Loss : 0.072274 Content Loss: 0.012034

run [2050]:
Style Loss : 0.071890 Content Loss: 0.012025

run [2100]:
Style Loss : 0.071516 Content Loss: 0.012024

run [2150]:
Style Loss : 0.071190 Content Loss: 0.012016

run [2200]:
Style Loss : 0.070902 Content Loss: 0.012008

run [2250]:
Style Loss : 0.070612 Content Loss: 0.011999

run [2300]:
Style Loss : 0.070339 Content Loss: 0.011994

run [2350]:
Style Loss : 0.070084 Content Loss: 0.011989

run [2400]:
Style Loss : 0.069830 Content Loss: 0.011985

run [2450]:
Style Loss : 0.069589 Content Loss: 0.011980

run [2500]:
Style Loss : 0.069339 Content Loss: 0.011983

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.058635 Content Loss: 0.002002

run [100]:
Style Loss : 1.385080 Content Loss: 0.003364

run [150]:
Style Loss : 1.073559 Content Loss: 0.004780

run [200]:
Style Loss : 0.897482 Content Loss: 0.006015

run [250]:
Style Loss : 0.767068 Content Loss: 0.007232

run [300]:
Style Loss : 0.674543 Content Loss: 0.008319

run [350]:
Style Loss : 0.607191 Content Loss: 0.009370

run [400]:
Style Loss : 0.555483 Content Loss: 0.010475

run [450]:
Style Loss : 0.520166 Content Loss: 0.011304

run [500]:
Style Loss : 0.493825 Content Loss: 0.012129

run [550]:
Style Loss : 0.474567 Content Loss: 0.012754

run [600]:
Style Loss : 0.459709 Content Loss: 0.013308

run [650]:
Style Loss : 0.447109 Content Loss: 0.013717

run [700]:
Style Loss : 0.435383 Content Loss: 0.014092

run [750]:
Style Loss : 0.425344 Content Loss: 0.014338

run [800]:
Style Loss : 0.416054 Content Loss: 0.014571

run [850]:
Style Loss : 0.408240 Content Loss: 0.014731

run [900]:
Style Loss : 0.401541 Content Loss: 0.014910

run [950]:
Style Loss : 0.394963 Content Loss: 0.015059

run [1000]:
Style Loss : 0.389228 Content Loss: 0.015186

run [1050]:
Style Loss : 0.383429 Content Loss: 0.015312

run [1100]:
Style Loss : 0.377247 Content Loss: 0.015463

run [1150]:
Style Loss : 0.371237 Content Loss: 0.015599

run [1200]:
Style Loss : 0.365853 Content Loss: 0.015722

run [1250]:
Style Loss : 0.361061 Content Loss: 0.015844

run [1300]:
Style Loss : 0.356644 Content Loss: 0.015990

run [1350]:
Style Loss : 0.352572 Content Loss: 0.016120

run [1400]:
Style Loss : 0.348651 Content Loss: 0.016271

run [1450]:
Style Loss : 0.344541 Content Loss: 0.016452

run [1500]:
Style Loss : 0.340223 Content Loss: 0.016626

run [1550]:
Style Loss : 0.335936 Content Loss: 0.016799

run [1600]:
Style Loss : 0.331674 Content Loss: 0.016979

run [1650]:
Style Loss : 0.327706 Content Loss: 0.017139

run [1700]:
Style Loss : 0.323813 Content Loss: 0.017338

run [1750]:
Style Loss : 0.320203 Content Loss: 0.017523

run [1800]:
Style Loss : 0.316804 Content Loss: 0.017695

run [1850]:
Style Loss : 0.313671 Content Loss: 0.017861

run [1900]:
Style Loss : 0.310747 Content Loss: 0.018028

run [1950]:
Style Loss : 0.307982 Content Loss: 0.018212

run [2000]:
Style Loss : 0.305301 Content Loss: 0.018398

run [2050]:
Style Loss : 0.302699 Content Loss: 0.018590

run [2100]:
Style Loss : 0.299979 Content Loss: 0.018776

run [2150]:
Style Loss : 0.297559 Content Loss: 0.018969

run [2200]:
Style Loss : 0.295369 Content Loss: 0.019134

run [2250]:
Style Loss : 0.293119 Content Loss: 0.019309

run [2300]:
Style Loss : 0.290681 Content Loss: 0.019483

run [2350]:
Style Loss : 0.288541 Content Loss: 0.019644

run [2400]:
Style Loss : 0.286604 Content Loss: 0.019792

run [2450]:
Style Loss : 0.284789 Content Loss: 0.019924

run [2500]:
Style Loss : 0.283137 Content Loss: 0.020045

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.796836 Content Loss: 0.002137

run [100]:
Style Loss : 1.079981 Content Loss: 0.004651

run [150]:
Style Loss : 0.806731 Content Loss: 0.007160

run [200]:
Style Loss : 0.650794 Content Loss: 0.009437

run [250]:
Style Loss : 0.543236 Content Loss: 0.011697

run [300]:
Style Loss : 0.456873 Content Loss: 0.014275

run [350]:
Style Loss : 0.383614 Content Loss: 0.017035

run [400]:
Style Loss : 0.327606 Content Loss: 0.019487

run [450]:
Style Loss : 0.287926 Content Loss: 0.021528

run [500]:
Style Loss : 0.260083 Content Loss: 0.023108

run [550]:
Style Loss : 0.241648 Content Loss: 0.024191

run [600]:
Style Loss : 0.228354 Content Loss: 0.024942

run [650]:
Style Loss : 0.218254 Content Loss: 0.025468

run [700]:
Style Loss : 0.210160 Content Loss: 0.025848

run [750]:
Style Loss : 0.203371 Content Loss: 0.026143

run [800]:
Style Loss : 0.197598 Content Loss: 0.026423

run [850]:
Style Loss : 0.192650 Content Loss: 0.026675

run [900]:
Style Loss : 0.188029 Content Loss: 0.026924

run [950]:
Style Loss : 0.183922 Content Loss: 0.027112

run [1000]:
Style Loss : 0.179934 Content Loss: 0.027339

run [1050]:
Style Loss : 0.176176 Content Loss: 0.027578

run [1100]:
Style Loss : 0.172481 Content Loss: 0.027805

run [1150]:
Style Loss : 0.169095 Content Loss: 0.028018

run [1200]:
Style Loss : 0.165944 Content Loss: 0.028258

run [1250]:
Style Loss : 0.162876 Content Loss: 0.028476

run [1300]:
Style Loss : 0.160004 Content Loss: 0.028722

run [1350]:
Style Loss : 0.157309 Content Loss: 0.028957

run [1400]:
Style Loss : 0.154771 Content Loss: 0.029188

run [1450]:
Style Loss : 0.152412 Content Loss: 0.029379

run [1500]:
Style Loss : 0.150157 Content Loss: 0.029590

run [1550]:
Style Loss : 0.147985 Content Loss: 0.029806

run [1600]:
Style Loss : 0.146018 Content Loss: 0.030003

run [1650]:
Style Loss : 0.144256 Content Loss: 0.030164

run [1700]:
Style Loss : 0.142522 Content Loss: 0.030354

run [1750]:
Style Loss : 0.140934 Content Loss: 0.030527

run [1800]:
Style Loss : 0.139404 Content Loss: 0.030699

run [1850]:
Style Loss : 0.137854 Content Loss: 0.030892

run [1900]:
Style Loss : 0.136410 Content Loss: 0.031059

run [1950]:
Style Loss : 0.134999 Content Loss: 0.031230

run [2000]:
Style Loss : 0.133694 Content Loss: 0.031388

run [2050]:
Style Loss : 0.132531 Content Loss: 0.031529

run [2100]:
Style Loss : 0.131382 Content Loss: 0.031672

run [2150]:
Style Loss : 0.130289 Content Loss: 0.031791

run [2200]:
Style Loss : 0.129229 Content Loss: 0.031914

run [2250]:
Style Loss : 0.128236 Content Loss: 0.032012

run [2300]:
Style Loss : 0.127288 Content Loss: 0.032103

run [2350]:
Style Loss : 0.126389 Content Loss: 0.032196

run [2400]:
Style Loss : 0.125518 Content Loss: 0.032283

run [2450]:
Style Loss : 0.124708 Content Loss: 0.032367

run [2500]:
Style Loss : 0.123921 Content Loss: 0.032450

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.095123 Content Loss: 0.002167

run [100]:
Style Loss : 0.639180 Content Loss: 0.003886

run [150]:
Style Loss : 0.483045 Content Loss: 0.005329

run [200]:
Style Loss : 0.402981 Content Loss: 0.006729

run [250]:
Style Loss : 0.349444 Content Loss: 0.007931

run [300]:
Style Loss : 0.316286 Content Loss: 0.008844

run [350]:
Style Loss : 0.294527 Content Loss: 0.009624

run [400]:
Style Loss : 0.279508 Content Loss: 0.010219

run [450]:
Style Loss : 0.268927 Content Loss: 0.010636

run [500]:
Style Loss : 0.260794 Content Loss: 0.010917

run [550]:
Style Loss : 0.253879 Content Loss: 0.011131

run [600]:
Style Loss : 0.248029 Content Loss: 0.011302

run [650]:
Style Loss : 0.243149 Content Loss: 0.011438

run [700]:
Style Loss : 0.238772 Content Loss: 0.011581

run [750]:
Style Loss : 0.235088 Content Loss: 0.011712

run [800]:
Style Loss : 0.231615 Content Loss: 0.011828

run [850]:
Style Loss : 0.228386 Content Loss: 0.011946

run [900]:
Style Loss : 0.225407 Content Loss: 0.012063

run [950]:
Style Loss : 0.222441 Content Loss: 0.012192

run [1000]:
Style Loss : 0.219559 Content Loss: 0.012332

run [1050]:
Style Loss : 0.216926 Content Loss: 0.012466

run [1100]:
Style Loss : 0.214374 Content Loss: 0.012614

run [1150]:
Style Loss : 0.212037 Content Loss: 0.012738

run [1200]:
Style Loss : 0.209846 Content Loss: 0.012874

run [1250]:
Style Loss : 0.207686 Content Loss: 0.013010

run [1300]:
Style Loss : 0.205676 Content Loss: 0.013130

run [1350]:
Style Loss : 0.203636 Content Loss: 0.013265

run [1400]:
Style Loss : 0.201655 Content Loss: 0.013403

run [1450]:
Style Loss : 0.199813 Content Loss: 0.013522

run [1500]:
Style Loss : 0.198116 Content Loss: 0.013626

run [1550]:
Style Loss : 0.196579 Content Loss: 0.013718

run [1600]:
Style Loss : 0.195123 Content Loss: 0.013804

run [1650]:
Style Loss : 0.193696 Content Loss: 0.013885

run [1700]:
Style Loss : 0.192374 Content Loss: 0.013957

run [1750]:
Style Loss : 0.191149 Content Loss: 0.014033

run [1800]:
Style Loss : 0.190036 Content Loss: 0.014094

run [1850]:
Style Loss : 0.188992 Content Loss: 0.014153

run [1900]:
Style Loss : 0.188064 Content Loss: 0.014202

run [1950]:
Style Loss : 0.187227 Content Loss: 0.014250

run [2000]:
Style Loss : 0.186476 Content Loss: 0.014293

run [2050]:
Style Loss : 0.185778 Content Loss: 0.014330

run [2100]:
Style Loss : 0.185147 Content Loss: 0.014365

run [2150]:
Style Loss : 0.184558 Content Loss: 0.014403

run [2200]:
Style Loss : 0.184038 Content Loss: 0.014432

run [2250]:
Style Loss : 0.183491 Content Loss: 0.014466

run [2300]:
Style Loss : 0.183034 Content Loss: 0.014492

run [2350]:
Style Loss : 0.182633 Content Loss: 0.014512

run [2400]:
Style Loss : 0.182242 Content Loss: 0.014539

run [2450]:
Style Loss : 0.181868 Content Loss: 0.014561

run [2500]:
Style Loss : 0.181535 Content Loss: 0.014577

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.985094 Content Loss: 0.001927

run [100]:
Style Loss : 1.898585 Content Loss: 0.003194

run [150]:
Style Loss : 1.438412 Content Loss: 0.004407

run [200]:
Style Loss : 1.196627 Content Loss: 0.005488

run [250]:
Style Loss : 1.048479 Content Loss: 0.006538

run [300]:
Style Loss : 0.939959 Content Loss: 0.007504

run [350]:
Style Loss : 0.846493 Content Loss: 0.008483

run [400]:
Style Loss : 0.777007 Content Loss: 0.009436

run [450]:
Style Loss : 0.719722 Content Loss: 0.010297

run [500]:
Style Loss : 0.676018 Content Loss: 0.011102

run [550]:
Style Loss : 0.643378 Content Loss: 0.011758

run [600]:
Style Loss : 0.616487 Content Loss: 0.012419

run [650]:
Style Loss : 0.593334 Content Loss: 0.013019

run [700]:
Style Loss : 0.573952 Content Loss: 0.013570

run [750]:
Style Loss : 0.557237 Content Loss: 0.014034

run [800]:
Style Loss : 0.543859 Content Loss: 0.014413

run [850]:
Style Loss : 0.532817 Content Loss: 0.014708

run [900]:
Style Loss : 0.524139 Content Loss: 0.014982

run [950]:
Style Loss : 0.516454 Content Loss: 0.015185

run [1000]:
Style Loss : 0.508552 Content Loss: 0.015377

run [1050]:
Style Loss : 0.501428 Content Loss: 0.015534

run [1100]:
Style Loss : 0.494696 Content Loss: 0.015681

run [1150]:
Style Loss : 0.488780 Content Loss: 0.015787

run [1200]:
Style Loss : 0.483364 Content Loss: 0.015885

run [1250]:
Style Loss : 0.478525 Content Loss: 0.015981

run [1300]:
Style Loss : 0.474612 Content Loss: 0.016054

run [1350]:
Style Loss : 0.471048 Content Loss: 0.016126

run [1400]:
Style Loss : 0.467648 Content Loss: 0.016187

run [1450]:
Style Loss : 0.464579 Content Loss: 0.016236

run [1500]:
Style Loss : 0.461729 Content Loss: 0.016287

run [1550]:
Style Loss : 0.459151 Content Loss: 0.016335

run [1600]:
Style Loss : 0.456533 Content Loss: 0.016386

run [1650]:
Style Loss : 0.453524 Content Loss: 0.016445

run [1700]:
Style Loss : 0.450397 Content Loss: 0.016503

run [1750]:
Style Loss : 0.447262 Content Loss: 0.016561

run [1800]:
Style Loss : 0.443845 Content Loss: 0.016617

run [1850]:
Style Loss : 0.440874 Content Loss: 0.016667

run [1900]:
Style Loss : 0.438339 Content Loss: 0.016718

run [1950]:
Style Loss : 0.436149 Content Loss: 0.016764

run [2000]:
Style Loss : 0.433957 Content Loss: 0.016821

run [2050]:
Style Loss : 0.431824 Content Loss: 0.016877

run [2100]:
Style Loss : 0.429683 Content Loss: 0.016910

run [2150]:
Style Loss : 0.427579 Content Loss: 0.016957

run [2200]:
Style Loss : 0.425492 Content Loss: 0.017009

run [2250]:
Style Loss : 0.423559 Content Loss: 0.017047

run [2300]:
Style Loss : 0.421698 Content Loss: 0.017089

run [2350]:
Style Loss : 0.420105 Content Loss: 0.017124

run [2400]:
Style Loss : 0.418543 Content Loss: 0.017164

run [2450]:
Style Loss : 0.417026 Content Loss: 0.017205

run [2500]:
Style Loss : 0.415382 Content Loss: 0.017238

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.960823 Content Loss: 0.011034

run [100]:
Style Loss : 1.002688 Content Loss: 0.016771

run [150]:
Style Loss : 0.713893 Content Loss: 0.019967

run [200]:
Style Loss : 0.570448 Content Loss: 0.022059

run [250]:
Style Loss : 0.481804 Content Loss: 0.023783

run [300]:
Style Loss : 0.414227 Content Loss: 0.025747

run [350]:
Style Loss : 0.358145 Content Loss: 0.027834

run [400]:
Style Loss : 0.314397 Content Loss: 0.029903

run [450]:
Style Loss : 0.281828 Content Loss: 0.031438

run [500]:
Style Loss : 0.255593 Content Loss: 0.032969

run [550]:
Style Loss : 0.236134 Content Loss: 0.034197

run [600]:
Style Loss : 0.221287 Content Loss: 0.035198

run [650]:
Style Loss : 0.210045 Content Loss: 0.036012

run [700]:
Style Loss : 0.200705 Content Loss: 0.036673

run [750]:
Style Loss : 0.192808 Content Loss: 0.037170

run [800]:
Style Loss : 0.185917 Content Loss: 0.037566

run [850]:
Style Loss : 0.179884 Content Loss: 0.037916

run [900]:
Style Loss : 0.174508 Content Loss: 0.038238

run [950]:
Style Loss : 0.169429 Content Loss: 0.038492

run [1000]:
Style Loss : 0.164828 Content Loss: 0.038752

run [1050]:
Style Loss : 0.160690 Content Loss: 0.038969

run [1100]:
Style Loss : 0.157058 Content Loss: 0.039159

run [1150]:
Style Loss : 0.153767 Content Loss: 0.039354

run [1200]:
Style Loss : 0.150815 Content Loss: 0.039520

run [1250]:
Style Loss : 0.148070 Content Loss: 0.039683

run [1300]:
Style Loss : 0.145489 Content Loss: 0.039836

run [1350]:
Style Loss : 0.142945 Content Loss: 0.039985

run [1400]:
Style Loss : 0.140554 Content Loss: 0.040127

run [1450]:
Style Loss : 0.138306 Content Loss: 0.040264

run [1500]:
Style Loss : 0.136140 Content Loss: 0.040429

run [1550]:
Style Loss : 0.134169 Content Loss: 0.040598

run [1600]:
Style Loss : 0.132302 Content Loss: 0.040787

run [1650]:
Style Loss : 0.130645 Content Loss: 0.040944

run [1700]:
Style Loss : 0.129168 Content Loss: 0.041095

run [1750]:
Style Loss : 0.127758 Content Loss: 0.041235

run [1800]:
Style Loss : 0.126507 Content Loss: 0.041366

run [1850]:
Style Loss : 0.125400 Content Loss: 0.041485

run [1900]:
Style Loss : 0.124418 Content Loss: 0.041596

run [1950]:
Style Loss : 0.123549 Content Loss: 0.041691

run [2000]:
Style Loss : 0.122727 Content Loss: 0.041776

run [2050]:
Style Loss : 0.121967 Content Loss: 0.041865

run [2100]:
Style Loss : 0.121270 Content Loss: 0.041939

run [2150]:
Style Loss : 0.120598 Content Loss: 0.042008

run [2200]:
Style Loss : 0.119989 Content Loss: 0.042048

run [2250]:
Style Loss : 0.119367 Content Loss: 0.042092

run [2300]:
Style Loss : 0.118858 Content Loss: 0.042117

run [2350]:
Style Loss : 0.118377 Content Loss: 0.042145

run [2400]:
Style Loss : 0.117969 Content Loss: 0.042165

run [2450]:
Style Loss : 0.117589 Content Loss: 0.042179

run [2500]:
Style Loss : 0.117221 Content Loss: 0.042189

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.067617 Content Loss: 0.010163

run [100]:
Style Loss : 0.543043 Content Loss: 0.014703

run [150]:
Style Loss : 0.404263 Content Loss: 0.016961

run [200]:
Style Loss : 0.334862 Content Loss: 0.018539

run [250]:
Style Loss : 0.292353 Content Loss: 0.019614

run [300]:
Style Loss : 0.260486 Content Loss: 0.020353

run [350]:
Style Loss : 0.237058 Content Loss: 0.020720

run [400]:
Style Loss : 0.221364 Content Loss: 0.021033

run [450]:
Style Loss : 0.210013 Content Loss: 0.021235

run [500]:
Style Loss : 0.201472 Content Loss: 0.021347

run [550]:
Style Loss : 0.195044 Content Loss: 0.021364

run [600]:
Style Loss : 0.189911 Content Loss: 0.021427

run [650]:
Style Loss : 0.185530 Content Loss: 0.021508

run [700]:
Style Loss : 0.181843 Content Loss: 0.021536

run [750]:
Style Loss : 0.178540 Content Loss: 0.021553

run [800]:
Style Loss : 0.175541 Content Loss: 0.021561

run [850]:
Style Loss : 0.173020 Content Loss: 0.021564

run [900]:
Style Loss : 0.170827 Content Loss: 0.021563

run [950]:
Style Loss : 0.169000 Content Loss: 0.021558

run [1000]:
Style Loss : 0.166980 Content Loss: 0.021575

run [1050]:
Style Loss : 0.165234 Content Loss: 0.021581

run [1100]:
Style Loss : 0.163263 Content Loss: 0.021579

run [1150]:
Style Loss : 0.161467 Content Loss: 0.021593

run [1200]:
Style Loss : 0.159855 Content Loss: 0.021610

run [1250]:
Style Loss : 0.158284 Content Loss: 0.021623

run [1300]:
Style Loss : 0.156389 Content Loss: 0.021640

run [1350]:
Style Loss : 0.154969 Content Loss: 0.021647

run [1400]:
Style Loss : 0.153610 Content Loss: 0.021662

run [1450]:
Style Loss : 0.152408 Content Loss: 0.021661

run [1500]:
Style Loss : 0.151502 Content Loss: 0.021657

run [1550]:
Style Loss : 0.150662 Content Loss: 0.021652

run [1600]:
Style Loss : 0.149914 Content Loss: 0.021638

run [1650]:
Style Loss : 0.149066 Content Loss: 0.021628

run [1700]:
Style Loss : 0.148326 Content Loss: 0.021620

run [1750]:
Style Loss : 0.147725 Content Loss: 0.021618

run [1800]:
Style Loss : 0.147172 Content Loss: 0.021616

run [1850]:
Style Loss : 0.146694 Content Loss: 0.021615

run [1900]:
Style Loss : 0.146254 Content Loss: 0.021611

run [1950]:
Style Loss : 0.145848 Content Loss: 0.021613

run [2000]:
Style Loss : 0.145461 Content Loss: 0.021611

run [2050]:
Style Loss : 0.145127 Content Loss: 0.021609

run [2100]:
Style Loss : 0.144820 Content Loss: 0.021604

run [2150]:
Style Loss : 0.144514 Content Loss: 0.021599

run [2200]:
Style Loss : 0.144246 Content Loss: 0.021595

run [2250]:
Style Loss : 0.143984 Content Loss: 0.021588

run [2300]:
Style Loss : 0.143739 Content Loss: 0.021578

run [2350]:
Style Loss : 0.143490 Content Loss: 0.021573

run [2400]:
Style Loss : 0.143266 Content Loss: 0.021567

run [2450]:
Style Loss : 0.143059 Content Loss: 0.021561

run [2500]:
Style Loss : 0.142849 Content Loss: 0.021557

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.856723 Content Loss: 0.007820

run [100]:
Style Loss : 1.883599 Content Loss: 0.013806

run [150]:
Style Loss : 1.368532 Content Loss: 0.016917

run [200]:
Style Loss : 1.110055 Content Loss: 0.018767

run [250]:
Style Loss : 0.949409 Content Loss: 0.020267

run [300]:
Style Loss : 0.834788 Content Loss: 0.021514

run [350]:
Style Loss : 0.741198 Content Loss: 0.022524

run [400]:
Style Loss : 0.672095 Content Loss: 0.023456

run [450]:
Style Loss : 0.619406 Content Loss: 0.024268

run [500]:
Style Loss : 0.578536 Content Loss: 0.024922

run [550]:
Style Loss : 0.547427 Content Loss: 0.025504

run [600]:
Style Loss : 0.521437 Content Loss: 0.026072

run [650]:
Style Loss : 0.497896 Content Loss: 0.026546

run [700]:
Style Loss : 0.477251 Content Loss: 0.026988

run [750]:
Style Loss : 0.459928 Content Loss: 0.027323

run [800]:
Style Loss : 0.446279 Content Loss: 0.027606

run [850]:
Style Loss : 0.431834 Content Loss: 0.027861

run [900]:
Style Loss : 0.420841 Content Loss: 0.028115

run [950]:
Style Loss : 0.411754 Content Loss: 0.028314

run [1000]:
Style Loss : 0.404066 Content Loss: 0.028507

run [1050]:
Style Loss : 0.397053 Content Loss: 0.028674

run [1100]:
Style Loss : 0.390917 Content Loss: 0.028853

run [1150]:
Style Loss : 0.385156 Content Loss: 0.029025

run [1200]:
Style Loss : 0.380093 Content Loss: 0.029173

run [1250]:
Style Loss : 0.375157 Content Loss: 0.029318

run [1300]:
Style Loss : 0.370481 Content Loss: 0.029454

run [1350]:
Style Loss : 0.366461 Content Loss: 0.029568

run [1400]:
Style Loss : 0.362542 Content Loss: 0.029679

run [1450]:
Style Loss : 0.358812 Content Loss: 0.029784

run [1500]:
Style Loss : 0.355119 Content Loss: 0.029890

run [1550]:
Style Loss : 0.351339 Content Loss: 0.030000

run [1600]:
Style Loss : 0.347652 Content Loss: 0.030099

run [1650]:
Style Loss : 0.344089 Content Loss: 0.030191

run [1700]:
Style Loss : 0.340943 Content Loss: 0.030273

run [1750]:
Style Loss : 0.337879 Content Loss: 0.030376

run [1800]:
Style Loss : 0.334992 Content Loss: 0.030458

run [1850]:
Style Loss : 0.332362 Content Loss: 0.030552

run [1900]:
Style Loss : 0.329874 Content Loss: 0.030624

run [1950]:
Style Loss : 0.327456 Content Loss: 0.030698

run [2000]:
Style Loss : 0.325165 Content Loss: 0.030781

run [2050]:
Style Loss : 0.322980 Content Loss: 0.030867

run [2100]:
Style Loss : 0.320738 Content Loss: 0.030964

run [2150]:
Style Loss : 0.318382 Content Loss: 0.031052

run [2200]:
Style Loss : 0.315936 Content Loss: 0.031156

run [2250]:
Style Loss : 0.313614 Content Loss: 0.031256

run [2300]:
Style Loss : 0.311432 Content Loss: 0.031338

run [2350]:
Style Loss : 0.309213 Content Loss: 0.031457

run [2400]:
Style Loss : 0.307017 Content Loss: 0.031566

run [2450]:
Style Loss : 0.305044 Content Loss: 0.031668

run [2500]:
Style Loss : 0.303276 Content Loss: 0.031735

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 0.651822 Content Loss: 0.007724

run [100]:
Style Loss : 0.345826 Content Loss: 0.011053

run [150]:
Style Loss : 0.249060 Content Loss: 0.012498

run [200]:
Style Loss : 0.197591 Content Loss: 0.013929

run [250]:
Style Loss : 0.168441 Content Loss: 0.014619

run [300]:
Style Loss : 0.149779 Content Loss: 0.015191

run [350]:
Style Loss : 0.135535 Content Loss: 0.015638

run [400]:
Style Loss : 0.124935 Content Loss: 0.016134

run [450]:
Style Loss : 0.116710 Content Loss: 0.016480

run [500]:
Style Loss : 0.109329 Content Loss: 0.016812

run [550]:
Style Loss : 0.103002 Content Loss: 0.017050

run [600]:
Style Loss : 0.097659 Content Loss: 0.017171

run [650]:
Style Loss : 0.092855 Content Loss: 0.017281

run [700]:
Style Loss : 0.088533 Content Loss: 0.017368

run [750]:
Style Loss : 0.084905 Content Loss: 0.017396

run [800]:
Style Loss : 0.081745 Content Loss: 0.017355

run [850]:
Style Loss : 0.078911 Content Loss: 0.017286

run [900]:
Style Loss : 0.076356 Content Loss: 0.017231

run [950]:
Style Loss : 0.073940 Content Loss: 0.017144

run [1000]:
Style Loss : 0.071961 Content Loss: 0.017090

run [1050]:
Style Loss : 0.070339 Content Loss: 0.016976

run [1100]:
Style Loss : 0.068959 Content Loss: 0.016891

run [1150]:
Style Loss : 0.067563 Content Loss: 0.016816

run [1200]:
Style Loss : 0.066293 Content Loss: 0.016732

run [1250]:
Style Loss : 0.065342 Content Loss: 0.016653

run [1300]:
Style Loss : 0.064474 Content Loss: 0.016597

run [1350]:
Style Loss : 0.063710 Content Loss: 0.016544

run [1400]:
Style Loss : 0.063052 Content Loss: 0.016507

run [1450]:
Style Loss : 0.062465 Content Loss: 0.016453

run [1500]:
Style Loss : 0.061940 Content Loss: 0.016423

run [1550]:
Style Loss : 0.061512 Content Loss: 0.016376

run [1600]:
Style Loss : 0.061128 Content Loss: 0.016332

run [1650]:
Style Loss : 0.060783 Content Loss: 0.016289

run [1700]:
Style Loss : 0.060479 Content Loss: 0.016243

run [1750]:
Style Loss : 0.060170 Content Loss: 0.016196

run [1800]:
Style Loss : 0.059907 Content Loss: 0.016162

run [1850]:
Style Loss : 0.059681 Content Loss: 0.016121

run [1900]:
Style Loss : 0.059491 Content Loss: 0.016086

run [1950]:
Style Loss : 0.059331 Content Loss: 0.016051

run [2000]:
Style Loss : 0.059116 Content Loss: 0.016024

run [2050]:
Style Loss : 0.058907 Content Loss: 0.016005

run [2100]:
Style Loss : 0.058701 Content Loss: 0.015988

run [2150]:
Style Loss : 0.058522 Content Loss: 0.015971

run [2200]:
Style Loss : 0.058349 Content Loss: 0.015954

run [2250]:
Style Loss : 0.058183 Content Loss: 0.015928

run [2300]:
Style Loss : 0.058049 Content Loss: 0.015911

run [2350]:
Style Loss : 0.057939 Content Loss: 0.015890

run [2400]:
Style Loss : 0.057804 Content Loss: 0.015880

run [2450]:
Style Loss : 0.057684 Content Loss: 0.015859

run [2500]:
Style Loss : 0.057910 Content Loss: 0.015849

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.467283 Content Loss: 0.009197

run [100]:
Style Loss : 0.733966 Content Loss: 0.014685

run [150]:
Style Loss : 0.512550 Content Loss: 0.016766

run [200]:
Style Loss : 0.399567 Content Loss: 0.018363

run [250]:
Style Loss : 0.339373 Content Loss: 0.019663

run [300]:
Style Loss : 0.299910 Content Loss: 0.020534

run [350]:
Style Loss : 0.273490 Content Loss: 0.021250

run [400]:
Style Loss : 0.255049 Content Loss: 0.021601

run [450]:
Style Loss : 0.242239 Content Loss: 0.021915

run [500]:
Style Loss : 0.232916 Content Loss: 0.022126

run [550]:
Style Loss : 0.224315 Content Loss: 0.022306

run [600]:
Style Loss : 0.217662 Content Loss: 0.022456

run [650]:
Style Loss : 0.212091 Content Loss: 0.022595

run [700]:
Style Loss : 0.207377 Content Loss: 0.022694

run [750]:
Style Loss : 0.203235 Content Loss: 0.022793

run [800]:
Style Loss : 0.198492 Content Loss: 0.022865

run [850]:
Style Loss : 0.194636 Content Loss: 0.022935

run [900]:
Style Loss : 0.191168 Content Loss: 0.023006

run [950]:
Style Loss : 0.187729 Content Loss: 0.023090

run [1000]:
Style Loss : 0.184798 Content Loss: 0.023143

run [1050]:
Style Loss : 0.181827 Content Loss: 0.023229

run [1100]:
Style Loss : 0.178532 Content Loss: 0.023304

run [1150]:
Style Loss : 0.175693 Content Loss: 0.023373

run [1200]:
Style Loss : 0.172767 Content Loss: 0.023466

run [1250]:
Style Loss : 0.169563 Content Loss: 0.023551

run [1300]:
Style Loss : 0.167002 Content Loss: 0.023622

run [1350]:
Style Loss : 0.164477 Content Loss: 0.023710

run [1400]:
Style Loss : 0.162267 Content Loss: 0.023772

run [1450]:
Style Loss : 0.160327 Content Loss: 0.023830

run [1500]:
Style Loss : 0.158741 Content Loss: 0.023880

run [1550]:
Style Loss : 0.157217 Content Loss: 0.023918

run [1600]:
Style Loss : 0.155661 Content Loss: 0.023972

run [1650]:
Style Loss : 0.154175 Content Loss: 0.024031

run [1700]:
Style Loss : 0.152746 Content Loss: 0.024058

run [1750]:
Style Loss : 0.151435 Content Loss: 0.024085

run [1800]:
Style Loss : 0.150156 Content Loss: 0.024102

run [1850]:
Style Loss : 0.148986 Content Loss: 0.024119

run [1900]:
Style Loss : 0.147945 Content Loss: 0.024140

run [1950]:
Style Loss : 0.146988 Content Loss: 0.024157

run [2000]:
Style Loss : 0.146102 Content Loss: 0.024176

run [2050]:
Style Loss : 0.145232 Content Loss: 0.024208

run [2100]:
Style Loss : 0.144345 Content Loss: 0.024223

run [2150]:
Style Loss : 0.143493 Content Loss: 0.024231

run [2200]:
Style Loss : 0.142730 Content Loss: 0.024238

run [2250]:
Style Loss : 0.141984 Content Loss: 0.024245

run [2300]:
Style Loss : 0.141257 Content Loss: 0.024266

run [2350]:
Style Loss : 0.140623 Content Loss: 0.024288

run [2400]:
Style Loss : 0.140004 Content Loss: 0.024313

run [2450]:
Style Loss : 0.139485 Content Loss: 0.024347

run [2500]:
Style Loss : 0.138783 Content Loss: 0.024379

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.297858 Content Loss: 0.008049

run [100]:
Style Loss : 1.591832 Content Loss: 0.014437

run [150]:
Style Loss : 1.049767 Content Loss: 0.019712

run [200]:
Style Loss : 0.792075 Content Loss: 0.024308

run [250]:
Style Loss : 0.640404 Content Loss: 0.027909

run [300]:
Style Loss : 0.539220 Content Loss: 0.030843

run [350]:
Style Loss : 0.470398 Content Loss: 0.032587

run [400]:
Style Loss : 0.419011 Content Loss: 0.034270

run [450]:
Style Loss : 0.381911 Content Loss: 0.035414

run [500]:
Style Loss : 0.354849 Content Loss: 0.036484

run [550]:
Style Loss : 0.334747 Content Loss: 0.037420

run [600]:
Style Loss : 0.318348 Content Loss: 0.038190

run [650]:
Style Loss : 0.305631 Content Loss: 0.038747

run [700]:
Style Loss : 0.295328 Content Loss: 0.039265

run [750]:
Style Loss : 0.286555 Content Loss: 0.039656

run [800]:
Style Loss : 0.278541 Content Loss: 0.039934

run [850]:
Style Loss : 0.270203 Content Loss: 0.040190

run [900]:
Style Loss : 0.263252 Content Loss: 0.040348

run [950]:
Style Loss : 0.257596 Content Loss: 0.040489

run [1000]:
Style Loss : 0.252699 Content Loss: 0.040621

run [1050]:
Style Loss : 0.248354 Content Loss: 0.040759

run [1100]:
Style Loss : 0.244118 Content Loss: 0.040892

run [1150]:
Style Loss : 0.240319 Content Loss: 0.040983

run [1200]:
Style Loss : 0.236970 Content Loss: 0.041054

run [1250]:
Style Loss : 0.233981 Content Loss: 0.041102

run [1300]:
Style Loss : 0.231114 Content Loss: 0.041139

run [1350]:
Style Loss : 0.228565 Content Loss: 0.041177

run [1400]:
Style Loss : 0.226301 Content Loss: 0.041210

run [1450]:
Style Loss : 0.224136 Content Loss: 0.041237

run [1500]:
Style Loss : 0.222015 Content Loss: 0.041273

run [1550]:
Style Loss : 0.219922 Content Loss: 0.041318

run [1600]:
Style Loss : 0.217786 Content Loss: 0.041358

run [1650]:
Style Loss : 0.215690 Content Loss: 0.041418

run [1700]:
Style Loss : 0.213868 Content Loss: 0.041464

run [1750]:
Style Loss : 0.212106 Content Loss: 0.041517

run [1800]:
Style Loss : 0.210481 Content Loss: 0.041560

run [1850]:
Style Loss : 0.209116 Content Loss: 0.041592

run [1900]:
Style Loss : 0.207821 Content Loss: 0.041626

run [1950]:
Style Loss : 0.206647 Content Loss: 0.041657

run [2000]:
Style Loss : 0.205612 Content Loss: 0.041695

run [2050]:
Style Loss : 0.204563 Content Loss: 0.041730

run [2100]:
Style Loss : 0.203550 Content Loss: 0.041765

run [2150]:
Style Loss : 0.202554 Content Loss: 0.041799

run [2200]:
Style Loss : 0.201664 Content Loss: 0.041829

run [2250]:
Style Loss : 0.200770 Content Loss: 0.041859

run [2300]:
Style Loss : 0.199904 Content Loss: 0.041887

run [2350]:
Style Loss : 0.199036 Content Loss: 0.041918

run [2400]:
Style Loss : 0.198251 Content Loss: 0.041946

run [2450]:
Style Loss : 0.197500 Content Loss: 0.041977

run [2500]:
Style Loss : 0.196726 Content Loss: 0.042004

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.162783 Content Loss: 0.010704

run [100]:
Style Loss : 0.313215 Content Loss: 0.025545

run [150]:
Style Loss : 0.189757 Content Loss: 0.028896

run [200]:
Style Loss : 0.138689 Content Loss: 0.030288

run [250]:
Style Loss : 0.113820 Content Loss: 0.030813

run [300]:
Style Loss : 0.099873 Content Loss: 0.031221

run [350]:
Style Loss : 0.091312 Content Loss: 0.031143

run [400]:
Style Loss : 0.084490 Content Loss: 0.031034

run [450]:
Style Loss : 0.078943 Content Loss: 0.030992

run [500]:
Style Loss : 0.074753 Content Loss: 0.030766

run [550]:
Style Loss : 0.070971 Content Loss: 0.030645

run [600]:
Style Loss : 0.068029 Content Loss: 0.030513

run [650]:
Style Loss : 0.065173 Content Loss: 0.030396

run [700]:
Style Loss : 0.062706 Content Loss: 0.030355

run [750]:
Style Loss : 0.060621 Content Loss: 0.030307

run [800]:
Style Loss : 0.058874 Content Loss: 0.030216

run [850]:
Style Loss : 0.057314 Content Loss: 0.030141

run [900]:
Style Loss : 0.055976 Content Loss: 0.030035

run [950]:
Style Loss : 0.054703 Content Loss: 0.029943

run [1000]:
Style Loss : 0.053626 Content Loss: 0.029863

run [1050]:
Style Loss : 0.052724 Content Loss: 0.029763

run [1100]:
Style Loss : 0.051773 Content Loss: 0.029677

run [1150]:
Style Loss : 0.050897 Content Loss: 0.029625

run [1200]:
Style Loss : 0.050141 Content Loss: 0.029575

run [1250]:
Style Loss : 0.049393 Content Loss: 0.029539

run [1300]:
Style Loss : 0.048719 Content Loss: 0.029496

run [1350]:
Style Loss : 0.048126 Content Loss: 0.029461

run [1400]:
Style Loss : 0.047614 Content Loss: 0.029425

run [1450]:
Style Loss : 0.047138 Content Loss: 0.029370

run [1500]:
Style Loss : 0.046695 Content Loss: 0.029324

run [1550]:
Style Loss : 0.046245 Content Loss: 0.029302

run [1600]:
Style Loss : 0.045847 Content Loss: 0.029273

run [1650]:
Style Loss : 0.045485 Content Loss: 0.029245

run [1700]:
Style Loss : 0.045121 Content Loss: 0.029226

run [1750]:
Style Loss : 0.044789 Content Loss: 0.029203

run [1800]:
Style Loss : 0.044497 Content Loss: 0.029178

run [1850]:
Style Loss : 0.044246 Content Loss: 0.029153

run [1900]:
Style Loss : 0.044015 Content Loss: 0.029124

run [1950]:
Style Loss : 0.043779 Content Loss: 0.029108

run [2000]:
Style Loss : 0.043566 Content Loss: 0.029088

run [2050]:
Style Loss : 0.043356 Content Loss: 0.029066

run [2100]:
Style Loss : 0.043173 Content Loss: 0.029050

run [2150]:
Style Loss : 0.042992 Content Loss: 0.029033

run [2200]:
Style Loss : 0.042836 Content Loss: 0.029014

run [2250]:
Style Loss : 0.042695 Content Loss: 0.028992

run [2300]:
Style Loss : 0.042551 Content Loss: 0.028982

run [2350]:
Style Loss : 0.042426 Content Loss: 0.028970

run [2400]:
Style Loss : 0.042313 Content Loss: 0.028952

run [2450]:
Style Loss : 0.042203 Content Loss: 0.028937

run [2500]:
Style Loss : 0.042090 Content Loss: 0.028927

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.984356 Content Loss: 0.008240

run [100]:
Style Loss : 0.821591 Content Loss: 0.018616

run [150]:
Style Loss : 0.500097 Content Loss: 0.025099

run [200]:
Style Loss : 0.375918 Content Loss: 0.029451

run [250]:
Style Loss : 0.310996 Content Loss: 0.031492

run [300]:
Style Loss : 0.270181 Content Loss: 0.032857

run [350]:
Style Loss : 0.245245 Content Loss: 0.033451

run [400]:
Style Loss : 0.229222 Content Loss: 0.034113

run [450]:
Style Loss : 0.217932 Content Loss: 0.034351

run [500]:
Style Loss : 0.209486 Content Loss: 0.034619

run [550]:
Style Loss : 0.203347 Content Loss: 0.034711

run [600]:
Style Loss : 0.198398 Content Loss: 0.034690

run [650]:
Style Loss : 0.194357 Content Loss: 0.034684

run [700]:
Style Loss : 0.190609 Content Loss: 0.034692

run [750]:
Style Loss : 0.187350 Content Loss: 0.034702

run [800]:
Style Loss : 0.184536 Content Loss: 0.034708

run [850]:
Style Loss : 0.181874 Content Loss: 0.034722

run [900]:
Style Loss : 0.179853 Content Loss: 0.034717

run [950]:
Style Loss : 0.178194 Content Loss: 0.034702

run [1000]:
Style Loss : 0.176745 Content Loss: 0.034687

run [1050]:
Style Loss : 0.175485 Content Loss: 0.034672

run [1100]:
Style Loss : 0.174277 Content Loss: 0.034644

run [1150]:
Style Loss : 0.173113 Content Loss: 0.034627

run [1200]:
Style Loss : 0.171899 Content Loss: 0.034608

run [1250]:
Style Loss : 0.170883 Content Loss: 0.034597

run [1300]:
Style Loss : 0.169968 Content Loss: 0.034586

run [1350]:
Style Loss : 0.169128 Content Loss: 0.034585

run [1400]:
Style Loss : 0.168379 Content Loss: 0.034588

run [1450]:
Style Loss : 0.167691 Content Loss: 0.034594

run [1500]:
Style Loss : 0.167076 Content Loss: 0.034595

run [1550]:
Style Loss : 0.166494 Content Loss: 0.034598

run [1600]:
Style Loss : 0.165935 Content Loss: 0.034600

run [1650]:
Style Loss : 0.165454 Content Loss: 0.034597

run [1700]:
Style Loss : 0.165025 Content Loss: 0.034594

run [1750]:
Style Loss : 0.164579 Content Loss: 0.034597

run [1800]:
Style Loss : 0.164162 Content Loss: 0.034597

run [1850]:
Style Loss : 0.163785 Content Loss: 0.034598

run [1900]:
Style Loss : 0.163405 Content Loss: 0.034600

run [1950]:
Style Loss : 0.163046 Content Loss: 0.034605

run [2000]:
Style Loss : 0.162690 Content Loss: 0.034616

run [2050]:
Style Loss : 0.162372 Content Loss: 0.034623

run [2100]:
Style Loss : 0.162069 Content Loss: 0.034627

run [2150]:
Style Loss : 0.161771 Content Loss: 0.034628

run [2200]:
Style Loss : 0.161488 Content Loss: 0.034624

run [2250]:
Style Loss : 0.161220 Content Loss: 0.034624

run [2300]:
Style Loss : 0.160919 Content Loss: 0.034628

run [2350]:
Style Loss : 0.160665 Content Loss: 0.034630

run [2400]:
Style Loss : 0.160447 Content Loss: 0.034631

run [2450]:
Style Loss : 0.160228 Content Loss: 0.034634

run [2500]:
Style Loss : 0.160028 Content Loss: 0.034636

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.992350 Content Loss: 0.007082

run [100]:
Style Loss : 1.957654 Content Loss: 0.012630

run [150]:
Style Loss : 1.282884 Content Loss: 0.018704

run [200]:
Style Loss : 0.964610 Content Loss: 0.023643

run [250]:
Style Loss : 0.795619 Content Loss: 0.026937

run [300]:
Style Loss : 0.692530 Content Loss: 0.028869

run [350]:
Style Loss : 0.622454 Content Loss: 0.030530

run [400]:
Style Loss : 0.575153 Content Loss: 0.031907

run [450]:
Style Loss : 0.542844 Content Loss: 0.033007

run [500]:
Style Loss : 0.518360 Content Loss: 0.033955

run [550]:
Style Loss : 0.499510 Content Loss: 0.034754

run [600]:
Style Loss : 0.485334 Content Loss: 0.035303

run [650]:
Style Loss : 0.473167 Content Loss: 0.035807

run [700]:
Style Loss : 0.461839 Content Loss: 0.036209

run [750]:
Style Loss : 0.451357 Content Loss: 0.036489

run [800]:
Style Loss : 0.442727 Content Loss: 0.036725

run [850]:
Style Loss : 0.435864 Content Loss: 0.036906

run [900]:
Style Loss : 0.429462 Content Loss: 0.037080

run [950]:
Style Loss : 0.422648 Content Loss: 0.037230

run [1000]:
Style Loss : 0.416695 Content Loss: 0.037343

run [1050]:
Style Loss : 0.412020 Content Loss: 0.037452

run [1100]:
Style Loss : 0.408323 Content Loss: 0.037541

run [1150]:
Style Loss : 0.405119 Content Loss: 0.037641

run [1200]:
Style Loss : 0.401802 Content Loss: 0.037719

run [1250]:
Style Loss : 0.398827 Content Loss: 0.037803

run [1300]:
Style Loss : 0.396261 Content Loss: 0.037876

run [1350]:
Style Loss : 0.393835 Content Loss: 0.037938

run [1400]:
Style Loss : 0.391747 Content Loss: 0.038003

run [1450]:
Style Loss : 0.389727 Content Loss: 0.038069

run [1500]:
Style Loss : 0.387780 Content Loss: 0.038132

run [1550]:
Style Loss : 0.385723 Content Loss: 0.038219

run [1600]:
Style Loss : 0.384031 Content Loss: 0.038282

run [1650]:
Style Loss : 0.382418 Content Loss: 0.038336

run [1700]:
Style Loss : 0.380826 Content Loss: 0.038389

run [1750]:
Style Loss : 0.379313 Content Loss: 0.038436

run [1800]:
Style Loss : 0.377939 Content Loss: 0.038458

run [1850]:
Style Loss : 0.376588 Content Loss: 0.038485

run [1900]:
Style Loss : 0.375412 Content Loss: 0.038502

run [1950]:
Style Loss : 0.374274 Content Loss: 0.038533

run [2000]:
Style Loss : 0.373246 Content Loss: 0.038554

run [2050]:
Style Loss : 0.372203 Content Loss: 0.038579

run [2100]:
Style Loss : 0.371253 Content Loss: 0.038600

run [2150]:
Style Loss : 0.370355 Content Loss: 0.038615

run [2200]:
Style Loss : 0.369569 Content Loss: 0.038632

run [2250]:
Style Loss : 0.368774 Content Loss: 0.038654

run [2300]:
Style Loss : 0.368022 Content Loss: 0.038674

run [2350]:
Style Loss : 0.367263 Content Loss: 0.038695

run [2400]:
Style Loss : 0.366522 Content Loss: 0.038713

run [2450]:
Style Loss : 0.365727 Content Loss: 0.038735

run [2500]:
Style Loss : 0.364965 Content Loss: 0.038755

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 6.402964 Content Loss: 0.007878

run [100]:
Style Loss : 3.236898 Content Loss: 0.013446

run [150]:
Style Loss : 2.130720 Content Loss: 0.017967

run [200]:
Style Loss : 1.653368 Content Loss: 0.021777

run [250]:
Style Loss : 1.388070 Content Loss: 0.024921

run [300]:
Style Loss : 1.216257 Content Loss: 0.027951

run [350]:
Style Loss : 1.093889 Content Loss: 0.030490

run [400]:
Style Loss : 1.003647 Content Loss: 0.032787

run [450]:
Style Loss : 0.932756 Content Loss: 0.035041

run [500]:
Style Loss : 0.875970 Content Loss: 0.036922

run [550]:
Style Loss : 0.831201 Content Loss: 0.038480

run [600]:
Style Loss : 0.794274 Content Loss: 0.039942

run [650]:
Style Loss : 0.764085 Content Loss: 0.041165

run [700]:
Style Loss : 0.741026 Content Loss: 0.042137

run [750]:
Style Loss : 0.722158 Content Loss: 0.042991

run [800]:
Style Loss : 0.706436 Content Loss: 0.043737

run [850]:
Style Loss : 0.693360 Content Loss: 0.044331

run [900]:
Style Loss : 0.682006 Content Loss: 0.044920

run [950]:
Style Loss : 0.672812 Content Loss: 0.045380

run [1000]:
Style Loss : 0.664762 Content Loss: 0.045820

run [1050]:
Style Loss : 0.657657 Content Loss: 0.046164

run [1100]:
Style Loss : 0.652047 Content Loss: 0.046461

run [1150]:
Style Loss : 0.646694 Content Loss: 0.046767

run [1200]:
Style Loss : 0.641930 Content Loss: 0.047011

run [1250]:
Style Loss : 0.637434 Content Loss: 0.047241

run [1300]:
Style Loss : 0.633148 Content Loss: 0.047468

run [1350]:
Style Loss : 0.629362 Content Loss: 0.047650

run [1400]:
Style Loss : 0.625879 Content Loss: 0.047811

run [1450]:
Style Loss : 0.622654 Content Loss: 0.047970

run [1500]:
Style Loss : 0.619491 Content Loss: 0.048138

run [1550]:
Style Loss : 0.616500 Content Loss: 0.048289

run [1600]:
Style Loss : 0.613502 Content Loss: 0.048439

run [1650]:
Style Loss : 0.610558 Content Loss: 0.048557

run [1700]:
Style Loss : 0.607790 Content Loss: 0.048667

run [1750]:
Style Loss : 0.605304 Content Loss: 0.048766

run [1800]:
Style Loss : 0.602852 Content Loss: 0.048879

run [1850]:
Style Loss : 0.600291 Content Loss: 0.048999

run [1900]:
Style Loss : 0.597924 Content Loss: 0.049095

run [1950]:
Style Loss : 0.595374 Content Loss: 0.049198

run [2000]:
Style Loss : 0.593037 Content Loss: 0.049294

run [2050]:
Style Loss : 0.590927 Content Loss: 0.049384

run [2100]:
Style Loss : 0.589074 Content Loss: 0.049463

run [2150]:
Style Loss : 0.587283 Content Loss: 0.049543

run [2200]:
Style Loss : 0.585369 Content Loss: 0.049627

run [2250]:
Style Loss : 0.583653 Content Loss: 0.049701

run [2300]:
Style Loss : 0.581866 Content Loss: 0.049778

run [2350]:
Style Loss : 0.580196 Content Loss: 0.049847

run [2400]:
Style Loss : 0.578489 Content Loss: 0.049924

run [2450]:
Style Loss : 0.576822 Content Loss: 0.049999

run [2500]:
Style Loss : 0.575218 Content Loss: 0.050071

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 5.588295 Content Loss: 0.008890

run [100]:
Style Loss : 3.569993 Content Loss: 0.009580

run [150]:
Style Loss : 2.872601 Content Loss: 0.011097

run [200]:
Style Loss : 2.441047 Content Loss: 0.012582

run [250]:
Style Loss : 2.162748 Content Loss: 0.014277

run [300]:
Style Loss : 1.974790 Content Loss: 0.015890

run [350]:
Style Loss : 1.834356 Content Loss: 0.017242

run [400]:
Style Loss : 1.739780 Content Loss: 0.018285

run [450]:
Style Loss : 1.663913 Content Loss: 0.019428

run [500]:
Style Loss : 1.600235 Content Loss: 0.020225

run [550]:
Style Loss : 1.544486 Content Loss: 0.021012

run [600]:
Style Loss : 1.493427 Content Loss: 0.021693

run [650]:
Style Loss : 1.450527 Content Loss: 0.022252

run [700]:
Style Loss : 1.410290 Content Loss: 0.022892

run [750]:
Style Loss : 1.371966 Content Loss: 0.023380

run [800]:
Style Loss : 1.333792 Content Loss: 0.023803

run [850]:
Style Loss : 1.298376 Content Loss: 0.024311

run [900]:
Style Loss : 1.268308 Content Loss: 0.024588

run [950]:
Style Loss : 1.243859 Content Loss: 0.024922

run [1000]:
Style Loss : 1.222068 Content Loss: 0.025264

run [1050]:
Style Loss : 1.202028 Content Loss: 0.025603

run [1100]:
Style Loss : 1.185248 Content Loss: 0.025903

run [1150]:
Style Loss : 1.168810 Content Loss: 0.026203

run [1200]:
Style Loss : 1.154609 Content Loss: 0.026486

run [1250]:
Style Loss : 1.141084 Content Loss: 0.026740

run [1300]:
Style Loss : 1.126640 Content Loss: 0.026952

run [1350]:
Style Loss : 1.113319 Content Loss: 0.027192

run [1400]:
Style Loss : 1.100170 Content Loss: 0.027377

run [1450]:
Style Loss : 1.086581 Content Loss: 0.027546

run [1500]:
Style Loss : 1.073246 Content Loss: 0.027735

run [1550]:
Style Loss : 1.058592 Content Loss: 0.027931

run [1600]:
Style Loss : 1.045525 Content Loss: 0.028090

run [1650]:
Style Loss : 1.034654 Content Loss: 0.028270

run [1700]:
Style Loss : 1.024068 Content Loss: 0.028429

run [1750]:
Style Loss : 1.013875 Content Loss: 0.028623

run [1800]:
Style Loss : 1.003414 Content Loss: 0.028786

run [1850]:
Style Loss : 0.993945 Content Loss: 0.028965

run [1900]:
Style Loss : 0.985162 Content Loss: 0.029131

run [1950]:
Style Loss : 0.976900 Content Loss: 0.029275

run [2000]:
Style Loss : 0.969315 Content Loss: 0.029470

run [2050]:
Style Loss : 0.962260 Content Loss: 0.029673

run [2100]:
Style Loss : 0.955183 Content Loss: 0.029848

run [2150]:
Style Loss : 0.948646 Content Loss: 0.030023

run [2200]:
Style Loss : 0.942277 Content Loss: 0.030196

run [2250]:
Style Loss : 0.935837 Content Loss: 0.030337

run [2300]:
Style Loss : 0.928988 Content Loss: 0.030493

run [2350]:
Style Loss : 0.922854 Content Loss: 0.030630

run [2400]:
Style Loss : 0.917442 Content Loss: 0.030754

run [2450]:
Style Loss : 0.912088 Content Loss: 0.030897

run [2500]:
Style Loss : 0.907416 Content Loss: 0.031009

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.908877 Content Loss: 0.002642

run [100]:
Style Loss : 1.152107 Content Loss: 0.003587

run [150]:
Style Loss : 0.846320 Content Loss: 0.004468

run [200]:
Style Loss : 0.688232 Content Loss: 0.005588

run [250]:
Style Loss : 0.600856 Content Loss: 0.006629

run [300]:
Style Loss : 0.542900 Content Loss: 0.007467

run [350]:
Style Loss : 0.503210 Content Loss: 0.008236

run [400]:
Style Loss : 0.475262 Content Loss: 0.008782

run [450]:
Style Loss : 0.453125 Content Loss: 0.009239

run [500]:
Style Loss : 0.436379 Content Loss: 0.009595

run [550]:
Style Loss : 0.423396 Content Loss: 0.009930

run [600]:
Style Loss : 0.413756 Content Loss: 0.010184

run [650]:
Style Loss : 0.405983 Content Loss: 0.010464

run [700]:
Style Loss : 0.399011 Content Loss: 0.010707

run [750]:
Style Loss : 0.392858 Content Loss: 0.010921

run [800]:
Style Loss : 0.387501 Content Loss: 0.011116

run [850]:
Style Loss : 0.382466 Content Loss: 0.011323

run [900]:
Style Loss : 0.377890 Content Loss: 0.011506

run [950]:
Style Loss : 0.373971 Content Loss: 0.011661

run [1000]:
Style Loss : 0.370928 Content Loss: 0.011781

run [1050]:
Style Loss : 0.368314 Content Loss: 0.011898

run [1100]:
Style Loss : 0.366053 Content Loss: 0.012004

run [1150]:
Style Loss : 0.363851 Content Loss: 0.012103

run [1200]:
Style Loss : 0.361981 Content Loss: 0.012192

run [1250]:
Style Loss : 0.360402 Content Loss: 0.012261

run [1300]:
Style Loss : 0.358971 Content Loss: 0.012331

run [1350]:
Style Loss : 0.357518 Content Loss: 0.012398

run [1400]:
Style Loss : 0.356041 Content Loss: 0.012462

run [1450]:
Style Loss : 0.354603 Content Loss: 0.012523

run [1500]:
Style Loss : 0.353337 Content Loss: 0.012575

run [1550]:
Style Loss : 0.352051 Content Loss: 0.012633

run [1600]:
Style Loss : 0.350774 Content Loss: 0.012691

run [1650]:
Style Loss : 0.349579 Content Loss: 0.012738

run [1700]:
Style Loss : 0.348531 Content Loss: 0.012781

run [1750]:
Style Loss : 0.347375 Content Loss: 0.012825

run [1800]:
Style Loss : 0.346327 Content Loss: 0.012862

run [1850]:
Style Loss : 0.345292 Content Loss: 0.012904

run [1900]:
Style Loss : 0.344221 Content Loss: 0.012939

run [1950]:
Style Loss : 0.343277 Content Loss: 0.012972

run [2000]:
Style Loss : 0.342431 Content Loss: 0.013000

run [2050]:
Style Loss : 0.341614 Content Loss: 0.013032

run [2100]:
Style Loss : 0.340888 Content Loss: 0.013064

run [2150]:
Style Loss : 0.340170 Content Loss: 0.013103

run [2200]:
Style Loss : 0.339513 Content Loss: 0.013133

run [2250]:
Style Loss : 0.338809 Content Loss: 0.013169

run [2300]:
Style Loss : 0.338166 Content Loss: 0.013200

run [2350]:
Style Loss : 0.337551 Content Loss: 0.013235

run [2400]:
Style Loss : 0.336849 Content Loss: 0.013265

run [2450]:
Style Loss : 0.336189 Content Loss: 0.013291

run [2500]:
Style Loss : 0.335610 Content Loss: 0.013313

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.878267 Content Loss: 0.003283

run [100]:
Style Loss : 1.187643 Content Loss: 0.004523

run [150]:
Style Loss : 0.884656 Content Loss: 0.006558

run [200]:
Style Loss : 0.724050 Content Loss: 0.008721

run [250]:
Style Loss : 0.625708 Content Loss: 0.010211

run [300]:
Style Loss : 0.562024 Content Loss: 0.011122

run [350]:
Style Loss : 0.516975 Content Loss: 0.011750

run [400]:
Style Loss : 0.485531 Content Loss: 0.012242

run [450]:
Style Loss : 0.461090 Content Loss: 0.012727

run [500]:
Style Loss : 0.441303 Content Loss: 0.013127

run [550]:
Style Loss : 0.424845 Content Loss: 0.013500

run [600]:
Style Loss : 0.411450 Content Loss: 0.013811

run [650]:
Style Loss : 0.400446 Content Loss: 0.014114

run [700]:
Style Loss : 0.391117 Content Loss: 0.014385

run [750]:
Style Loss : 0.383139 Content Loss: 0.014649

run [800]:
Style Loss : 0.376204 Content Loss: 0.014871

run [850]:
Style Loss : 0.370177 Content Loss: 0.015085

run [900]:
Style Loss : 0.364574 Content Loss: 0.015270

run [950]:
Style Loss : 0.359517 Content Loss: 0.015447

run [1000]:
Style Loss : 0.354794 Content Loss: 0.015623

run [1050]:
Style Loss : 0.350587 Content Loss: 0.015794

run [1100]:
Style Loss : 0.345770 Content Loss: 0.015981

run [1150]:
Style Loss : 0.341303 Content Loss: 0.016119

run [1200]:
Style Loss : 0.337171 Content Loss: 0.016267

run [1250]:
Style Loss : 0.333440 Content Loss: 0.016397

run [1300]:
Style Loss : 0.329944 Content Loss: 0.016551

run [1350]:
Style Loss : 0.326439 Content Loss: 0.016663

run [1400]:
Style Loss : 0.322995 Content Loss: 0.016779

run [1450]:
Style Loss : 0.319503 Content Loss: 0.016896

run [1500]:
Style Loss : 0.316225 Content Loss: 0.016999

run [1550]:
Style Loss : 0.313088 Content Loss: 0.017073

run [1600]:
Style Loss : 0.309626 Content Loss: 0.017180

run [1650]:
Style Loss : 0.306216 Content Loss: 0.017260

run [1700]:
Style Loss : 0.302714 Content Loss: 0.017352

run [1750]:
Style Loss : 0.298550 Content Loss: 0.017421

run [1800]:
Style Loss : 0.294893 Content Loss: 0.017488

run [1850]:
Style Loss : 0.291948 Content Loss: 0.017559

run [1900]:
Style Loss : 0.289091 Content Loss: 0.017627

run [1950]:
Style Loss : 0.286535 Content Loss: 0.017702

run [2000]:
Style Loss : 0.284229 Content Loss: 0.017772

run [2050]:
Style Loss : 0.281999 Content Loss: 0.017838

run [2100]:
Style Loss : 0.279823 Content Loss: 0.017893

run [2150]:
Style Loss : 0.277686 Content Loss: 0.017952

run [2200]:
Style Loss : 0.275911 Content Loss: 0.017998

run [2250]:
Style Loss : 0.274149 Content Loss: 0.018057

run [2300]:
Style Loss : 0.272597 Content Loss: 0.018110

run [2350]:
Style Loss : 0.271157 Content Loss: 0.018164

run [2400]:
Style Loss : 0.269738 Content Loss: 0.018202

run [2450]:
Style Loss : 0.268417 Content Loss: 0.018226

run [2500]:
Style Loss : 0.267371 Content Loss: 0.018286

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.220065 Content Loss: 0.012186

run [100]:
Style Loss : 1.095091 Content Loss: 0.015053

run [150]:
Style Loss : 0.753090 Content Loss: 0.018442

run [200]:
Style Loss : 0.617229 Content Loss: 0.019874

run [250]:
Style Loss : 0.539325 Content Loss: 0.020436

run [300]:
Style Loss : 0.486820 Content Loss: 0.020822

run [350]:
Style Loss : 0.447175 Content Loss: 0.021318

run [400]:
Style Loss : 0.417451 Content Loss: 0.021845

run [450]:
Style Loss : 0.392374 Content Loss: 0.022259

run [500]:
Style Loss : 0.371553 Content Loss: 0.022684

run [550]:
Style Loss : 0.354237 Content Loss: 0.023050

run [600]:
Style Loss : 0.339954 Content Loss: 0.023404

run [650]:
Style Loss : 0.327530 Content Loss: 0.023726

run [700]:
Style Loss : 0.316932 Content Loss: 0.024034

run [750]:
Style Loss : 0.307215 Content Loss: 0.024337

run [800]:
Style Loss : 0.299087 Content Loss: 0.024614

run [850]:
Style Loss : 0.292042 Content Loss: 0.024884

run [900]:
Style Loss : 0.285927 Content Loss: 0.025132

run [950]:
Style Loss : 0.280459 Content Loss: 0.025372

run [1000]:
Style Loss : 0.275239 Content Loss: 0.025578

run [1050]:
Style Loss : 0.270534 Content Loss: 0.025756

run [1100]:
Style Loss : 0.266300 Content Loss: 0.025909

run [1150]:
Style Loss : 0.262530 Content Loss: 0.026040

run [1200]:
Style Loss : 0.259019 Content Loss: 0.026178

run [1250]:
Style Loss : 0.255832 Content Loss: 0.026282

run [1300]:
Style Loss : 0.253060 Content Loss: 0.026376

run [1350]:
Style Loss : 0.250469 Content Loss: 0.026470

run [1400]:
Style Loss : 0.248084 Content Loss: 0.026545

run [1450]:
Style Loss : 0.246056 Content Loss: 0.026625

run [1500]:
Style Loss : 0.244096 Content Loss: 0.026685

run [1550]:
Style Loss : 0.242081 Content Loss: 0.026753

run [1600]:
Style Loss : 0.240121 Content Loss: 0.026809

run [1650]:
Style Loss : 0.238301 Content Loss: 0.026874

run [1700]:
Style Loss : 0.236765 Content Loss: 0.026921

run [1750]:
Style Loss : 0.235253 Content Loss: 0.026966

run [1800]:
Style Loss : 0.233662 Content Loss: 0.027020

run [1850]:
Style Loss : 0.232213 Content Loss: 0.027062

run [1900]:
Style Loss : 0.230830 Content Loss: 0.027098

run [1950]:
Style Loss : 0.229548 Content Loss: 0.027136

run [2000]:
Style Loss : 0.228332 Content Loss: 0.027168

run [2050]:
Style Loss : 0.227244 Content Loss: 0.027201

run [2100]:
Style Loss : 0.226175 Content Loss: 0.027234

run [2150]:
Style Loss : 0.225226 Content Loss: 0.027255

run [2200]:
Style Loss : 0.224317 Content Loss: 0.027265

run [2250]:
Style Loss : 0.223431 Content Loss: 0.027299

run [2300]:
Style Loss : 0.222602 Content Loss: 0.027312

run [2350]:
Style Loss : 0.221810 Content Loss: 0.027327

run [2400]:
Style Loss : 0.220998 Content Loss: 0.027329

run [2450]:
Style Loss : 0.220237 Content Loss: 0.027349

run [2500]:
Style Loss : 0.219516 Content Loss: 0.027367

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.090955 Content Loss: 0.009106

run [100]:
Style Loss : 1.152394 Content Loss: 0.011312

run [150]:
Style Loss : 0.791338 Content Loss: 0.014459

run [200]:
Style Loss : 0.606024 Content Loss: 0.017304

run [250]:
Style Loss : 0.507071 Content Loss: 0.019466

run [300]:
Style Loss : 0.445480 Content Loss: 0.020926

run [350]:
Style Loss : 0.403891 Content Loss: 0.021954

run [400]:
Style Loss : 0.374504 Content Loss: 0.022786

run [450]:
Style Loss : 0.351010 Content Loss: 0.023656

run [500]:
Style Loss : 0.332617 Content Loss: 0.024280

run [550]:
Style Loss : 0.318020 Content Loss: 0.024818

run [600]:
Style Loss : 0.306172 Content Loss: 0.025286

run [650]:
Style Loss : 0.295606 Content Loss: 0.025748

run [700]:
Style Loss : 0.285507 Content Loss: 0.026123

run [750]:
Style Loss : 0.277029 Content Loss: 0.026503

run [800]:
Style Loss : 0.269867 Content Loss: 0.026880

run [850]:
Style Loss : 0.263720 Content Loss: 0.027178

run [900]:
Style Loss : 0.258347 Content Loss: 0.027463

run [950]:
Style Loss : 0.253803 Content Loss: 0.027693

run [1000]:
Style Loss : 0.249746 Content Loss: 0.027894

run [1050]:
Style Loss : 0.245796 Content Loss: 0.028054

run [1100]:
Style Loss : 0.242079 Content Loss: 0.028191

run [1150]:
Style Loss : 0.238592 Content Loss: 0.028316

run [1200]:
Style Loss : 0.235464 Content Loss: 0.028428

run [1250]:
Style Loss : 0.232687 Content Loss: 0.028492

run [1300]:
Style Loss : 0.229929 Content Loss: 0.028575

run [1350]:
Style Loss : 0.227405 Content Loss: 0.028657

run [1400]:
Style Loss : 0.225180 Content Loss: 0.028709

run [1450]:
Style Loss : 0.223341 Content Loss: 0.028748

run [1500]:
Style Loss : 0.221429 Content Loss: 0.028774

run [1550]:
Style Loss : 0.219796 Content Loss: 0.028821

run [1600]:
Style Loss : 0.218303 Content Loss: 0.028855

run [1650]:
Style Loss : 0.216925 Content Loss: 0.028879

run [1700]:
Style Loss : 0.215611 Content Loss: 0.028890

run [1750]:
Style Loss : 0.214316 Content Loss: 0.028898

run [1800]:
Style Loss : 0.213038 Content Loss: 0.028905

run [1850]:
Style Loss : 0.211839 Content Loss: 0.028913

run [1900]:
Style Loss : 0.210739 Content Loss: 0.028931

run [1950]:
Style Loss : 0.209662 Content Loss: 0.028956

run [2000]:
Style Loss : 0.208760 Content Loss: 0.028970

run [2050]:
Style Loss : 0.207890 Content Loss: 0.029004

run [2100]:
Style Loss : 0.207063 Content Loss: 0.029014

run [2150]:
Style Loss : 0.206262 Content Loss: 0.029014

run [2200]:
Style Loss : 0.205527 Content Loss: 0.029023

run [2250]:
Style Loss : 0.204835 Content Loss: 0.029034

run [2300]:
Style Loss : 0.204103 Content Loss: 0.029040

run [2350]:
Style Loss : 0.203401 Content Loss: 0.029046

run [2400]:
Style Loss : 0.202746 Content Loss: 0.029056

run [2450]:
Style Loss : 0.202080 Content Loss: 0.029070

run [2500]:
Style Loss : 0.201450 Content Loss: 0.029083

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.999321 Content Loss: 0.003069

run [100]:
Style Loss : 1.188320 Content Loss: 0.004092

run [150]:
Style Loss : 0.907797 Content Loss: 0.005308

run [200]:
Style Loss : 0.749743 Content Loss: 0.006605

run [250]:
Style Loss : 0.656685 Content Loss: 0.007764

run [300]:
Style Loss : 0.594154 Content Loss: 0.008709

run [350]:
Style Loss : 0.545652 Content Loss: 0.009458

run [400]:
Style Loss : 0.505209 Content Loss: 0.009973

run [450]:
Style Loss : 0.474833 Content Loss: 0.010334

run [500]:
Style Loss : 0.450958 Content Loss: 0.010760

run [550]:
Style Loss : 0.429966 Content Loss: 0.011147

run [600]:
Style Loss : 0.413420 Content Loss: 0.011529

run [650]:
Style Loss : 0.400835 Content Loss: 0.011864

run [700]:
Style Loss : 0.389501 Content Loss: 0.012181

run [750]:
Style Loss : 0.379615 Content Loss: 0.012585

run [800]:
Style Loss : 0.370334 Content Loss: 0.012805

run [850]:
Style Loss : 0.362427 Content Loss: 0.013073

run [900]:
Style Loss : 0.355081 Content Loss: 0.013322

run [950]:
Style Loss : 0.348496 Content Loss: 0.013595

run [1000]:
Style Loss : 0.358787 Content Loss: 0.014072

run [1050]:
Style Loss : 0.338247 Content Loss: 0.014066

run [1100]:
Style Loss : 0.331481 Content Loss: 0.014272

run [1150]:
Style Loss : 0.324793 Content Loss: 0.014446

run [1200]:
Style Loss : 0.323749 Content Loss: 0.014891

run [1250]:
Style Loss : 0.313852 Content Loss: 0.014965

run [1300]:
Style Loss : 0.307570 Content Loss: 0.015148

run [1350]:
Style Loss : 0.302480 Content Loss: 0.015347

run [1400]:
Style Loss : 0.296977 Content Loss: 0.015555

run [1450]:
Style Loss : 0.291078 Content Loss: 0.015813

run [1500]:
Style Loss : 0.285927 Content Loss: 0.016071

run [1550]:
Style Loss : 0.280730 Content Loss: 0.016327

run [1600]:
Style Loss : 0.275750 Content Loss: 0.016565

run [1650]:
Style Loss : 0.270919 Content Loss: 0.016817

run [1700]:
Style Loss : 0.266099 Content Loss: 0.017118

run [1750]:
Style Loss : 0.262129 Content Loss: 0.017370

run [1800]:
Style Loss : 0.257638 Content Loss: 0.017638

run [1850]:
Style Loss : 0.253255 Content Loss: 0.017882

run [1900]:
Style Loss : 0.249064 Content Loss: 0.018128

run [1950]:
Style Loss : 0.245305 Content Loss: 0.018366

run [2000]:
Style Loss : 0.241984 Content Loss: 0.018596

run [2050]:
Style Loss : 0.239044 Content Loss: 0.018897

run [2100]:
Style Loss : 0.236064 Content Loss: 0.019142

run [2150]:
Style Loss : 0.233116 Content Loss: 0.019429

run [2200]:
Style Loss : 0.230335 Content Loss: 0.019678

run [2250]:
Style Loss : 0.228174 Content Loss: 0.020047

run [2300]:
Style Loss : 0.225628 Content Loss: 0.020389

run [2350]:
Style Loss : 0.223165 Content Loss: 0.020641

run [2400]:
Style Loss : 0.221796 Content Loss: 0.021048

run [2450]:
Style Loss : 0.219770 Content Loss: 0.021405

run [2500]:
Style Loss : 0.217056 Content Loss: 0.021551

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.622161 Content Loss: 0.014277

run [100]:
Style Loss : 1.123818 Content Loss: 0.016413

run [150]:
Style Loss : 0.735794 Content Loss: 0.018663

run [200]:
Style Loss : 0.582208 Content Loss: 0.020177

run [250]:
Style Loss : 0.502129 Content Loss: 0.020769

run [300]:
Style Loss : 0.450024 Content Loss: 0.021177

run [350]:
Style Loss : 0.414340 Content Loss: 0.021593

run [400]:
Style Loss : 0.389570 Content Loss: 0.022016

run [450]:
Style Loss : 0.371185 Content Loss: 0.022348

run [500]:
Style Loss : 0.356222 Content Loss: 0.022622

run [550]:
Style Loss : 0.343610 Content Loss: 0.022862

run [600]:
Style Loss : 0.333285 Content Loss: 0.023113

run [650]:
Style Loss : 0.325460 Content Loss: 0.023303

run [700]:
Style Loss : 0.318450 Content Loss: 0.023495

run [750]:
Style Loss : 0.312666 Content Loss: 0.023635

run [800]:
Style Loss : 0.307245 Content Loss: 0.023773

run [850]:
Style Loss : 0.302155 Content Loss: 0.023892

run [900]:
Style Loss : 0.297870 Content Loss: 0.023995

run [950]:
Style Loss : 0.293828 Content Loss: 0.024123

run [1000]:
Style Loss : 0.290226 Content Loss: 0.024223

run [1050]:
Style Loss : 0.286956 Content Loss: 0.024328

run [1100]:
Style Loss : 0.284102 Content Loss: 0.024402

run [1150]:
Style Loss : 0.281653 Content Loss: 0.024464

run [1200]:
Style Loss : 0.279474 Content Loss: 0.024548

run [1250]:
Style Loss : 0.277293 Content Loss: 0.024601

run [1300]:
Style Loss : 0.275378 Content Loss: 0.024661

run [1350]:
Style Loss : 0.273645 Content Loss: 0.024705

run [1400]:
Style Loss : 0.271860 Content Loss: 0.024750

run [1450]:
Style Loss : 0.270118 Content Loss: 0.024784

run [1500]:
Style Loss : 0.268505 Content Loss: 0.024823

run [1550]:
Style Loss : 0.266926 Content Loss: 0.024874

run [1600]:
Style Loss : 0.265339 Content Loss: 0.024905

run [1650]:
Style Loss : 0.263791 Content Loss: 0.024949

run [1700]:
Style Loss : 0.262320 Content Loss: 0.025003

run [1750]:
Style Loss : 0.260910 Content Loss: 0.025036

run [1800]:
Style Loss : 0.259341 Content Loss: 0.025085

run [1850]:
Style Loss : 0.257968 Content Loss: 0.025117

run [1900]:
Style Loss : 0.255912 Content Loss: 0.025170

run [1950]:
Style Loss : 0.253961 Content Loss: 0.025198

run [2000]:
Style Loss : 0.252235 Content Loss: 0.025244

run [2050]:
Style Loss : 0.250477 Content Loss: 0.025276

run [2100]:
Style Loss : 0.248875 Content Loss: 0.025308

run [2150]:
Style Loss : 0.247451 Content Loss: 0.025336

run [2200]:
Style Loss : 0.246206 Content Loss: 0.025368

run [2250]:
Style Loss : 0.245028 Content Loss: 0.025387

run [2300]:
Style Loss : 0.243968 Content Loss: 0.025413

run [2350]:
Style Loss : 0.242990 Content Loss: 0.025437

run [2400]:
Style Loss : 0.242019 Content Loss: 0.025459

run [2450]:
Style Loss : 0.241136 Content Loss: 0.025484

run [2500]:
Style Loss : 0.240309 Content Loss: 0.025503

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.621087 Content Loss: 0.011273

run [100]:
Style Loss : 1.843202 Content Loss: 0.012507

run [150]:
Style Loss : 1.232675 Content Loss: 0.014645

run [200]:
Style Loss : 0.917244 Content Loss: 0.016586

run [250]:
Style Loss : 0.756286 Content Loss: 0.018326

run [300]:
Style Loss : 0.651673 Content Loss: 0.019771

run [350]:
Style Loss : 0.582520 Content Loss: 0.020643

run [400]:
Style Loss : 0.533631 Content Loss: 0.021588

run [450]:
Style Loss : 0.497823 Content Loss: 0.022287

run [500]:
Style Loss : 0.467757 Content Loss: 0.022973

run [550]:
Style Loss : 0.443193 Content Loss: 0.023525

run [600]:
Style Loss : 0.422920 Content Loss: 0.024075

run [650]:
Style Loss : 0.406357 Content Loss: 0.024509

run [700]:
Style Loss : 0.391355 Content Loss: 0.024842

run [750]:
Style Loss : 0.379654 Content Loss: 0.025258

run [800]:
Style Loss : 0.369029 Content Loss: 0.025551

run [850]:
Style Loss : 0.359073 Content Loss: 0.025939

run [900]:
Style Loss : 0.350554 Content Loss: 0.026212

run [950]:
Style Loss : 0.342583 Content Loss: 0.026548

run [1000]:
Style Loss : 0.335003 Content Loss: 0.026821

run [1050]:
Style Loss : 0.328007 Content Loss: 0.027127

run [1100]:
Style Loss : 0.322168 Content Loss: 0.027422

run [1150]:
Style Loss : 0.316821 Content Loss: 0.027722

run [1200]:
Style Loss : 0.311465 Content Loss: 0.027947

run [1250]:
Style Loss : 0.306499 Content Loss: 0.028181

run [1300]:
Style Loss : 0.302095 Content Loss: 0.028434

run [1350]:
Style Loss : 0.297948 Content Loss: 0.028607

run [1400]:
Style Loss : 0.294164 Content Loss: 0.028830

run [1450]:
Style Loss : 0.290317 Content Loss: 0.029029

run [1500]:
Style Loss : 0.286889 Content Loss: 0.029204

run [1550]:
Style Loss : 0.283646 Content Loss: 0.029370

run [1600]:
Style Loss : 0.280656 Content Loss: 0.029533

run [1650]:
Style Loss : 0.277825 Content Loss: 0.029677

run [1700]:
Style Loss : 0.275373 Content Loss: 0.029819

run [1750]:
Style Loss : 0.273055 Content Loss: 0.029966

run [1800]:
Style Loss : 0.270961 Content Loss: 0.030094

run [1850]:
Style Loss : 0.268886 Content Loss: 0.030215

run [1900]:
Style Loss : 0.267165 Content Loss: 0.030368

run [1950]:
Style Loss : 0.265548 Content Loss: 0.030468

run [2000]:
Style Loss : 0.263986 Content Loss: 0.030566

run [2050]:
Style Loss : 0.262594 Content Loss: 0.030666

run [2100]:
Style Loss : 0.261295 Content Loss: 0.030776

run [2150]:
Style Loss : 0.260065 Content Loss: 0.030865

run [2200]:
Style Loss : 0.258875 Content Loss: 0.030965

run [2250]:
Style Loss : 0.257636 Content Loss: 0.031052

run [2300]:
Style Loss : 0.256384 Content Loss: 0.031096

run [2350]:
Style Loss : 0.255292 Content Loss: 0.031180

run [2400]:
Style Loss : 0.254280 Content Loss: 0.031236

run [2450]:
Style Loss : 0.253380 Content Loss: 0.031326

run [2500]:
Style Loss : 0.252468 Content Loss: 0.031398

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.065139 Content Loss: 0.001928

run [100]:
Style Loss : 1.822466 Content Loss: 0.002068

run [150]:
Style Loss : 1.406488 Content Loss: 0.002200

run [200]:
Style Loss : 1.227184 Content Loss: 0.002537

run [250]:
Style Loss : 1.095439 Content Loss: 0.002953

run [300]:
Style Loss : 0.994476 Content Loss: 0.003398

run [350]:
Style Loss : 0.922962 Content Loss: 0.003754

run [400]:
Style Loss : 0.868000 Content Loss: 0.004176

run [450]:
Style Loss : 0.820673 Content Loss: 0.004589

run [500]:
Style Loss : 0.783321 Content Loss: 0.004932

run [550]:
Style Loss : 0.754530 Content Loss: 0.005283

run [600]:
Style Loss : 0.732231 Content Loss: 0.005623

run [650]:
Style Loss : 0.714190 Content Loss: 0.005897

run [700]:
Style Loss : 0.698763 Content Loss: 0.006140

run [750]:
Style Loss : 0.686323 Content Loss: 0.006414

run [800]:
Style Loss : 0.672520 Content Loss: 0.006713

run [850]:
Style Loss : 0.659514 Content Loss: 0.006983

run [900]:
Style Loss : 0.649330 Content Loss: 0.007205

run [950]:
Style Loss : 0.640079 Content Loss: 0.007378

run [1000]:
Style Loss : 0.632022 Content Loss: 0.007548

run [1050]:
Style Loss : 0.624500 Content Loss: 0.007678

run [1100]:
Style Loss : 0.618027 Content Loss: 0.007811

run [1150]:
Style Loss : 0.612404 Content Loss: 0.007921

run [1200]:
Style Loss : 0.607318 Content Loss: 0.008036

run [1250]:
Style Loss : 0.602626 Content Loss: 0.008143

run [1300]:
Style Loss : 0.597975 Content Loss: 0.008220

run [1350]:
Style Loss : 0.594068 Content Loss: 0.008281

run [1400]:
Style Loss : 0.591087 Content Loss: 0.008372

run [1450]:
Style Loss : 0.587937 Content Loss: 0.008416

run [1500]:
Style Loss : 0.585132 Content Loss: 0.008476

run [1550]:
Style Loss : 0.582538 Content Loss: 0.008557

run [1600]:
Style Loss : 0.579910 Content Loss: 0.008604

run [1650]:
Style Loss : 0.577469 Content Loss: 0.008655

run [1700]:
Style Loss : 0.575303 Content Loss: 0.008723

run [1750]:
Style Loss : 0.573364 Content Loss: 0.008779

run [1800]:
Style Loss : 0.571304 Content Loss: 0.008819

run [1850]:
Style Loss : 0.569486 Content Loss: 0.008866

run [1900]:
Style Loss : 0.568039 Content Loss: 0.008909

run [1950]:
Style Loss : 0.566203 Content Loss: 0.008944

run [2000]:
Style Loss : 0.564531 Content Loss: 0.008975

run [2050]:
Style Loss : 0.563025 Content Loss: 0.009006

run [2100]:
Style Loss : 0.561729 Content Loss: 0.009044

run [2150]:
Style Loss : 0.560431 Content Loss: 0.009063

run [2200]:
Style Loss : 0.559317 Content Loss: 0.009098

run [2250]:
Style Loss : 0.558268 Content Loss: 0.009125

run [2300]:
Style Loss : 0.556962 Content Loss: 0.009159

run [2350]:
Style Loss : 0.555435 Content Loss: 0.009176

run [2400]:
Style Loss : 0.554661 Content Loss: 0.009212

run [2450]:
Style Loss : 0.553165 Content Loss: 0.009230

run [2500]:
Style Loss : 0.552009 Content Loss: 0.009259

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.591138 Content Loss: 0.002488

run [100]:
Style Loss : 0.868714 Content Loss: 0.002791

run [150]:
Style Loss : 0.655733 Content Loss: 0.003225

run [200]:
Style Loss : 0.544728 Content Loss: 0.003672

run [250]:
Style Loss : 0.461303 Content Loss: 0.004136

run [300]:
Style Loss : 0.400497 Content Loss: 0.004518

run [350]:
Style Loss : 0.361408 Content Loss: 0.004840

run [400]:
Style Loss : 0.333326 Content Loss: 0.005169

run [450]:
Style Loss : 0.312731 Content Loss: 0.005470

run [500]:
Style Loss : 0.297377 Content Loss: 0.005749

run [550]:
Style Loss : 0.284142 Content Loss: 0.005997

run [600]:
Style Loss : 0.273290 Content Loss: 0.006190

run [650]:
Style Loss : 0.265452 Content Loss: 0.006357

run [700]:
Style Loss : 0.259381 Content Loss: 0.006508

run [750]:
Style Loss : 0.254638 Content Loss: 0.006653

run [800]:
Style Loss : 0.251247 Content Loss: 0.006788

run [850]:
Style Loss : 0.247965 Content Loss: 0.006870

run [900]:
Style Loss : 0.245090 Content Loss: 0.006962

run [950]:
Style Loss : 0.242455 Content Loss: 0.007041

run [1000]:
Style Loss : 0.240053 Content Loss: 0.007112

run [1050]:
Style Loss : 0.237773 Content Loss: 0.007184

run [1100]:
Style Loss : 0.235707 Content Loss: 0.007242

run [1150]:
Style Loss : 0.233873 Content Loss: 0.007309

run [1200]:
Style Loss : 0.232111 Content Loss: 0.007367

run [1250]:
Style Loss : 0.230578 Content Loss: 0.007412

run [1300]:
Style Loss : 0.229295 Content Loss: 0.007470

run [1350]:
Style Loss : 0.227993 Content Loss: 0.007509

run [1400]:
Style Loss : 0.226815 Content Loss: 0.007552

run [1450]:
Style Loss : 0.225641 Content Loss: 0.007581

run [1500]:
Style Loss : 0.224632 Content Loss: 0.007624

run [1550]:
Style Loss : 0.223665 Content Loss: 0.007653

run [1600]:
Style Loss : 0.224391 Content Loss: 0.007754

run [1650]:
Style Loss : 0.221954 Content Loss: 0.007728

run [1700]:
Style Loss : 0.221175 Content Loss: 0.007772

run [1750]:
Style Loss : 0.705520 Content Loss: 0.011214

run [1800]:
Style Loss : 0.384014 Content Loss: 0.009506

run [1850]:
Style Loss : 0.303756 Content Loss: 0.009168

run [1900]:
Style Loss : 0.265634 Content Loss: 0.009155

run [1950]:
Style Loss : 0.241846 Content Loss: 0.009177

run [2000]:
Style Loss : 0.225504 Content Loss: 0.009200

run [2050]:
Style Loss : 0.213891 Content Loss: 0.009224

run [2100]:
Style Loss : 0.205684 Content Loss: 0.009241

run [2150]:
Style Loss : 0.199848 Content Loss: 0.009251

run [2200]:
Style Loss : 0.194925 Content Loss: 0.009254

run [2250]:
Style Loss : 0.190824 Content Loss: 0.009262

run [2300]:
Style Loss : 0.187299 Content Loss: 0.009265

run [2350]:
Style Loss : 0.184561 Content Loss: 0.009266

run [2400]:
Style Loss : 0.182304 Content Loss: 0.009272

run [2450]:
Style Loss : 0.180285 Content Loss: 0.009272

run [2500]:
Style Loss : 0.178628 Content Loss: 0.009268

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.107926 Content Loss: 0.012138

run [100]:
Style Loss : 1.746393 Content Loss: 0.014130

run [150]:
Style Loss : 1.194015 Content Loss: 0.016578

run [200]:
Style Loss : 0.913206 Content Loss: 0.019385

run [250]:
Style Loss : 0.751254 Content Loss: 0.021800

run [300]:
Style Loss : 0.644214 Content Loss: 0.023284

run [350]:
Style Loss : 0.569134 Content Loss: 0.024534

run [400]:
Style Loss : 0.517314 Content Loss: 0.025575

run [450]:
Style Loss : 0.478383 Content Loss: 0.026405

run [500]:
Style Loss : 0.447602 Content Loss: 0.027033

run [550]:
Style Loss : 0.422433 Content Loss: 0.027569

run [600]:
Style Loss : 0.401598 Content Loss: 0.028031

run [650]:
Style Loss : 0.382703 Content Loss: 0.028544

run [700]:
Style Loss : 0.365735 Content Loss: 0.029108

run [750]:
Style Loss : 0.349979 Content Loss: 0.029518

run [800]:
Style Loss : 0.336309 Content Loss: 0.029956

run [850]:
Style Loss : 0.323688 Content Loss: 0.030448

run [900]:
Style Loss : 0.312936 Content Loss: 0.030901

run [950]:
Style Loss : 0.303173 Content Loss: 0.031421

run [1000]:
Style Loss : 0.294728 Content Loss: 0.031918

run [1050]:
Style Loss : 0.286839 Content Loss: 0.032432

run [1100]:
Style Loss : 0.279790 Content Loss: 0.032904

run [1150]:
Style Loss : 0.273885 Content Loss: 0.033363

run [1200]:
Style Loss : 0.268777 Content Loss: 0.033718

run [1250]:
Style Loss : 0.264598 Content Loss: 0.034035

run [1300]:
Style Loss : 0.260845 Content Loss: 0.034364

run [1350]:
Style Loss : 0.257817 Content Loss: 0.034629

run [1400]:
Style Loss : 0.255115 Content Loss: 0.034878

run [1450]:
Style Loss : 0.252710 Content Loss: 0.035075

run [1500]:
Style Loss : 0.250719 Content Loss: 0.035280

run [1550]:
Style Loss : 0.248924 Content Loss: 0.035413

run [1600]:
Style Loss : 0.247190 Content Loss: 0.035533

run [1650]:
Style Loss : 0.245654 Content Loss: 0.035663

run [1700]:
Style Loss : 0.244200 Content Loss: 0.035762

run [1750]:
Style Loss : 0.242850 Content Loss: 0.035852

run [1800]:
Style Loss : 0.241480 Content Loss: 0.035920

run [1850]:
Style Loss : 0.240286 Content Loss: 0.035952

run [1900]:
Style Loss : 0.239149 Content Loss: 0.035985

run [1950]:
Style Loss : 0.238041 Content Loss: 0.036007

run [2000]:
Style Loss : 0.237038 Content Loss: 0.036024

run [2050]:
Style Loss : 0.236065 Content Loss: 0.036048

run [2100]:
Style Loss : 0.235176 Content Loss: 0.036058

run [2150]:
Style Loss : 0.234384 Content Loss: 0.036076

run [2200]:
Style Loss : 0.233649 Content Loss: 0.036089

run [2250]:
Style Loss : 0.232837 Content Loss: 0.036100

run [2300]:
Style Loss : 0.232159 Content Loss: 0.036104

run [2350]:
Style Loss : 0.231561 Content Loss: 0.036092

run [2400]:
Style Loss : 0.230930 Content Loss: 0.036081

run [2450]:
Style Loss : 0.230443 Content Loss: 0.036075

run [2500]:
Style Loss : 0.229837 Content Loss: 0.036066

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.171368 Content Loss: 0.001623

run [100]:
Style Loss : 1.433671 Content Loss: 0.001816

run [150]:
Style Loss : 1.142956 Content Loss: 0.002034

run [200]:
Style Loss : 1.000806 Content Loss: 0.002201

run [250]:
Style Loss : 0.914389 Content Loss: 0.002394

run [300]:
Style Loss : 0.852477 Content Loss: 0.002594

run [350]:
Style Loss : 0.800369 Content Loss: 0.002805

run [400]:
Style Loss : 0.762142 Content Loss: 0.003002

run [450]:
Style Loss : 0.732493 Content Loss: 0.003185

run [500]:
Style Loss : 0.706622 Content Loss: 0.003391

run [550]:
Style Loss : 0.687063 Content Loss: 0.003551

run [600]:
Style Loss : 0.670953 Content Loss: 0.003725

run [650]:
Style Loss : 0.658030 Content Loss: 0.003897

run [700]:
Style Loss : 0.646615 Content Loss: 0.004053

run [750]:
Style Loss : 0.636399 Content Loss: 0.004223

run [800]:
Style Loss : 0.627396 Content Loss: 0.004378

run [850]:
Style Loss : 0.619268 Content Loss: 0.004530

run [900]:
Style Loss : 0.611703 Content Loss: 0.004670

run [950]:
Style Loss : 0.605083 Content Loss: 0.004796

run [1000]:
Style Loss : 0.598242 Content Loss: 0.004921

run [1050]:
Style Loss : 0.592259 Content Loss: 0.005026

run [1100]:
Style Loss : 0.587364 Content Loss: 0.005113

run [1150]:
Style Loss : 0.583369 Content Loss: 0.005195

run [1200]:
Style Loss : 0.580002 Content Loss: 0.005270

run [1250]:
Style Loss : 0.576871 Content Loss: 0.005351

run [1300]:
Style Loss : 0.573919 Content Loss: 0.005425

run [1350]:
Style Loss : 0.571197 Content Loss: 0.005504

run [1400]:
Style Loss : 0.568509 Content Loss: 0.005568

run [1450]:
Style Loss : 0.565998 Content Loss: 0.005636

run [1500]:
Style Loss : 0.563789 Content Loss: 0.005706

run [1550]:
Style Loss : 0.561738 Content Loss: 0.005763

run [1600]:
Style Loss : 0.559661 Content Loss: 0.005817

run [1650]:
Style Loss : 0.557621 Content Loss: 0.005867

run [1700]:
Style Loss : 0.555861 Content Loss: 0.005915

run [1750]:
Style Loss : 0.554083 Content Loss: 0.005965

run [1800]:
Style Loss : 0.552463 Content Loss: 0.006004

run [1850]:
Style Loss : 0.551048 Content Loss: 0.006045

run [1900]:
Style Loss : 0.549574 Content Loss: 0.006078

run [1950]:
Style Loss : 0.548146 Content Loss: 0.006115

run [2000]:
Style Loss : 0.546737 Content Loss: 0.006150

run [2050]:
Style Loss : 0.545468 Content Loss: 0.006184

run [2100]:
Style Loss : 0.544103 Content Loss: 0.006216

run [2150]:
Style Loss : 0.542836 Content Loss: 0.006245

run [2200]:
Style Loss : 0.541536 Content Loss: 0.006277

run [2250]:
Style Loss : 0.540263 Content Loss: 0.006308

run [2300]:
Style Loss : 0.539065 Content Loss: 0.006329

run [2350]:
Style Loss : 0.537962 Content Loss: 0.006347

run [2400]:
Style Loss : 0.536951 Content Loss: 0.006368

run [2450]:
Style Loss : 0.535976 Content Loss: 0.006392

run [2500]:
Style Loss : 0.534945 Content Loss: 0.006409

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.553375 Content Loss: 0.003295

run [100]:
Style Loss : 0.954020 Content Loss: 0.003427

run [150]:
Style Loss : 0.738609 Content Loss: 0.003741

run [200]:
Style Loss : 0.616524 Content Loss: 0.004024

run [250]:
Style Loss : 0.536151 Content Loss: 0.004286

run [300]:
Style Loss : 0.486172 Content Loss: 0.004567

run [350]:
Style Loss : 0.454157 Content Loss: 0.004778

run [400]:
Style Loss : 0.429957 Content Loss: 0.005044

run [450]:
Style Loss : 0.409160 Content Loss: 0.005300

run [500]:
Style Loss : 0.391127 Content Loss: 0.005488

run [550]:
Style Loss : 0.375605 Content Loss: 0.005673

run [600]:
Style Loss : 0.362529 Content Loss: 0.005839

run [650]:
Style Loss : 0.351512 Content Loss: 0.005979

run [700]:
Style Loss : 0.342133 Content Loss: 0.006151

run [750]:
Style Loss : 0.334309 Content Loss: 0.006284

run [800]:
Style Loss : 0.326781 Content Loss: 0.006409

run [850]:
Style Loss : 0.320528 Content Loss: 0.006526

run [900]:
Style Loss : 0.315183 Content Loss: 0.006635

run [950]:
Style Loss : 0.309145 Content Loss: 0.006743

run [1000]:
Style Loss : 0.304163 Content Loss: 0.006826

run [1050]:
Style Loss : 0.300033 Content Loss: 0.006905

run [1100]:
Style Loss : 0.296235 Content Loss: 0.006995

run [1150]:
Style Loss : 0.293045 Content Loss: 0.007070

run [1200]:
Style Loss : 0.290170 Content Loss: 0.007150

run [1250]:
Style Loss : 0.287262 Content Loss: 0.007220

run [1300]:
Style Loss : 0.284513 Content Loss: 0.007286

run [1350]:
Style Loss : 0.282028 Content Loss: 0.007348

run [1400]:
Style Loss : 0.279939 Content Loss: 0.007404

run [1450]:
Style Loss : 0.278159 Content Loss: 0.007445

run [1500]:
Style Loss : 0.276438 Content Loss: 0.007490

run [1550]:
Style Loss : 0.274863 Content Loss: 0.007539

run [1600]:
Style Loss : 0.273474 Content Loss: 0.007580

run [1650]:
Style Loss : 0.272192 Content Loss: 0.007615

run [1700]:
Style Loss : 0.271054 Content Loss: 0.007649

run [1750]:
Style Loss : 0.269955 Content Loss: 0.007690

run [1800]:
Style Loss : 0.268958 Content Loss: 0.007720

run [1850]:
Style Loss : 0.268081 Content Loss: 0.007747

run [1900]:
Style Loss : 0.267258 Content Loss: 0.007775

run [1950]:
Style Loss : 0.266436 Content Loss: 0.007809

run [2000]:
Style Loss : 0.265655 Content Loss: 0.007835

run [2050]:
Style Loss : 0.264901 Content Loss: 0.007862

run [2100]:
Style Loss : 0.264225 Content Loss: 0.007886

run [2150]:
Style Loss : 0.263514 Content Loss: 0.007913

run [2200]:
Style Loss : 0.262863 Content Loss: 0.007937

run [2250]:
Style Loss : 0.262225 Content Loss: 0.007962

run [2300]:
Style Loss : 0.261542 Content Loss: 0.007992

run [2350]:
Style Loss : 0.260853 Content Loss: 0.008021

run [2400]:
Style Loss : 0.260135 Content Loss: 0.008047

run [2450]:
Style Loss : 0.259367 Content Loss: 0.008085

run [2500]:
Style Loss : 0.258498 Content Loss: 0.008110

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.590633 Content Loss: 0.007622

run [100]:
Style Loss : 1.692216 Content Loss: 0.008575

run [150]:
Style Loss : 1.323718 Content Loss: 0.009595

run [200]:
Style Loss : 1.136782 Content Loss: 0.010306

run [250]:
Style Loss : 1.018469 Content Loss: 0.010870

run [300]:
Style Loss : 0.936984 Content Loss: 0.011461

run [350]:
Style Loss : 0.873845 Content Loss: 0.011985

run [400]:
Style Loss : 0.824883 Content Loss: 0.012374

run [450]:
Style Loss : 0.783044 Content Loss: 0.012720

run [500]:
Style Loss : 0.748401 Content Loss: 0.013176

run [550]:
Style Loss : 0.718583 Content Loss: 0.013520

run [600]:
Style Loss : 0.695275 Content Loss: 0.013798

run [650]:
Style Loss : 0.674263 Content Loss: 0.014089

run [700]:
Style Loss : 0.654730 Content Loss: 0.014374

run [750]:
Style Loss : 0.638420 Content Loss: 0.014616

run [800]:
Style Loss : 0.624005 Content Loss: 0.014849

run [850]:
Style Loss : 0.609593 Content Loss: 0.015103

run [900]:
Style Loss : 0.595615 Content Loss: 0.015383

run [950]:
Style Loss : 0.582501 Content Loss: 0.015570

run [1000]:
Style Loss : 0.570525 Content Loss: 0.015782

run [1050]:
Style Loss : 0.559739 Content Loss: 0.015989

run [1100]:
Style Loss : 0.549249 Content Loss: 0.016160

run [1150]:
Style Loss : 0.539596 Content Loss: 0.016327

run [1200]:
Style Loss : 0.530860 Content Loss: 0.016487

run [1250]:
Style Loss : 0.522935 Content Loss: 0.016630

run [1300]:
Style Loss : 0.515879 Content Loss: 0.016755

run [1350]:
Style Loss : 0.509751 Content Loss: 0.016902

run [1400]:
Style Loss : 0.503880 Content Loss: 0.017051

run [1450]:
Style Loss : 0.498199 Content Loss: 0.017194

run [1500]:
Style Loss : 0.492867 Content Loss: 0.017314

run [1550]:
Style Loss : 0.487829 Content Loss: 0.017423

run [1600]:
Style Loss : 0.482527 Content Loss: 0.017584

run [1650]:
Style Loss : 0.477820 Content Loss: 0.017684

run [1700]:
Style Loss : 0.473373 Content Loss: 0.017832

run [1750]:
Style Loss : 0.469258 Content Loss: 0.017972

run [1800]:
Style Loss : 0.465253 Content Loss: 0.018114

run [1850]:
Style Loss : 0.461361 Content Loss: 0.018230

run [1900]:
Style Loss : 0.457687 Content Loss: 0.018336

run [1950]:
Style Loss : 0.454010 Content Loss: 0.018458

run [2000]:
Style Loss : 0.450613 Content Loss: 0.018605

run [2050]:
Style Loss : 0.447310 Content Loss: 0.018717

run [2100]:
Style Loss : 0.444116 Content Loss: 0.018850

run [2150]:
Style Loss : 0.441178 Content Loss: 0.018948

run [2200]:
Style Loss : 0.438380 Content Loss: 0.019068

run [2250]:
Style Loss : 0.435781 Content Loss: 0.019171

run [2300]:
Style Loss : 0.433052 Content Loss: 0.019297

run [2350]:
Style Loss : 0.430561 Content Loss: 0.019398

run [2400]:
Style Loss : 0.428218 Content Loss: 0.019513

run [2450]:
Style Loss : 0.425954 Content Loss: 0.019628

run [2500]:
Style Loss : 0.423838 Content Loss: 0.019739

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 3.882801 Content Loss: 0.005813

run [100]:
Style Loss : 2.053398 Content Loss: 0.006112

run [150]:
Style Loss : 1.479368 Content Loss: 0.006576

run [200]:
Style Loss : 1.218473 Content Loss: 0.007146

run [250]:
Style Loss : 1.053003 Content Loss: 0.007826

run [300]:
Style Loss : 0.947132 Content Loss: 0.008346

run [350]:
Style Loss : 0.871359 Content Loss: 0.008813

run [400]:
Style Loss : 0.812200 Content Loss: 0.009288

run [450]:
Style Loss : 0.762395 Content Loss: 0.009664

run [500]:
Style Loss : 0.717576 Content Loss: 0.010019

run [550]:
Style Loss : 0.681710 Content Loss: 0.010347

run [600]:
Style Loss : 0.652404 Content Loss: 0.010599

run [650]:
Style Loss : 0.628528 Content Loss: 0.010886

run [700]:
Style Loss : 0.609201 Content Loss: 0.011135

run [750]:
Style Loss : 0.592327 Content Loss: 0.011400

run [800]:
Style Loss : 0.577825 Content Loss: 0.011640

run [850]:
Style Loss : 0.566048 Content Loss: 0.011839

run [900]:
Style Loss : 0.556259 Content Loss: 0.012043

run [950]:
Style Loss : 0.547133 Content Loss: 0.012235

run [1000]:
Style Loss : 0.537926 Content Loss: 0.012451

run [1050]:
Style Loss : 0.528977 Content Loss: 0.012654

run [1100]:
Style Loss : 0.520216 Content Loss: 0.012841

run [1150]:
Style Loss : 0.511546 Content Loss: 0.013038

run [1200]:
Style Loss : 0.503358 Content Loss: 0.013231

run [1250]:
Style Loss : 0.495234 Content Loss: 0.013440

run [1300]:
Style Loss : 0.488105 Content Loss: 0.013616

run [1350]:
Style Loss : 0.481768 Content Loss: 0.013787

run [1400]:
Style Loss : 0.475627 Content Loss: 0.013977

run [1450]:
Style Loss : 0.470078 Content Loss: 0.014152

run [1500]:
Style Loss : 0.464800 Content Loss: 0.014338

run [1550]:
Style Loss : 0.459616 Content Loss: 0.014526

run [1600]:
Style Loss : 0.454518 Content Loss: 0.014704

run [1650]:
Style Loss : 0.450161 Content Loss: 0.014867

run [1700]:
Style Loss : 0.445523 Content Loss: 0.015030

run [1750]:
Style Loss : 0.441185 Content Loss: 0.015200

run [1800]:
Style Loss : 0.437089 Content Loss: 0.015367

run [1850]:
Style Loss : 0.433392 Content Loss: 0.015523

run [1900]:
Style Loss : 0.429847 Content Loss: 0.015703

run [1950]:
Style Loss : 0.426563 Content Loss: 0.015867

run [2000]:
Style Loss : 0.423163 Content Loss: 0.016089

run [2050]:
Style Loss : 0.419663 Content Loss: 0.016307

run [2100]:
Style Loss : 0.416523 Content Loss: 0.016460

run [2150]:
Style Loss : 0.413702 Content Loss: 0.016655

run [2200]:
Style Loss : 0.410961 Content Loss: 0.016847

run [2250]:
Style Loss : 0.408312 Content Loss: 0.017043

run [2300]:
Style Loss : 0.405623 Content Loss: 0.017264

run [2350]:
Style Loss : 0.403120 Content Loss: 0.017455

run [2400]:
Style Loss : 0.400790 Content Loss: 0.017656

run [2450]:
Style Loss : 0.398475 Content Loss: 0.017874

run [2500]:
Style Loss : 0.396212 Content Loss: 0.018056

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.811786 Content Loss: 0.003030

run [100]:
Style Loss : 1.120563 Content Loss: 0.003550

run [150]:
Style Loss : 0.876524 Content Loss: 0.004236

run [200]:
Style Loss : 0.749378 Content Loss: 0.004849

run [250]:
Style Loss : 0.667437 Content Loss: 0.005386

run [300]:
Style Loss : 0.615463 Content Loss: 0.005916

run [350]:
Style Loss : 0.569110 Content Loss: 0.006411

run [400]:
Style Loss : 0.531420 Content Loss: 0.006842

run [450]:
Style Loss : 0.502842 Content Loss: 0.007183

run [500]:
Style Loss : 0.479339 Content Loss: 0.007528

run [550]:
Style Loss : 0.461817 Content Loss: 0.007822

run [600]:
Style Loss : 0.448245 Content Loss: 0.008054

run [650]:
Style Loss : 0.436980 Content Loss: 0.008288

run [700]:
Style Loss : 0.428111 Content Loss: 0.008517

run [750]:
Style Loss : 0.421104 Content Loss: 0.008681

run [800]:
Style Loss : 0.414960 Content Loss: 0.008870

run [850]:
Style Loss : 0.409810 Content Loss: 0.009012

run [900]:
Style Loss : 0.404806 Content Loss: 0.009157

run [950]:
Style Loss : 0.399625 Content Loss: 0.009298

run [1000]:
Style Loss : 0.393677 Content Loss: 0.009433

run [1050]:
Style Loss : 0.388687 Content Loss: 0.009565

run [1100]:
Style Loss : 0.384240 Content Loss: 0.009676

run [1150]:
Style Loss : 0.379883 Content Loss: 0.009791

run [1200]:
Style Loss : 0.375944 Content Loss: 0.009893

run [1250]:
Style Loss : 0.372627 Content Loss: 0.009982

run [1300]:
Style Loss : 0.369740 Content Loss: 0.010065

run [1350]:
Style Loss : 0.366840 Content Loss: 0.010155

run [1400]:
Style Loss : 0.364044 Content Loss: 0.010248

run [1450]:
Style Loss : 0.361009 Content Loss: 0.010347

run [1500]:
Style Loss : 0.358380 Content Loss: 0.010433

run [1550]:
Style Loss : 0.355964 Content Loss: 0.010516

run [1600]:
Style Loss : 0.353514 Content Loss: 0.010594

run [1650]:
Style Loss : 0.350823 Content Loss: 0.010674

run [1700]:
Style Loss : 0.348344 Content Loss: 0.010744

run [1750]:
Style Loss : 0.346203 Content Loss: 0.010819

run [1800]:
Style Loss : 0.344148 Content Loss: 0.010899

run [1850]:
Style Loss : 0.342267 Content Loss: 0.010966

run [1900]:
Style Loss : 0.340437 Content Loss: 0.011034

run [1950]:
Style Loss : 0.338762 Content Loss: 0.011101

run [2000]:
Style Loss : 0.336981 Content Loss: 0.011177

run [2050]:
Style Loss : 0.335197 Content Loss: 0.011255

run [2100]:
Style Loss : 0.333348 Content Loss: 0.011327

run [2150]:
Style Loss : 0.331720 Content Loss: 0.011400

run [2200]:
Style Loss : 0.330194 Content Loss: 0.011463

run [2250]:
Style Loss : 0.328799 Content Loss: 0.011525

run [2300]:
Style Loss : 0.327460 Content Loss: 0.011598

run [2350]:
Style Loss : 0.326122 Content Loss: 0.011666

run [2400]:
Style Loss : 0.324621 Content Loss: 0.011746

run [2450]:
Style Loss : 0.323212 Content Loss: 0.011822

run [2500]:
Style Loss : 0.321719 Content Loss: 0.011894

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.160294 Content Loss: 0.005254

run [100]:
Style Loss : 1.429153 Content Loss: 0.006142

run [150]:
Style Loss : 1.086046 Content Loss: 0.007063

run [200]:
Style Loss : 0.917072 Content Loss: 0.007992

run [250]:
Style Loss : 0.816664 Content Loss: 0.008837

run [300]:
Style Loss : 0.747700 Content Loss: 0.009567

run [350]:
Style Loss : 0.695570 Content Loss: 0.010235

run [400]:
Style Loss : 0.658227 Content Loss: 0.010749

run [450]:
Style Loss : 0.629359 Content Loss: 0.011144

run [500]:
Style Loss : 0.605060 Content Loss: 0.011627

run [550]:
Style Loss : 0.585912 Content Loss: 0.011946

run [600]:
Style Loss : 0.569660 Content Loss: 0.012266

run [650]:
Style Loss : 0.556153 Content Loss: 0.012549

run [700]:
Style Loss : 0.544522 Content Loss: 0.012825

run [750]:
Style Loss : 0.534398 Content Loss: 0.013089

run [800]:
Style Loss : 0.524828 Content Loss: 0.013366

run [850]:
Style Loss : 0.516548 Content Loss: 0.013588

run [900]:
Style Loss : 0.509115 Content Loss: 0.013765

run [950]:
Style Loss : 0.502355 Content Loss: 0.013954

run [1000]:
Style Loss : 0.496585 Content Loss: 0.014091

run [1050]:
Style Loss : 0.491303 Content Loss: 0.014251

run [1100]:
Style Loss : 0.486648 Content Loss: 0.014391

run [1150]:
Style Loss : 0.482449 Content Loss: 0.014503

run [1200]:
Style Loss : 0.478703 Content Loss: 0.014624

run [1250]:
Style Loss : 0.474605 Content Loss: 0.014723

run [1300]:
Style Loss : 0.471114 Content Loss: 0.014824

run [1350]:
Style Loss : 0.467957 Content Loss: 0.014912

run [1400]:
Style Loss : 0.465225 Content Loss: 0.015007

run [1450]:
Style Loss : 0.462702 Content Loss: 0.015087

run [1500]:
Style Loss : 0.460326 Content Loss: 0.015168

run [1550]:
Style Loss : 0.458118 Content Loss: 0.015249

run [1600]:
Style Loss : 0.456018 Content Loss: 0.015327

run [1650]:
Style Loss : 0.454064 Content Loss: 0.015396

run [1700]:
Style Loss : 0.451980 Content Loss: 0.015462

run [1750]:
Style Loss : 0.450064 Content Loss: 0.015532

run [1800]:
Style Loss : 0.448400 Content Loss: 0.015596

run [1850]:
Style Loss : 0.446626 Content Loss: 0.015652

run [1900]:
Style Loss : 0.444916 Content Loss: 0.015716

run [1950]:
Style Loss : 0.443311 Content Loss: 0.015769

run [2000]:
Style Loss : 0.441807 Content Loss: 0.015815

run [2050]:
Style Loss : 0.440476 Content Loss: 0.015861

run [2100]:
Style Loss : 0.439215 Content Loss: 0.015905

run [2150]:
Style Loss : 0.438008 Content Loss: 0.015955

run [2200]:
Style Loss : 0.436826 Content Loss: 0.015992

run [2250]:
Style Loss : 0.435645 Content Loss: 0.016035

run [2300]:
Style Loss : 0.434259 Content Loss: 0.016078

run [2350]:
Style Loss : 0.432941 Content Loss: 0.016122

run [2400]:
Style Loss : 0.431509 Content Loss: 0.016163

run [2450]:
Style Loss : 0.430400 Content Loss: 0.016199

run [2500]:
Style Loss : 0.429377 Content Loss: 0.016244

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.867845 Content Loss: 0.005077

run [100]:
Style Loss : 1.521351 Content Loss: 0.005574

run [150]:
Style Loss : 1.168836 Content Loss: 0.006486

run [200]:
Style Loss : 0.988723 Content Loss: 0.007364

run [250]:
Style Loss : 0.861712 Content Loss: 0.008263

run [300]:
Style Loss : 0.777335 Content Loss: 0.008993

run [350]:
Style Loss : 0.719127 Content Loss: 0.009595

run [400]:
Style Loss : 0.673386 Content Loss: 0.010155

run [450]:
Style Loss : 0.639858 Content Loss: 0.010667

run [500]:
Style Loss : 0.614403 Content Loss: 0.011090

run [550]:
Style Loss : 0.591476 Content Loss: 0.011503

run [600]:
Style Loss : 0.573732 Content Loss: 0.011842

run [650]:
Style Loss : 0.558168 Content Loss: 0.012182

run [700]:
Style Loss : 0.544734 Content Loss: 0.012501

run [750]:
Style Loss : 0.533376 Content Loss: 0.012815

run [800]:
Style Loss : 0.523319 Content Loss: 0.013054

run [850]:
Style Loss : 0.514199 Content Loss: 0.013341

run [900]:
Style Loss : 0.505357 Content Loss: 0.013552

run [950]:
Style Loss : 0.497739 Content Loss: 0.013762

run [1000]:
Style Loss : 0.490279 Content Loss: 0.013953

run [1050]:
Style Loss : 0.484054 Content Loss: 0.014137

run [1100]:
Style Loss : 0.478673 Content Loss: 0.014318

run [1150]:
Style Loss : 0.473557 Content Loss: 0.014514

run [1200]:
Style Loss : 0.468116 Content Loss: 0.014699

run [1250]:
Style Loss : 0.463224 Content Loss: 0.014843

run [1300]:
Style Loss : 0.458432 Content Loss: 0.014995

run [1350]:
Style Loss : 0.453840 Content Loss: 0.015140

run [1400]:
Style Loss : 0.449289 Content Loss: 0.015298

run [1450]:
Style Loss : 0.444785 Content Loss: 0.015431

run [1500]:
Style Loss : 0.440583 Content Loss: 0.015572

run [1550]:
Style Loss : 0.436641 Content Loss: 0.015738

run [1600]:
Style Loss : 0.432770 Content Loss: 0.015883

run [1650]:
Style Loss : 0.429412 Content Loss: 0.016014

run [1700]:
Style Loss : 0.426274 Content Loss: 0.016131

run [1750]:
Style Loss : 0.423111 Content Loss: 0.016256

run [1800]:
Style Loss : 0.420191 Content Loss: 0.016381

run [1850]:
Style Loss : 0.417536 Content Loss: 0.016480

run [1900]:
Style Loss : 0.414974 Content Loss: 0.016589

run [1950]:
Style Loss : 0.412576 Content Loss: 0.016675

run [2000]:
Style Loss : 0.410515 Content Loss: 0.016745

run [2050]:
Style Loss : 0.408623 Content Loss: 0.016818

run [2100]:
Style Loss : 0.406909 Content Loss: 0.016888

run [2150]:
Style Loss : 0.405352 Content Loss: 0.016955

run [2200]:
Style Loss : 0.403872 Content Loss: 0.017034

run [2250]:
Style Loss : 0.402405 Content Loss: 0.017087

run [2300]:
Style Loss : 0.401032 Content Loss: 0.017147

run [2350]:
Style Loss : 0.399676 Content Loss: 0.017195

run [2400]:
Style Loss : 0.398497 Content Loss: 0.017233

run [2450]:
Style Loss : 0.397399 Content Loss: 0.017277

run [2500]:
Style Loss : 0.396347 Content Loss: 0.017322

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.905765 Content Loss: 0.003225

run [100]:
Style Loss : 1.754492 Content Loss: 0.003946

run [150]:
Style Loss : 1.311871 Content Loss: 0.004808

run [200]:
Style Loss : 1.075547 Content Loss: 0.005523

run [250]:
Style Loss : 0.927580 Content Loss: 0.006133

run [300]:
Style Loss : 0.826162 Content Loss: 0.006653

run [350]:
Style Loss : 0.748837 Content Loss: 0.007164

run [400]:
Style Loss : 0.689641 Content Loss: 0.007526

run [450]:
Style Loss : 0.643004 Content Loss: 0.007930

run [500]:
Style Loss : 0.602914 Content Loss: 0.008254

run [550]:
Style Loss : 0.570990 Content Loss: 0.008591

run [600]:
Style Loss : 0.544156 Content Loss: 0.008861

run [650]:
Style Loss : 0.524724 Content Loss: 0.009069

run [700]:
Style Loss : 0.509963 Content Loss: 0.009261

run [750]:
Style Loss : 0.497480 Content Loss: 0.009434

run [800]:
Style Loss : 0.486065 Content Loss: 0.009596

run [850]:
Style Loss : 0.476537 Content Loss: 0.009728

run [900]:
Style Loss : 0.468425 Content Loss: 0.009847

run [950]:
Style Loss : 0.461544 Content Loss: 0.009944

run [1000]:
Style Loss : 0.455889 Content Loss: 0.010038

run [1050]:
Style Loss : 0.451159 Content Loss: 0.010136

run [1100]:
Style Loss : 0.446894 Content Loss: 0.010229

run [1150]:
Style Loss : 0.442850 Content Loss: 0.010316

run [1200]:
Style Loss : 0.438902 Content Loss: 0.010399

run [1250]:
Style Loss : 0.434806 Content Loss: 0.010486

run [1300]:
Style Loss : 0.431505 Content Loss: 0.010548

run [1350]:
Style Loss : 0.428546 Content Loss: 0.010607

run [1400]:
Style Loss : 0.425902 Content Loss: 0.010673

run [1450]:
Style Loss : 0.423062 Content Loss: 0.010734

run [1500]:
Style Loss : 0.419936 Content Loss: 0.010798

run [1550]:
Style Loss : 0.417008 Content Loss: 0.010858

run [1600]:
Style Loss : 0.413880 Content Loss: 0.010925

run [1650]:
Style Loss : 0.410657 Content Loss: 0.010989

run [1700]:
Style Loss : 0.407525 Content Loss: 0.011042

run [1750]:
Style Loss : 0.404651 Content Loss: 0.011091

run [1800]:
Style Loss : 0.402062 Content Loss: 0.011137

run [1850]:
Style Loss : 0.399989 Content Loss: 0.011174

run [1900]:
Style Loss : 0.398084 Content Loss: 0.011215

run [1950]:
Style Loss : 0.396399 Content Loss: 0.011251

run [2000]:
Style Loss : 0.394714 Content Loss: 0.011289

run [2050]:
Style Loss : 0.392980 Content Loss: 0.011325

run [2100]:
Style Loss : 0.391202 Content Loss: 0.011361

run [2150]:
Style Loss : 0.389690 Content Loss: 0.011392

run [2200]:
Style Loss : 0.388335 Content Loss: 0.011420

run [2250]:
Style Loss : 0.387082 Content Loss: 0.011448

run [2300]:
Style Loss : 0.385971 Content Loss: 0.011472

run [2350]:
Style Loss : 0.384832 Content Loss: 0.011500

run [2400]:
Style Loss : 0.383717 Content Loss: 0.011528

run [2450]:
Style Loss : 0.382676 Content Loss: 0.011554

run [2500]:
Style Loss : 0.381652 Content Loss: 0.011578

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.514266 Content Loss: 0.003995

run [100]:
Style Loss : 0.873546 Content Loss: 0.004495

run [150]:
Style Loss : 0.656265 Content Loss: 0.005104

run [200]:
Style Loss : 0.548448 Content Loss: 0.005561

run [250]:
Style Loss : 0.487590 Content Loss: 0.005971

run [300]:
Style Loss : 0.439616 Content Loss: 0.006403

run [350]:
Style Loss : 0.403741 Content Loss: 0.006733

run [400]:
Style Loss : 0.377162 Content Loss: 0.007011

run [450]:
Style Loss : 0.356720 Content Loss: 0.007285

run [500]:
Style Loss : 0.340119 Content Loss: 0.007535

run [550]:
Style Loss : 0.324672 Content Loss: 0.007744

run [600]:
Style Loss : 0.311490 Content Loss: 0.007962

run [650]:
Style Loss : 0.300927 Content Loss: 0.008140

run [700]:
Style Loss : 0.292057 Content Loss: 0.008324

run [750]:
Style Loss : 0.284162 Content Loss: 0.008499

run [800]:
Style Loss : 0.277423 Content Loss: 0.008666

run [850]:
Style Loss : 0.271858 Content Loss: 0.008798

run [900]:
Style Loss : 0.266728 Content Loss: 0.008921

run [950]:
Style Loss : 0.261795 Content Loss: 0.009039

run [1000]:
Style Loss : 0.257172 Content Loss: 0.009148

run [1050]:
Style Loss : 0.253086 Content Loss: 0.009245

run [1100]:
Style Loss : 0.249621 Content Loss: 0.009338

run [1150]:
Style Loss : 0.246486 Content Loss: 0.009425

run [1200]:
Style Loss : 0.243679 Content Loss: 0.009495

run [1250]:
Style Loss : 0.241194 Content Loss: 0.009565

run [1300]:
Style Loss : 0.238782 Content Loss: 0.009632

run [1350]:
Style Loss : 0.236372 Content Loss: 0.009691

run [1400]:
Style Loss : 0.234355 Content Loss: 0.009743

run [1450]:
Style Loss : 0.232326 Content Loss: 0.009803

run [1500]:
Style Loss : 0.230526 Content Loss: 0.009850

run [1550]:
Style Loss : 0.228904 Content Loss: 0.009892

run [1600]:
Style Loss : 0.227024 Content Loss: 0.009944

run [1650]:
Style Loss : 0.224987 Content Loss: 0.010002

run [1700]:
Style Loss : 0.223151 Content Loss: 0.010050

run [1750]:
Style Loss : 0.221460 Content Loss: 0.010096

run [1800]:
Style Loss : 0.219866 Content Loss: 0.010140

run [1850]:
Style Loss : 0.218538 Content Loss: 0.010179

run [1900]:
Style Loss : 0.217198 Content Loss: 0.010218

run [1950]:
Style Loss : 0.215734 Content Loss: 0.010267

run [2000]:
Style Loss : 0.214316 Content Loss: 0.010310

run [2050]:
Style Loss : 0.213114 Content Loss: 0.010349

run [2100]:
Style Loss : 0.212062 Content Loss: 0.010392

run [2150]:
Style Loss : 0.210964 Content Loss: 0.010436

run [2200]:
Style Loss : 0.209908 Content Loss: 0.010482

run [2250]:
Style Loss : 0.208923 Content Loss: 0.010522

run [2300]:
Style Loss : 0.207963 Content Loss: 0.010565

run [2350]:
Style Loss : 0.206987 Content Loss: 0.010609

run [2400]:
Style Loss : 0.206058 Content Loss: 0.010650

run [2450]:
Style Loss : 0.205242 Content Loss: 0.010689

run [2500]:
Style Loss : 0.204438 Content Loss: 0.010729

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 4.424379 Content Loss: 0.006712

run [100]:
Style Loss : 2.423437 Content Loss: 0.007231

run [150]:
Style Loss : 1.715541 Content Loss: 0.009016

run [200]:
Style Loss : 1.385349 Content Loss: 0.011129

run [250]:
Style Loss : 1.184135 Content Loss: 0.013381

run [300]:
Style Loss : 1.033599 Content Loss: 0.015378

run [350]:
Style Loss : 0.921118 Content Loss: 0.017053

run [400]:
Style Loss : 0.849424 Content Loss: 0.018282

run [450]:
Style Loss : 0.796486 Content Loss: 0.019393

run [500]:
Style Loss : 0.756559 Content Loss: 0.020369

run [550]:
Style Loss : 0.725723 Content Loss: 0.021186

run [600]:
Style Loss : 0.699849 Content Loss: 0.021936

run [650]:
Style Loss : 0.678492 Content Loss: 0.022607

run [700]:
Style Loss : 0.658699 Content Loss: 0.023166

run [750]:
Style Loss : 0.641502 Content Loss: 0.023680

run [800]:
Style Loss : 0.627127 Content Loss: 0.024114

run [850]:
Style Loss : 0.614579 Content Loss: 0.024526

run [900]:
Style Loss : 0.603413 Content Loss: 0.024870

run [950]:
Style Loss : 0.592776 Content Loss: 0.025190

run [1000]:
Style Loss : 0.584123 Content Loss: 0.025465

run [1050]:
Style Loss : 0.576573 Content Loss: 0.025776

run [1100]:
Style Loss : 0.569806 Content Loss: 0.026032

run [1150]:
Style Loss : 0.563756 Content Loss: 0.026282

run [1200]:
Style Loss : 0.558469 Content Loss: 0.026475

run [1250]:
Style Loss : 0.553668 Content Loss: 0.026667

run [1300]:
Style Loss : 0.549141 Content Loss: 0.026862

run [1350]:
Style Loss : 0.545132 Content Loss: 0.027013

run [1400]:
Style Loss : 0.541216 Content Loss: 0.027190

run [1450]:
Style Loss : 0.537075 Content Loss: 0.027362

run [1500]:
Style Loss : 0.533186 Content Loss: 0.027511

run [1550]:
Style Loss : 0.529416 Content Loss: 0.027653

run [1600]:
Style Loss : 0.526127 Content Loss: 0.027764

run [1650]:
Style Loss : 0.523097 Content Loss: 0.027869

run [1700]:
Style Loss : 0.520462 Content Loss: 0.027972

run [1750]:
Style Loss : 0.517661 Content Loss: 0.028084

run [1800]:
Style Loss : 0.515108 Content Loss: 0.028183

run [1850]:
Style Loss : 0.512541 Content Loss: 0.028282

run [1900]:
Style Loss : 0.510106 Content Loss: 0.028359

run [1950]:
Style Loss : 0.507880 Content Loss: 0.028426

run [2000]:
Style Loss : 0.505807 Content Loss: 0.028479

run [2050]:
Style Loss : 0.503789 Content Loss: 0.028545

run [2100]:
Style Loss : 0.500979 Content Loss: 0.028624

run [2150]:
Style Loss : 0.498382 Content Loss: 0.028695

run [2200]:
Style Loss : 0.495871 Content Loss: 0.028755

run [2250]:
Style Loss : 0.493791 Content Loss: 0.028809

run [2300]:
Style Loss : 0.492001 Content Loss: 0.028855

run [2350]:
Style Loss : 0.490339 Content Loss: 0.028913

run [2400]:
Style Loss : 0.488735 Content Loss: 0.028955

run [2450]:
Style Loss : 0.487099 Content Loss: 0.029003

run [2500]:
Style Loss : 0.485651 Content Loss: 0.029047

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 2.739669 Content Loss: 0.002528

run [100]:
Style Loss : 1.725478 Content Loss: 0.003258

run [150]:
Style Loss : 1.327686 Content Loss: 0.004461

run [200]:
Style Loss : 1.120113 Content Loss: 0.005727

run [250]:
Style Loss : 0.966435 Content Loss: 0.006974

run [300]:
Style Loss : 0.863748 Content Loss: 0.008225

run [350]:
Style Loss : 0.786296 Content Loss: 0.009441

run [400]:
Style Loss : 0.722063 Content Loss: 0.010512

run [450]:
Style Loss : 0.660773 Content Loss: 0.011529

run [500]:
Style Loss : 0.615079 Content Loss: 0.012331

run [550]:
Style Loss : 0.579247 Content Loss: 0.013148

run [600]:
Style Loss : 0.551854 Content Loss: 0.013752

run [650]:
Style Loss : 0.528243 Content Loss: 0.014333

run [700]:
Style Loss : 0.507139 Content Loss: 0.014841

run [750]:
Style Loss : 0.488537 Content Loss: 0.015269

run [800]:
Style Loss : 0.474049 Content Loss: 0.015601

run [850]:
Style Loss : 0.462778 Content Loss: 0.015925

run [900]:
Style Loss : 0.451938 Content Loss: 0.016205

run [950]:
Style Loss : 0.440717 Content Loss: 0.016496

run [1000]:
Style Loss : 0.431090 Content Loss: 0.016720

run [1050]:
Style Loss : 0.423691 Content Loss: 0.016947

run [1100]:
Style Loss : 0.417614 Content Loss: 0.017123

run [1150]:
Style Loss : 0.412192 Content Loss: 0.017300

run [1200]:
Style Loss : 0.407614 Content Loss: 0.017465

run [1250]:
Style Loss : 0.403411 Content Loss: 0.017613

run [1300]:
Style Loss : 0.399459 Content Loss: 0.017748

run [1350]:
Style Loss : 0.395750 Content Loss: 0.017867

run [1400]:
Style Loss : 0.392084 Content Loss: 0.018002

run [1450]:
Style Loss : 0.388760 Content Loss: 0.018117

run [1500]:
Style Loss : 0.385531 Content Loss: 0.018231

run [1550]:
Style Loss : 0.382846 Content Loss: 0.018333

run [1600]:
Style Loss : 0.380249 Content Loss: 0.018435

run [1650]:
Style Loss : 0.377768 Content Loss: 0.018537

run [1700]:
Style Loss : 0.375509 Content Loss: 0.018625

run [1750]:
Style Loss : 0.373435 Content Loss: 0.018704

run [1800]:
Style Loss : 0.371256 Content Loss: 0.018786

run [1850]:
Style Loss : 0.369379 Content Loss: 0.018855

run [1900]:
Style Loss : 0.367692 Content Loss: 0.018920

run [1950]:
Style Loss : 0.366072 Content Loss: 0.018972

run [2000]:
Style Loss : 0.364637 Content Loss: 0.019024

run [2050]:
Style Loss : 0.363348 Content Loss: 0.019077

run [2100]:
Style Loss : 0.362137 Content Loss: 0.019129

run [2150]:
Style Loss : 0.360977 Content Loss: 0.019182

run [2200]:
Style Loss : 0.359907 Content Loss: 0.019233

run [2250]:
Style Loss : 0.358894 Content Loss: 0.019282

run [2300]:
Style Loss : 0.357965 Content Loss: 0.019327

run [2350]:
Style Loss : 0.356916 Content Loss: 0.019377

run [2400]:
Style Loss : 0.355784 Content Loss: 0.019422

run [2450]:
Style Loss : 0.354762 Content Loss: 0.019470

run [2500]:
Style Loss : 0.353887 Content Loss: 0.019510

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.738456 Content Loss: 0.001758

run [100]:
Style Loss : 1.130445 Content Loss: 0.002686

run [150]:
Style Loss : 0.876106 Content Loss: 0.003734

run [200]:
Style Loss : 0.727807 Content Loss: 0.004594

run [250]:
Style Loss : 0.629491 Content Loss: 0.005561

run [300]:
Style Loss : 0.559374 Content Loss: 0.006289

run [350]:
Style Loss : 0.510143 Content Loss: 0.007050

run [400]:
Style Loss : 0.475087 Content Loss: 0.007776

run [450]:
Style Loss : 0.447147 Content Loss: 0.008437

run [500]:
Style Loss : 0.426538 Content Loss: 0.008942

run [550]:
Style Loss : 0.410215 Content Loss: 0.009397

run [600]:
Style Loss : 0.397253 Content Loss: 0.009834

run [650]:
Style Loss : 0.385568 Content Loss: 0.010181

run [700]:
Style Loss : 0.376143 Content Loss: 0.010455

run [750]:
Style Loss : 0.367634 Content Loss: 0.010719

run [800]:
Style Loss : 0.359530 Content Loss: 0.010921

run [850]:
Style Loss : 0.352175 Content Loss: 0.011128

run [900]:
Style Loss : 0.345503 Content Loss: 0.011323

run [950]:
Style Loss : 0.339413 Content Loss: 0.011462

run [1000]:
Style Loss : 0.334176 Content Loss: 0.011593

run [1050]:
Style Loss : 0.329207 Content Loss: 0.011714

run [1100]:
Style Loss : 0.324262 Content Loss: 0.011848

run [1150]:
Style Loss : 0.320259 Content Loss: 0.011959

run [1200]:
Style Loss : 0.316736 Content Loss: 0.012052

run [1250]:
Style Loss : 0.313609 Content Loss: 0.012131

run [1300]:
Style Loss : 0.310536 Content Loss: 0.012228

run [1350]:
Style Loss : 0.307740 Content Loss: 0.012321

run [1400]:
Style Loss : 0.304444 Content Loss: 0.012427

run [1450]:
Style Loss : 0.301489 Content Loss: 0.012513

run [1500]:
Style Loss : 0.298826 Content Loss: 0.012587

run [1550]:
Style Loss : 0.296431 Content Loss: 0.012657

run [1600]:
Style Loss : 0.294126 Content Loss: 0.012727

run [1650]:
Style Loss : 0.292197 Content Loss: 0.012788

run [1700]:
Style Loss : 0.290000 Content Loss: 0.012865

run [1750]:
Style Loss : 0.287631 Content Loss: 0.012934

run [1800]:
Style Loss : 0.285369 Content Loss: 0.013007

run [1850]:
Style Loss : 0.282863 Content Loss: 0.013087

run [1900]:
Style Loss : 0.280408 Content Loss: 0.013153

run [1950]:
Style Loss : 0.277750 Content Loss: 0.013215

run [2000]:
Style Loss : 0.275354 Content Loss: 0.013272

run [2050]:
Style Loss : 0.273303 Content Loss: 0.013322

run [2100]:
Style Loss : 0.271377 Content Loss: 0.013366

run [2150]:
Style Loss : 0.269521 Content Loss: 0.013410

run [2200]:
Style Loss : 0.267727 Content Loss: 0.013460

run [2250]:
Style Loss : 0.266169 Content Loss: 0.013498

run [2300]:
Style Loss : 0.264681 Content Loss: 0.013535

run [2350]:
Style Loss : 0.263313 Content Loss: 0.013569

run [2400]:
Style Loss : 0.262059 Content Loss: 0.013600

run [2450]:
Style Loss : 0.260868 Content Loss: 0.013637

run [2500]:
Style Loss : 0.259663 Content Loss: 0.013665

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.782616 Content Loss: 0.005858

run [100]:
Style Loss : 1.065389 Content Loss: 0.007816

run [150]:
Style Loss : 0.755389 Content Loss: 0.010853

run [200]:
Style Loss : 0.607130 Content Loss: 0.013731

run [250]:
Style Loss : 0.524478 Content Loss: 0.016234

run [300]:
Style Loss : 0.471365 Content Loss: 0.018120

run [350]:
Style Loss : 0.435154 Content Loss: 0.019357

run [400]:
Style Loss : 0.407331 Content Loss: 0.020413

run [450]:
Style Loss : 0.384905 Content Loss: 0.021314

run [500]:
Style Loss : 0.366477 Content Loss: 0.022114

run [550]:
Style Loss : 0.351823 Content Loss: 0.022780

run [600]:
Style Loss : 0.339427 Content Loss: 0.023304

run [650]:
Style Loss : 0.328792 Content Loss: 0.023774

run [700]:
Style Loss : 0.319936 Content Loss: 0.024186

run [750]:
Style Loss : 0.311958 Content Loss: 0.024548

run [800]:
Style Loss : 0.305030 Content Loss: 0.024859

run [850]:
Style Loss : 0.299017 Content Loss: 0.025083

run [900]:
Style Loss : 0.293700 Content Loss: 0.025303

run [950]:
Style Loss : 0.288628 Content Loss: 0.025536

run [1000]:
Style Loss : 0.284036 Content Loss: 0.025709

run [1050]:
Style Loss : 0.279942 Content Loss: 0.025887

run [1100]:
Style Loss : 0.276090 Content Loss: 0.026020

run [1150]:
Style Loss : 0.272812 Content Loss: 0.026155

run [1200]:
Style Loss : 0.270005 Content Loss: 0.026267

run [1250]:
Style Loss : 0.267341 Content Loss: 0.026411

run [1300]:
Style Loss : 0.264967 Content Loss: 0.026525

run [1350]:
Style Loss : 0.262884 Content Loss: 0.026626

run [1400]:
Style Loss : 0.261001 Content Loss: 0.026718

run [1450]:
Style Loss : 0.259189 Content Loss: 0.026797

run [1500]:
Style Loss : 0.257415 Content Loss: 0.026875

run [1550]:
Style Loss : 0.255834 Content Loss: 0.026948

run [1600]:
Style Loss : 0.254390 Content Loss: 0.027005

run [1650]:
Style Loss : 0.253137 Content Loss: 0.027070

run [1700]:
Style Loss : 0.251955 Content Loss: 0.027119

run [1750]:
Style Loss : 0.250846 Content Loss: 0.027169

run [1800]:
Style Loss : 0.249837 Content Loss: 0.027217

run [1850]:
Style Loss : 0.248869 Content Loss: 0.027271

run [1900]:
Style Loss : 0.247687 Content Loss: 0.027323

run [1950]:
Style Loss : 0.246717 Content Loss: 0.027365

run [2000]:
Style Loss : 0.245900 Content Loss: 0.027394

run [2050]:
Style Loss : 0.244954 Content Loss: 0.027444

run [2100]:
Style Loss : 0.244078 Content Loss: 0.027470

run [2150]:
Style Loss : 0.243233 Content Loss: 0.027503

run [2200]:
Style Loss : 0.242556 Content Loss: 0.027523

run [2250]:
Style Loss : 0.241890 Content Loss: 0.027562

run [2300]:
Style Loss : 0.241188 Content Loss: 0.027590

run [2350]:
Style Loss : 0.240484 Content Loss: 0.027620

run [2400]:
Style Loss : 0.239776 Content Loss: 0.027644

run [2450]:
Style Loss : 0.239148 Content Loss: 0.027671

run [2500]:
Style Loss : 0.238523 Content Loss: 0.027693

/home/chan21/projects/visualsemantic/src/neural_transfer.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mean = torch.tensor(mean).view(-1, 1, 1)
/home/chan21/projects/visualsemantic/src/neural_transfer.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.std = torch.tensor(std).view(-1, 1, 1)
Building the style transfer model..
Optimizing..
run [50]:
Style Loss : 1.049142 Content Loss: 0.004621

run [100]:
Style Loss : 0.617130 Content Loss: 0.006167

run [150]:
Style Loss : 0.451730 Content Loss: 0.007510

run [200]:
Style Loss : 0.380989 Content Loss: 0.008875

run [250]:
Style Loss : 0.339519 Content Loss: 0.010320

run [300]:
Style Loss : 0.313229 Content Loss: 0.011383

run [350]:
Style Loss : 0.293866 Content Loss: 0.012153

run [400]:
Style Loss : 0.279290 Content Loss: 0.012809

run [450]:
Style Loss : 0.269157 Content Loss: 0.013252

run [500]:
Style Loss : 0.261101 Content Loss: 0.013548

run [550]:
Style Loss : 0.254310 Content Loss: 0.013842

run [600]:
Style Loss : 0.247346 Content Loss: 0.014089

run [650]:
Style Loss : 0.241052 Content Loss: 0.014259

run [700]:
Style Loss : 0.235971 Content Loss: 0.014407

run [750]:
Style Loss : 0.231467 Content Loss: 0.014568

run [800]:
Style Loss : 0.227837 Content Loss: 0.014692

run [850]:
Style Loss : 0.224896 Content Loss: 0.014801

run [900]:
Style Loss : 0.222404 Content Loss: 0.014907

run [950]:
Style Loss : 0.220311 Content Loss: 0.015000

run [1000]:
Style Loss : 0.218384 Content Loss: 0.015095

run [1050]:
Style Loss : 0.216386 Content Loss: 0.015190

run [1100]:
Style Loss : 0.214654 Content Loss: 0.015282

run [1150]:
Style Loss : 0.213108 Content Loss: 0.015374

run [1200]:
Style Loss : 0.211713 Content Loss: 0.015460

run [1250]:
Style Loss : 0.210358 Content Loss: 0.015548

run [1300]:
Style Loss : 0.209204 Content Loss: 0.015639

run [1350]:
Style Loss : 0.208003 Content Loss: 0.015739

run [1400]:
Style Loss : 0.206876 Content Loss: 0.015831

run [1450]:
Style Loss : 0.205853 Content Loss: 0.015936

run [1500]:
Style Loss : 0.204859 Content Loss: 0.016038

run [1550]:
Style Loss : 0.203872 Content Loss: 0.016141

run [1600]:
Style Loss : 0.202951 Content Loss: 0.016228

run [1650]:
Style Loss : 0.202096 Content Loss: 0.016323

run [1700]:
Style Loss : 0.201178 Content Loss: 0.016412

run [1750]:
Style Loss : 0.200330 Content Loss: 0.016513

run [1800]:
Style Loss : 0.199523 Content Loss: 0.016597

run [1850]:
Style Loss : 0.198794 Content Loss: 0.016706

run [1900]:
Style Loss : 0.198075 Content Loss: 0.016807

run [1950]:
Style Loss : 0.197392 Content Loss: 0.016879

run [2000]:
Style Loss : 0.196705 Content Loss: 0.016967

run [2050]:
Style Loss : 0.196060 Content Loss: 0.017060

run [2100]:
Style Loss : 0.195435 Content Loss: 0.017149

run [2150]:
Style Loss : 0.194825 Content Loss: 0.017237

run [2200]:
Style Loss : 0.194408 Content Loss: 0.017342

run [2250]:
Style Loss : 0.193926 Content Loss: 0.017405

run [2300]:
Style Loss : 0.193344 Content Loss: 0.017507

run [2350]:
Style Loss : 0.192799 Content Loss: 0.017618

run [2400]:
Style Loss : 0.192300 Content Loss: 0.017726

run [2450]:
Style Loss : 0.192030 Content Loss: 0.017817

run [2500]:
Style Loss : 0.191195 Content Loss: 0.017850

